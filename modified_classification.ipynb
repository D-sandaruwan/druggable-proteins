{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import optuna\n",
    "import ast\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, recall_score, precision_score, f1_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "data_dir = '/home/darshana/Projects/druggable_proteins/processed_dataset'\n",
    "feature_engineered_data_dir = '/home/darshana/Projects/druggable_proteins/feature_engineered_dataset'\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "\n",
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test, results_dataframe, feature_type):\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    accuracy = scores.mean()\n",
    "\n",
    "    # fit the model on the training set\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict the test set results\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # compute the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # calculate precision, recall (sensitivity), f1-score\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # calculate specificity\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "\n",
    "    # calculate MCC\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "    temp_df = pd.DataFrame({\n",
    "        'feature_type': feature_type, \n",
    "        'model': name, \n",
    "        'with_hypertuning': False,\n",
    "        'best_params': 'None',\n",
    "        'accuracy': accuracy, \n",
    "        'sensitivity': recall, \n",
    "        'specificity': specificity, \n",
    "        'precision': precision, \n",
    "        'f1': f1, \n",
    "        'mcc': mcc,\n",
    "        'index': f'{feature_type}_{name}_no_hypertuning'\n",
    "        }, index=['index'])\n",
    "    # results_dataframe is an empty dataframe to store results with the columns feature_type, model, with_hypertuning, accuracy, sensitivity, specificity, precision, f1, mcc\n",
    "    return pd.concat([results_dataframe, temp_df])\n",
    "\n",
    "\n",
    "def optimize_hyperparameters(name, model, objective, trials, results_dataframe, feature_type, X_train, y_train, X_test, y_test):\n",
    "    def optuna_objective(trial):\n",
    "        params = objective(trial)\n",
    "        model_instance = model(**params)\n",
    "        model_instance.fit(X_train, y_train)\n",
    "        y_pred = model_instance.predict(X_test)\n",
    "\n",
    "        # compute the confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        # calculate precision, recall (sensitivity), f1-score\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        # calculate specificity\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        specificity = tn / (tn+fp)\n",
    "\n",
    "        # calculate MCC\n",
    "        mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "        # Set user attributes\n",
    "        trial.set_user_attr(\"precision\", precision)\n",
    "        trial.set_user_attr(\"recall\", recall)\n",
    "        trial.set_user_attr(\"f1\", f1)\n",
    "        trial.set_user_attr(\"specificity\", specificity)\n",
    "        trial.set_user_attr(\"mcc\", mcc)\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(optuna_objective, n_trials=trials)\n",
    "\n",
    "    temp_df = pd.DataFrame({\n",
    "        'feature_type': feature_type, \n",
    "        'model': name, \n",
    "        'with_hypertuning': True,\n",
    "        'best_params': [str(study.best_trial.params)],\n",
    "        'accuracy': study.best_trial.value, \n",
    "        'sensitivity': study.best_trial.user_attrs['recall'], \n",
    "        'specificity': study.best_trial.user_attrs['specificity'], \n",
    "        'precision': study.best_trial.user_attrs['precision'], \n",
    "        'f1': study.best_trial.user_attrs['f1'], \n",
    "        'mcc': study.best_trial.user_attrs['mcc'],\n",
    "        'index': f'{feature_type}_{name}_with_hypertuning'\n",
    "        }, index=['index'])\n",
    "    results_dataframe = pd.concat([results_dataframe, temp_df])\n",
    "    return results_dataframe\n",
    "\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'SVC': SVC(),\n",
    "    'XGBClassifier': XGBClassifier(),\n",
    "    'LGBMClassifier': LGBMClassifier()\n",
    "}\n",
    "\n",
    "models_ = {\n",
    "    'LogisticRegression': LogisticRegression,\n",
    "    'SVC': SVC,\n",
    "    'XGBClassifier': XGBClassifier,\n",
    "    'LGBMClassifier': LGBMClassifier\n",
    "}\n",
    "\n",
    "# Define objectives for hyperparameters tuning\n",
    "objectives = {\n",
    "    'LogisticRegression': lambda trial: {\n",
    "        'C': trial.suggest_float('C', 1e-2, 1e-1),\n",
    "        'penalty': trial.suggest_categorical('penalty', ['l1', 'l2']),\n",
    "        'solver': trial.suggest_categorical('solver', ['liblinear', 'saga']),\n",
    "        'max_iter': trial.suggest_int('max_iter', 100, 1000)\n",
    "    },\n",
    "    'SVC': lambda trial: {\n",
    "        'C': trial.suggest_float('svc_c', 1e-2, 1e2),\n",
    "        'gamma': trial.suggest_float('svc_gamma', 1e-2, 1e2),\n",
    "    },\n",
    "    'XGBClassifier': lambda trial: {\n",
    "        'learning_rate': trial.suggest_float(\"learning_rate\", 1e-2, 0.3),\n",
    "        'max_depth': trial.suggest_int(\"max_depth\", 2, 6),\n",
    "        'n_estimators': trial.suggest_int(\"n_estimators\", 100, 1000)\n",
    "    },\n",
    "    'LGBMClassifier': lambda trial: {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 50),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 2000)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating AAC LogisticRegression\n",
      "      feature_type               model with_hypertuning best_params  accuracy   \n",
      "index          AAC  LogisticRegression            False        None  0.875077  \\\n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "\n",
      "                                       index  \n",
      "index  AAC_LogisticRegression_no_hypertuning  \n",
      "Evaluating AAC SVC\n",
      "      feature_type               model with_hypertuning best_params  accuracy   \n",
      "index          AAC  LogisticRegression            False        None  0.875077  \\\n",
      "index          AAC                 SVC            False        None  0.897209   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "\n",
      "                                       index  \n",
      "index  AAC_LogisticRegression_no_hypertuning  \n",
      "index                 AAC_SVC_no_hypertuning  \n",
      "Evaluating AAC XGBClassifier\n",
      "      feature_type               model with_hypertuning best_params  accuracy   \n",
      "index          AAC  LogisticRegression            False        None  0.875077  \\\n",
      "index          AAC                 SVC            False        None  0.897209   \n",
      "index          AAC       XGBClassifier            False        None  0.890297   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "\n",
      "                                       index  \n",
      "index  AAC_LogisticRegression_no_hypertuning  \n",
      "index                 AAC_SVC_no_hypertuning  \n",
      "index       AAC_XGBClassifier_no_hypertuning  \n",
      "Evaluating AAC LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 10:09:55,554]\u001b[0m A new study created in memory with name: no-name-daae56c1-c117-41a1-9c4a-b5bbc95a14d6\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:55,580]\u001b[0m Trial 0 finished with value: 0.8428290766208252 and parameters: {'C': 0.024676775179329563, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 782}. Best is trial 0 with value: 0.8428290766208252.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:55,600]\u001b[0m Trial 1 finished with value: 0.8565815324165029 and parameters: {'C': 0.09094766750588791, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 431}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:55,620]\u001b[0m Trial 2 finished with value: 0.8546168958742633 and parameters: {'C': 0.06823992043723134, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 310}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:55,639]\u001b[0m Trial 3 finished with value: 0.8526522593320236 and parameters: {'C': 0.041434628004611083, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 950}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:55,658]\u001b[0m Trial 4 finished with value: 0.8546168958742633 and parameters: {'C': 0.06454637269349447, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 612}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:55,687]\u001b[0m Trial 5 finished with value: 0.8546168958742633 and parameters: {'C': 0.0165051744186388, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 433}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:55,724]\u001b[0m Trial 6 finished with value: 0.8428290766208252 and parameters: {'C': 0.01896757752128336, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 827}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:55,738]\u001b[0m Trial 7 finished with value: 0.8428290766208252 and parameters: {'C': 0.012443230958074383, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 929}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning best_params  accuracy   \n",
      "index          AAC  LogisticRegression            False        None  0.875077  \\\n",
      "index          AAC                 SVC            False        None  0.897209   \n",
      "index          AAC       XGBClassifier            False        None  0.890297   \n",
      "index          AAC      LGBMClassifier            False        None  0.883399   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "\n",
      "                                       index  \n",
      "index  AAC_LogisticRegression_no_hypertuning  \n",
      "index                 AAC_SVC_no_hypertuning  \n",
      "index       AAC_XGBClassifier_no_hypertuning  \n",
      "index      AAC_LGBMClassifier_no_hypertuning  \n",
      "Optimizing AAC LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 10:09:55,778]\u001b[0m Trial 8 finished with value: 0.8546168958742633 and parameters: {'C': 0.09673575707935296, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 178}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:55,820]\u001b[0m Trial 9 finished with value: 0.8506876227897839 and parameters: {'C': 0.03917073268527012, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 153}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:55,863]\u001b[0m Trial 10 finished with value: 0.8526522593320236 and parameters: {'C': 0.09505930844922625, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 560}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:55,908]\u001b[0m Trial 11 finished with value: 0.8546168958742633 and parameters: {'C': 0.07594439674443194, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 354}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:55,950]\u001b[0m Trial 12 finished with value: 0.8526522593320236 and parameters: {'C': 0.07954464093850114, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 335}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:55,991]\u001b[0m Trial 13 finished with value: 0.8526522593320236 and parameters: {'C': 0.08052482269215473, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 290}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,025]\u001b[0m Trial 14 finished with value: 0.8565815324165029 and parameters: {'C': 0.06064515329512011, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 465}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,052]\u001b[0m Trial 15 finished with value: 0.8526522593320236 and parameters: {'C': 0.05399314553152628, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 461}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,085]\u001b[0m Trial 16 finished with value: 0.8526522593320236 and parameters: {'C': 0.08853088450730275, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 654}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,114]\u001b[0m Trial 17 finished with value: 0.8565815324165029 and parameters: {'C': 0.058804127218188035, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 452}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,183]\u001b[0m Trial 18 finished with value: 0.8526522593320236 and parameters: {'C': 0.09087915982624399, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 679}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,210]\u001b[0m Trial 19 finished with value: 0.8526522593320236 and parameters: {'C': 0.09910414355792471, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 512}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,236]\u001b[0m Trial 20 finished with value: 0.8526522593320236 and parameters: {'C': 0.0840118642185803, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 232}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,264]\u001b[0m Trial 21 finished with value: 0.8565815324165029 and parameters: {'C': 0.05961759778121656, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 442}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,298]\u001b[0m Trial 22 finished with value: 0.8546168958742633 and parameters: {'C': 0.07493150675314653, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 415}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,325]\u001b[0m Trial 23 finished with value: 0.8546168958742633 and parameters: {'C': 0.06953613752842583, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 539}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,355]\u001b[0m Trial 24 finished with value: 0.8546168958742633 and parameters: {'C': 0.05686791528081941, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 497}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,388]\u001b[0m Trial 25 finished with value: 0.8526522593320236 and parameters: {'C': 0.08713829966922917, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 392}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,418]\u001b[0m Trial 26 finished with value: 0.8506876227897839 and parameters: {'C': 0.04995158108383553, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 233}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,477]\u001b[0m Trial 27 finished with value: 0.8506876227897839 and parameters: {'C': 0.07117171590575828, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 574}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,504]\u001b[0m Trial 28 finished with value: 0.8546168958742633 and parameters: {'C': 0.06564669667485659, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 734}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,534]\u001b[0m Trial 29 finished with value: 0.8546168958742633 and parameters: {'C': 0.06084530139379035, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 376}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,567]\u001b[0m Trial 30 finished with value: 0.8506876227897839 and parameters: {'C': 0.048708715813795954, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 261}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,596]\u001b[0m Trial 31 finished with value: 0.8546168958742633 and parameters: {'C': 0.07415399954247207, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 472}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,626]\u001b[0m Trial 32 finished with value: 0.8565815324165029 and parameters: {'C': 0.05921073684819012, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 436}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,655]\u001b[0m Trial 33 finished with value: 0.8565815324165029 and parameters: {'C': 0.06162282033769961, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 318}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,684]\u001b[0m Trial 34 finished with value: 0.8546168958742633 and parameters: {'C': 0.06630246495997337, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 615}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,719]\u001b[0m Trial 35 finished with value: 0.8526522593320236 and parameters: {'C': 0.04006809769803024, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 107}. Best is trial 1 with value: 0.8565815324165029.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,747]\u001b[0m Trial 36 finished with value: 0.8585461689587426 and parameters: {'C': 0.03277840391147581, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 501}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,797]\u001b[0m Trial 37 finished with value: 0.8487229862475442 and parameters: {'C': 0.030812845508021703, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 597}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,833]\u001b[0m Trial 38 finished with value: 0.8506876227897839 and parameters: {'C': 0.0317392156129256, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 522}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,876]\u001b[0m Trial 39 finished with value: 0.8546168958742633 and parameters: {'C': 0.04573371259625192, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 790}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,927]\u001b[0m Trial 40 finished with value: 0.8467583497053045 and parameters: {'C': 0.051257865413331924, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 877}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,958]\u001b[0m Trial 41 finished with value: 0.8565815324165029 and parameters: {'C': 0.06449433674556325, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 470}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:56,991]\u001b[0m Trial 42 finished with value: 0.8526522593320236 and parameters: {'C': 0.053901556868760594, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 414}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,017]\u001b[0m Trial 43 finished with value: 0.8546168958742633 and parameters: {'C': 0.0567332767581438, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 362}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,045]\u001b[0m Trial 44 finished with value: 0.8546168958742633 and parameters: {'C': 0.043010312810731866, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 491}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,075]\u001b[0m Trial 45 finished with value: 0.8546168958742633 and parameters: {'C': 0.07063125381119288, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 434}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,104]\u001b[0m Trial 46 finished with value: 0.8546168958742633 and parameters: {'C': 0.06074756672205656, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 641}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,144]\u001b[0m Trial 47 finished with value: 0.8546168958742633 and parameters: {'C': 0.018952374944588346, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 557}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,173]\u001b[0m Trial 48 finished with value: 0.8546168958742633 and parameters: {'C': 0.07963637737769101, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 311}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,202]\u001b[0m Trial 49 finished with value: 0.8565815324165029 and parameters: {'C': 0.09284871452379914, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 699}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,229]\u001b[0m Trial 50 finished with value: 0.8526522593320236 and parameters: {'C': 0.05325280985218227, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 449}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,258]\u001b[0m Trial 51 finished with value: 0.8565815324165029 and parameters: {'C': 0.0581550954169631, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 397}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,290]\u001b[0m Trial 52 finished with value: 0.8565815324165029 and parameters: {'C': 0.06326984818705815, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 440}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,319]\u001b[0m Trial 53 finished with value: 0.8546168958742633 and parameters: {'C': 0.06675471217714399, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 524}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,350]\u001b[0m Trial 54 finished with value: 0.8565815324165029 and parameters: {'C': 0.05935258466370489, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 344}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,380]\u001b[0m Trial 55 finished with value: 0.8526522593320236 and parameters: {'C': 0.05586744865595269, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 482}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,409]\u001b[0m Trial 56 finished with value: 0.8526522593320236 and parameters: {'C': 0.04748917456311436, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 410}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,438]\u001b[0m Trial 57 finished with value: 0.8506876227897839 and parameters: {'C': 0.051120057367268774, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 590}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,486]\u001b[0m Trial 58 finished with value: 0.8487229862475442 and parameters: {'C': 0.04470499804093378, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 280}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,516]\u001b[0m Trial 59 finished with value: 0.8565815324165029 and parameters: {'C': 0.06277860219236117, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 552}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,552]\u001b[0m Trial 60 finished with value: 0.8546168958742633 and parameters: {'C': 0.07198931581804484, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 388}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,579]\u001b[0m Trial 61 finished with value: 0.8565815324165029 and parameters: {'C': 0.06055982914472638, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 349}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,612]\u001b[0m Trial 62 finished with value: 0.8546168958742633 and parameters: {'C': 0.05768696043262574, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 452}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,639]\u001b[0m Trial 63 finished with value: 0.8546168958742633 and parameters: {'C': 0.06823741698907634, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 319}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,669]\u001b[0m Trial 64 finished with value: 0.8506876227897839 and parameters: {'C': 0.05449259972192642, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 503}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,704]\u001b[0m Trial 65 finished with value: 0.8546168958742633 and parameters: {'C': 0.07690870847434698, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 197}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,732]\u001b[0m Trial 66 finished with value: 0.8526522593320236 and parameters: {'C': 0.08313121640966832, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 372}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,763]\u001b[0m Trial 67 finished with value: 0.8546168958742633 and parameters: {'C': 0.06324393928839961, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 421}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,817]\u001b[0m Trial 68 finished with value: 0.8487229862475442 and parameters: {'C': 0.06863620584502622, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 533}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,844]\u001b[0m Trial 69 finished with value: 0.8506876227897839 and parameters: {'C': 0.05206107741431574, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 284}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,876]\u001b[0m Trial 70 finished with value: 0.8526522593320236 and parameters: {'C': 0.07333448884459687, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 244}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,905]\u001b[0m Trial 71 finished with value: 0.8546168958742633 and parameters: {'C': 0.06658448439516414, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 467}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,933]\u001b[0m Trial 72 finished with value: 0.8506876227897839 and parameters: {'C': 0.055714275371821304, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 478}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,965]\u001b[0m Trial 73 finished with value: 0.8565815324165029 and parameters: {'C': 0.0644208700785204, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 990}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:57,996]\u001b[0m Trial 74 finished with value: 0.8565815324165029 and parameters: {'C': 0.05950437425037289, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 508}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:58,025]\u001b[0m Trial 75 finished with value: 0.8565815324165029 and parameters: {'C': 0.06147151973759402, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 432}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:58,059]\u001b[0m Trial 76 finished with value: 0.8565815324165029 and parameters: {'C': 0.05823911323581872, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 328}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:58,092]\u001b[0m Trial 77 finished with value: 0.8506876227897839 and parameters: {'C': 0.04850148394352514, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 581}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:58,124]\u001b[0m Trial 78 finished with value: 0.8546168958742633 and parameters: {'C': 0.06472411501895836, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 460}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:58,178]\u001b[0m Trial 79 finished with value: 0.8506876227897839 and parameters: {'C': 0.07053720372557297, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 379}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:58,205]\u001b[0m Trial 80 finished with value: 0.8526522593320236 and parameters: {'C': 0.05396114101903285, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 617}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:58,234]\u001b[0m Trial 81 finished with value: 0.8565815324165029 and parameters: {'C': 0.09065787625774244, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 493}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:58,265]\u001b[0m Trial 82 finished with value: 0.8565815324165029 and parameters: {'C': 0.09780215041504237, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 402}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:58,295]\u001b[0m Trial 83 finished with value: 0.8565815324165029 and parameters: {'C': 0.09308266102149222, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 689}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:58,326]\u001b[0m Trial 84 finished with value: 0.8565815324165029 and parameters: {'C': 0.08653512767175975, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 748}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:58,358]\u001b[0m Trial 85 finished with value: 0.8526522593320236 and parameters: {'C': 0.0503844118608424, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 539}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:58,391]\u001b[0m Trial 86 finished with value: 0.8546168958742633 and parameters: {'C': 0.061667950907875656, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 435}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:58,421]\u001b[0m Trial 87 finished with value: 0.8526522593320236 and parameters: {'C': 0.09956862520956795, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 520}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:58,463]\u001b[0m Trial 88 finished with value: 0.8526522593320236 and parameters: {'C': 0.09489049772755419, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 876}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:58,491]\u001b[0m Trial 89 finished with value: 0.8506876227897839 and parameters: {'C': 0.05600940338951954, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 564}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:58,526]\u001b[0m Trial 90 finished with value: 0.8546168958742633 and parameters: {'C': 0.06496391034705404, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 470}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:58,560]\u001b[0m Trial 91 finished with value: 0.8546168958742633 and parameters: {'C': 0.05790325846147572, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 411}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:58,593]\u001b[0m Trial 92 finished with value: 0.8565815324165029 and parameters: {'C': 0.0579853041021142, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 399}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:58,624]\u001b[0m Trial 93 finished with value: 0.8565815324165029 and parameters: {'C': 0.05950685879482127, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 363}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:58,657]\u001b[0m Trial 94 finished with value: 0.8506876227897839 and parameters: {'C': 0.05286629296642862, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 455}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:58,687]\u001b[0m Trial 95 finished with value: 0.8565815324165029 and parameters: {'C': 0.06161439119602601, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 487}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:58,723]\u001b[0m Trial 96 finished with value: 0.8546168958742633 and parameters: {'C': 0.06836067568532783, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 423}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:58,780]\u001b[0m Trial 97 finished with value: 0.8487229862475442 and parameters: {'C': 0.05462499926461633, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 296}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:58,814]\u001b[0m Trial 98 finished with value: 0.8565815324165029 and parameters: {'C': 0.0637824895135943, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 333}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:58,846]\u001b[0m Trial 99 finished with value: 0.8546168958742633 and parameters: {'C': 0.07694353506482636, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 389}. Best is trial 36 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:58,856]\u001b[0m A new study created in memory with name: no-name-80a005f7-1d19-4612-9b07-14201ff033ff\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "\n",
      "                                         index  \n",
      "index    AAC_LogisticRegression_no_hypertuning  \n",
      "index                   AAC_SVC_no_hypertuning  \n",
      "index         AAC_XGBClassifier_no_hypertuning  \n",
      "index        AAC_LGBMClassifier_no_hypertuning  \n",
      "index  AAC_LogisticRegression_with_hypertuning  \n",
      "Optimizing AAC SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 10:09:59,265]\u001b[0m Trial 0 finished with value: 0.5245579567779961 and parameters: {'svc_c': 97.98665538074123, 'svc_gamma': 50.5335805860252}. Best is trial 0 with value: 0.5245579567779961.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:09:59,625]\u001b[0m Trial 1 finished with value: 0.5245579567779961 and parameters: {'svc_c': 5.984359298284984, 'svc_gamma': 58.66433751509819}. Best is trial 0 with value: 0.5245579567779961.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:00,004]\u001b[0m Trial 2 finished with value: 0.5265225933202358 and parameters: {'svc_c': 42.17120071873789, 'svc_gamma': 16.75794800201258}. Best is trial 2 with value: 0.5265225933202358.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:00,370]\u001b[0m Trial 3 finished with value: 0.5225933202357563 and parameters: {'svc_c': 4.42946854773202, 'svc_gamma': 66.13533538870537}. Best is trial 2 with value: 0.5265225933202358.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:00,729]\u001b[0m Trial 4 finished with value: 0.5265225933202358 and parameters: {'svc_c': 11.81896991339862, 'svc_gamma': 12.648663825866512}. Best is trial 2 with value: 0.5265225933202358.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:01,062]\u001b[0m Trial 5 finished with value: 0.5225933202357563 and parameters: {'svc_c': 29.997764949982702, 'svc_gamma': 99.77008852280659}. Best is trial 2 with value: 0.5265225933202358.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:01,431]\u001b[0m Trial 6 finished with value: 0.5245579567779961 and parameters: {'svc_c': 20.493726657669185, 'svc_gamma': 39.82051088856539}. Best is trial 2 with value: 0.5265225933202358.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:01,778]\u001b[0m Trial 7 finished with value: 0.5225933202357563 and parameters: {'svc_c': 69.62237870436607, 'svc_gamma': 64.54145177505984}. Best is trial 2 with value: 0.5265225933202358.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:02,125]\u001b[0m Trial 8 finished with value: 0.5225933202357563 and parameters: {'svc_c': 66.23996236243114, 'svc_gamma': 62.744966178368394}. Best is trial 2 with value: 0.5265225933202358.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:02,479]\u001b[0m Trial 9 finished with value: 0.5225933202357563 and parameters: {'svc_c': 46.39917253710204, 'svc_gamma': 80.49641564480251}. Best is trial 2 with value: 0.5265225933202358.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:02,765]\u001b[0m Trial 10 finished with value: 0.6679764243614931 and parameters: {'svc_c': 37.95767648911047, 'svc_gamma': 1.1464578420840539}. Best is trial 10 with value: 0.6679764243614931.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:03,037]\u001b[0m Trial 11 finished with value: 0.6011787819253438 and parameters: {'svc_c': 37.14892633488683, 'svc_gamma': 1.6471483647183263}. Best is trial 10 with value: 0.6679764243614931.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:03,420]\u001b[0m Trial 12 finished with value: 0.5265225933202358 and parameters: {'svc_c': 31.517343925191653, 'svc_gamma': 9.080039734335916}. Best is trial 10 with value: 0.6679764243614931.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:03,718]\u001b[0m Trial 13 finished with value: 0.7092337917485265 and parameters: {'svc_c': 30.04988063846598, 'svc_gamma': 0.949580885185401}. Best is trial 13 with value: 0.7092337917485265.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:04,168]\u001b[0m Trial 14 finished with value: 0.5245579567779961 and parameters: {'svc_c': 21.49734477038976, 'svc_gamma': 25.73975682071043}. Best is trial 13 with value: 0.7092337917485265.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:04,461]\u001b[0m Trial 15 finished with value: 0.5599214145383105 and parameters: {'svc_c': 54.51443656483466, 'svc_gamma': 2.304162833642029}. Best is trial 13 with value: 0.7092337917485265.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:04,870]\u001b[0m Trial 16 finished with value: 0.5245579567779961 and parameters: {'svc_c': 22.00902444450389, 'svc_gamma': 24.97002047143388}. Best is trial 13 with value: 0.7092337917485265.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:05,033]\u001b[0m Trial 17 finished with value: 0.8703339882121808 and parameters: {'svc_c': 51.76797681729799, 'svc_gamma': 0.0381317238646659}. Best is trial 17 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:05,471]\u001b[0m Trial 18 finished with value: 0.5245579567779961 and parameters: {'svc_c': 55.054078602795386, 'svc_gamma': 32.83440473716646}. Best is trial 17 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:05,878]\u001b[0m Trial 19 finished with value: 0.5245579567779961 and parameters: {'svc_c': 49.028048673146074, 'svc_gamma': 17.85035464347875}. Best is trial 17 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:06,307]\u001b[0m Trial 20 finished with value: 0.5245579567779961 and parameters: {'svc_c': 61.95045796276358, 'svc_gamma': 36.69105444653324}. Best is trial 17 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:06,601]\u001b[0m Trial 21 finished with value: 0.6011787819253438 and parameters: {'svc_c': 38.27544858167195, 'svc_gamma': 1.6388260727220705}. Best is trial 17 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:06,943]\u001b[0m Trial 22 finished with value: 0.5265225933202358 and parameters: {'svc_c': 29.791023041384825, 'svc_gamma': 10.653709454585556}. Best is trial 17 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:07,227]\u001b[0m Trial 23 finished with value: 0.5638506876227898 and parameters: {'svc_c': 45.85050777171725, 'svc_gamma': 2.1688974196342192}. Best is trial 17 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:07,608]\u001b[0m Trial 24 finished with value: 0.5245579567779961 and parameters: {'svc_c': 38.71536166223397, 'svc_gamma': 18.761871715712847}. Best is trial 17 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:07,932]\u001b[0m Trial 25 finished with value: 0.5265225933202358 and parameters: {'svc_c': 15.711244978349402, 'svc_gamma': 7.974264894722558}. Best is trial 17 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:08,204]\u001b[0m Trial 26 finished with value: 0.7721021611001965 and parameters: {'svc_c': 0.011880435758435226, 'svc_gamma': 0.1144444234171148}. Best is trial 17 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:08,645]\u001b[0m Trial 27 finished with value: 0.5245579567779961 and parameters: {'svc_c': 2.2273282164299175, 'svc_gamma': 24.25044738437352}. Best is trial 17 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:09,022]\u001b[0m Trial 28 finished with value: 0.5265225933202358 and parameters: {'svc_c': 2.5931620243814706, 'svc_gamma': 10.483756028144246}. Best is trial 17 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:09,410]\u001b[0m Trial 29 finished with value: 0.5245579567779961 and parameters: {'svc_c': 10.192333827364905, 'svc_gamma': 17.332150599414412}. Best is trial 17 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:09,729]\u001b[0m Trial 30 finished with value: 0.5284872298624754 and parameters: {'svc_c': 78.85390433783613, 'svc_gamma': 6.700498263613083}. Best is trial 17 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:10,024]\u001b[0m Trial 31 finished with value: 0.5677799607072691 and parameters: {'svc_c': 28.864704550244955, 'svc_gamma': 2.027843436844738}. Best is trial 17 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:10,330]\u001b[0m Trial 32 finished with value: 0.5265225933202358 and parameters: {'svc_c': 14.54457772026577, 'svc_gamma': 7.274763916770532}. Best is trial 17 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:10:10,675]\u001b[0m Trial 33 finished with value: 0.518664047151277 and parameters: {'svc_c': 0.09469693513583621, 'svc_gamma': 14.325311181713227}. Best is trial 17 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:10,852]\u001b[0m Trial 34 finished with value: 0.8781925343811395 and parameters: {'svc_c': 9.136416688181043, 'svc_gamma': 0.12119957329766366}. Best is trial 34 with value: 0.8781925343811395.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:11,097]\u001b[0m Trial 35 finished with value: 0.8703339882121808 and parameters: {'svc_c': 7.776965770873858, 'svc_gamma': 0.14906999426842293}. Best is trial 34 with value: 0.8781925343811395.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:11,459]\u001b[0m Trial 36 finished with value: 0.5265225933202358 and parameters: {'svc_c': 7.965902074150841, 'svc_gamma': 12.498893327039506}. Best is trial 34 with value: 0.8781925343811395.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:11,786]\u001b[0m Trial 37 finished with value: 0.5265225933202358 and parameters: {'svc_c': 7.455786978227063, 'svc_gamma': 7.596542951054867}. Best is trial 34 with value: 0.8781925343811395.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:12,185]\u001b[0m Trial 38 finished with value: 0.5265225933202358 and parameters: {'svc_c': 6.34032136580301, 'svc_gamma': 15.122688647746278}. Best is trial 34 with value: 0.8781925343811395.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:12,604]\u001b[0m Trial 39 finished with value: 0.5245579567779961 and parameters: {'svc_c': 16.19886211773104, 'svc_gamma': 22.218089769748612}. Best is trial 34 with value: 0.8781925343811395.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:12,964]\u001b[0m Trial 40 finished with value: 0.5245579567779961 and parameters: {'svc_c': 10.771074590520993, 'svc_gamma': 49.5299935121389}. Best is trial 34 with value: 0.8781925343811395.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:13,289]\u001b[0m Trial 41 finished with value: 0.5284872298624754 and parameters: {'svc_c': 13.134947813366885, 'svc_gamma': 5.212946126313743}. Best is trial 34 with value: 0.8781925343811395.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:13,596]\u001b[0m Trial 42 finished with value: 0.5245579567779961 and parameters: {'svc_c': 0.7365261364524647, 'svc_gamma': 5.415446767544536}. Best is trial 34 with value: 0.8781925343811395.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:13,771]\u001b[0m Trial 43 finished with value: 0.8801571709233792 and parameters: {'svc_c': 7.144069526662534, 'svc_gamma': 0.10888614616827345}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:14,128]\u001b[0m Trial 44 finished with value: 0.5265225933202358 and parameters: {'svc_c': 4.881515518489346, 'svc_gamma': 11.953338091743037}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:14,511]\u001b[0m Trial 45 finished with value: 0.5284872298624754 and parameters: {'svc_c': 19.842564862679648, 'svc_gamma': 5.592738368389871}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:14,823]\u001b[0m Trial 46 finished with value: 0.831041257367387 and parameters: {'svc_c': 6.4066179253590505, 'svc_gamma': 0.3710320437180779}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:15,178]\u001b[0m Trial 47 finished with value: 0.5265225933202358 and parameters: {'svc_c': 9.299280477909955, 'svc_gamma': 12.655921170316342}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:15,520]\u001b[0m Trial 48 finished with value: 0.5265225933202358 and parameters: {'svc_c': 6.181359351283673, 'svc_gamma': 9.373919307473646}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:15,915]\u001b[0m Trial 49 finished with value: 0.5245579567779961 and parameters: {'svc_c': 18.767421074530965, 'svc_gamma': 20.74883065114274}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:16,306]\u001b[0m Trial 50 finished with value: 0.5265225933202358 and parameters: {'svc_c': 13.267517593419516, 'svc_gamma': 15.105543421508589}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:16,624]\u001b[0m Trial 51 finished with value: 0.5324165029469549 and parameters: {'svc_c': 4.366109404148386, 'svc_gamma': 4.132190216058534}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:16,903]\u001b[0m Trial 52 finished with value: 0.8172888015717092 and parameters: {'svc_c': 9.75530268025257, 'svc_gamma': 0.4142078574453222}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:17,206]\u001b[0m Trial 53 finished with value: 0.730844793713163 and parameters: {'svc_c': 22.829981283683992, 'svc_gamma': 0.8769493890907849}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:17,520]\u001b[0m Trial 54 finished with value: 0.8113948919449901 and parameters: {'svc_c': 24.939198609952864, 'svc_gamma': 0.43393708648584095}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:17,869]\u001b[0m Trial 55 finished with value: 0.5284872298624754 and parameters: {'svc_c': 10.211353118455843, 'svc_gamma': 5.07304541147796}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:18,237]\u001b[0m Trial 56 finished with value: 0.5265225933202358 and parameters: {'svc_c': 17.19497970988116, 'svc_gamma': 10.129117684030307}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:18,587]\u001b[0m Trial 57 finished with value: 0.5324165029469549 and parameters: {'svc_c': 13.807949573066537, 'svc_gamma': 4.452722985722238}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:18,901]\u001b[0m Trial 58 finished with value: 0.8349705304518664 and parameters: {'svc_c': 4.871546841870192, 'svc_gamma': 0.3472506057262875}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:19,244]\u001b[0m Trial 59 finished with value: 0.5265225933202358 and parameters: {'svc_c': 4.627610783842961, 'svc_gamma': 8.786997221998174}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:19,693]\u001b[0m Trial 60 finished with value: 0.5245579567779961 and parameters: {'svc_c': 12.76288634929256, 'svc_gamma': 27.992840221952772}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:19,878]\u001b[0m Trial 61 finished with value: 0.8703339882121808 and parameters: {'svc_c': 9.439844426642125, 'svc_gamma': 0.1306715265849656}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:20,190]\u001b[0m Trial 62 finished with value: 0.5383104125736738 and parameters: {'svc_c': 6.245843697004261, 'svc_gamma': 3.5024972310274203}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:20,506]\u001b[0m Trial 63 finished with value: 0.5284872298624754 and parameters: {'svc_c': 17.059373611479863, 'svc_gamma': 7.195976287348609}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:20,860]\u001b[0m Trial 64 finished with value: 0.5265225933202358 and parameters: {'svc_c': 3.1221329915569767, 'svc_gamma': 11.687488101804313}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:21,179]\u001b[0m Trial 65 finished with value: 0.5363457760314342 and parameters: {'svc_c': 8.414236373463567, 'svc_gamma': 3.574766644885143}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:21,604]\u001b[0m Trial 66 finished with value: 0.5245579567779961 and parameters: {'svc_c': 11.806240872529994, 'svc_gamma': 17.698758409568356}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:21,943]\u001b[0m Trial 67 finished with value: 0.5265225933202358 and parameters: {'svc_c': 25.361808525114732, 'svc_gamma': 8.661428042327165}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:22,255]\u001b[0m Trial 68 finished with value: 0.768172888015717 and parameters: {'svc_c': 3.36060223847576, 'svc_gamma': 0.684964860355269}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:22,580]\u001b[0m Trial 69 finished with value: 0.5383104125736738 and parameters: {'svc_c': 20.285152106570756, 'svc_gamma': 3.3056894914979114}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:22,953]\u001b[0m Trial 70 finished with value: 0.5265225933202358 and parameters: {'svc_c': 14.61251613527001, 'svc_gamma': 14.208245042426643}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:23,220]\u001b[0m Trial 71 finished with value: 0.8585461689587426 and parameters: {'svc_c': 7.79674102359467, 'svc_gamma': 0.20326514148973365}. Best is trial 43 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:23,340]\u001b[0m Trial 72 finished with value: 0.8821218074656189 and parameters: {'svc_c': 7.554678737818476, 'svc_gamma': 0.020179576154941203}. Best is trial 72 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:23,652]\u001b[0m Trial 73 finished with value: 0.5284872298624754 and parameters: {'svc_c': 1.8026843974800437, 'svc_gamma': 6.4390510311651745}. Best is trial 72 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:23,977]\u001b[0m Trial 74 finished with value: 0.5442043222003929 and parameters: {'svc_c': 8.597681512991079, 'svc_gamma': 2.99584209722385}. Best is trial 72 with value: 0.8821218074656189.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:10:24,263]\u001b[0m Trial 75 finished with value: 0.518664047151277 and parameters: {'svc_c': 0.11983872520698569, 'svc_gamma': 9.707554605590685}. Best is trial 72 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:24,651]\u001b[0m Trial 76 finished with value: 0.5284872298624754 and parameters: {'svc_c': 17.027258689306407, 'svc_gamma': 6.164062877813319}. Best is trial 72 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:24,973]\u001b[0m Trial 77 finished with value: 0.5383104125736738 and parameters: {'svc_c': 10.463828038524916, 'svc_gamma': 3.439138564722251}. Best is trial 72 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:25,289]\u001b[0m Trial 78 finished with value: 0.5265225933202358 and parameters: {'svc_c': 3.300779126982399, 'svc_gamma': 7.740078198479127}. Best is trial 72 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:25,515]\u001b[0m Trial 79 finished with value: 0.8664047151277013 and parameters: {'svc_c': 11.589278585575713, 'svc_gamma': 0.15506702250201218}. Best is trial 72 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:25,889]\u001b[0m Trial 80 finished with value: 0.5265225933202358 and parameters: {'svc_c': 12.851453981717171, 'svc_gamma': 12.430194942574143}. Best is trial 72 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:26,212]\u001b[0m Trial 81 finished with value: 0.5402750491159135 and parameters: {'svc_c': 6.859519077167937, 'svc_gamma': 3.1894422714064}. Best is trial 72 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:26,384]\u001b[0m Trial 82 finished with value: 0.8742632612966601 and parameters: {'svc_c': 8.191095213055135, 'svc_gamma': 0.10618531085005037}. Best is trial 72 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:26,691]\u001b[0m Trial 83 finished with value: 0.5284872298624754 and parameters: {'svc_c': 10.906297671274231, 'svc_gamma': 6.1202787239776}. Best is trial 72 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:26,979]\u001b[0m Trial 84 finished with value: 0.5461689587426326 and parameters: {'svc_c': 15.618933430863853, 'svc_gamma': 2.735334627074229}. Best is trial 72 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:27,089]\u001b[0m Trial 85 finished with value: 0.8781925343811395 and parameters: {'svc_c': 7.835470869919152, 'svc_gamma': 0.01180030213010061}. Best is trial 72 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:27,435]\u001b[0m Trial 86 finished with value: 0.5265225933202358 and parameters: {'svc_c': 11.325405818606965, 'svc_gamma': 10.50563780661755}. Best is trial 72 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:27,755]\u001b[0m Trial 87 finished with value: 0.5284872298624754 and parameters: {'svc_c': 18.16556237385652, 'svc_gamma': 5.5360729117562}. Best is trial 72 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:28,056]\u001b[0m Trial 88 finished with value: 0.5442043222003929 and parameters: {'svc_c': 2.265801734054137, 'svc_gamma': 2.7846281955943692}. Best is trial 72 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:28,390]\u001b[0m Trial 89 finished with value: 0.5265225933202358 and parameters: {'svc_c': 15.364307513670036, 'svc_gamma': 8.05829755130916}. Best is trial 72 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:28,700]\u001b[0m Trial 90 finished with value: 0.5284872298624754 and parameters: {'svc_c': 7.886605762998091, 'svc_gamma': 5.631560896579142}. Best is trial 72 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:28,996]\u001b[0m Trial 91 finished with value: 0.7976424361493124 and parameters: {'svc_c': 8.951982842069269, 'svc_gamma': 0.47165119984680637}. Best is trial 72 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:29,275]\u001b[0m Trial 92 finished with value: 0.768172888015717 and parameters: {'svc_c': 5.570243284905982, 'svc_gamma': 0.690804709060737}. Best is trial 72 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:29,437]\u001b[0m Trial 93 finished with value: 0.8762278978388998 and parameters: {'svc_c': 7.890820840271459, 'svc_gamma': 0.1032482591269712}. Best is trial 72 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:29,754]\u001b[0m Trial 94 finished with value: 0.5324165029469549 and parameters: {'svc_c': 12.893659891057293, 'svc_gamma': 4.338420359232477}. Best is trial 72 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:30,044]\u001b[0m Trial 95 finished with value: 0.5461689587426326 and parameters: {'svc_c': 4.499614587821238, 'svc_gamma': 2.630378380010116}. Best is trial 72 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:30,373]\u001b[0m Trial 96 finished with value: 0.5265225933202358 and parameters: {'svc_c': 11.475834656248672, 'svc_gamma': 9.009145846685142}. Best is trial 72 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:30,528]\u001b[0m Trial 97 finished with value: 0.8821218074656189 and parameters: {'svc_c': 1.064571927575491, 'svc_gamma': 0.10145438249626351}. Best is trial 72 with value: 0.8821218074656189.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:10:30,828]\u001b[0m Trial 98 finished with value: 0.518664047151277 and parameters: {'svc_c': 0.3459937775040318, 'svc_gamma': 4.810106086011053}. Best is trial 72 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:31,139]\u001b[0m Trial 99 finished with value: 0.5284872298624754 and parameters: {'svc_c': 2.4982407110093297, 'svc_gamma': 6.991400557109794}. Best is trial 72 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:31,145]\u001b[0m A new study created in memory with name: no-name-2553e966-0cdb-4884-b8dd-1c341898d455\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "\n",
      "                                         index  \n",
      "index    AAC_LogisticRegression_no_hypertuning  \n",
      "index                   AAC_SVC_no_hypertuning  \n",
      "index         AAC_XGBClassifier_no_hypertuning  \n",
      "index        AAC_LGBMClassifier_no_hypertuning  \n",
      "index  AAC_LogisticRegression_with_hypertuning  \n",
      "index                 AAC_SVC_with_hypertuning  \n",
      "Optimizing AAC XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 10:10:32,059]\u001b[0m Trial 0 finished with value: 0.8683693516699411 and parameters: {'learning_rate': 0.07765118371411048, 'max_depth': 2, 'n_estimators': 936}. Best is trial 0 with value: 0.8683693516699411.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:32,506]\u001b[0m Trial 1 finished with value: 0.8722986247544204 and parameters: {'learning_rate': 0.2659848731751826, 'max_depth': 4, 'n_estimators': 232}. Best is trial 1 with value: 0.8722986247544204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:32,993]\u001b[0m Trial 2 finished with value: 0.8703339882121808 and parameters: {'learning_rate': 0.11903843826405786, 'max_depth': 6, 'n_estimators': 194}. Best is trial 1 with value: 0.8722986247544204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:34,794]\u001b[0m Trial 3 finished with value: 0.8762278978388998 and parameters: {'learning_rate': 0.14060499049435843, 'max_depth': 5, 'n_estimators': 996}. Best is trial 3 with value: 0.8762278978388998.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:35,484]\u001b[0m Trial 4 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.05254356165282262, 'max_depth': 5, 'n_estimators': 219}. Best is trial 4 with value: 0.8781925343811395.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:36,069]\u001b[0m Trial 5 finished with value: 0.8703339882121808 and parameters: {'learning_rate': 0.28718687068316834, 'max_depth': 3, 'n_estimators': 417}. Best is trial 4 with value: 0.8781925343811395.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:37,390]\u001b[0m Trial 6 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.03423916097639297, 'max_depth': 6, 'n_estimators': 468}. Best is trial 4 with value: 0.8781925343811395.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:38,166]\u001b[0m Trial 7 finished with value: 0.8742632612966601 and parameters: {'learning_rate': 0.059451951306997056, 'max_depth': 2, 'n_estimators': 655}. Best is trial 4 with value: 0.8781925343811395.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:38,683]\u001b[0m Trial 8 finished with value: 0.8585461689587426 and parameters: {'learning_rate': 0.28774952409207605, 'max_depth': 3, 'n_estimators': 370}. Best is trial 4 with value: 0.8781925343811395.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:39,957]\u001b[0m Trial 9 finished with value: 0.862475442043222 and parameters: {'learning_rate': 0.18245707251446697, 'max_depth': 3, 'n_estimators': 948}. Best is trial 4 with value: 0.8781925343811395.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:42,016]\u001b[0m Trial 10 finished with value: 0.8860510805500982 and parameters: {'learning_rate': 0.010999635564743593, 'max_depth': 5, 'n_estimators': 711}. Best is trial 10 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:44,008]\u001b[0m Trial 11 finished with value: 0.8899803536345776 and parameters: {'learning_rate': 0.015313093956924949, 'max_depth': 5, 'n_estimators': 695}. Best is trial 11 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:46,147]\u001b[0m Trial 12 finished with value: 0.8899803536345776 and parameters: {'learning_rate': 0.016665200116871583, 'max_depth': 5, 'n_estimators': 712}. Best is trial 11 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:47,718]\u001b[0m Trial 13 finished with value: 0.8840864440078585 and parameters: {'learning_rate': 0.024582178680339274, 'max_depth': 4, 'n_estimators': 726}. Best is trial 11 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:49,586]\u001b[0m Trial 14 finished with value: 0.8742632612966601 and parameters: {'learning_rate': 0.08826765262707083, 'max_depth': 5, 'n_estimators': 813}. Best is trial 11 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:51,597]\u001b[0m Trial 15 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.010065003286304207, 'max_depth': 6, 'n_estimators': 553}. Best is trial 11 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:53,306]\u001b[0m Trial 16 finished with value: 0.8762278978388998 and parameters: {'learning_rate': 0.07485078911627692, 'max_depth': 4, 'n_estimators': 826}. Best is trial 11 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:54,764]\u001b[0m Trial 17 finished with value: 0.8742632612966601 and parameters: {'learning_rate': 0.10454340012620156, 'max_depth': 5, 'n_estimators': 598}. Best is trial 11 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:57,181]\u001b[0m Trial 18 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.04523185817137633, 'max_depth': 6, 'n_estimators': 811}. Best is trial 11 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:10:58,598]\u001b[0m Trial 19 finished with value: 0.8762278978388998 and parameters: {'learning_rate': 0.05189881719844291, 'max_depth': 5, 'n_estimators': 504}. Best is trial 11 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:00,143]\u001b[0m Trial 20 finished with value: 0.888015717092338 and parameters: {'learning_rate': 0.012139304336448388, 'max_depth': 4, 'n_estimators': 646}. Best is trial 11 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:02,331]\u001b[0m Trial 21 finished with value: 0.8821218074656189 and parameters: {'learning_rate': 0.02471635703493469, 'max_depth': 4, 'n_estimators': 628}. Best is trial 11 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:04,250]\u001b[0m Trial 22 finished with value: 0.888015717092338 and parameters: {'learning_rate': 0.012268308676920255, 'max_depth': 4, 'n_estimators': 699}. Best is trial 11 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:06,018]\u001b[0m Trial 23 finished with value: 0.8742632612966601 and parameters: {'learning_rate': 0.04398407872936251, 'max_depth': 4, 'n_estimators': 764}. Best is trial 11 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:08,188]\u001b[0m Trial 24 finished with value: 0.8762278978388998 and parameters: {'learning_rate': 0.07032955932819535, 'max_depth': 5, 'n_estimators': 863}. Best is trial 11 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:09,187]\u001b[0m Trial 25 finished with value: 0.8742632612966601 and parameters: {'learning_rate': 0.03543490677079711, 'max_depth': 3, 'n_estimators': 553}. Best is trial 11 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:10,148]\u001b[0m Trial 26 finished with value: 0.8860510805500982 and parameters: {'learning_rate': 0.06042682062852058, 'max_depth': 5, 'n_estimators': 353}. Best is trial 11 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:11,673]\u001b[0m Trial 27 finished with value: 0.8703339882121808 and parameters: {'learning_rate': 0.09677578100284794, 'max_depth': 4, 'n_estimators': 650}. Best is trial 11 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:14,452]\u001b[0m Trial 28 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.03229077286171838, 'max_depth': 6, 'n_estimators': 889}. Best is trial 11 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:15,431]\u001b[0m Trial 29 finished with value: 0.8742632612966601 and parameters: {'learning_rate': 0.07176651556406438, 'max_depth': 2, 'n_estimators': 768}. Best is trial 11 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:17,164]\u001b[0m Trial 30 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.07856172919944554, 'max_depth': 5, 'n_estimators': 582}. Best is trial 11 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:18,828]\u001b[0m Trial 31 finished with value: 0.8821218074656189 and parameters: {'learning_rate': 0.016937924499691805, 'max_depth': 4, 'n_estimators': 695}. Best is trial 11 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:20,430]\u001b[0m Trial 32 finished with value: 0.8840864440078585 and parameters: {'learning_rate': 0.01016241392407305, 'max_depth': 4, 'n_estimators': 674}. Best is trial 11 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:22,431]\u001b[0m Trial 33 finished with value: 0.888015717092338 and parameters: {'learning_rate': 0.032741359244603904, 'max_depth': 4, 'n_estimators': 750}. Best is trial 11 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:23,617]\u001b[0m Trial 34 finished with value: 0.8683693516699411 and parameters: {'learning_rate': 0.04564487925042658, 'max_depth': 3, 'n_estimators': 616}. Best is trial 11 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:25,069]\u001b[0m Trial 35 finished with value: 0.8821218074656189 and parameters: {'learning_rate': 0.024180155911863163, 'max_depth': 4, 'n_estimators': 496}. Best is trial 11 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:28,002]\u001b[0m Trial 36 finished with value: 0.8919449901768173 and parameters: {'learning_rate': 0.011048009324978417, 'max_depth': 5, 'n_estimators': 904}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:28,443]\u001b[0m Trial 37 finished with value: 0.8840864440078585 and parameters: {'learning_rate': 0.0621729745764574, 'max_depth': 5, 'n_estimators': 120}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:31,155]\u001b[0m Trial 38 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.04126680895128372, 'max_depth': 6, 'n_estimators': 960}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:33,188]\u001b[0m Trial 39 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.1253759972965885, 'max_depth': 5, 'n_estimators': 872}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:35,427]\u001b[0m Trial 40 finished with value: 0.8742632612966601 and parameters: {'learning_rate': 0.052773396901485976, 'max_depth': 5, 'n_estimators': 896}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:37,961]\u001b[0m Trial 41 finished with value: 0.8840864440078585 and parameters: {'learning_rate': 0.024188139999800518, 'max_depth': 4, 'n_estimators': 991}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:40,135]\u001b[0m Trial 42 finished with value: 0.8840864440078585 and parameters: {'learning_rate': 0.011493934813484732, 'max_depth': 5, 'n_estimators': 681}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:41,605]\u001b[0m Trial 43 finished with value: 0.8683693516699411 and parameters: {'learning_rate': 0.02981844829403151, 'max_depth': 3, 'n_estimators': 779}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:43,507]\u001b[0m Trial 44 finished with value: 0.8840864440078585 and parameters: {'learning_rate': 0.02289144319917214, 'max_depth': 4, 'n_estimators': 705}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:44,787]\u001b[0m Trial 45 finished with value: 0.8860510805500982 and parameters: {'learning_rate': 0.03969230834590795, 'max_depth': 5, 'n_estimators': 425}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:47,489]\u001b[0m Trial 46 finished with value: 0.8722986247544204 and parameters: {'learning_rate': 0.01042942645672221, 'max_depth': 6, 'n_estimators': 636}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:49,184]\u001b[0m Trial 47 finished with value: 0.8742632612966601 and parameters: {'learning_rate': 0.05762726989693611, 'max_depth': 4, 'n_estimators': 726}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:51,015]\u001b[0m Trial 48 finished with value: 0.8762278978388998 and parameters: {'learning_rate': 0.15917786610107304, 'max_depth': 5, 'n_estimators': 838}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:52,509]\u001b[0m Trial 49 finished with value: 0.8762278978388998 and parameters: {'learning_rate': 0.022276923945642898, 'max_depth': 3, 'n_estimators': 795}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:55,303]\u001b[0m Trial 50 finished with value: 0.8722986247544204 and parameters: {'learning_rate': 0.03548559076434865, 'max_depth': 6, 'n_estimators': 910}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:57,049]\u001b[0m Trial 51 finished with value: 0.8762278978388998 and parameters: {'learning_rate': 0.034521051776646196, 'max_depth': 4, 'n_estimators': 742}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:11:58,639]\u001b[0m Trial 52 finished with value: 0.8860510805500982 and parameters: {'learning_rate': 0.02059065737616363, 'max_depth': 4, 'n_estimators': 577}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:00,378]\u001b[0m Trial 53 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.045374183501369396, 'max_depth': 4, 'n_estimators': 724}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:02,404]\u001b[0m Trial 54 finished with value: 0.8821218074656189 and parameters: {'learning_rate': 0.030324712412160428, 'max_depth': 4, 'n_estimators': 837}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:04,614]\u001b[0m Trial 55 finished with value: 0.8899803536345776 and parameters: {'learning_rate': 0.01638504146737107, 'max_depth': 5, 'n_estimators': 661}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:06,240]\u001b[0m Trial 56 finished with value: 0.8762278978388998 and parameters: {'learning_rate': 0.010108313789760761, 'max_depth': 5, 'n_estimators': 509}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:08,178]\u001b[0m Trial 57 finished with value: 0.8742632612966601 and parameters: {'learning_rate': 0.05276987975272721, 'max_depth': 5, 'n_estimators': 657}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:10,257]\u001b[0m Trial 58 finished with value: 0.8840864440078585 and parameters: {'learning_rate': 0.019898673708187254, 'max_depth': 5, 'n_estimators': 609}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:11,265]\u001b[0m Trial 59 finished with value: 0.8742632612966601 and parameters: {'learning_rate': 0.06295868189261292, 'max_depth': 5, 'n_estimators': 323}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:12,903]\u001b[0m Trial 60 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.04355785675732271, 'max_depth': 5, 'n_estimators': 525}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:14,876]\u001b[0m Trial 61 finished with value: 0.8762278978388998 and parameters: {'learning_rate': 0.03040033607199822, 'max_depth': 4, 'n_estimators': 750}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:16,572]\u001b[0m Trial 62 finished with value: 0.8840864440078585 and parameters: {'learning_rate': 0.019362187304363607, 'max_depth': 4, 'n_estimators': 675}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:19,038]\u001b[0m Trial 63 finished with value: 0.8801571709233792 and parameters: {'learning_rate': 0.03636961258633124, 'max_depth': 5, 'n_estimators': 792}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:21,033]\u001b[0m Trial 64 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.017185900329516654, 'max_depth': 4, 'n_estimators': 702}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:23,342]\u001b[0m Trial 65 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.027379843627944486, 'max_depth': 6, 'n_estimators': 641}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:24,623]\u001b[0m Trial 66 finished with value: 0.8683693516699411 and parameters: {'learning_rate': 0.04923960547953775, 'max_depth': 3, 'n_estimators': 563}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:26,580]\u001b[0m Trial 67 finished with value: 0.8840864440078585 and parameters: {'learning_rate': 0.010207456031625876, 'max_depth': 4, 'n_estimators': 751}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:28,990]\u001b[0m Trial 68 finished with value: 0.8742632612966601 and parameters: {'learning_rate': 0.038622927824873976, 'max_depth': 5, 'n_estimators': 617}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:31,787]\u001b[0m Trial 69 finished with value: 0.8801571709233792 and parameters: {'learning_rate': 0.028640499754413875, 'max_depth': 5, 'n_estimators': 926}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:33,419]\u001b[0m Trial 70 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.08139208342563484, 'max_depth': 4, 'n_estimators': 662}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:35,947]\u001b[0m Trial 71 finished with value: 0.8860510805500982 and parameters: {'learning_rate': 0.017745006325588158, 'max_depth': 5, 'n_estimators': 711}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:38,020]\u001b[0m Trial 72 finished with value: 0.888015717092338 and parameters: {'learning_rate': 0.016646978878481017, 'max_depth': 5, 'n_estimators': 588}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:40,088]\u001b[0m Trial 73 finished with value: 0.8899803536345776 and parameters: {'learning_rate': 0.01744623509387179, 'max_depth': 5, 'n_estimators': 583}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:41,873]\u001b[0m Trial 74 finished with value: 0.8821218074656189 and parameters: {'learning_rate': 0.030336868083388785, 'max_depth': 5, 'n_estimators': 543}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:44,040]\u001b[0m Trial 75 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.03946799531514309, 'max_depth': 5, 'n_estimators': 679}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:45,770]\u001b[0m Trial 76 finished with value: 0.8860510805500982 and parameters: {'learning_rate': 0.024359294907526273, 'max_depth': 5, 'n_estimators': 474}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:47,682]\u001b[0m Trial 77 finished with value: 0.8801571709233792 and parameters: {'learning_rate': 0.053686286309268326, 'max_depth': 6, 'n_estimators': 598}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:49,249]\u001b[0m Trial 78 finished with value: 0.8703339882121808 and parameters: {'learning_rate': 0.06514356776922381, 'max_depth': 4, 'n_estimators': 636}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:51,754]\u001b[0m Trial 79 finished with value: 0.8801571709233792 and parameters: {'learning_rate': 0.015641199226177502, 'max_depth': 4, 'n_estimators': 860}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:54,072]\u001b[0m Trial 80 finished with value: 0.8742632612966601 and parameters: {'learning_rate': 0.04486445436083371, 'max_depth': 5, 'n_estimators': 770}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:56,024]\u001b[0m Trial 81 finished with value: 0.888015717092338 and parameters: {'learning_rate': 0.016996528994705447, 'max_depth': 5, 'n_estimators': 580}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:12:58,104]\u001b[0m Trial 82 finished with value: 0.8840864440078585 and parameters: {'learning_rate': 0.02483143563849515, 'max_depth': 5, 'n_estimators': 687}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:00,552]\u001b[0m Trial 83 finished with value: 0.8860510805500982 and parameters: {'learning_rate': 0.014211488731592333, 'max_depth': 5, 'n_estimators': 727}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:02,386]\u001b[0m Trial 84 finished with value: 0.8801571709233792 and parameters: {'learning_rate': 0.03542345932116623, 'max_depth': 5, 'n_estimators': 597}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:03,847]\u001b[0m Trial 85 finished with value: 0.8840864440078585 and parameters: {'learning_rate': 0.01017269758323696, 'max_depth': 4, 'n_estimators': 531}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:06,036]\u001b[0m Trial 86 finished with value: 0.8840864440078585 and parameters: {'learning_rate': 0.026935262982374482, 'max_depth': 5, 'n_estimators': 659}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:07,842]\u001b[0m Trial 87 finished with value: 0.8860510805500982 and parameters: {'learning_rate': 0.021501703420671158, 'max_depth': 5, 'n_estimators': 568}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:10,972]\u001b[0m Trial 88 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.03287414602019408, 'max_depth': 6, 'n_estimators': 802}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:12,313]\u001b[0m Trial 89 finished with value: 0.8722986247544204 and parameters: {'learning_rate': 0.0184658112843966, 'max_depth': 3, 'n_estimators': 621}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:13,506]\u001b[0m Trial 90 finished with value: 0.8840864440078585 and parameters: {'learning_rate': 0.04830157249953142, 'max_depth': 4, 'n_estimators': 429}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:15,692]\u001b[0m Trial 91 finished with value: 0.8899803536345776 and parameters: {'learning_rate': 0.015373636378855648, 'max_depth': 5, 'n_estimators': 639}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:18,106]\u001b[0m Trial 92 finished with value: 0.8840864440078585 and parameters: {'learning_rate': 0.014833777878727071, 'max_depth': 5, 'n_estimators': 699}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:20,102]\u001b[0m Trial 93 finished with value: 0.8860510805500982 and parameters: {'learning_rate': 0.026470044164972003, 'max_depth': 5, 'n_estimators': 645}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:22,209]\u001b[0m Trial 94 finished with value: 0.8762278978388998 and parameters: {'learning_rate': 0.03917111317952798, 'max_depth': 5, 'n_estimators': 596}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:25,202]\u001b[0m Trial 95 finished with value: 0.8840864440078585 and parameters: {'learning_rate': 0.02099464328440636, 'max_depth': 5, 'n_estimators': 966}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:27,391]\u001b[0m Trial 96 finished with value: 0.888015717092338 and parameters: {'learning_rate': 0.010305386350976935, 'max_depth': 4, 'n_estimators': 729}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:29,516]\u001b[0m Trial 97 finished with value: 0.8801571709233792 and parameters: {'learning_rate': 0.03397547113198657, 'max_depth': 5, 'n_estimators': 662}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:30,427]\u001b[0m Trial 98 finished with value: 0.8683693516699411 and parameters: {'learning_rate': 0.016460211426455477, 'max_depth': 2, 'n_estimators': 634}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:32,621]\u001b[0m Trial 99 finished with value: 0.8821218074656189 and parameters: {'learning_rate': 0.028983263032008225, 'max_depth': 4, 'n_estimators': 712}. Best is trial 36 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:32,632]\u001b[0m A new study created in memory with name: no-name-020fc669-4320-437f-999f-029b3994972d\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "\n",
      "                                         index  \n",
      "index    AAC_LogisticRegression_no_hypertuning  \n",
      "index                   AAC_SVC_no_hypertuning  \n",
      "index         AAC_XGBClassifier_no_hypertuning  \n",
      "index        AAC_LGBMClassifier_no_hypertuning  \n",
      "index  AAC_LogisticRegression_with_hypertuning  \n",
      "index                 AAC_SVC_with_hypertuning  \n",
      "index       AAC_XGBClassifier_with_hypertuning  \n",
      "Optimizing AAC LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 10:13:33,623]\u001b[0m Trial 0 finished with value: 0.8781925343811395 and parameters: {'num_leaves': 127, 'max_depth': 32, 'learning_rate': 0.15295363700847528, 'n_estimators': 857}. Best is trial 0 with value: 0.8781925343811395.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:34,564]\u001b[0m Trial 1 finished with value: 0.8683693516699411 and parameters: {'num_leaves': 237, 'max_depth': 36, 'learning_rate': 0.20829406223755478, 'n_estimators': 1163}. Best is trial 0 with value: 0.8781925343811395.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:34,923]\u001b[0m Trial 2 finished with value: 0.8801571709233792 and parameters: {'num_leaves': 43, 'max_depth': 9, 'learning_rate': 0.15535758672785846, 'n_estimators': 247}. Best is trial 2 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:38,150]\u001b[0m Trial 3 finished with value: 0.8840864440078585 and parameters: {'num_leaves': 256, 'max_depth': 15, 'learning_rate': 0.020958080646914356, 'n_estimators': 975}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:39,533]\u001b[0m Trial 4 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 254, 'max_depth': 25, 'learning_rate': 0.10001700795369724, 'n_estimators': 1173}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:42,050]\u001b[0m Trial 5 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 146, 'max_depth': 13, 'learning_rate': 0.043249711950631, 'n_estimators': 1926}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:42,940]\u001b[0m Trial 6 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 58, 'max_depth': 26, 'learning_rate': 0.11782169949213099, 'n_estimators': 803}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:44,195]\u001b[0m Trial 7 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 47, 'max_depth': 11, 'learning_rate': 0.03054971040112744, 'n_estimators': 622}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:45,085]\u001b[0m Trial 8 finished with value: 0.8742632612966601 and parameters: {'num_leaves': 211, 'max_depth': 50, 'learning_rate': 0.11140171341004969, 'n_estimators': 486}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:46,061]\u001b[0m Trial 9 finished with value: 0.8762278978388998 and parameters: {'num_leaves': 213, 'max_depth': 18, 'learning_rate': 0.27656608387378045, 'n_estimators': 1670}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:46,858]\u001b[0m Trial 10 finished with value: 0.8487229862475442 and parameters: {'num_leaves': 154, 'max_depth': 3, 'learning_rate': 0.0013114042436939838, 'n_estimators': 1399}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:46,963]\u001b[0m Trial 11 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 3, 'max_depth': 2, 'learning_rate': 0.1785868325703309, 'n_estimators': 100}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:47,468]\u001b[0m Trial 12 finished with value: 0.8801571709233792 and parameters: {'num_leaves': 90, 'max_depth': 12, 'learning_rate': 0.07185269316066831, 'n_estimators': 141}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:48,803]\u001b[0m Trial 13 finished with value: 0.8762278978388998 and parameters: {'num_leaves': 174, 'max_depth': 19, 'learning_rate': 0.05950445131015063, 'n_estimators': 367}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:50,597]\u001b[0m Trial 14 finished with value: 0.8781925343811395 and parameters: {'num_leaves': 108, 'max_depth': 8, 'learning_rate': 0.0069003558801266785, 'n_estimators': 853}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:51,787]\u001b[0m Trial 15 finished with value: 0.8801571709233792 and parameters: {'num_leaves': 11, 'max_depth': 20, 'learning_rate': 0.08609622333742609, 'n_estimators': 1553}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:52,303]\u001b[0m Trial 16 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 69, 'max_depth': 7, 'learning_rate': 0.13479826799834213, 'n_estimators': 326}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:53,337]\u001b[0m Trial 17 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 33, 'max_depth': 34, 'learning_rate': 0.06780960792181444, 'n_estimators': 675}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:54,296]\u001b[0m Trial 18 finished with value: 0.8840864440078585 and parameters: {'num_leaves': 191, 'max_depth': 16, 'learning_rate': 0.16270568249192666, 'n_estimators': 1068}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:55,181]\u001b[0m Trial 19 finished with value: 0.8664047151277013 and parameters: {'num_leaves': 193, 'max_depth': 26, 'learning_rate': 0.2138029505891301, 'n_estimators': 1051}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:56,689]\u001b[0m Trial 20 finished with value: 0.8801571709233792 and parameters: {'num_leaves': 254, 'max_depth': 16, 'learning_rate': 0.08984281507607704, 'n_estimators': 1290}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:57,515]\u001b[0m Trial 21 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 182, 'max_depth': 7, 'learning_rate': 0.1540118926800079, 'n_estimators': 981}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:58,763]\u001b[0m Trial 22 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 223, 'max_depth': 22, 'learning_rate': 0.13235971428118218, 'n_estimators': 1378}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:13:59,468]\u001b[0m Trial 23 finished with value: 0.8781925343811395 and parameters: {'num_leaves': 157, 'max_depth': 15, 'learning_rate': 0.17715949704194822, 'n_estimators': 548}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:14:01,430]\u001b[0m Trial 24 finished with value: 0.8742632612966601 and parameters: {'num_leaves': 114, 'max_depth': 10, 'learning_rate': 0.11199166768542992, 'n_estimators': 1992}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:14:03,056]\u001b[0m Trial 25 finished with value: 0.8840864440078585 and parameters: {'num_leaves': 196, 'max_depth': 5, 'learning_rate': 0.0313600451640874, 'n_estimators': 1726}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:14:04,156]\u001b[0m Trial 26 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 203, 'max_depth': 4, 'learning_rate': 0.029528262149646895, 'n_estimators': 1757}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:14:06,628]\u001b[0m Trial 27 finished with value: 0.8703339882121808 and parameters: {'num_leaves': 231, 'max_depth': 40, 'learning_rate': 0.049189034587265174, 'n_estimators': 1813}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:14:10,292]\u001b[0m Trial 28 finished with value: 0.8762278978388998 and parameters: {'num_leaves': 172, 'max_depth': 14, 'learning_rate': 0.0220006760167563, 'n_estimators': 1556}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:14:12,688]\u001b[0m Trial 29 finished with value: 0.8605108055009824 and parameters: {'num_leaves': 134, 'max_depth': 30, 'learning_rate': 0.04860644028532432, 'n_estimators': 948}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:14:14,398]\u001b[0m Trial 30 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 195, 'max_depth': 23, 'learning_rate': 0.07797520486218576, 'n_estimators': 754}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:14:14,864]\u001b[0m Trial 31 finished with value: 0.8762278978388998 and parameters: {'num_leaves': 87, 'max_depth': 6, 'learning_rate': 0.016249961262676, 'n_estimators': 303}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:14:16,719]\u001b[0m Trial 32 finished with value: 0.8762278978388998 and parameters: {'num_leaves': 241, 'max_depth': 10, 'learning_rate': 0.06361445965658506, 'n_estimators': 1115}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:14:18,447]\u001b[0m Trial 33 finished with value: 0.8840864440078585 and parameters: {'num_leaves': 221, 'max_depth': 16, 'learning_rate': 0.09857624221934269, 'n_estimators': 1507}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:14:20,964]\u001b[0m Trial 34 finished with value: 0.8703339882121808 and parameters: {'num_leaves': 238, 'max_depth': 16, 'learning_rate': 0.037776403986461676, 'n_estimators': 1261}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:14:27,047]\u001b[0m Trial 35 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 219, 'max_depth': 29, 'learning_rate': 0.0014438056298539219, 'n_estimators': 1578}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:14:28,950]\u001b[0m Trial 36 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 241, 'max_depth': 22, 'learning_rate': 0.09346864145132044, 'n_estimators': 1445}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:14:32,507]\u001b[0m Trial 37 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 190, 'max_depth': 17, 'learning_rate': 0.022130647972835968, 'n_estimators': 1220}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:14:35,178]\u001b[0m Trial 38 finished with value: 0.8742632612966601 and parameters: {'num_leaves': 166, 'max_depth': 40, 'learning_rate': 0.04888012483601633, 'n_estimators': 1829}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:14:36,777]\u001b[0m Trial 39 finished with value: 0.8801571709233792 and parameters: {'num_leaves': 207, 'max_depth': 12, 'learning_rate': 0.10201940128967646, 'n_estimators': 1699}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:14:37,655]\u001b[0m Trial 40 finished with value: 0.8703339882121808 and parameters: {'num_leaves': 254, 'max_depth': 5, 'learning_rate': 0.07956721948147165, 'n_estimators': 946}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:14:41,504]\u001b[0m Trial 41 finished with value: 0.8762278978388998 and parameters: {'num_leaves': 221, 'max_depth': 9, 'learning_rate': 0.026016517326332728, 'n_estimators': 1906}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:14:42,909]\u001b[0m Trial 42 finished with value: 0.8742632612966601 and parameters: {'num_leaves': 132, 'max_depth': 14, 'learning_rate': 0.12023935777169967, 'n_estimators': 1662}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:14:43,428]\u001b[0m Trial 43 finished with value: 0.8801571709233792 and parameters: {'num_leaves': 232, 'max_depth': 2, 'learning_rate': 0.03804991628521294, 'n_estimators': 1437}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:14:44,284]\u001b[0m Trial 44 finished with value: 0.8683693516699411 and parameters: {'num_leaves': 142, 'max_depth': 19, 'learning_rate': 0.1023007428068618, 'n_estimators': 229}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:14:45,430]\u001b[0m Trial 45 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 205, 'max_depth': 12, 'learning_rate': 0.05699979093618181, 'n_estimators': 438}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:14:46,281]\u001b[0m Trial 46 finished with value: 0.8781925343811395 and parameters: {'num_leaves': 31, 'max_depth': 9, 'learning_rate': 0.14982943412702796, 'n_estimators': 1126}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:14:49,271]\u001b[0m Trial 47 finished with value: 0.8821218074656189 and parameters: {'num_leaves': 256, 'max_depth': 13, 'learning_rate': 0.009221160713315787, 'n_estimators': 712}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:14:54,544]\u001b[0m Trial 48 finished with value: 0.8821218074656189 and parameters: {'num_leaves': 256, 'max_depth': 21, 'learning_rate': 0.00995337735874794, 'n_estimators': 722}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:14:58,490]\u001b[0m Trial 49 finished with value: 0.8840864440078585 and parameters: {'num_leaves': 247, 'max_depth': 25, 'learning_rate': 0.01593996967174429, 'n_estimators': 612}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:15:00,309]\u001b[0m Trial 50 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 243, 'max_depth': 24, 'learning_rate': 0.0684046787182093, 'n_estimators': 854}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:15:02,355]\u001b[0m Trial 51 finished with value: 0.8821218074656189 and parameters: {'num_leaves': 228, 'max_depth': 17, 'learning_rate': 0.017580533219589377, 'n_estimators': 602}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:15:04,903]\u001b[0m Trial 52 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 247, 'max_depth': 29, 'learning_rate': 0.03514514519427106, 'n_estimators': 808}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:15:06,427]\u001b[0m Trial 53 finished with value: 0.8664047151277013 and parameters: {'num_leaves': 211, 'max_depth': 19, 'learning_rate': 0.008931434039740414, 'n_estimators': 462}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:15:09,017]\u001b[0m Trial 54 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 218, 'max_depth': 13, 'learning_rate': 0.03291814112574325, 'n_estimators': 1022}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:15:11,086]\u001b[0m Trial 55 finished with value: 0.8821218074656189 and parameters: {'num_leaves': 247, 'max_depth': 49, 'learning_rate': 0.013822340751590351, 'n_estimators': 561}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:15:13,064]\u001b[0m Trial 56 finished with value: 0.8781925343811395 and parameters: {'num_leaves': 184, 'max_depth': 15, 'learning_rate': 0.04312159917226753, 'n_estimators': 685}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:15:15,359]\u001b[0m Trial 57 finished with value: 0.8703339882121808 and parameters: {'num_leaves': 234, 'max_depth': 26, 'learning_rate': 0.05371096260280076, 'n_estimators': 927}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:15:18,909]\u001b[0m Trial 58 finished with value: 0.8683693516699411 and parameters: {'num_leaves': 198, 'max_depth': 20, 'learning_rate': 0.002333685252516128, 'n_estimators': 772}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:15:21,506]\u001b[0m Trial 59 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 224, 'max_depth': 11, 'learning_rate': 0.026335655932494328, 'n_estimators': 1070}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:15:22,599]\u001b[0m Trial 60 finished with value: 0.8801571709233792 and parameters: {'num_leaves': 250, 'max_depth': 7, 'learning_rate': 0.060691994522678386, 'n_estimators': 885}. Best is trial 3 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:15:25,344]\u001b[0m Trial 61 finished with value: 0.8860510805500982 and parameters: {'num_leaves': 256, 'max_depth': 21, 'learning_rate': 0.011277185506428228, 'n_estimators': 714}. Best is trial 61 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:15:27,778]\u001b[0m Trial 62 finished with value: 0.8801571709233792 and parameters: {'num_leaves': 256, 'max_depth': 25, 'learning_rate': 0.012725157571443017, 'n_estimators': 688}. Best is trial 61 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:15:32,157]\u001b[0m Trial 63 finished with value: 0.8781925343811395 and parameters: {'num_leaves': 233, 'max_depth': 18, 'learning_rate': 0.022369377732234866, 'n_estimators': 1347}. Best is trial 61 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:15:34,159]\u001b[0m Trial 64 finished with value: 0.8742632612966601 and parameters: {'num_leaves': 243, 'max_depth': 23, 'learning_rate': 0.04186039989014459, 'n_estimators': 636}. Best is trial 61 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:15:36,443]\u001b[0m Trial 65 finished with value: 0.8860510805500982 and parameters: {'num_leaves': 217, 'max_depth': 28, 'learning_rate': 0.029293547469828776, 'n_estimators': 569}. Best is trial 61 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:15:38,593]\u001b[0m Trial 66 finished with value: 0.8801571709233792 and parameters: {'num_leaves': 214, 'max_depth': 32, 'learning_rate': 0.029795114965052057, 'n_estimators': 503}. Best is trial 61 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:15:40,119]\u001b[0m Trial 67 finished with value: 0.8840864440078585 and parameters: {'num_leaves': 187, 'max_depth': 28, 'learning_rate': 0.047496247002906306, 'n_estimators': 395}. Best is trial 61 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:15:42,216]\u001b[0m Trial 68 finished with value: 0.8683693516699411 and parameters: {'num_leaves': 198, 'max_depth': 27, 'learning_rate': 0.07446597410880233, 'n_estimators': 1625}. Best is trial 61 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:15:46,989]\u001b[0m Trial 69 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 172, 'max_depth': 35, 'learning_rate': 0.01912352853315307, 'n_estimators': 1505}. Best is trial 61 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:15:49,417]\u001b[0m Trial 70 finished with value: 0.8703339882121808 and parameters: {'num_leaves': 157, 'max_depth': 21, 'learning_rate': 0.03775225539833077, 'n_estimators': 569}. Best is trial 61 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:15:51,519]\u001b[0m Trial 71 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 226, 'max_depth': 28, 'learning_rate': 0.0480299200738836, 'n_estimators': 414}. Best is trial 61 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:15:52,219]\u001b[0m Trial 72 finished with value: 0.8290766208251473 and parameters: {'num_leaves': 189, 'max_depth': 33, 'learning_rate': 0.0010241862637863763, 'n_estimators': 189}. Best is trial 61 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:15:53,714]\u001b[0m Trial 73 finished with value: 0.8762278978388998 and parameters: {'num_leaves': 182, 'max_depth': 30, 'learning_rate': 0.03155747380977014, 'n_estimators': 339}. Best is trial 61 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:15:55,653]\u001b[0m Trial 74 finished with value: 0.8762278978388998 and parameters: {'num_leaves': 209, 'max_depth': 25, 'learning_rate': 0.05445589106367796, 'n_estimators': 515}. Best is trial 61 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:15:58,327]\u001b[0m Trial 75 finished with value: 0.888015717092338 and parameters: {'num_leaves': 202, 'max_depth': 31, 'learning_rate': 0.02428018983995739, 'n_estimators': 643}. Best is trial 75 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:16:00,735]\u001b[0m Trial 76 finished with value: 0.8821218074656189 and parameters: {'num_leaves': 202, 'max_depth': 31, 'learning_rate': 0.02107329256137792, 'n_estimators': 645}. Best is trial 75 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:16:05,728]\u001b[0m Trial 77 finished with value: 0.8840864440078585 and parameters: {'num_leaves': 219, 'max_depth': 36, 'learning_rate': 0.015129344785868706, 'n_estimators': 1178}. Best is trial 75 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:16:18,552]\u001b[0m Trial 78 finished with value: 0.8781925343811395 and parameters: {'num_leaves': 237, 'max_depth': 37, 'learning_rate': 0.06393931182085258, 'n_estimators': 816}. Best is trial 75 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:16:22,224]\u001b[0m Trial 79 finished with value: 0.8703339882121808 and parameters: {'num_leaves': 214, 'max_depth': 16, 'learning_rate': 0.028854004244822474, 'n_estimators': 1832}. Best is trial 75 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:16:25,232]\u001b[0m Trial 80 finished with value: 0.8762278978388998 and parameters: {'num_leaves': 164, 'max_depth': 23, 'learning_rate': 0.04051640727709601, 'n_estimators': 1742}. Best is trial 75 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:16:26,860]\u001b[0m Trial 81 finished with value: 0.8742632612966601 and parameters: {'num_leaves': 179, 'max_depth': 27, 'learning_rate': 0.045847802036876356, 'n_estimators': 370}. Best is trial 75 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:16:28,008]\u001b[0m Trial 82 finished with value: 0.8840864440078585 and parameters: {'num_leaves': 193, 'max_depth': 28, 'learning_rate': 0.026638708129585888, 'n_estimators': 285}. Best is trial 75 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:16:30,512]\u001b[0m Trial 83 finished with value: 0.8860510805500982 and parameters: {'num_leaves': 229, 'max_depth': 24, 'learning_rate': 0.016074118004330677, 'n_estimators': 598}. Best is trial 75 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:16:33,142]\u001b[0m Trial 84 finished with value: 0.8703339882121808 and parameters: {'num_leaves': 229, 'max_depth': 21, 'learning_rate': 0.006797390519793781, 'n_estimators': 601}. Best is trial 75 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:16:36,068]\u001b[0m Trial 85 finished with value: 0.8801571709233792 and parameters: {'num_leaves': 248, 'max_depth': 24, 'learning_rate': 0.013955371826998858, 'n_estimators': 739}. Best is trial 75 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:16:38,129]\u001b[0m Trial 86 finished with value: 0.8762278978388998 and parameters: {'num_leaves': 239, 'max_depth': 18, 'learning_rate': 0.019684271791746265, 'n_estimators': 488}. Best is trial 75 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:16:40,977]\u001b[0m Trial 87 finished with value: 0.8742632612966601 and parameters: {'num_leaves': 204, 'max_depth': 20, 'learning_rate': 0.0355436255777881, 'n_estimators': 1288}. Best is trial 75 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:16:42,930]\u001b[0m Trial 88 finished with value: 0.8742632612966601 and parameters: {'num_leaves': 226, 'max_depth': 15, 'learning_rate': 0.005418888875966223, 'n_estimators': 550}. Best is trial 75 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:16:46,056]\u001b[0m Trial 89 finished with value: 0.8821218074656189 and parameters: {'num_leaves': 249, 'max_depth': 25, 'learning_rate': 0.025197380323334333, 'n_estimators': 785}. Best is trial 75 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:16:48,430]\u001b[0m Trial 90 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 216, 'max_depth': 22, 'learning_rate': 0.009124386983130665, 'n_estimators': 654}. Best is trial 75 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:16:50,098]\u001b[0m Trial 91 finished with value: 0.8860510805500982 and parameters: {'num_leaves': 235, 'max_depth': 28, 'learning_rate': 0.03487156162371142, 'n_estimators': 424}. Best is trial 75 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:16:52,263]\u001b[0m Trial 92 finished with value: 0.8801571709233792 and parameters: {'num_leaves': 234, 'max_depth': 31, 'learning_rate': 0.033570186994505695, 'n_estimators': 529}. Best is trial 75 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:16:53,004]\u001b[0m Trial 93 finished with value: 0.888015717092338 and parameters: {'num_leaves': 243, 'max_depth': 4, 'learning_rate': 0.015198162766234043, 'n_estimators': 612}. Best is trial 75 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:16:53,448]\u001b[0m Trial 94 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 242, 'max_depth': 5, 'learning_rate': 0.0531987543147156, 'n_estimators': 458}. Best is trial 75 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:16:55,091]\u001b[0m Trial 95 finished with value: 0.8742632612966601 and parameters: {'num_leaves': 221, 'max_depth': 5, 'learning_rate': 0.04042495444368187, 'n_estimators': 1960}. Best is trial 75 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:16:55,537]\u001b[0m Trial 96 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 228, 'max_depth': 3, 'learning_rate': 0.022888237672694607, 'n_estimators': 1020}. Best is trial 75 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:16:56,678]\u001b[0m Trial 97 finished with value: 0.8821218074656189 and parameters: {'num_leaves': 117, 'max_depth': 8, 'learning_rate': 0.013462340473266983, 'n_estimators': 573}. Best is trial 75 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:16:57,478]\u001b[0m Trial 98 finished with value: 0.8762278978388998 and parameters: {'num_leaves': 237, 'max_depth': 3, 'learning_rate': 0.030803726342377866, 'n_estimators': 1495}. Best is trial 75 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:16:58,748]\u001b[0m Trial 99 finished with value: 0.8840864440078585 and parameters: {'num_leaves': 210, 'max_depth': 11, 'learning_rate': 0.08484189399561379, 'n_estimators': 900}. Best is trial 75 with value: 0.888015717092338.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "\n",
      "                                         index  \n",
      "index    AAC_LogisticRegression_no_hypertuning  \n",
      "index                   AAC_SVC_no_hypertuning  \n",
      "index         AAC_XGBClassifier_no_hypertuning  \n",
      "index        AAC_LGBMClassifier_no_hypertuning  \n",
      "index  AAC_LogisticRegression_with_hypertuning  \n",
      "index                 AAC_SVC_with_hypertuning  \n",
      "index       AAC_XGBClassifier_with_hypertuning  \n",
      "index      AAC_LGBMClassifier_with_hypertuning  \n",
      "Evaluating APAAC LogisticRegression\n",
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "\n",
      "                                         index  \n",
      "index    AAC_LogisticRegression_no_hypertuning  \n",
      "index                   AAC_SVC_no_hypertuning  \n",
      "index         AAC_XGBClassifier_no_hypertuning  \n",
      "index        AAC_LGBMClassifier_no_hypertuning  \n",
      "index  AAC_LogisticRegression_with_hypertuning  \n",
      "index                 AAC_SVC_with_hypertuning  \n",
      "index       AAC_XGBClassifier_with_hypertuning  \n",
      "index      AAC_LGBMClassifier_with_hypertuning  \n",
      "index  APAAC_LogisticRegression_no_hypertuning  \n",
      "Evaluating APAAC SVC\n",
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "\n",
      "                                         index  \n",
      "index    AAC_LogisticRegression_no_hypertuning  \n",
      "index                   AAC_SVC_no_hypertuning  \n",
      "index         AAC_XGBClassifier_no_hypertuning  \n",
      "index        AAC_LGBMClassifier_no_hypertuning  \n",
      "index  AAC_LogisticRegression_with_hypertuning  \n",
      "index                 AAC_SVC_with_hypertuning  \n",
      "index       AAC_XGBClassifier_with_hypertuning  \n",
      "index      AAC_LGBMClassifier_with_hypertuning  \n",
      "index  APAAC_LogisticRegression_no_hypertuning  \n",
      "index                 APAAC_SVC_no_hypertuning  \n",
      "Evaluating APAAC XGBClassifier\n",
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "\n",
      "                                         index  \n",
      "index    AAC_LogisticRegression_no_hypertuning  \n",
      "index                   AAC_SVC_no_hypertuning  \n",
      "index         AAC_XGBClassifier_no_hypertuning  \n",
      "index        AAC_LGBMClassifier_no_hypertuning  \n",
      "index  AAC_LogisticRegression_with_hypertuning  \n",
      "index                 AAC_SVC_with_hypertuning  \n",
      "index       AAC_XGBClassifier_with_hypertuning  \n",
      "index      AAC_LGBMClassifier_with_hypertuning  \n",
      "index  APAAC_LogisticRegression_no_hypertuning  \n",
      "index                 APAAC_SVC_no_hypertuning  \n",
      "index       APAAC_XGBClassifier_no_hypertuning  \n",
      "Evaluating APAAC LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 10:17:08,150]\u001b[0m A new study created in memory with name: no-name-14e58cb2-fc65-497c-a9bb-862681cf6fe8\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "\n",
      "                                         index  \n",
      "index    AAC_LogisticRegression_no_hypertuning  \n",
      "index                   AAC_SVC_no_hypertuning  \n",
      "index         AAC_XGBClassifier_no_hypertuning  \n",
      "index        AAC_LGBMClassifier_no_hypertuning  \n",
      "index  AAC_LogisticRegression_with_hypertuning  \n",
      "index                 AAC_SVC_with_hypertuning  \n",
      "index       AAC_XGBClassifier_with_hypertuning  \n",
      "index      AAC_LGBMClassifier_with_hypertuning  \n",
      "index  APAAC_LogisticRegression_no_hypertuning  \n",
      "index                 APAAC_SVC_no_hypertuning  \n",
      "index       APAAC_XGBClassifier_no_hypertuning  \n",
      "index      APAAC_LGBMClassifier_no_hypertuning  \n",
      "Optimizing APAAC LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:17:09,023]\u001b[0m Trial 0 finished with value: 0.8695652173913043 and parameters: {'C': 0.04501902305401195, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 600}. Best is trial 0 with value: 0.8695652173913043.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:09,042]\u001b[0m Trial 1 finished with value: 0.8853754940711462 and parameters: {'C': 0.06929258545739253, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 844}. Best is trial 1 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:09,060]\u001b[0m Trial 2 finished with value: 0.8774703557312253 and parameters: {'C': 0.032839713305619356, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 335}. Best is trial 1 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:10,020]\u001b[0m Trial 3 finished with value: 0.8636363636363636 and parameters: {'C': 0.022842884444580772, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 903}. Best is trial 1 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:10,043]\u001b[0m Trial 4 finished with value: 0.8814229249011858 and parameters: {'C': 0.0679394708535535, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 640}. Best is trial 1 with value: 0.8853754940711462.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:17:10,843]\u001b[0m Trial 5 finished with value: 0.8794466403162056 and parameters: {'C': 0.09254471532241403, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 537}. Best is trial 1 with value: 0.8853754940711462.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:17:12,032]\u001b[0m Trial 6 finished with value: 0.8478260869565217 and parameters: {'C': 0.022476008617961417, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 713}. Best is trial 1 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:12,061]\u001b[0m Trial 7 finished with value: 0.8794466403162056 and parameters: {'C': 0.06746987978856965, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 465}. Best is trial 1 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:12,092]\u001b[0m Trial 8 finished with value: 0.8774703557312253 and parameters: {'C': 0.06289108948146137, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 164}. Best is trial 1 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:13,140]\u001b[0m Trial 9 finished with value: 0.8675889328063241 and parameters: {'C': 0.02752679244447665, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 817}. Best is trial 1 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:13,194]\u001b[0m Trial 10 finished with value: 0.8893280632411067 and parameters: {'C': 0.08737796182671907, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 988}. Best is trial 10 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:13,275]\u001b[0m Trial 11 finished with value: 0.8893280632411067 and parameters: {'C': 0.08817414112150222, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 999}. Best is trial 10 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:13,329]\u001b[0m Trial 12 finished with value: 0.8932806324110671 and parameters: {'C': 0.09972241221770178, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 978}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:13,363]\u001b[0m Trial 13 finished with value: 0.8913043478260869 and parameters: {'C': 0.09845066051871783, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 968}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:13,396]\u001b[0m Trial 14 finished with value: 0.8913043478260869 and parameters: {'C': 0.09962701348758425, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 789}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:13,429]\u001b[0m Trial 15 finished with value: 0.8893280632411067 and parameters: {'C': 0.08358761862494549, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 895}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:13,466]\u001b[0m Trial 16 finished with value: 0.8913043478260869 and parameters: {'C': 0.09942362446575254, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 713}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:13,499]\u001b[0m Trial 17 finished with value: 0.8873517786561265 and parameters: {'C': 0.08187673026375143, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 363}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:13,530]\u001b[0m Trial 18 finished with value: 0.8873517786561265 and parameters: {'C': 0.07710866428311047, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 117}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:13,563]\u001b[0m Trial 19 finished with value: 0.8873517786561265 and parameters: {'C': 0.07661353754950431, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 921}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:13,596]\u001b[0m Trial 20 finished with value: 0.7747035573122529 and parameters: {'C': 0.01068726552650115, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 741}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:13,635]\u001b[0m Trial 21 finished with value: 0.8932806324110671 and parameters: {'C': 0.09962129577781795, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 795}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:13,677]\u001b[0m Trial 22 finished with value: 0.8913043478260869 and parameters: {'C': 0.09407815139458253, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 945}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:13,715]\u001b[0m Trial 23 finished with value: 0.8913043478260869 and parameters: {'C': 0.09927841869196197, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 859}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:13,747]\u001b[0m Trial 24 finished with value: 0.8893280632411067 and parameters: {'C': 0.09138632803868156, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 1000}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:13,781]\u001b[0m Trial 25 finished with value: 0.8913043478260869 and parameters: {'C': 0.09308215198561832, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 794}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:13,821]\u001b[0m Trial 26 finished with value: 0.8893280632411067 and parameters: {'C': 0.08369078881050732, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 934}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:17:15,274]\u001b[0m Trial 27 finished with value: 0.8774703557312253 and parameters: {'C': 0.07700372959657126, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 861}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:15,318]\u001b[0m Trial 28 finished with value: 0.8913043478260869 and parameters: {'C': 0.09622068133780128, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 674}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:17:16,307]\u001b[0m Trial 29 finished with value: 0.8695652173913043 and parameters: {'C': 0.05226352455210531, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 584}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:16,344]\u001b[0m Trial 30 finished with value: 0.8893280632411067 and parameters: {'C': 0.08780123061751692, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 782}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:16,383]\u001b[0m Trial 31 finished with value: 0.8913043478260869 and parameters: {'C': 0.0985369634941717, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 768}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:16,423]\u001b[0m Trial 32 finished with value: 0.8932806324110671 and parameters: {'C': 0.09979513762483304, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 848}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:16,464]\u001b[0m Trial 33 finished with value: 0.8893280632411067 and parameters: {'C': 0.09206674916279078, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 884}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:16,506]\u001b[0m Trial 34 finished with value: 0.8932806324110671 and parameters: {'C': 0.09997391680696986, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 951}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:16,545]\u001b[0m Trial 35 finished with value: 0.8893280632411067 and parameters: {'C': 0.0895622580694682, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 835}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:16,595]\u001b[0m Trial 36 finished with value: 0.8814229249011858 and parameters: {'C': 0.09232895375990431, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 639}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:17:18,131]\u001b[0m Trial 37 finished with value: 0.8774703557312253 and parameters: {'C': 0.09501159535438553, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 912}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:18,170]\u001b[0m Trial 38 finished with value: 0.8814229249011858 and parameters: {'C': 0.08481833804995861, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 465}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:17:19,389]\u001b[0m Trial 39 finished with value: 0.8794466403162056 and parameters: {'C': 0.08019251715267961, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 855}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:19,435]\u001b[0m Trial 40 finished with value: 0.8814229249011858 and parameters: {'C': 0.0725675759139536, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 949}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:19,469]\u001b[0m Trial 41 finished with value: 0.8913043478260869 and parameters: {'C': 0.09632565364169715, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 970}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:19,497]\u001b[0m Trial 42 finished with value: 0.8932806324110671 and parameters: {'C': 0.09981373854387154, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 892}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:19,537]\u001b[0m Trial 43 finished with value: 0.8893280632411067 and parameters: {'C': 0.08875264420453768, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 824}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:19,579]\u001b[0m Trial 44 finished with value: 0.8913043478260869 and parameters: {'C': 0.09466754947696383, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 894}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:19,622]\u001b[0m Trial 45 finished with value: 0.8932806324110671 and parameters: {'C': 0.09975068320112022, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 728}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:19,666]\u001b[0m Trial 46 finished with value: 0.8893280632411067 and parameters: {'C': 0.08881529968073937, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 237}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:19,719]\u001b[0m Trial 47 finished with value: 0.8794466403162056 and parameters: {'C': 0.09601715612215048, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 944}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:17:20,833]\u001b[0m Trial 48 finished with value: 0.8754940711462451 and parameters: {'C': 0.08659940385693812, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 675}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:20,876]\u001b[0m Trial 49 finished with value: 0.8893280632411067 and parameters: {'C': 0.09140807121544856, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 819}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:20,917]\u001b[0m Trial 50 finished with value: 0.8893280632411067 and parameters: {'C': 0.08559698245875152, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 870}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:20,962]\u001b[0m Trial 51 finished with value: 0.8913043478260869 and parameters: {'C': 0.09959952920100147, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 739}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:21,005]\u001b[0m Trial 52 finished with value: 0.8913043478260869 and parameters: {'C': 0.09945432571268062, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 753}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:21,046]\u001b[0m Trial 53 finished with value: 0.8913043478260869 and parameters: {'C': 0.09608680909265001, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 505}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:21,091]\u001b[0m Trial 54 finished with value: 0.8932806324110671 and parameters: {'C': 0.09991647579421824, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 915}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:21,133]\u001b[0m Trial 55 finished with value: 0.8893280632411067 and parameters: {'C': 0.09231117509446932, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 975}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:21,178]\u001b[0m Trial 56 finished with value: 0.8913043478260869 and parameters: {'C': 0.09554899723878812, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 808}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:21,222]\u001b[0m Trial 57 finished with value: 0.8893280632411067 and parameters: {'C': 0.08970559222650973, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 692}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:21,274]\u001b[0m Trial 58 finished with value: 0.8814229249011858 and parameters: {'C': 0.08181143689640295, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 620}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:21,317]\u001b[0m Trial 59 finished with value: 0.8913043478260869 and parameters: {'C': 0.09702047256770956, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 718}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:17:22,826]\u001b[0m Trial 60 finished with value: 0.8774703557312253 and parameters: {'C': 0.09356119369512048, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 893}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:22,865]\u001b[0m Trial 61 finished with value: 0.8932806324110671 and parameters: {'C': 0.09972150694901499, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 916}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:22,906]\u001b[0m Trial 62 finished with value: 0.8932806324110671 and parameters: {'C': 0.09973983475795076, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 845}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:22,937]\u001b[0m Trial 63 finished with value: 0.8913043478260869 and parameters: {'C': 0.09683836440768796, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 963}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:22,968]\u001b[0m Trial 64 finished with value: 0.8913043478260869 and parameters: {'C': 0.09348694904413578, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 994}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:23,003]\u001b[0m Trial 65 finished with value: 0.8893280632411067 and parameters: {'C': 0.08967832511059697, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 933}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:23,047]\u001b[0m Trial 66 finished with value: 0.8913043478260869 and parameters: {'C': 0.09647582112952258, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 790}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:23,093]\u001b[0m Trial 67 finished with value: 0.8893280632411067 and parameters: {'C': 0.09109668262337212, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 881}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:23,138]\u001b[0m Trial 68 finished with value: 0.8893280632411067 and parameters: {'C': 0.08695683498699121, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 913}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:23,189]\u001b[0m Trial 69 finished with value: 0.8932806324110671 and parameters: {'C': 0.09987233614579774, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 841}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:23,237]\u001b[0m Trial 70 finished with value: 0.8913043478260869 and parameters: {'C': 0.09391527397037618, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 765}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:23,285]\u001b[0m Trial 71 finished with value: 0.8932806324110671 and parameters: {'C': 0.09971378746238568, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 918}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:23,326]\u001b[0m Trial 72 finished with value: 0.8913043478260869 and parameters: {'C': 0.09751171858391702, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 875}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:23,369]\u001b[0m Trial 73 finished with value: 0.8913043478260869 and parameters: {'C': 0.09716308373648619, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 962}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:23,409]\u001b[0m Trial 74 finished with value: 0.8913043478260869 and parameters: {'C': 0.094069178404143, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 937}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:23,454]\u001b[0m Trial 75 finished with value: 0.8893280632411067 and parameters: {'C': 0.09077960390009689, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 908}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:17:24,837]\u001b[0m Trial 76 finished with value: 0.8794466403162056 and parameters: {'C': 0.09998136182880601, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 981}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:24,879]\u001b[0m Trial 77 finished with value: 0.8913043478260869 and parameters: {'C': 0.0971281736224283, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 392}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:24,921]\u001b[0m Trial 78 finished with value: 0.8913043478260869 and parameters: {'C': 0.09414227271447596, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 808}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:24,959]\u001b[0m Trial 79 finished with value: 0.8893280632411067 and parameters: {'C': 0.09158661167699977, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 849}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:24,995]\u001b[0m Trial 80 finished with value: 0.8893280632411067 and parameters: {'C': 0.08441971328691308, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 875}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:25,033]\u001b[0m Trial 81 finished with value: 0.8913043478260869 and parameters: {'C': 0.09789638849694923, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 1000}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:25,070]\u001b[0m Trial 82 finished with value: 0.8913043478260869 and parameters: {'C': 0.09469131516338701, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 835}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:25,109]\u001b[0m Trial 83 finished with value: 0.8913043478260869 and parameters: {'C': 0.09828606106831862, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 941}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:25,150]\u001b[0m Trial 84 finished with value: 0.8893280632411067 and parameters: {'C': 0.0881123205768286, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 904}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:25,192]\u001b[0m Trial 85 finished with value: 0.8932806324110671 and parameters: {'C': 0.09959307298965903, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 856}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:25,239]\u001b[0m Trial 86 finished with value: 0.8913043478260869 and parameters: {'C': 0.09482532604655812, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 825}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:25,293]\u001b[0m Trial 87 finished with value: 0.8814229249011858 and parameters: {'C': 0.09223929869227043, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 787}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:17:26,824]\u001b[0m Trial 88 finished with value: 0.8774703557312253 and parameters: {'C': 0.09800575096048092, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 955}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:26,863]\u001b[0m Trial 89 finished with value: 0.8913043478260869 and parameters: {'C': 0.09550829154525588, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 924}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:26,902]\u001b[0m Trial 90 finished with value: 0.8893280632411067 and parameters: {'C': 0.09049824042131908, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 888}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:26,942]\u001b[0m Trial 91 finished with value: 0.8932806324110671 and parameters: {'C': 0.09980999530479341, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 848}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:26,979]\u001b[0m Trial 92 finished with value: 0.8932806324110671 and parameters: {'C': 0.09999109774922046, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 730}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:27,024]\u001b[0m Trial 93 finished with value: 0.8913043478260869 and parameters: {'C': 0.09714217908512807, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 839}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:27,063]\u001b[0m Trial 94 finished with value: 0.8913043478260869 and parameters: {'C': 0.09548605390224564, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 801}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:27,102]\u001b[0m Trial 95 finished with value: 0.8913043478260869 and parameters: {'C': 0.09297413562381875, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 868}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:27,140]\u001b[0m Trial 96 finished with value: 0.8913043478260869 and parameters: {'C': 0.09795974421440164, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 901}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:27,175]\u001b[0m Trial 97 finished with value: 0.8913043478260869 and parameters: {'C': 0.09810315847017656, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 817}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:27,212]\u001b[0m Trial 98 finished with value: 0.8893280632411067 and parameters: {'C': 0.09276722621941984, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 770}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:27,250]\u001b[0m Trial 99 finished with value: 0.8913043478260869 and parameters: {'C': 0.09532823070992848, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 972}. Best is trial 12 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:27,258]\u001b[0m A new study created in memory with name: no-name-626f4461-bee7-4c60-8cc6-b8ed87a3cc13\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "index        APAAC  LogisticRegression             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "index  {'C': 0.09972241221770178, 'penalty': 'l1', 's...  0.893281   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "index     0.885714     0.900383   0.893004  0.889344  0.786319   \n",
      "\n",
      "                                           index  \n",
      "index      AAC_LogisticRegression_no_hypertuning  \n",
      "index                     AAC_SVC_no_hypertuning  \n",
      "index           AAC_XGBClassifier_no_hypertuning  \n",
      "index          AAC_LGBMClassifier_no_hypertuning  \n",
      "index    AAC_LogisticRegression_with_hypertuning  \n",
      "index                   AAC_SVC_with_hypertuning  \n",
      "index         AAC_XGBClassifier_with_hypertuning  \n",
      "index        AAC_LGBMClassifier_with_hypertuning  \n",
      "index    APAAC_LogisticRegression_no_hypertuning  \n",
      "index                   APAAC_SVC_no_hypertuning  \n",
      "index         APAAC_XGBClassifier_no_hypertuning  \n",
      "index        APAAC_LGBMClassifier_no_hypertuning  \n",
      "index  APAAC_LogisticRegression_with_hypertuning  \n",
      "Optimizing APAAC SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 10:17:27,791]\u001b[0m Trial 0 finished with value: 0.5177865612648221 and parameters: {'svc_c': 10.558646932590793, 'svc_gamma': 26.536802544944056}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:28,158]\u001b[0m Trial 1 finished with value: 0.5790513833992095 and parameters: {'svc_c': 42.135889710368524, 'svc_gamma': 2.189225733502864}. Best is trial 1 with value: 0.5790513833992095.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:28,623]\u001b[0m Trial 2 finished with value: 0.5197628458498024 and parameters: {'svc_c': 5.014263037747232, 'svc_gamma': 18.42537080388125}. Best is trial 1 with value: 0.5790513833992095.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:29,086]\u001b[0m Trial 3 finished with value: 0.5197628458498024 and parameters: {'svc_c': 60.001335134357745, 'svc_gamma': 15.201376588476053}. Best is trial 1 with value: 0.5790513833992095.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:29,458]\u001b[0m Trial 4 finished with value: 0.5158102766798419 and parameters: {'svc_c': 54.11795105196635, 'svc_gamma': 98.87487609830669}. Best is trial 1 with value: 0.5790513833992095.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:29,819]\u001b[0m Trial 5 finished with value: 0.5158102766798419 and parameters: {'svc_c': 59.4532605336955, 'svc_gamma': 87.19340338459088}. Best is trial 1 with value: 0.5790513833992095.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:30,240]\u001b[0m Trial 6 finished with value: 0.5158102766798419 and parameters: {'svc_c': 35.33860921027635, 'svc_gamma': 42.46861446168044}. Best is trial 1 with value: 0.5790513833992095.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:30,621]\u001b[0m Trial 7 finished with value: 0.5158102766798419 and parameters: {'svc_c': 63.4452735241725, 'svc_gamma': 80.41606792314283}. Best is trial 1 with value: 0.5790513833992095.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:31,033]\u001b[0m Trial 8 finished with value: 0.5158102766798419 and parameters: {'svc_c': 43.15545432807979, 'svc_gamma': 43.2235956777387}. Best is trial 1 with value: 0.5790513833992095.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:31,415]\u001b[0m Trial 9 finished with value: 0.5158102766798419 and parameters: {'svc_c': 38.37418419976335, 'svc_gamma': 72.16642904940934}. Best is trial 1 with value: 0.5790513833992095.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:31,755]\u001b[0m Trial 10 finished with value: 0.6225296442687747 and parameters: {'svc_c': 89.78886227633494, 'svc_gamma': 1.1887975619417617}. Best is trial 10 with value: 0.6225296442687747.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:32,087]\u001b[0m Trial 11 finished with value: 0.5573122529644269 and parameters: {'svc_c': 94.16332452912292, 'svc_gamma': 2.5387147845274116}. Best is trial 10 with value: 0.6225296442687747.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:32,423]\u001b[0m Trial 12 finished with value: 0.6976284584980237 and parameters: {'svc_c': 98.8937569001853, 'svc_gamma': 0.6301957749308853}. Best is trial 12 with value: 0.6976284584980237.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:32,867]\u001b[0m Trial 13 finished with value: 0.5177865612648221 and parameters: {'svc_c': 97.14007608894576, 'svc_gamma': 27.373969894918286}. Best is trial 12 with value: 0.6976284584980237.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:33,224]\u001b[0m Trial 14 finished with value: 0.6521739130434783 and parameters: {'svc_c': 88.24138868648035, 'svc_gamma': 0.9334118938743842}. Best is trial 12 with value: 0.6976284584980237.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:33,628]\u001b[0m Trial 15 finished with value: 0.5158102766798419 and parameters: {'svc_c': 82.701432536744, 'svc_gamma': 57.694408288843064}. Best is trial 12 with value: 0.6976284584980237.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:34,034]\u001b[0m Trial 16 finished with value: 0.5197628458498024 and parameters: {'svc_c': 77.27769155452015, 'svc_gamma': 13.006212409498891}. Best is trial 12 with value: 0.6976284584980237.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:34,489]\u001b[0m Trial 17 finished with value: 0.5177865612648221 and parameters: {'svc_c': 75.12727395765444, 'svc_gamma': 31.103684526075043}. Best is trial 12 with value: 0.6976284584980237.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:34,956]\u001b[0m Trial 18 finished with value: 0.5197628458498024 and parameters: {'svc_c': 98.2063904737042, 'svc_gamma': 12.198654131854418}. Best is trial 12 with value: 0.6976284584980237.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:35,291]\u001b[0m Trial 19 finished with value: 0.6541501976284585 and parameters: {'svc_c': 86.1587626532559, 'svc_gamma': 0.9261068724241228}. Best is trial 12 with value: 0.6976284584980237.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:35,756]\u001b[0m Trial 20 finished with value: 0.5158102766798419 and parameters: {'svc_c': 70.1200960358571, 'svc_gamma': 35.45528475690065}. Best is trial 12 with value: 0.6976284584980237.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:36,094]\u001b[0m Trial 21 finished with value: 0.6561264822134387 and parameters: {'svc_c': 83.28435083824252, 'svc_gamma': 0.9140659598955869}. Best is trial 12 with value: 0.6976284584980237.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:36,547]\u001b[0m Trial 22 finished with value: 0.5197628458498024 and parameters: {'svc_c': 85.54018506691943, 'svc_gamma': 20.651062290539805}. Best is trial 12 with value: 0.6976284584980237.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:36,953]\u001b[0m Trial 23 finished with value: 0.5217391304347826 and parameters: {'svc_c': 99.406575394612, 'svc_gamma': 10.033269985252222}. Best is trial 12 with value: 0.6976284584980237.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:37,368]\u001b[0m Trial 24 finished with value: 0.5197628458498024 and parameters: {'svc_c': 83.75167962543918, 'svc_gamma': 11.113981761307508}. Best is trial 12 with value: 0.6976284584980237.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:37,825]\u001b[0m Trial 25 finished with value: 0.5197628458498024 and parameters: {'svc_c': 90.30280912069303, 'svc_gamma': 22.9758524158192}. Best is trial 12 with value: 0.6976284584980237.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:38,203]\u001b[0m Trial 26 finished with value: 0.525691699604743 and parameters: {'svc_c': 69.6396876507924, 'svc_gamma': 5.949448073755262}. Best is trial 12 with value: 0.6976284584980237.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:38,583]\u001b[0m Trial 27 finished with value: 0.5217391304347826 and parameters: {'svc_c': 79.77677108315578, 'svc_gamma': 8.05124474801028}. Best is trial 12 with value: 0.6976284584980237.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:39,024]\u001b[0m Trial 28 finished with value: 0.5197628458498024 and parameters: {'svc_c': 91.39764327575044, 'svc_gamma': 17.183580280818724}. Best is trial 12 with value: 0.6976284584980237.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:39,511]\u001b[0m Trial 29 finished with value: 0.5197628458498024 and parameters: {'svc_c': 99.40671197450082, 'svc_gamma': 23.00124442299103}. Best is trial 12 with value: 0.6976284584980237.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:39,937]\u001b[0m Trial 30 finished with value: 0.5217391304347826 and parameters: {'svc_c': 83.28426861672897, 'svc_gamma': 8.082829215562432}. Best is trial 12 with value: 0.6976284584980237.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:40,359]\u001b[0m Trial 31 finished with value: 0.5296442687747036 and parameters: {'svc_c': 88.32305471424098, 'svc_gamma': 4.592134541919601}. Best is trial 12 with value: 0.6976284584980237.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:40,711]\u001b[0m Trial 32 finished with value: 0.8043478260869565 and parameters: {'svc_c': 92.72241595925865, 'svc_gamma': 0.3020281223186323}. Best is trial 32 with value: 0.8043478260869565.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:41,099]\u001b[0m Trial 33 finished with value: 0.6086956521739131 and parameters: {'svc_c': 92.48666772552531, 'svc_gamma': 1.6223525363851379}. Best is trial 32 with value: 0.8043478260869565.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:41,580]\u001b[0m Trial 34 finished with value: 0.5197628458498024 and parameters: {'svc_c': 74.32070537468168, 'svc_gamma': 16.05121086492048}. Best is trial 32 with value: 0.8043478260869565.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:41,943]\u001b[0m Trial 35 finished with value: 0.7015810276679841 and parameters: {'svc_c': 94.19277174321769, 'svc_gamma': 0.6137706963504594}. Best is trial 32 with value: 0.8043478260869565.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:42,358]\u001b[0m Trial 36 finished with value: 0.5217391304347826 and parameters: {'svc_c': 92.98455174250122, 'svc_gamma': 8.697103179606891}. Best is trial 32 with value: 0.8043478260869565.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:42,812]\u001b[0m Trial 37 finished with value: 0.5197628458498024 and parameters: {'svc_c': 99.43055307375076, 'svc_gamma': 14.96851315595066}. Best is trial 32 with value: 0.8043478260869565.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:43,301]\u001b[0m Trial 38 finished with value: 0.5197628458498024 and parameters: {'svc_c': 93.64465770670414, 'svc_gamma': 19.088997124390442}. Best is trial 32 with value: 0.8043478260869565.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:43,723]\u001b[0m Trial 39 finished with value: 0.5276679841897233 and parameters: {'svc_c': 83.34451844376244, 'svc_gamma': 5.683459916643077}. Best is trial 32 with value: 0.8043478260869565.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:44,176]\u001b[0m Trial 40 finished with value: 0.5197628458498024 and parameters: {'svc_c': 79.66514771506463, 'svc_gamma': 13.491612268675501}. Best is trial 32 with value: 0.8043478260869565.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:44,503]\u001b[0m Trial 41 finished with value: 0.8280632411067194 and parameters: {'svc_c': 87.16327229222483, 'svc_gamma': 0.1691526273321532}. Best is trial 41 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:44,884]\u001b[0m Trial 42 finished with value: 0.7094861660079052 and parameters: {'svc_c': 94.82903037086575, 'svc_gamma': 0.5888205945429527}. Best is trial 41 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:45,286]\u001b[0m Trial 43 finished with value: 0.525691699604743 and parameters: {'svc_c': 94.7323613736594, 'svc_gamma': 5.904604302669829}. Best is trial 41 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:45,687]\u001b[0m Trial 44 finished with value: 0.5237154150197628 and parameters: {'svc_c': 94.62049714913726, 'svc_gamma': 7.185297392946178}. Best is trial 41 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:46,044]\u001b[0m Trial 45 finished with value: 0.8122529644268774 and parameters: {'svc_c': 87.64294557168266, 'svc_gamma': 0.27687856578433956}. Best is trial 41 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:46,496]\u001b[0m Trial 46 finished with value: 0.5197628458498024 and parameters: {'svc_c': 89.99527774515845, 'svc_gamma': 11.665689715405861}. Best is trial 41 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:46,885]\u001b[0m Trial 47 finished with value: 0.5276679841897233 and parameters: {'svc_c': 52.28098577992823, 'svc_gamma': 5.3921038031463215}. Best is trial 41 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:47,240]\u001b[0m Trial 48 finished with value: 0.7944664031620553 and parameters: {'svc_c': 87.6100995941699, 'svc_gamma': 0.3386809618496058}. Best is trial 41 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:47,690]\u001b[0m Trial 49 finished with value: 0.5197628458498024 and parameters: {'svc_c': 87.23733676328385, 'svc_gamma': 18.053881170081684}. Best is trial 41 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:48,131]\u001b[0m Trial 50 finished with value: 0.5177865612648221 and parameters: {'svc_c': 78.85094721092025, 'svc_gamma': 11.445467399982004}. Best is trial 41 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:48,536]\u001b[0m Trial 51 finished with value: 0.5335968379446641 and parameters: {'svc_c': 95.63638804629758, 'svc_gamma': 4.058196863836986}. Best is trial 41 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:48,917]\u001b[0m Trial 52 finished with value: 0.6086956521739131 and parameters: {'svc_c': 90.92995651694638, 'svc_gamma': 1.622920060655138}. Best is trial 41 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:49,306]\u001b[0m Trial 53 finished with value: 0.5296442687747036 and parameters: {'svc_c': 88.0223241890579, 'svc_gamma': 4.805338237035077}. Best is trial 41 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:49,682]\u001b[0m Trial 54 finished with value: 0.7944664031620553 and parameters: {'svc_c': 96.24211647210197, 'svc_gamma': 0.34062988674925226}. Best is trial 41 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:50,006]\u001b[0m Trial 55 finished with value: 0.8300395256916996 and parameters: {'svc_c': 86.65233591417928, 'svc_gamma': 0.20601537001361156}. Best is trial 55 with value: 0.8300395256916996.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:50,407]\u001b[0m Trial 56 finished with value: 0.5217391304347826 and parameters: {'svc_c': 86.90684494069535, 'svc_gamma': 9.088325718540831}. Best is trial 55 with value: 0.8300395256916996.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:50,838]\u001b[0m Trial 57 finished with value: 0.5197628458498024 and parameters: {'svc_c': 74.572676405482, 'svc_gamma': 13.176596396969936}. Best is trial 55 with value: 0.8300395256916996.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:51,085]\u001b[0m Trial 58 finished with value: 0.8596837944664032 and parameters: {'svc_c': 81.00794411499099, 'svc_gamma': 0.03264730820833686}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:51,524]\u001b[0m Trial 59 finished with value: 0.5217391304347826 and parameters: {'svc_c': 80.34991750878339, 'svc_gamma': 9.095987522493552}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:51,988]\u001b[0m Trial 60 finished with value: 0.5197628458498024 and parameters: {'svc_c': 65.56505560630194, 'svc_gamma': 14.801886671610589}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:52,374]\u001b[0m Trial 61 finished with value: 0.5375494071146245 and parameters: {'svc_c': 85.09526552001813, 'svc_gamma': 3.6232176209653417}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:52,763]\u001b[0m Trial 62 finished with value: 0.5296442687747036 and parameters: {'svc_c': 81.1777711048205, 'svc_gamma': 4.729876905144239}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:53,079]\u001b[0m Trial 63 finished with value: 0.8300395256916996 and parameters: {'svc_c': 90.1773141851233, 'svc_gamma': 0.17083912486356811}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:53,478]\u001b[0m Trial 64 finished with value: 0.5237154150197628 and parameters: {'svc_c': 85.73593630884142, 'svc_gamma': 7.086078211975728}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:53,896]\u001b[0m Trial 65 finished with value: 0.5197628458498024 and parameters: {'svc_c': 76.41863656952991, 'svc_gamma': 10.636791615783807}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:54,278]\u001b[0m Trial 66 finished with value: 0.5434782608695652 and parameters: {'svc_c': 89.79584662781457, 'svc_gamma': 3.320892712250834}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:54,540]\u001b[0m Trial 67 finished with value: 0.8399209486166008 and parameters: {'svc_c': 80.93275501092367, 'svc_gamma': 0.07829196989247443}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:54,955]\u001b[0m Trial 68 finished with value: 0.5335968379446641 and parameters: {'svc_c': 81.46690126703464, 'svc_gamma': 3.959132891114629}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:55,371]\u001b[0m Trial 69 finished with value: 0.5217391304347826 and parameters: {'svc_c': 76.9182305817821, 'svc_gamma': 8.507651998835623}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:55,848]\u001b[0m Trial 70 finished with value: 0.5197628458498024 and parameters: {'svc_c': 72.76239028304269, 'svc_gamma': 15.955696821485446}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:56,161]\u001b[0m Trial 71 finished with value: 0.8320158102766798 and parameters: {'svc_c': 85.9178814522318, 'svc_gamma': 0.1720285447023689}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:56,399]\u001b[0m Trial 72 finished with value: 0.8359683794466403 and parameters: {'svc_c': 83.81207667794475, 'svc_gamma': 0.08541521076692143}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:56,778]\u001b[0m Trial 73 finished with value: 0.5335968379446641 and parameters: {'svc_c': 84.7349555854745, 'svc_gamma': 4.103167413939759}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:57,181]\u001b[0m Trial 74 finished with value: 0.5237154150197628 and parameters: {'svc_c': 82.62700553768506, 'svc_gamma': 6.946417644962393}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:57,549]\u001b[0m Trial 75 finished with value: 0.5434782608695652 and parameters: {'svc_c': 78.17672456935134, 'svc_gamma': 2.782076305876209}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:57,996]\u001b[0m Trial 76 finished with value: 0.5217391304347826 and parameters: {'svc_c': 90.80005036326021, 'svc_gamma': 10.359149583189058}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:58,382]\u001b[0m Trial 77 finished with value: 0.5454545454545454 and parameters: {'svc_c': 72.1654254415568, 'svc_gamma': 2.818474575588808}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:58,790]\u001b[0m Trial 78 finished with value: 0.525691699604743 and parameters: {'svc_c': 82.19468102875742, 'svc_gamma': 6.089516442933424}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:59,191]\u001b[0m Trial 79 finished with value: 0.5217391304347826 and parameters: {'svc_c': 77.69207757464169, 'svc_gamma': 8.089685450209904}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:59,634]\u001b[0m Trial 80 finished with value: 0.5197628458498024 and parameters: {'svc_c': 97.71964828115779, 'svc_gamma': 13.384178193978283}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:17:59,989]\u001b[0m Trial 81 finished with value: 0.7470355731225297 and parameters: {'svc_c': 92.16113096399006, 'svc_gamma': 0.46861610660920744}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:00,324]\u001b[0m Trial 82 finished with value: 0.8181818181818182 and parameters: {'svc_c': 88.7858735897932, 'svc_gamma': 0.2533537939956902}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:00,704]\u001b[0m Trial 83 finished with value: 0.5434782608695652 and parameters: {'svc_c': 85.06199744146299, 'svc_gamma': 2.801048646357889}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:00,937]\u001b[0m Trial 84 finished with value: 0.8478260869565217 and parameters: {'svc_c': 87.41861066525377, 'svc_gamma': 0.044040464538930874}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:01,324]\u001b[0m Trial 85 finished with value: 0.5237154150197628 and parameters: {'svc_c': 88.55766417534512, 'svc_gamma': 7.118030536349844}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:01,743]\u001b[0m Trial 86 finished with value: 0.5177865612648221 and parameters: {'svc_c': 80.19933366380252, 'svc_gamma': 11.261864810935222}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:02,126]\u001b[0m Trial 87 finished with value: 0.5395256916996047 and parameters: {'svc_c': 83.4615953431622, 'svc_gamma': 3.448012850315959}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:02,529]\u001b[0m Trial 88 finished with value: 0.525691699604743 and parameters: {'svc_c': 96.59341840573717, 'svc_gamma': 5.833876623400614}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:02,891]\u001b[0m Trial 89 finished with value: 0.5454545454545454 and parameters: {'svc_c': 85.28556558008734, 'svc_gamma': 2.86739293646677}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:03,265]\u001b[0m Trial 90 finished with value: 0.5810276679841897 and parameters: {'svc_c': 91.12729170384151, 'svc_gamma': 2.14843414109695}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:03,499]\u001b[0m Trial 91 finished with value: 0.8537549407114624 and parameters: {'svc_c': 88.87340616117449, 'svc_gamma': 0.03718813355429451}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:03,874]\u001b[0m Trial 92 finished with value: 0.6936758893280632 and parameters: {'svc_c': 89.08251524031623, 'svc_gamma': 0.7165364210394551}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:04,266]\u001b[0m Trial 93 finished with value: 0.5276679841897233 and parameters: {'svc_c': 92.8518158382546, 'svc_gamma': 5.649383175722882}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:04,671]\u001b[0m Trial 94 finished with value: 0.5217391304347826 and parameters: {'svc_c': 86.83687604271364, 'svc_gamma': 9.768359760730995}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:05,019]\u001b[0m Trial 95 finished with value: 0.5632411067193676 and parameters: {'svc_c': 81.50117115782444, 'svc_gamma': 2.477657656121462}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:05,420]\u001b[0m Trial 96 finished with value: 0.5237154150197628 and parameters: {'svc_c': 89.17237432402598, 'svc_gamma': 6.424256706116277}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:05,839]\u001b[0m Trial 97 finished with value: 0.5217391304347826 and parameters: {'svc_c': 83.80863158567506, 'svc_gamma': 8.451741935165941}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:06,146]\u001b[0m Trial 98 finished with value: 0.8280632411067194 and parameters: {'svc_c': 78.54056457184555, 'svc_gamma': 0.16198547214807213}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:06,534]\u001b[0m Trial 99 finished with value: 0.5296442687747036 and parameters: {'svc_c': 80.02076506697634, 'svc_gamma': 4.539133322221907}. Best is trial 58 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:06,541]\u001b[0m A new study created in memory with name: no-name-0c872a0f-ee82-459b-9df0-270ea6d2a520\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "index        APAAC  LogisticRegression             True   \n",
      "index        APAAC                 SVC             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "index  {'C': 0.09972241221770178, 'penalty': 'l1', 's...  0.893281   \n",
      "index  {'svc_c': 81.00794411499099, 'svc_gamma': 0.03...  0.859684   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "index     0.885714     0.900383   0.893004  0.889344  0.786319   \n",
      "index     0.869388     0.850575   0.845238  0.857143  0.719608   \n",
      "\n",
      "                                           index  \n",
      "index      AAC_LogisticRegression_no_hypertuning  \n",
      "index                     AAC_SVC_no_hypertuning  \n",
      "index           AAC_XGBClassifier_no_hypertuning  \n",
      "index          AAC_LGBMClassifier_no_hypertuning  \n",
      "index    AAC_LogisticRegression_with_hypertuning  \n",
      "index                   AAC_SVC_with_hypertuning  \n",
      "index         AAC_XGBClassifier_with_hypertuning  \n",
      "index        AAC_LGBMClassifier_with_hypertuning  \n",
      "index    APAAC_LogisticRegression_no_hypertuning  \n",
      "index                   APAAC_SVC_no_hypertuning  \n",
      "index         APAAC_XGBClassifier_no_hypertuning  \n",
      "index        APAAC_LGBMClassifier_no_hypertuning  \n",
      "index  APAAC_LogisticRegression_with_hypertuning  \n",
      "index                 APAAC_SVC_with_hypertuning  \n",
      "Optimizing APAAC XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 10:18:06,925]\u001b[0m Trial 0 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.20770919351354106, 'max_depth': 2, 'n_estimators': 183}. Best is trial 0 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:09,180]\u001b[0m Trial 1 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.1397319714351558, 'max_depth': 3, 'n_estimators': 811}. Best is trial 0 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:09,817]\u001b[0m Trial 2 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.21557448587004335, 'max_depth': 3, 'n_estimators': 181}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:13,241]\u001b[0m Trial 3 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.08633580978558991, 'max_depth': 4, 'n_estimators': 964}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:14,215]\u001b[0m Trial 4 finished with value: 0.8656126482213439 and parameters: {'learning_rate': 0.22960106700141195, 'max_depth': 3, 'n_estimators': 315}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:15,979]\u001b[0m Trial 5 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.2593108640139175, 'max_depth': 2, 'n_estimators': 735}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:18,033]\u001b[0m Trial 6 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.21801193060568907, 'max_depth': 4, 'n_estimators': 625}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:21,094]\u001b[0m Trial 7 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.12887070616489354, 'max_depth': 3, 'n_estimators': 943}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:24,998]\u001b[0m Trial 8 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.0867088446226504, 'max_depth': 5, 'n_estimators': 926}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:25,974]\u001b[0m Trial 9 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.16870528029169296, 'max_depth': 6, 'n_estimators': 179}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:27,619]\u001b[0m Trial 10 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.2851600665810642, 'max_depth': 5, 'n_estimators': 462}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:27,968]\u001b[0m Trial 11 finished with value: 0.8675889328063241 and parameters: {'learning_rate': 0.19159398733593816, 'max_depth': 2, 'n_estimators': 129}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:28,725]\u001b[0m Trial 12 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.29802163728835884, 'max_depth': 2, 'n_estimators': 345}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:29,581]\u001b[0m Trial 13 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.20456233474713273, 'max_depth': 3, 'n_estimators': 273}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:30,844]\u001b[0m Trial 14 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.03789274531142031, 'max_depth': 2, 'n_estimators': 470}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:31,571]\u001b[0m Trial 15 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.24183066468330403, 'max_depth': 3, 'n_estimators': 214}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:32,421]\u001b[0m Trial 16 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.17913067166367325, 'max_depth': 2, 'n_estimators': 380}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:32,989]\u001b[0m Trial 17 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.24948220977763774, 'max_depth': 4, 'n_estimators': 128}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:34,641]\u001b[0m Trial 18 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.20655740575904624, 'max_depth': 3, 'n_estimators': 510}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:37,068]\u001b[0m Trial 19 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.16245931364064842, 'max_depth': 4, 'n_estimators': 615}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:38,605]\u001b[0m Trial 20 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.2683124684889191, 'max_depth': 5, 'n_estimators': 240}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:39,110]\u001b[0m Trial 21 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.24317801194601812, 'max_depth': 4, 'n_estimators': 101}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:39,636]\u001b[0m Trial 22 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.22884150666098815, 'max_depth': 3, 'n_estimators': 103}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:40,323]\u001b[0m Trial 23 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.23203647582707804, 'max_depth': 4, 'n_estimators': 120}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:41,586]\u001b[0m Trial 24 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.26823533175589764, 'max_depth': 3, 'n_estimators': 400}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:42,228]\u001b[0m Trial 25 finished with value: 0.8675889328063241 and parameters: {'learning_rate': 0.23404089643222659, 'max_depth': 5, 'n_estimators': 107}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:43,870]\u001b[0m Trial 26 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.1914463094049089, 'max_depth': 6, 'n_estimators': 308}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:45,082]\u001b[0m Trial 27 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.25837845479563243, 'max_depth': 4, 'n_estimators': 230}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:45,860]\u001b[0m Trial 28 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.2244863369632195, 'max_depth': 3, 'n_estimators': 158}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:46,569]\u001b[0m Trial 29 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.20831872245402966, 'max_depth': 3, 'n_estimators': 199}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:47,692]\u001b[0m Trial 30 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.24575841916614602, 'max_depth': 4, 'n_estimators': 270}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:48,845]\u001b[0m Trial 31 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.24755571135648213, 'max_depth': 4, 'n_estimators': 274}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:49,620]\u001b[0m Trial 32 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.28002631850755977, 'max_depth': 4, 'n_estimators': 181}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:50,356]\u001b[0m Trial 33 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.2770083277673472, 'max_depth': 4, 'n_estimators': 174}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:51,309]\u001b[0m Trial 34 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.27843107577245535, 'max_depth': 5, 'n_estimators': 172}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:51,719]\u001b[0m Trial 35 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.2997035978801007, 'max_depth': 3, 'n_estimators': 106}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:54,082]\u001b[0m Trial 36 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.22893246931725772, 'max_depth': 3, 'n_estimators': 790}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:55,633]\u001b[0m Trial 37 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.2607197333670117, 'max_depth': 4, 'n_estimators': 381}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:57,139]\u001b[0m Trial 38 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.2163922815366295, 'max_depth': 5, 'n_estimators': 237}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:18:58,522]\u001b[0m Trial 39 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.24633953465613417, 'max_depth': 4, 'n_estimators': 330}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:00,543]\u001b[0m Trial 40 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.14542962593738432, 'max_depth': 3, 'n_estimators': 630}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:01,806]\u001b[0m Trial 41 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.2534120080363962, 'max_depth': 4, 'n_estimators': 276}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:02,558]\u001b[0m Trial 42 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.24087747315632618, 'max_depth': 4, 'n_estimators': 168}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:03,304]\u001b[0m Trial 43 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.22053807995089994, 'max_depth': 5, 'n_estimators': 142}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:04,094]\u001b[0m Trial 44 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.2874367299078717, 'max_depth': 4, 'n_estimators': 196}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:04,989]\u001b[0m Trial 45 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.27411696275289177, 'max_depth': 3, 'n_estimators': 252}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:05,696]\u001b[0m Trial 46 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.2577065096624919, 'max_depth': 2, 'n_estimators': 303}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:06,296]\u001b[0m Trial 47 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.28802881470374736, 'max_depth': 4, 'n_estimators': 104}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:06,935]\u001b[0m Trial 48 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.2877285932692016, 'max_depth': 6, 'n_estimators': 108}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:07,470]\u001b[0m Trial 49 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.2652922239411843, 'max_depth': 3, 'n_estimators': 150}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:08,307]\u001b[0m Trial 50 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.2949723077311628, 'max_depth': 4, 'n_estimators': 209}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:08,963]\u001b[0m Trial 51 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.23835075155388002, 'max_depth': 4, 'n_estimators': 151}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:09,464]\u001b[0m Trial 52 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.2776651277334662, 'max_depth': 4, 'n_estimators': 100}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:10,296]\u001b[0m Trial 53 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.24833210253125562, 'max_depth': 4, 'n_estimators': 206}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:11,007]\u001b[0m Trial 54 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.26587752092860223, 'max_depth': 5, 'n_estimators': 142}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:11,869]\u001b[0m Trial 55 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.22965394680935847, 'max_depth': 3, 'n_estimators': 262}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:13,901]\u001b[0m Trial 56 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.28336022618253975, 'max_depth': 2, 'n_estimators': 863}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:14,985]\u001b[0m Trial 57 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.240072656826985, 'max_depth': 4, 'n_estimators': 186}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:15,783]\u001b[0m Trial 58 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.25696775313845027, 'max_depth': 3, 'n_estimators': 224}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:17,427]\u001b[0m Trial 59 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.19617374114371355, 'max_depth': 4, 'n_estimators': 423}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:18,933]\u001b[0m Trial 60 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.2091587870843868, 'max_depth': 3, 'n_estimators': 359}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:19,815]\u001b[0m Trial 61 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.2197141971223665, 'max_depth': 5, 'n_estimators': 136}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:20,653]\u001b[0m Trial 62 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.22352422775077269, 'max_depth': 6, 'n_estimators': 137}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:22,891]\u001b[0m Trial 63 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.23427489407982818, 'max_depth': 5, 'n_estimators': 577}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:23,803]\u001b[0m Trial 64 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.21610114119023313, 'max_depth': 5, 'n_estimators': 172}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:25,271]\u001b[0m Trial 65 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.25176560586883845, 'max_depth': 4, 'n_estimators': 293}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:25,853]\u001b[0m Trial 66 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.2697845050206195, 'max_depth': 5, 'n_estimators': 101}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:26,440]\u001b[0m Trial 67 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.2418625422384198, 'max_depth': 4, 'n_estimators': 134}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:28,860]\u001b[0m Trial 68 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.19893202962009146, 'max_depth': 4, 'n_estimators': 705}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:29,570]\u001b[0m Trial 69 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.18159265369922356, 'max_depth': 3, 'n_estimators': 192}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:30,710]\u001b[0m Trial 70 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.21283269891154422, 'max_depth': 5, 'n_estimators': 215}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:31,396]\u001b[0m Trial 71 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.2875470242185251, 'max_depth': 6, 'n_estimators': 117}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:32,207]\u001b[0m Trial 72 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.2950797239286441, 'max_depth': 6, 'n_estimators': 162}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:32,951]\u001b[0m Trial 73 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.2718632346124924, 'max_depth': 6, 'n_estimators': 129}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:34,084]\u001b[0m Trial 74 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.2623991868516966, 'max_depth': 6, 'n_estimators': 236}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:34,655]\u001b[0m Trial 75 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.2832682018145925, 'max_depth': 4, 'n_estimators': 123}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:35,843]\u001b[0m Trial 76 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.23210037069774295, 'max_depth': 5, 'n_estimators': 182}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:36,719]\u001b[0m Trial 77 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.2284115199513117, 'max_depth': 4, 'n_estimators': 191}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:37,935]\u001b[0m Trial 78 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.2533015560557055, 'max_depth': 5, 'n_estimators': 166}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:39,697]\u001b[0m Trial 79 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.2895977951653332, 'max_depth': 3, 'n_estimators': 253}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:40,175]\u001b[0m Trial 80 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.28019447486907606, 'max_depth': 2, 'n_estimators': 116}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:41,037]\u001b[0m Trial 81 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.2341108248565959, 'max_depth': 6, 'n_estimators': 151}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:41,947]\u001b[0m Trial 82 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.2212470008893951, 'max_depth': 5, 'n_estimators': 182}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:42,883]\u001b[0m Trial 83 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.27055324437545697, 'max_depth': 4, 'n_estimators': 216}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:43,459]\u001b[0m Trial 84 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.262878605776045, 'max_depth': 4, 'n_estimators': 129}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:44,294]\u001b[0m Trial 85 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.24525190591818086, 'max_depth': 6, 'n_estimators': 152}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:44,894]\u001b[0m Trial 86 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.29247309003517385, 'max_depth': 5, 'n_estimators': 103}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:45,772]\u001b[0m Trial 87 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.29821132938992506, 'max_depth': 4, 'n_estimators': 181}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:46,922]\u001b[0m Trial 88 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.22429627113139727, 'max_depth': 4, 'n_estimators': 278}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:47,755]\u001b[0m Trial 89 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.2507135313688761, 'max_depth': 3, 'n_estimators': 240}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:49,144]\u001b[0m Trial 90 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.2779232469318435, 'max_depth': 5, 'n_estimators': 321}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:49,762]\u001b[0m Trial 91 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.2873289711524205, 'max_depth': 6, 'n_estimators': 100}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:53,048]\u001b[0m Trial 92 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.28512405486327186, 'max_depth': 6, 'n_estimators': 1000}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:53,787]\u001b[0m Trial 93 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.27309507582186926, 'max_depth': 6, 'n_estimators': 127}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:54,591]\u001b[0m Trial 94 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.25708257186707545, 'max_depth': 6, 'n_estimators': 154}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:55,295]\u001b[0m Trial 95 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.23791974728542112, 'max_depth': 6, 'n_estimators': 112}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:56,227]\u001b[0m Trial 96 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.2641534624222398, 'max_depth': 4, 'n_estimators': 196}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:56,932]\u001b[0m Trial 97 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.2923654601675701, 'max_depth': 4, 'n_estimators': 169}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:57,406]\u001b[0m Trial 98 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.2035080725812571, 'max_depth': 3, 'n_estimators': 139}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:58,115]\u001b[0m Trial 99 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.21531078179488067, 'max_depth': 6, 'n_estimators': 119}. Best is trial 2 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:19:58,126]\u001b[0m A new study created in memory with name: no-name-47fc870c-b53a-4aa4-ac95-a75e358431e7\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "index        APAAC  LogisticRegression             True   \n",
      "index        APAAC                 SVC             True   \n",
      "index        APAAC       XGBClassifier             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "index  {'C': 0.09972241221770178, 'penalty': 'l1', 's...  0.893281   \n",
      "index  {'svc_c': 81.00794411499099, 'svc_gamma': 0.03...  0.859684   \n",
      "index  {'learning_rate': 0.21557448587004335, 'max_de...  0.891304   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "index     0.885714     0.900383   0.893004  0.889344  0.786319   \n",
      "index     0.869388     0.850575   0.845238  0.857143  0.719608   \n",
      "index     0.885714     0.896552   0.889344  0.887526  0.782370   \n",
      "\n",
      "                                           index  \n",
      "index      AAC_LogisticRegression_no_hypertuning  \n",
      "index                     AAC_SVC_no_hypertuning  \n",
      "index           AAC_XGBClassifier_no_hypertuning  \n",
      "index          AAC_LGBMClassifier_no_hypertuning  \n",
      "index    AAC_LogisticRegression_with_hypertuning  \n",
      "index                   AAC_SVC_with_hypertuning  \n",
      "index         AAC_XGBClassifier_with_hypertuning  \n",
      "index        AAC_LGBMClassifier_with_hypertuning  \n",
      "index    APAAC_LogisticRegression_no_hypertuning  \n",
      "index                   APAAC_SVC_no_hypertuning  \n",
      "index         APAAC_XGBClassifier_no_hypertuning  \n",
      "index        APAAC_LGBMClassifier_no_hypertuning  \n",
      "index  APAAC_LogisticRegression_with_hypertuning  \n",
      "index                 APAAC_SVC_with_hypertuning  \n",
      "index       APAAC_XGBClassifier_with_hypertuning  \n",
      "Optimizing APAAC LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 10:19:58,491]\u001b[0m Trial 0 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 48, 'max_depth': 37, 'learning_rate': 0.04630805574289482, 'n_estimators': 107}. Best is trial 0 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:00,045]\u001b[0m Trial 1 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 225, 'max_depth': 12, 'learning_rate': 0.21554888410581882, 'n_estimators': 1380}. Best is trial 1 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:00,984]\u001b[0m Trial 2 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 155, 'max_depth': 19, 'learning_rate': 0.1878955468734353, 'n_estimators': 279}. Best is trial 1 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:03,074]\u001b[0m Trial 3 finished with value: 0.883399209486166 and parameters: {'num_leaves': 247, 'max_depth': 24, 'learning_rate': 0.059362876278883606, 'n_estimators': 382}. Best is trial 1 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:03,805]\u001b[0m Trial 4 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 28, 'max_depth': 24, 'learning_rate': 0.27862741765577576, 'n_estimators': 682}. Best is trial 1 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:04,668]\u001b[0m Trial 5 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 189, 'max_depth': 40, 'learning_rate': 0.2626788035107903, 'n_estimators': 368}. Best is trial 5 with value: 0.8873517786561265.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:06,465]\u001b[0m Trial 6 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 123, 'max_depth': 37, 'learning_rate': 0.25106970941874746, 'n_estimators': 1732}. Best is trial 5 with value: 0.8873517786561265.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:08,895]\u001b[0m Trial 7 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 54, 'max_depth': 43, 'learning_rate': 0.04180126801818206, 'n_estimators': 975}. Best is trial 5 with value: 0.8873517786561265.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:09,722]\u001b[0m Trial 8 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 126, 'max_depth': 42, 'learning_rate': 0.18584457006431696, 'n_estimators': 318}. Best is trial 5 with value: 0.8873517786561265.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:11,542]\u001b[0m Trial 9 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 89, 'max_depth': 30, 'learning_rate': 0.030386813196448658, 'n_estimators': 276}. Best is trial 5 with value: 0.8873517786561265.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:11,946]\u001b[0m Trial 10 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 192, 'max_depth': 2, 'learning_rate': 0.29003647890630646, 'n_estimators': 1027}. Best is trial 5 with value: 0.8873517786561265.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:14,108]\u001b[0m Trial 11 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 158, 'max_depth': 34, 'learning_rate': 0.24432932370226415, 'n_estimators': 1939}. Best is trial 5 with value: 0.8873517786561265.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:15,743]\u001b[0m Trial 12 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 122, 'max_depth': 50, 'learning_rate': 0.299022393719336, 'n_estimators': 1626}. Best is trial 5 with value: 0.8873517786561265.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:17,589]\u001b[0m Trial 13 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 195, 'max_depth': 50, 'learning_rate': 0.24354913132344852, 'n_estimators': 1340}. Best is trial 13 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:19,403]\u001b[0m Trial 14 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 196, 'max_depth': 49, 'learning_rate': 0.13652066688655543, 'n_estimators': 1292}. Best is trial 13 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:20,420]\u001b[0m Trial 15 finished with value: 0.883399209486166 and parameters: {'num_leaves': 196, 'max_depth': 45, 'learning_rate': 0.24580339575206414, 'n_estimators': 733}. Best is trial 13 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:22,362]\u001b[0m Trial 16 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 165, 'max_depth': 40, 'learning_rate': 0.13789744986253258, 'n_estimators': 1310}. Best is trial 13 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:23,601]\u001b[0m Trial 17 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 244, 'max_depth': 31, 'learning_rate': 0.21032405896544543, 'n_estimators': 699}. Best is trial 13 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:24,689]\u001b[0m Trial 18 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 251, 'max_depth': 15, 'learning_rate': 0.20396998172976755, 'n_estimators': 710}. Best is trial 13 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:26,313]\u001b[0m Trial 19 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 228, 'max_depth': 30, 'learning_rate': 0.16939027614049923, 'n_estimators': 1180}. Best is trial 13 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:28,014]\u001b[0m Trial 20 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 222, 'max_depth': 6, 'learning_rate': 0.22767318097756406, 'n_estimators': 865}. Best is trial 13 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:29,028]\u001b[0m Trial 21 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 180, 'max_depth': 46, 'learning_rate': 0.26810994701918694, 'n_estimators': 473}. Best is trial 13 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:29,820]\u001b[0m Trial 22 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 168, 'max_depth': 47, 'learning_rate': 0.267955770624678, 'n_estimators': 539}. Best is trial 13 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:30,668]\u001b[0m Trial 23 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 213, 'max_depth': 31, 'learning_rate': 0.22533288946770183, 'n_estimators': 526}. Best is trial 13 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:32,105]\u001b[0m Trial 24 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 256, 'max_depth': 46, 'learning_rate': 0.2745659292079408, 'n_estimators': 1505}. Best is trial 13 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:33,900]\u001b[0m Trial 25 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 176, 'max_depth': 50, 'learning_rate': 0.23472805360617716, 'n_estimators': 863}. Best is trial 13 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:34,751]\u001b[0m Trial 26 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 148, 'max_depth': 35, 'learning_rate': 0.25922865006792056, 'n_estimators': 554}. Best is trial 13 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:36,004]\u001b[0m Trial 27 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 100, 'max_depth': 44, 'learning_rate': 0.2995284434155097, 'n_estimators': 1132}. Best is trial 13 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:37,285]\u001b[0m Trial 28 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 212, 'max_depth': 27, 'learning_rate': 0.20916384873082425, 'n_estimators': 897}. Best is trial 13 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:38,097]\u001b[0m Trial 29 finished with value: 0.8754940711462451 and parameters: {'num_leaves': 237, 'max_depth': 38, 'learning_rate': 0.23446788854681797, 'n_estimators': 148}. Best is trial 13 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:38,768]\u001b[0m Trial 30 finished with value: 0.883399209486166 and parameters: {'num_leaves': 209, 'max_depth': 20, 'learning_rate': 0.2713406546693494, 'n_estimators': 138}. Best is trial 13 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:39,567]\u001b[0m Trial 31 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 177, 'max_depth': 47, 'learning_rate': 0.2646174006977665, 'n_estimators': 524}. Best is trial 13 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:40,402]\u001b[0m Trial 32 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 144, 'max_depth': 47, 'learning_rate': 0.27726423704723385, 'n_estimators': 609}. Best is trial 13 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:41,229]\u001b[0m Trial 33 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 174, 'max_depth': 41, 'learning_rate': 0.25393290910361127, 'n_estimators': 461}. Best is trial 13 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:42,948]\u001b[0m Trial 34 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 142, 'max_depth': 34, 'learning_rate': 0.21568424014280385, 'n_estimators': 779}. Best is trial 13 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:44,796]\u001b[0m Trial 35 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 233, 'max_depth': 47, 'learning_rate': 0.24131451541609084, 'n_estimators': 1449}. Best is trial 13 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:45,599]\u001b[0m Trial 36 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 204, 'max_depth': 19, 'learning_rate': 0.28473147104462215, 'n_estimators': 420}. Best is trial 13 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:45,779]\u001b[0m Trial 37 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 2, 'max_depth': 43, 'learning_rate': 0.19843286175570002, 'n_estimators': 622}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:46,491]\u001b[0m Trial 38 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 16, 'max_depth': 37, 'learning_rate': 0.19632103406655665, 'n_estimators': 633}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:47,615]\u001b[0m Trial 39 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 59, 'max_depth': 26, 'learning_rate': 0.22155249139607391, 'n_estimators': 1111}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:47,793]\u001b[0m Trial 40 finished with value: 0.8754940711462451 and parameters: {'num_leaves': 4, 'max_depth': 42, 'learning_rate': 0.1807463395410751, 'n_estimators': 265}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:48,432]\u001b[0m Trial 41 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 39, 'max_depth': 44, 'learning_rate': 0.2606474385120072, 'n_estimators': 442}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:49,716]\u001b[0m Trial 42 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 108, 'max_depth': 48, 'learning_rate': 0.2142925907809983, 'n_estimators': 768}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:50,600]\u001b[0m Trial 43 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 75, 'max_depth': 39, 'learning_rate': 0.2502673340849357, 'n_estimators': 629}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:51,328]\u001b[0m Trial 44 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 184, 'max_depth': 50, 'learning_rate': 0.23296129641473706, 'n_estimators': 326}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:52,382]\u001b[0m Trial 45 finished with value: 0.883399209486166 and parameters: {'num_leaves': 163, 'max_depth': 44, 'learning_rate': 0.28611415961854664, 'n_estimators': 911}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:53,182]\u001b[0m Trial 46 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 138, 'max_depth': 42, 'learning_rate': 0.20035959298766212, 'n_estimators': 217}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:54,481]\u001b[0m Trial 47 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 114, 'max_depth': 36, 'learning_rate': 0.24646465370354442, 'n_estimators': 1021}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:56,530]\u001b[0m Trial 48 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 187, 'max_depth': 32, 'learning_rate': 0.26861669849642195, 'n_estimators': 1848}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:57,448]\u001b[0m Trial 49 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 133, 'max_depth': 46, 'learning_rate': 0.2185419979435223, 'n_estimators': 399}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:20:58,478]\u001b[0m Trial 50 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 241, 'max_depth': 22, 'learning_rate': 0.2568900329394243, 'n_estimators': 815}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:00,166]\u001b[0m Trial 51 finished with value: 0.8754940711462451 and parameters: {'num_leaves': 86, 'max_depth': 45, 'learning_rate': 0.2971942298720672, 'n_estimators': 1306}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:01,670]\u001b[0m Trial 52 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 168, 'max_depth': 43, 'learning_rate': 0.2927856941647377, 'n_estimators': 1604}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:02,940]\u001b[0m Trial 53 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 158, 'max_depth': 15, 'learning_rate': 0.27746390452797215, 'n_estimators': 1162}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:04,295]\u001b[0m Trial 54 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 99, 'max_depth': 40, 'learning_rate': 0.2869720004470977, 'n_estimators': 1252}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:06,006]\u001b[0m Trial 55 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 197, 'max_depth': 49, 'learning_rate': 0.2709352896745841, 'n_estimators': 1399}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:07,126]\u001b[0m Trial 56 finished with value: 0.8754940711462451 and parameters: {'num_leaves': 221, 'max_depth': 48, 'learning_rate': 0.29551170924539855, 'n_estimators': 954}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:08,036]\u001b[0m Trial 57 finished with value: 0.883399209486166 and parameters: {'num_leaves': 61, 'max_depth': 45, 'learning_rate': 0.2349141430319419, 'n_estimators': 665}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:09,284]\u001b[0m Trial 58 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 28, 'max_depth': 43, 'learning_rate': 0.2629697743053525, 'n_estimators': 1067}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:10,393]\u001b[0m Trial 59 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 201, 'max_depth': 28, 'learning_rate': 0.2440782420248201, 'n_estimators': 550}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:11,812]\u001b[0m Trial 60 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 217, 'max_depth': 39, 'learning_rate': 0.2803905172980538, 'n_estimators': 1229}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:12,952]\u001b[0m Trial 61 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 150, 'max_depth': 33, 'learning_rate': 0.22117508916748166, 'n_estimators': 778}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:14,176]\u001b[0m Trial 62 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 124, 'max_depth': 35, 'learning_rate': 0.21528531533258946, 'n_estimators': 715}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:15,668]\u001b[0m Trial 63 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 182, 'max_depth': 30, 'learning_rate': 0.20670326090598662, 'n_estimators': 483}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:16,617]\u001b[0m Trial 64 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 169, 'max_depth': 50, 'learning_rate': 0.25404301468741763, 'n_estimators': 579}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:17,884]\u001b[0m Trial 65 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 142, 'max_depth': 25, 'learning_rate': 0.1929858014249065, 'n_estimators': 810}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:18,708]\u001b[0m Trial 66 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 154, 'max_depth': 48, 'learning_rate': 0.230140597015686, 'n_estimators': 357}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:20,130]\u001b[0m Trial 67 finished with value: 0.8754940711462451 and parameters: {'num_leaves': 137, 'max_depth': 46, 'learning_rate': 0.181957116260337, 'n_estimators': 966}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:21,148]\u001b[0m Trial 68 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 249, 'max_depth': 28, 'learning_rate': 0.26822949668707585, 'n_estimators': 675}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:21,973]\u001b[0m Trial 69 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 256, 'max_depth': 22, 'learning_rate': 0.26933491437950907, 'n_estimators': 507}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:22,892]\u001b[0m Trial 70 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 246, 'max_depth': 41, 'learning_rate': 0.2808027153467753, 'n_estimators': 680}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:23,981]\u001b[0m Trial 71 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 229, 'max_depth': 27, 'learning_rate': 0.23801847119439043, 'n_estimators': 737}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:25,001]\u001b[0m Trial 72 finished with value: 0.883399209486166 and parameters: {'num_leaves': 236, 'max_depth': 29, 'learning_rate': 0.2534814341344893, 'n_estimators': 592}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:26,360]\u001b[0m Trial 73 finished with value: 0.883399209486166 and parameters: {'num_leaves': 247, 'max_depth': 23, 'learning_rate': 0.2254928273462362, 'n_estimators': 844}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:27,337]\u001b[0m Trial 74 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 207, 'max_depth': 33, 'learning_rate': 0.26335754988011456, 'n_estimators': 659}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:28,780]\u001b[0m Trial 75 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 209, 'max_depth': 32, 'learning_rate': 0.2637948212614204, 'n_estimators': 1377}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:30,260]\u001b[0m Trial 76 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 195, 'max_depth': 38, 'learning_rate': 0.2874045489677413, 'n_estimators': 1523}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:32,240]\u001b[0m Trial 77 finished with value: 0.8754940711462451 and parameters: {'num_leaves': 191, 'max_depth': 37, 'learning_rate': 0.27353483530979594, 'n_estimators': 1650}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:33,850]\u001b[0m Trial 78 finished with value: 0.883399209486166 and parameters: {'num_leaves': 225, 'max_depth': 34, 'learning_rate': 0.24806002597760932, 'n_estimators': 1470}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:35,353]\u001b[0m Trial 79 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 181, 'max_depth': 31, 'learning_rate': 0.28645143050393307, 'n_estimators': 1528}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:37,234]\u001b[0m Trial 80 finished with value: 0.8754940711462451 and parameters: {'num_leaves': 208, 'max_depth': 36, 'learning_rate': 0.26118931590373745, 'n_estimators': 1786}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:38,260]\u001b[0m Trial 81 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 199, 'max_depth': 44, 'learning_rate': 0.292291414607151, 'n_estimators': 641}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:39,578]\u001b[0m Trial 82 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 176, 'max_depth': 39, 'learning_rate': 0.28134460971807923, 'n_estimators': 1359}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:41,252]\u001b[0m Trial 83 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 191, 'max_depth': 47, 'learning_rate': 0.2738107248642924, 'n_estimators': 1575}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:42,336]\u001b[0m Trial 84 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 242, 'max_depth': 42, 'learning_rate': 0.29602565913109957, 'n_estimators': 481}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:44,222]\u001b[0m Trial 85 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 222, 'max_depth': 49, 'learning_rate': 0.242079606627816, 'n_estimators': 1696}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:46,269]\u001b[0m Trial 86 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 220, 'max_depth': 49, 'learning_rate': 0.2507609475028013, 'n_estimators': 1676}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:48,073]\u001b[0m Trial 87 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 231, 'max_depth': 46, 'learning_rate': 0.24120713473582348, 'n_estimators': 1768}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:49,825]\u001b[0m Trial 88 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 215, 'max_depth': 49, 'learning_rate': 0.26465268884886944, 'n_estimators': 1856}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:51,846]\u001b[0m Trial 89 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 252, 'max_depth': 29, 'learning_rate': 0.2581268458954551, 'n_estimators': 1691}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:52,640]\u001b[0m Trial 90 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 204, 'max_depth': 48, 'learning_rate': 0.24208145716192336, 'n_estimators': 419}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:53,934]\u001b[0m Trial 91 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 43, 'max_depth': 45, 'learning_rate': 0.28900418602402356, 'n_estimators': 1534}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:54,557]\u001b[0m Trial 92 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 236, 'max_depth': 6, 'learning_rate': 0.2766537119211787, 'n_estimators': 577}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:56,375]\u001b[0m Trial 93 finished with value: 0.8754940711462451 and parameters: {'num_leaves': 226, 'max_depth': 44, 'learning_rate': 0.2685126902496219, 'n_estimators': 1988}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:57,717]\u001b[0m Trial 94 finished with value: 0.8754940711462451 and parameters: {'num_leaves': 188, 'max_depth': 47, 'learning_rate': 0.2998713277677101, 'n_estimators': 1157}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:58,675]\u001b[0m Trial 95 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 205, 'max_depth': 43, 'learning_rate': 0.25674176796212106, 'n_estimators': 529}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:21:59,766]\u001b[0m Trial 96 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 71, 'max_depth': 38, 'learning_rate': 0.22787212508997423, 'n_estimators': 699}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:22:02,861]\u001b[0m Trial 97 finished with value: 0.883399209486166 and parameters: {'num_leaves': 197, 'max_depth': 41, 'learning_rate': 0.2836358454347627, 'n_estimators': 913}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:22:04,456]\u001b[0m Trial 98 finished with value: 0.883399209486166 and parameters: {'num_leaves': 172, 'max_depth': 50, 'learning_rate': 0.24516492805650206, 'n_estimators': 1429}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:22:05,785]\u001b[0m Trial 99 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 214, 'max_depth': 46, 'learning_rate': 0.2767658430639604, 'n_estimators': 1081}. Best is trial 37 with value: 0.8932806324110671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "index        APAAC  LogisticRegression             True   \n",
      "index        APAAC                 SVC             True   \n",
      "index        APAAC       XGBClassifier             True   \n",
      "index        APAAC      LGBMClassifier             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "index  {'C': 0.09972241221770178, 'penalty': 'l1', 's...  0.893281   \n",
      "index  {'svc_c': 81.00794411499099, 'svc_gamma': 0.03...  0.859684   \n",
      "index  {'learning_rate': 0.21557448587004335, 'max_de...  0.891304   \n",
      "index  {'num_leaves': 2, 'max_depth': 43, 'learning_r...  0.893281   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "index     0.885714     0.900383   0.893004  0.889344  0.786319   \n",
      "index     0.869388     0.850575   0.845238  0.857143  0.719608   \n",
      "index     0.885714     0.896552   0.889344  0.887526  0.782370   \n",
      "index     0.889796     0.896552   0.889796  0.889796  0.786348   \n",
      "\n",
      "                                           index  \n",
      "index      AAC_LogisticRegression_no_hypertuning  \n",
      "index                     AAC_SVC_no_hypertuning  \n",
      "index           AAC_XGBClassifier_no_hypertuning  \n",
      "index          AAC_LGBMClassifier_no_hypertuning  \n",
      "index    AAC_LogisticRegression_with_hypertuning  \n",
      "index                   AAC_SVC_with_hypertuning  \n",
      "index         AAC_XGBClassifier_with_hypertuning  \n",
      "index        AAC_LGBMClassifier_with_hypertuning  \n",
      "index    APAAC_LogisticRegression_no_hypertuning  \n",
      "index                   APAAC_SVC_no_hypertuning  \n",
      "index         APAAC_XGBClassifier_no_hypertuning  \n",
      "index        APAAC_LGBMClassifier_no_hypertuning  \n",
      "index  APAAC_LogisticRegression_with_hypertuning  \n",
      "index                 APAAC_SVC_with_hypertuning  \n",
      "index       APAAC_XGBClassifier_with_hypertuning  \n",
      "index      APAAC_LGBMClassifier_with_hypertuning  \n",
      "Evaluating CTD LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "index        APAAC  LogisticRegression             True   \n",
      "index        APAAC                 SVC             True   \n",
      "index        APAAC       XGBClassifier             True   \n",
      "index        APAAC      LGBMClassifier             True   \n",
      "index          CTD  LogisticRegression            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "index  {'C': 0.09972241221770178, 'penalty': 'l1', 's...  0.893281   \n",
      "index  {'svc_c': 81.00794411499099, 'svc_gamma': 0.03...  0.859684   \n",
      "index  {'learning_rate': 0.21557448587004335, 'max_de...  0.891304   \n",
      "index  {'num_leaves': 2, 'max_depth': 43, 'learning_r...  0.893281   \n",
      "index                                               None  0.862764   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "index     0.885714     0.900383   0.893004  0.889344  0.786319   \n",
      "index     0.869388     0.850575   0.845238  0.857143  0.719608   \n",
      "index     0.885714     0.896552   0.889344  0.887526  0.782370   \n",
      "index     0.889796     0.896552   0.889796  0.889796  0.786348   \n",
      "index     0.869388     0.867424   0.858871  0.864097  0.736539   \n",
      "\n",
      "                                           index  \n",
      "index      AAC_LogisticRegression_no_hypertuning  \n",
      "index                     AAC_SVC_no_hypertuning  \n",
      "index           AAC_XGBClassifier_no_hypertuning  \n",
      "index          AAC_LGBMClassifier_no_hypertuning  \n",
      "index    AAC_LogisticRegression_with_hypertuning  \n",
      "index                   AAC_SVC_with_hypertuning  \n",
      "index         AAC_XGBClassifier_with_hypertuning  \n",
      "index        AAC_LGBMClassifier_with_hypertuning  \n",
      "index    APAAC_LogisticRegression_no_hypertuning  \n",
      "index                   APAAC_SVC_no_hypertuning  \n",
      "index         APAAC_XGBClassifier_no_hypertuning  \n",
      "index        APAAC_LGBMClassifier_no_hypertuning  \n",
      "index  APAAC_LogisticRegression_with_hypertuning  \n",
      "index                 APAAC_SVC_with_hypertuning  \n",
      "index       APAAC_XGBClassifier_with_hypertuning  \n",
      "index      APAAC_LGBMClassifier_with_hypertuning  \n",
      "index      CTD_LogisticRegression_no_hypertuning  \n",
      "Evaluating CTD SVC\n",
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "index        APAAC  LogisticRegression             True   \n",
      "index        APAAC                 SVC             True   \n",
      "index        APAAC       XGBClassifier             True   \n",
      "index        APAAC      LGBMClassifier             True   \n",
      "index          CTD  LogisticRegression            False   \n",
      "index          CTD                 SVC            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "index  {'C': 0.09972241221770178, 'penalty': 'l1', 's...  0.893281   \n",
      "index  {'svc_c': 81.00794411499099, 'svc_gamma': 0.03...  0.859684   \n",
      "index  {'learning_rate': 0.21557448587004335, 'max_de...  0.891304   \n",
      "index  {'num_leaves': 2, 'max_depth': 43, 'learning_r...  0.893281   \n",
      "index                                               None  0.862764   \n",
      "index                                               None  0.846564   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "index     0.885714     0.900383   0.893004  0.889344  0.786319   \n",
      "index     0.869388     0.850575   0.845238  0.857143  0.719608   \n",
      "index     0.885714     0.896552   0.889344  0.887526  0.782370   \n",
      "index     0.889796     0.896552   0.889796  0.889796  0.786348   \n",
      "index     0.869388     0.867424   0.858871  0.864097  0.736539   \n",
      "index     0.836735     0.875000   0.861345  0.848861  0.712738   \n",
      "\n",
      "                                           index  \n",
      "index      AAC_LogisticRegression_no_hypertuning  \n",
      "index                     AAC_SVC_no_hypertuning  \n",
      "index           AAC_XGBClassifier_no_hypertuning  \n",
      "index          AAC_LGBMClassifier_no_hypertuning  \n",
      "index    AAC_LogisticRegression_with_hypertuning  \n",
      "index                   AAC_SVC_with_hypertuning  \n",
      "index         AAC_XGBClassifier_with_hypertuning  \n",
      "index        AAC_LGBMClassifier_with_hypertuning  \n",
      "index    APAAC_LogisticRegression_no_hypertuning  \n",
      "index                   APAAC_SVC_no_hypertuning  \n",
      "index         APAAC_XGBClassifier_no_hypertuning  \n",
      "index        APAAC_LGBMClassifier_no_hypertuning  \n",
      "index  APAAC_LogisticRegression_with_hypertuning  \n",
      "index                 APAAC_SVC_with_hypertuning  \n",
      "index       APAAC_XGBClassifier_with_hypertuning  \n",
      "index      APAAC_LGBMClassifier_with_hypertuning  \n",
      "index      CTD_LogisticRegression_no_hypertuning  \n",
      "index                     CTD_SVC_no_hypertuning  \n",
      "Evaluating CTD XGBClassifier\n",
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "index        APAAC  LogisticRegression             True   \n",
      "index        APAAC                 SVC             True   \n",
      "index        APAAC       XGBClassifier             True   \n",
      "index        APAAC      LGBMClassifier             True   \n",
      "index          CTD  LogisticRegression            False   \n",
      "index          CTD                 SVC            False   \n",
      "index          CTD       XGBClassifier            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "index  {'C': 0.09972241221770178, 'penalty': 'l1', 's...  0.893281   \n",
      "index  {'svc_c': 81.00794411499099, 'svc_gamma': 0.03...  0.859684   \n",
      "index  {'learning_rate': 0.21557448587004335, 'max_de...  0.891304   \n",
      "index  {'num_leaves': 2, 'max_depth': 43, 'learning_r...  0.893281   \n",
      "index                                               None  0.862764   \n",
      "index                                               None  0.846564   \n",
      "index                                               None  0.853410   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "index     0.885714     0.900383   0.893004  0.889344  0.786319   \n",
      "index     0.869388     0.850575   0.845238  0.857143  0.719608   \n",
      "index     0.885714     0.896552   0.889344  0.887526  0.782370   \n",
      "index     0.889796     0.896552   0.889796  0.889796  0.786348   \n",
      "index     0.869388     0.867424   0.858871  0.864097  0.736539   \n",
      "index     0.836735     0.875000   0.861345  0.848861  0.712738   \n",
      "index     0.844898     0.886364   0.873418  0.858921  0.732486   \n",
      "\n",
      "                                           index  \n",
      "index      AAC_LogisticRegression_no_hypertuning  \n",
      "index                     AAC_SVC_no_hypertuning  \n",
      "index           AAC_XGBClassifier_no_hypertuning  \n",
      "index          AAC_LGBMClassifier_no_hypertuning  \n",
      "index    AAC_LogisticRegression_with_hypertuning  \n",
      "index                   AAC_SVC_with_hypertuning  \n",
      "index         AAC_XGBClassifier_with_hypertuning  \n",
      "index        AAC_LGBMClassifier_with_hypertuning  \n",
      "index    APAAC_LogisticRegression_no_hypertuning  \n",
      "index                   APAAC_SVC_no_hypertuning  \n",
      "index         APAAC_XGBClassifier_no_hypertuning  \n",
      "index        APAAC_LGBMClassifier_no_hypertuning  \n",
      "index  APAAC_LogisticRegression_with_hypertuning  \n",
      "index                 APAAC_SVC_with_hypertuning  \n",
      "index       APAAC_XGBClassifier_with_hypertuning  \n",
      "index      APAAC_LGBMClassifier_with_hypertuning  \n",
      "index      CTD_LogisticRegression_no_hypertuning  \n",
      "index                     CTD_SVC_no_hypertuning  \n",
      "index           CTD_XGBClassifier_no_hypertuning  \n",
      "Evaluating CTD LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 10:22:27,641]\u001b[0m A new study created in memory with name: no-name-ee4b4757-71c6-4bc9-b70e-b630ef4c874b\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:22:27,826]\u001b[0m Trial 0 finished with value: 0.862475442043222 and parameters: {'C': 0.06773426040847502, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 833}. Best is trial 0 with value: 0.862475442043222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "index        APAAC  LogisticRegression             True   \n",
      "index        APAAC                 SVC             True   \n",
      "index        APAAC       XGBClassifier             True   \n",
      "index        APAAC      LGBMClassifier             True   \n",
      "index          CTD  LogisticRegression            False   \n",
      "index          CTD                 SVC            False   \n",
      "index          CTD       XGBClassifier            False   \n",
      "index          CTD      LGBMClassifier            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "index  {'C': 0.09972241221770178, 'penalty': 'l1', 's...  0.893281   \n",
      "index  {'svc_c': 81.00794411499099, 'svc_gamma': 0.03...  0.859684   \n",
      "index  {'learning_rate': 0.21557448587004335, 'max_de...  0.891304   \n",
      "index  {'num_leaves': 2, 'max_depth': 43, 'learning_r...  0.893281   \n",
      "index                                               None  0.862764   \n",
      "index                                               None  0.846564   \n",
      "index                                               None  0.853410   \n",
      "index                                               None  0.851444   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "index     0.885714     0.900383   0.893004  0.889344  0.786319   \n",
      "index     0.869388     0.850575   0.845238  0.857143  0.719608   \n",
      "index     0.885714     0.896552   0.889344  0.887526  0.782370   \n",
      "index     0.889796     0.896552   0.889796  0.889796  0.786348   \n",
      "index     0.869388     0.867424   0.858871  0.864097  0.736539   \n",
      "index     0.836735     0.875000   0.861345  0.848861  0.712738   \n",
      "index     0.844898     0.886364   0.873418  0.858921  0.732486   \n",
      "index     0.853061     0.893939   0.881857  0.867220  0.748251   \n",
      "\n",
      "                                           index  \n",
      "index      AAC_LogisticRegression_no_hypertuning  \n",
      "index                     AAC_SVC_no_hypertuning  \n",
      "index           AAC_XGBClassifier_no_hypertuning  \n",
      "index          AAC_LGBMClassifier_no_hypertuning  \n",
      "index    AAC_LogisticRegression_with_hypertuning  \n",
      "index                   AAC_SVC_with_hypertuning  \n",
      "index         AAC_XGBClassifier_with_hypertuning  \n",
      "index        AAC_LGBMClassifier_with_hypertuning  \n",
      "index    APAAC_LogisticRegression_no_hypertuning  \n",
      "index                   APAAC_SVC_no_hypertuning  \n",
      "index         APAAC_XGBClassifier_no_hypertuning  \n",
      "index        APAAC_LGBMClassifier_no_hypertuning  \n",
      "index  APAAC_LogisticRegression_with_hypertuning  \n",
      "index                 APAAC_SVC_with_hypertuning  \n",
      "index       APAAC_XGBClassifier_with_hypertuning  \n",
      "index      APAAC_LGBMClassifier_with_hypertuning  \n",
      "index      CTD_LogisticRegression_no_hypertuning  \n",
      "index                     CTD_SVC_no_hypertuning  \n",
      "index           CTD_XGBClassifier_no_hypertuning  \n",
      "index          CTD_LGBMClassifier_no_hypertuning  \n",
      "Optimizing CTD LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 10:22:27,876]\u001b[0m Trial 1 finished with value: 0.8546168958742633 and parameters: {'C': 0.050499999299842384, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 444}. Best is trial 0 with value: 0.862475442043222.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:22:30,274]\u001b[0m Trial 2 finished with value: 0.8664047151277013 and parameters: {'C': 0.04626336348645811, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 502}. Best is trial 2 with value: 0.8664047151277013.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:22:30,405]\u001b[0m Trial 3 finished with value: 0.862475442043222 and parameters: {'C': 0.060406106647597185, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 877}. Best is trial 2 with value: 0.8664047151277013.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:22:30,544]\u001b[0m Trial 4 finished with value: 0.862475442043222 and parameters: {'C': 0.07857386031180366, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 615}. Best is trial 2 with value: 0.8664047151277013.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:22:32,284]\u001b[0m Trial 5 finished with value: 0.8526522593320236 and parameters: {'C': 0.03324471049617744, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 310}. Best is trial 2 with value: 0.8664047151277013.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:22:32,422]\u001b[0m Trial 6 finished with value: 0.862475442043222 and parameters: {'C': 0.06232136367008966, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 751}. Best is trial 2 with value: 0.8664047151277013.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:22:32,552]\u001b[0m Trial 7 finished with value: 0.8565815324165029 and parameters: {'C': 0.03549363679501528, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 387}. Best is trial 2 with value: 0.8664047151277013.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:22:32,680]\u001b[0m Trial 8 finished with value: 0.8526522593320236 and parameters: {'C': 0.03298811240715666, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 908}. Best is trial 2 with value: 0.8664047151277013.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:22:34,636]\u001b[0m Trial 9 finished with value: 0.8644400785854617 and parameters: {'C': 0.042275419815743565, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 951}. Best is trial 2 with value: 0.8664047151277013.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:22:35,912]\u001b[0m Trial 10 finished with value: 0.8290766208251473 and parameters: {'C': 0.01402645283448304, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 209}. Best is trial 2 with value: 0.8664047151277013.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:22:38,177]\u001b[0m Trial 11 finished with value: 0.8664047151277013 and parameters: {'C': 0.04470204172700168, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 619}. Best is trial 2 with value: 0.8664047151277013.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:22:40,784]\u001b[0m Trial 12 finished with value: 0.8703339882121808 and parameters: {'C': 0.0906600851039587, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 611}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:22:43,124]\u001b[0m Trial 13 finished with value: 0.8683693516699411 and parameters: {'C': 0.09675036200860676, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 522}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:22:46,221]\u001b[0m Trial 14 finished with value: 0.8683693516699411 and parameters: {'C': 0.09532088540479061, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 694}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:22:49,392]\u001b[0m Trial 15 finished with value: 0.8644400785854617 and parameters: {'C': 0.09540838756511676, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 578}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:22:49,941]\u001b[0m Trial 16 finished with value: 0.8605108055009824 and parameters: {'C': 0.09974284919488907, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 117}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:22:51,518]\u001b[0m Trial 17 finished with value: 0.8644400785854617 and parameters: {'C': 0.08361915349632823, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 355}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:22:55,216]\u001b[0m Trial 18 finished with value: 0.8644400785854617 and parameters: {'C': 0.0849145995809998, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 738}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:22:57,526]\u001b[0m Trial 19 finished with value: 0.8664047151277013 and parameters: {'C': 0.07610365954219458, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 512}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:22:58,729]\u001b[0m Trial 20 finished with value: 0.862475442043222 and parameters: {'C': 0.08929519094090914, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 272}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:23:01,718]\u001b[0m Trial 21 finished with value: 0.8683693516699411 and parameters: {'C': 0.09295833281822119, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 698}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:23:04,600]\u001b[0m Trial 22 finished with value: 0.8683693516699411 and parameters: {'C': 0.09961935476291911, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 668}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:23:07,608]\u001b[0m Trial 23 finished with value: 0.8683693516699411 and parameters: {'C': 0.09159592264606066, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 783}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:23:09,591]\u001b[0m Trial 24 finished with value: 0.8683693516699411 and parameters: {'C': 0.08638586608100474, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 473}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:23:11,870]\u001b[0m Trial 25 finished with value: 0.8683693516699411 and parameters: {'C': 0.07538991482722159, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 545}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:23:15,037]\u001b[0m Trial 26 finished with value: 0.8703339882121808 and parameters: {'C': 0.09967060991806306, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 672}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:23:17,859]\u001b[0m Trial 27 finished with value: 0.862475442043222 and parameters: {'C': 0.08169478499426415, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 615}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:23:21,630]\u001b[0m Trial 28 finished with value: 0.8644400785854617 and parameters: {'C': 0.08891540474263183, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 815}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:23:23,712]\u001b[0m Trial 29 finished with value: 0.8605108055009824 and parameters: {'C': 0.07093199976662459, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 450}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:23:25,571]\u001b[0m Trial 30 finished with value: 0.8664047151277013 and parameters: {'C': 0.09932853480884596, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 395}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:23:28,460]\u001b[0m Trial 31 finished with value: 0.8683693516699411 and parameters: {'C': 0.09428703674979294, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 680}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:23:31,237]\u001b[0m Trial 32 finished with value: 0.8605108055009824 and parameters: {'C': 0.08900829979258977, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 559}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:23:33,925]\u001b[0m Trial 33 finished with value: 0.8683693516699411 and parameters: {'C': 0.09477258135356471, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 649}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:23:34,008]\u001b[0m Trial 34 finished with value: 0.8605108055009824 and parameters: {'C': 0.08237620155510877, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 722}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:23:36,936]\u001b[0m Trial 35 finished with value: 0.8683693516699411 and parameters: {'C': 0.09508155840575623, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 876}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:23:39,808]\u001b[0m Trial 36 finished with value: 0.8683693516699411 and parameters: {'C': 0.07921030349045521, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 790}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:23:39,902]\u001b[0m Trial 37 finished with value: 0.8605108055009824 and parameters: {'C': 0.0868644496698619, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 568}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:23:42,083]\u001b[0m Trial 38 finished with value: 0.8664047151277013 and parameters: {'C': 0.09033512938585701, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 504}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:23:42,218]\u001b[0m Trial 39 finished with value: 0.8644400785854617 and parameters: {'C': 0.09984421165135847, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 848}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:23:44,903]\u001b[0m Trial 40 finished with value: 0.8664047151277013 and parameters: {'C': 0.07028386658743996, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 610}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:23:47,945]\u001b[0m Trial 41 finished with value: 0.8683693516699411 and parameters: {'C': 0.09314554653548471, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 709}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:23:51,055]\u001b[0m Trial 42 finished with value: 0.8683693516699411 and parameters: {'C': 0.09476432080244081, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 707}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:23:54,004]\u001b[0m Trial 43 finished with value: 0.8703339882121808 and parameters: {'C': 0.08576737336609261, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 766}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:23:56,875]\u001b[0m Trial 44 finished with value: 0.8703339882121808 and parameters: {'C': 0.0855204202401945, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 761}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:23:57,010]\u001b[0m Trial 45 finished with value: 0.862475442043222 and parameters: {'C': 0.0799482774855117, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 952}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:23:59,922]\u001b[0m Trial 46 finished with value: 0.8703339882121808 and parameters: {'C': 0.08529559586076957, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 765}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:24:03,549]\u001b[0m Trial 47 finished with value: 0.8585461689587426 and parameters: {'C': 0.06381410631467906, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 770}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:24:05,984]\u001b[0m Trial 48 finished with value: 0.8664047151277013 and parameters: {'C': 0.07602964342952417, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 994}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:24:08,557]\u001b[0m Trial 49 finished with value: 0.8703339882121808 and parameters: {'C': 0.08490998643648953, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 832}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:24:08,708]\u001b[0m Trial 50 finished with value: 0.862475442043222 and parameters: {'C': 0.0864555022519397, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 648}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:24:11,311]\u001b[0m Trial 51 finished with value: 0.8703339882121808 and parameters: {'C': 0.08444699277277583, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 830}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:24:14,039]\u001b[0m Trial 52 finished with value: 0.8683693516699411 and parameters: {'C': 0.08999121385219105, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 886}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:24:16,628]\u001b[0m Trial 53 finished with value: 0.8703339882121808 and parameters: {'C': 0.08104616796786021, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 746}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:24:19,328]\u001b[0m Trial 54 finished with value: 0.8703339882121808 and parameters: {'C': 0.08499773190213944, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 810}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:24:21,847]\u001b[0m Trial 55 finished with value: 0.8683693516699411 and parameters: {'C': 0.07759723831949691, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 849}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:24:24,578]\u001b[0m Trial 56 finished with value: 0.8683693516699411 and parameters: {'C': 0.09038421833589858, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 766}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:24:28,777]\u001b[0m Trial 57 finished with value: 0.8683693516699411 and parameters: {'C': 0.09702435001052631, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 924}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:24:31,266]\u001b[0m Trial 58 finished with value: 0.8664047151277013 and parameters: {'C': 0.0734729084207997, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 742}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:24:33,821]\u001b[0m Trial 59 finished with value: 0.8703339882121808 and parameters: {'C': 0.0807216159623977, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 660}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:24:36,154]\u001b[0m Trial 60 finished with value: 0.8703339882121808 and parameters: {'C': 0.08389448190024697, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 588}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:24:38,897]\u001b[0m Trial 61 finished with value: 0.8683693516699411 and parameters: {'C': 0.08669348960806228, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 840}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:24:41,544]\u001b[0m Trial 62 finished with value: 0.8703339882121808 and parameters: {'C': 0.08322437472928873, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 799}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:24:44,352]\u001b[0m Trial 63 finished with value: 0.8683693516699411 and parameters: {'C': 0.09084309706450762, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 875}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:24:47,150]\u001b[0m Trial 64 finished with value: 0.8683693516699411 and parameters: {'C': 0.09223175364710529, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 768}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:24:51,242]\u001b[0m Trial 65 finished with value: 0.8644400785854617 and parameters: {'C': 0.08783613642586534, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 824}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:24:54,034]\u001b[0m Trial 66 finished with value: 0.8683693516699411 and parameters: {'C': 0.09681963408960854, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 635}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:24:56,572]\u001b[0m Trial 67 finished with value: 0.8683693516699411 and parameters: {'C': 0.07805862344918278, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 907}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:24:59,232]\u001b[0m Trial 68 finished with value: 0.8703339882121808 and parameters: {'C': 0.0847121341458647, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 679}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:25:02,503]\u001b[0m Trial 69 finished with value: 0.8605108055009824 and parameters: {'C': 0.07368748984224426, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 727}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:25:02,630]\u001b[0m Trial 70 finished with value: 0.862475442043222 and parameters: {'C': 0.0827074276294291, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 535}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:25:05,532]\u001b[0m Trial 71 finished with value: 0.8703339882121808 and parameters: {'C': 0.0806217081191436, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 744}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:25:08,294]\u001b[0m Trial 72 finished with value: 0.8683693516699411 and parameters: {'C': 0.08809515589341034, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 784}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:25:11,109]\u001b[0m Trial 73 finished with value: 0.8683693516699411 and parameters: {'C': 0.0926077406859276, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 750}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:25:13,859]\u001b[0m Trial 74 finished with value: 0.8703339882121808 and parameters: {'C': 0.08522191934299578, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 681}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:25:16,608]\u001b[0m Trial 75 finished with value: 0.8703339882121808 and parameters: {'C': 0.08220857498704418, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 826}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:25:19,393]\u001b[0m Trial 76 finished with value: 0.8683693516699411 and parameters: {'C': 0.0778081124363819, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 861}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:25:22,986]\u001b[0m Trial 77 finished with value: 0.8664047151277013 and parameters: {'C': 0.08835161276288371, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 697}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:25:26,102]\u001b[0m Trial 78 finished with value: 0.8683693516699411 and parameters: {'C': 0.0920657568588497, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 724}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:25:28,690]\u001b[0m Trial 79 finished with value: 0.8683693516699411 and parameters: {'C': 0.09778861285022349, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 593}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:25:32,622]\u001b[0m Trial 80 finished with value: 0.8683693516699411 and parameters: {'C': 0.09404750347259534, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 802}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:25:35,535]\u001b[0m Trial 81 finished with value: 0.8703339882121808 and parameters: {'C': 0.0850213250644523, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 822}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:25:38,362]\u001b[0m Trial 82 finished with value: 0.8703339882121808 and parameters: {'C': 0.08019166444431414, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 812}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:25:41,220]\u001b[0m Trial 83 finished with value: 0.8703339882121808 and parameters: {'C': 0.08476254533214467, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 756}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:25:44,096]\u001b[0m Trial 84 finished with value: 0.8683693516699411 and parameters: {'C': 0.08941766349739559, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 899}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:25:44,251]\u001b[0m Trial 85 finished with value: 0.862475442043222 and parameters: {'C': 0.08686678417281969, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 932}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:25:47,114]\u001b[0m Trial 86 finished with value: 0.8703339882121808 and parameters: {'C': 0.0820383543435077, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 777}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:25:49,684]\u001b[0m Trial 87 finished with value: 0.8683693516699411 and parameters: {'C': 0.09633643635557212, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 629}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:25:52,570]\u001b[0m Trial 88 finished with value: 0.8683693516699411 and parameters: {'C': 0.09108992832324744, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 711}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:25:53,034]\u001b[0m Trial 89 finished with value: 0.8605108055009824 and parameters: {'C': 0.0793290404024101, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 105}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:25:56,833]\u001b[0m Trial 90 finished with value: 0.8683693516699411 and parameters: {'C': 0.0930415740409785, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 792}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:25:59,567]\u001b[0m Trial 91 finished with value: 0.8703339882121808 and parameters: {'C': 0.08162531682091541, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 667}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:02,241]\u001b[0m Trial 92 finished with value: 0.8703339882121808 and parameters: {'C': 0.08399246564690717, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 846}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:26:04,894]\u001b[0m Trial 93 finished with value: 0.8703339882121808 and parameters: {'C': 0.08716102126771688, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 648}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:26:07,371]\u001b[0m Trial 94 finished with value: 0.8703339882121808 and parameters: {'C': 0.08007339836887833, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 606}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:10,072]\u001b[0m Trial 95 finished with value: 0.8664047151277013 and parameters: {'C': 0.07643972363370774, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 659}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:12,988]\u001b[0m Trial 96 finished with value: 0.8683693516699411 and parameters: {'C': 0.08926112189755601, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 729}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:26:13,619]\u001b[0m Trial 97 finished with value: 0.862475442043222 and parameters: {'C': 0.08498947979390876, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 146}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:13,765]\u001b[0m Trial 98 finished with value: 0.862475442043222 and parameters: {'C': 0.08137433770804102, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 689}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:26:17,463]\u001b[0m Trial 99 finished with value: 0.8703339882121808 and parameters: {'C': 0.09532375657260839, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 765}. Best is trial 12 with value: 0.8703339882121808.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:17,473]\u001b[0m A new study created in memory with name: no-name-3ae51f4d-4d4b-4092-9ed9-d8a83fd8cc67\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "index        APAAC  LogisticRegression             True   \n",
      "index        APAAC                 SVC             True   \n",
      "index        APAAC       XGBClassifier             True   \n",
      "index        APAAC      LGBMClassifier             True   \n",
      "index          CTD  LogisticRegression            False   \n",
      "index          CTD                 SVC            False   \n",
      "index          CTD       XGBClassifier            False   \n",
      "index          CTD      LGBMClassifier            False   \n",
      "index          CTD  LogisticRegression             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "index  {'C': 0.09972241221770178, 'penalty': 'l1', 's...  0.893281   \n",
      "index  {'svc_c': 81.00794411499099, 'svc_gamma': 0.03...  0.859684   \n",
      "index  {'learning_rate': 0.21557448587004335, 'max_de...  0.891304   \n",
      "index  {'num_leaves': 2, 'max_depth': 43, 'learning_r...  0.893281   \n",
      "index                                               None  0.862764   \n",
      "index                                               None  0.846564   \n",
      "index                                               None  0.853410   \n",
      "index                                               None  0.851444   \n",
      "index  {'C': 0.0906600851039587, 'penalty': 'l2', 'so...  0.870334   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "index     0.885714     0.900383   0.893004  0.889344  0.786319   \n",
      "index     0.869388     0.850575   0.845238  0.857143  0.719608   \n",
      "index     0.885714     0.896552   0.889344  0.887526  0.782370   \n",
      "index     0.889796     0.896552   0.889796  0.889796  0.786348   \n",
      "index     0.869388     0.867424   0.858871  0.864097  0.736539   \n",
      "index     0.836735     0.875000   0.861345  0.848861  0.712738   \n",
      "index     0.844898     0.886364   0.873418  0.858921  0.732486   \n",
      "index     0.853061     0.893939   0.881857  0.867220  0.748251   \n",
      "index     0.881633     0.859848   0.853755  0.867470  0.740977   \n",
      "\n",
      "                                           index  \n",
      "index      AAC_LogisticRegression_no_hypertuning  \n",
      "index                     AAC_SVC_no_hypertuning  \n",
      "index           AAC_XGBClassifier_no_hypertuning  \n",
      "index          AAC_LGBMClassifier_no_hypertuning  \n",
      "index    AAC_LogisticRegression_with_hypertuning  \n",
      "index                   AAC_SVC_with_hypertuning  \n",
      "index         AAC_XGBClassifier_with_hypertuning  \n",
      "index        AAC_LGBMClassifier_with_hypertuning  \n",
      "index    APAAC_LogisticRegression_no_hypertuning  \n",
      "index                   APAAC_SVC_no_hypertuning  \n",
      "index         APAAC_XGBClassifier_no_hypertuning  \n",
      "index        APAAC_LGBMClassifier_no_hypertuning  \n",
      "index  APAAC_LogisticRegression_with_hypertuning  \n",
      "index                 APAAC_SVC_with_hypertuning  \n",
      "index       APAAC_XGBClassifier_with_hypertuning  \n",
      "index      APAAC_LGBMClassifier_with_hypertuning  \n",
      "index      CTD_LogisticRegression_no_hypertuning  \n",
      "index                     CTD_SVC_no_hypertuning  \n",
      "index           CTD_XGBClassifier_no_hypertuning  \n",
      "index          CTD_LGBMClassifier_no_hypertuning  \n",
      "index    CTD_LogisticRegression_with_hypertuning  \n",
      "Optimizing CTD SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:18,162]\u001b[0m Trial 0 finished with value: 0.518664047151277 and parameters: {'svc_c': 67.14569939034313, 'svc_gamma': 90.66559685846383}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:18,811]\u001b[0m Trial 1 finished with value: 0.518664047151277 and parameters: {'svc_c': 85.91909749848747, 'svc_gamma': 87.46971584634281}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:19,534]\u001b[0m Trial 2 finished with value: 0.518664047151277 and parameters: {'svc_c': 41.747023602485655, 'svc_gamma': 91.91138809484421}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:20,249]\u001b[0m Trial 3 finished with value: 0.518664047151277 and parameters: {'svc_c': 46.83653197443338, 'svc_gamma': 10.810179226067767}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:20,906]\u001b[0m Trial 4 finished with value: 0.518664047151277 and parameters: {'svc_c': 90.8433583489263, 'svc_gamma': 62.9510677735992}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:21,566]\u001b[0m Trial 5 finished with value: 0.518664047151277 and parameters: {'svc_c': 43.174790475096835, 'svc_gamma': 73.78416364159203}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:22,291]\u001b[0m Trial 6 finished with value: 0.518664047151277 and parameters: {'svc_c': 90.28834025764887, 'svc_gamma': 8.805899134883662}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:22,959]\u001b[0m Trial 7 finished with value: 0.518664047151277 and parameters: {'svc_c': 40.21092823512418, 'svc_gamma': 32.57809135902186}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:23,625]\u001b[0m Trial 8 finished with value: 0.518664047151277 and parameters: {'svc_c': 47.008405598831644, 'svc_gamma': 73.87071854295283}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:24,384]\u001b[0m Trial 9 finished with value: 0.5206286836935167 and parameters: {'svc_c': 51.64589876302167, 'svc_gamma': 7.478671046079868}. Best is trial 9 with value: 0.5206286836935167.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:25,060]\u001b[0m Trial 10 finished with value: 0.518664047151277 and parameters: {'svc_c': 14.247252721270904, 'svc_gamma': 34.81103222455223}. Best is trial 9 with value: 0.5206286836935167.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:25,710]\u001b[0m Trial 11 finished with value: 0.518664047151277 and parameters: {'svc_c': 65.36564704257128, 'svc_gamma': 46.523389707363776}. Best is trial 9 with value: 0.5206286836935167.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:26,430]\u001b[0m Trial 12 finished with value: 0.5225933202357563 and parameters: {'svc_c': 65.26029336320248, 'svc_gamma': 2.3884367788719914}. Best is trial 12 with value: 0.5225933202357563.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:27,129]\u001b[0m Trial 13 finished with value: 0.5245579567779961 and parameters: {'svc_c': 61.41392621332529, 'svc_gamma': 1.974734147936493}. Best is trial 13 with value: 0.5245579567779961.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:27,771]\u001b[0m Trial 14 finished with value: 0.5343811394891945 and parameters: {'svc_c': 72.01621162133722, 'svc_gamma': 0.6368580524987237}. Best is trial 14 with value: 0.5343811394891945.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:28,428]\u001b[0m Trial 15 finished with value: 0.518664047151277 and parameters: {'svc_c': 77.06330277638061, 'svc_gamma': 21.012127662678807}. Best is trial 14 with value: 0.5343811394891945.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:29,062]\u001b[0m Trial 16 finished with value: 0.5324165029469549 and parameters: {'svc_c': 99.24401308732126, 'svc_gamma': 0.6630621202594484}. Best is trial 14 with value: 0.5343811394891945.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:29,725]\u001b[0m Trial 17 finished with value: 0.518664047151277 and parameters: {'svc_c': 98.30429668254723, 'svc_gamma': 23.275646014493454}. Best is trial 14 with value: 0.5343811394891945.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:30,384]\u001b[0m Trial 18 finished with value: 0.518664047151277 and parameters: {'svc_c': 80.54125110943875, 'svc_gamma': 20.269743177938313}. Best is trial 14 with value: 0.5343811394891945.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:31,033]\u001b[0m Trial 19 finished with value: 0.5599214145383105 and parameters: {'svc_c': 95.90897500933346, 'svc_gamma': 0.36281618714507147}. Best is trial 19 with value: 0.5599214145383105.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:31,719]\u001b[0m Trial 20 finished with value: 0.518664047151277 and parameters: {'svc_c': 76.3335734405625, 'svc_gamma': 12.193178093182027}. Best is trial 19 with value: 0.5599214145383105.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:32,362]\u001b[0m Trial 21 finished with value: 0.5343811394891945 and parameters: {'svc_c': 99.52895295467009, 'svc_gamma': 0.618714445595139}. Best is trial 19 with value: 0.5599214145383105.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:32,971]\u001b[0m Trial 22 finished with value: 0.75049115913556 and parameters: {'svc_c': 94.43521012429034, 'svc_gamma': 0.0905019951242984}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:33,678]\u001b[0m Trial 23 finished with value: 0.518664047151277 and parameters: {'svc_c': 87.33744589681052, 'svc_gamma': 15.139553418967902}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:34,313]\u001b[0m Trial 24 finished with value: 0.518664047151277 and parameters: {'svc_c': 80.6923420693288, 'svc_gamma': 27.666829477378585}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:34,988]\u001b[0m Trial 25 finished with value: 0.518664047151277 and parameters: {'svc_c': 91.98861411858158, 'svc_gamma': 15.690389537066048}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:35,728]\u001b[0m Trial 26 finished with value: 0.5206286836935167 and parameters: {'svc_c': 73.65638417432787, 'svc_gamma': 7.060375420688409}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:36,372]\u001b[0m Trial 27 finished with value: 0.518664047151277 and parameters: {'svc_c': 84.60855280549258, 'svc_gamma': 16.5170879966475}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:36,999]\u001b[0m Trial 28 finished with value: 0.518664047151277 and parameters: {'svc_c': 92.66043994041294, 'svc_gamma': 26.711574903161562}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:37,724]\u001b[0m Trial 29 finished with value: 0.5206286836935167 and parameters: {'svc_c': 71.55056743463891, 'svc_gamma': 6.587654961663895}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:38,308]\u001b[0m Trial 30 finished with value: 0.581532416502947 and parameters: {'svc_c': 82.55535106725932, 'svc_gamma': 0.3125924337757423}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:38,964]\u001b[0m Trial 31 finished with value: 0.518664047151277 and parameters: {'svc_c': 82.85965099198444, 'svc_gamma': 11.365999267974063}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:39,565]\u001b[0m Trial 32 finished with value: 0.5343811394891945 and parameters: {'svc_c': 94.43693827335353, 'svc_gamma': 0.596975262020166}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:40,275]\u001b[0m Trial 33 finished with value: 0.5206286836935167 and parameters: {'svc_c': 87.26268094260841, 'svc_gamma': 6.976239734768192}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:40,931]\u001b[0m Trial 34 finished with value: 0.518664047151277 and parameters: {'svc_c': 83.26330490569873, 'svc_gamma': 16.32321818160067}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:41,627]\u001b[0m Trial 35 finished with value: 0.518664047151277 and parameters: {'svc_c': 94.16861920638767, 'svc_gamma': 11.712948199902645}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:42,371]\u001b[0m Trial 36 finished with value: 0.5206286836935167 and parameters: {'svc_c': 87.33837536440346, 'svc_gamma': 5.938306030546089}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:43,083]\u001b[0m Trial 37 finished with value: 0.5225933202357563 and parameters: {'svc_c': 70.5414386728863, 'svc_gamma': 5.2844107345729645}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:43,655]\u001b[0m Trial 38 finished with value: 0.7210216110019646 and parameters: {'svc_c': 77.2595680524253, 'svc_gamma': 0.11953313380691305}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:44,317]\u001b[0m Trial 39 finished with value: 0.518664047151277 and parameters: {'svc_c': 79.91309407998088, 'svc_gamma': 11.773513581882487}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:44,999]\u001b[0m Trial 40 finished with value: 0.518664047151277 and parameters: {'svc_c': 88.69692898224142, 'svc_gamma': 9.638060280294606}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:45,650]\u001b[0m Trial 41 finished with value: 0.5245579567779961 and parameters: {'svc_c': 76.7717488157332, 'svc_gamma': 1.8833351677102332}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:46,265]\u001b[0m Trial 42 finished with value: 0.6051080550098232 and parameters: {'svc_c': 95.05111314680306, 'svc_gamma': 0.2839874189474685}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:47,020]\u001b[0m Trial 43 finished with value: 0.5225933202357563 and parameters: {'svc_c': 95.18113794281274, 'svc_gamma': 5.490546379883511}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:47,722]\u001b[0m Trial 44 finished with value: 0.518664047151277 and parameters: {'svc_c': 89.5625143059435, 'svc_gamma': 10.712580995215246}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:48,364]\u001b[0m Trial 45 finished with value: 0.518664047151277 and parameters: {'svc_c': 96.14751155701578, 'svc_gamma': 16.840511495900532}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:49,063]\u001b[0m Trial 46 finished with value: 0.5225933202357563 and parameters: {'svc_c': 99.83495420473061, 'svc_gamma': 5.575556099616501}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:49,663]\u001b[0m Trial 47 finished with value: 0.518664047151277 and parameters: {'svc_c': 90.81992364502457, 'svc_gamma': 37.88573051612389}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:50,259]\u001b[0m Trial 48 finished with value: 0.5599214145383105 and parameters: {'svc_c': 84.09381955613962, 'svc_gamma': 0.36248510625259056}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:50,982]\u001b[0m Trial 49 finished with value: 0.5225933202357563 and parameters: {'svc_c': 94.91584923738856, 'svc_gamma': 4.736200323664233}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:51,675]\u001b[0m Trial 50 finished with value: 0.518664047151277 and parameters: {'svc_c': 90.3983308518871, 'svc_gamma': 9.784310091232852}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:52,280]\u001b[0m Trial 51 finished with value: 0.6247544204322201 and parameters: {'svc_c': 85.64579671916974, 'svc_gamma': 0.25635410065571873}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:52,976]\u001b[0m Trial 52 finished with value: 0.5225933202357563 and parameters: {'svc_c': 86.11295731746146, 'svc_gamma': 3.024359922052814}. Best is trial 22 with value: 0.75049115913556.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:53,532]\u001b[0m Trial 53 finished with value: 0.8172888015717092 and parameters: {'svc_c': 96.58368803766115, 'svc_gamma': 0.051905011431178094}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:54,222]\u001b[0m Trial 54 finished with value: 0.5206286836935167 and parameters: {'svc_c': 79.60149702902378, 'svc_gamma': 8.396066690117953}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:54,925]\u001b[0m Trial 55 finished with value: 0.5225933202357563 and parameters: {'svc_c': 91.25798207330153, 'svc_gamma': 3.579482817092292}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:55,581]\u001b[0m Trial 56 finished with value: 0.518664047151277 and parameters: {'svc_c': 85.10303613159138, 'svc_gamma': 14.137828576336371}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:56,262]\u001b[0m Trial 57 finished with value: 0.518664047151277 and parameters: {'svc_c': 97.89142168031472, 'svc_gamma': 9.253212079649106}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:26:56,898]\u001b[0m Trial 58 finished with value: 0.518664047151277 and parameters: {'svc_c': 99.62495376933785, 'svc_gamma': 20.231821310999536}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:57,602]\u001b[0m Trial 59 finished with value: 0.5225933202357563 and parameters: {'svc_c': 92.7249467913693, 'svc_gamma': 4.758391166594889}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:58,207]\u001b[0m Trial 60 finished with value: 0.550098231827112 and parameters: {'svc_c': 81.30512244886918, 'svc_gamma': 0.44642237726971035}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:58,805]\u001b[0m Trial 61 finished with value: 0.5599214145383105 and parameters: {'svc_c': 94.77151257234159, 'svc_gamma': 0.36264142471196137}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:26:59,492]\u001b[0m Trial 62 finished with value: 0.5225933202357563 and parameters: {'svc_c': 89.10019568816108, 'svc_gamma': 3.2713143963872717}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:27:00,179]\u001b[0m Trial 63 finished with value: 0.518664047151277 and parameters: {'svc_c': 95.65968851585261, 'svc_gamma': 9.085895420914891}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:27:00,837]\u001b[0m Trial 64 finished with value: 0.518664047151277 and parameters: {'svc_c': 85.43702903158062, 'svc_gamma': 13.274659809713008}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:01,543]\u001b[0m Trial 65 finished with value: 0.5225933202357563 and parameters: {'svc_c': 92.55130112576074, 'svc_gamma': 3.6256340420389233}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:02,219]\u001b[0m Trial 66 finished with value: 0.5206286836935167 and parameters: {'svc_c': 96.60899296507107, 'svc_gamma': 8.229240172807497}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:02,809]\u001b[0m Trial 67 finished with value: 0.555992141453831 and parameters: {'svc_c': 75.67903683780287, 'svc_gamma': 0.38017382020344154}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:03,527]\u001b[0m Trial 68 finished with value: 0.5206286836935167 and parameters: {'svc_c': 89.20181322497092, 'svc_gamma': 6.9968443163747605}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:04,233]\u001b[0m Trial 69 finished with value: 0.5225933202357563 and parameters: {'svc_c': 87.03953129902774, 'svc_gamma': 3.5478855377277476}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:27:04,897]\u001b[0m Trial 70 finished with value: 0.518664047151277 and parameters: {'svc_c': 97.73078068425042, 'svc_gamma': 17.54568152540609}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:05,580]\u001b[0m Trial 71 finished with value: 0.5225933202357563 and parameters: {'svc_c': 82.97751435115755, 'svc_gamma': 2.7854589499503923}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:06,209]\u001b[0m Trial 72 finished with value: 0.6915520628683693 and parameters: {'svc_c': 83.75163949348, 'svc_gamma': 0.1541538674810631}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:27:06,948]\u001b[0m Trial 73 finished with value: 0.518664047151277 and parameters: {'svc_c': 78.58065934175282, 'svc_gamma': 13.22730499980269}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:07,672]\u001b[0m Trial 74 finished with value: 0.5206286836935167 and parameters: {'svc_c': 81.31295029725837, 'svc_gamma': 6.1920002258576705}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:08,373]\u001b[0m Trial 75 finished with value: 0.5225933202357563 and parameters: {'svc_c': 92.39514071000822, 'svc_gamma': 3.152821727334263}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:27:09,054]\u001b[0m Trial 76 finished with value: 0.518664047151277 and parameters: {'svc_c': 73.75683658217882, 'svc_gamma': 10.90850462250978}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:09,764]\u001b[0m Trial 77 finished with value: 0.5206286836935167 and parameters: {'svc_c': 87.98003335626662, 'svc_gamma': 7.290554739840061}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:10,363]\u001b[0m Trial 78 finished with value: 0.5324165029469549 and parameters: {'svc_c': 68.6879452267515, 'svc_gamma': 0.677115757314498}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:27:11,055]\u001b[0m Trial 79 finished with value: 0.518664047151277 and parameters: {'svc_c': 78.33213242169471, 'svc_gamma': 12.639240056228493}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:11,766]\u001b[0m Trial 80 finished with value: 0.5225933202357563 and parameters: {'svc_c': 82.41902903610716, 'svc_gamma': 4.691917677049956}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:12,412]\u001b[0m Trial 81 finished with value: 0.5284872298624754 and parameters: {'svc_c': 83.84708276855697, 'svc_gamma': 1.017291054978808}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:13,156]\u001b[0m Trial 82 finished with value: 0.5225933202357563 and parameters: {'svc_c': 91.61359278548244, 'svc_gamma': 2.5607735725722964}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:13,758]\u001b[0m Trial 83 finished with value: 0.5540275049115914 and parameters: {'svc_c': 84.00191918169101, 'svc_gamma': 0.4058156149543057}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:14,469]\u001b[0m Trial 84 finished with value: 0.5206286836935167 and parameters: {'svc_c': 86.45528499900787, 'svc_gamma': 8.206784388650131}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:15,234]\u001b[0m Trial 85 finished with value: 0.5225933202357563 and parameters: {'svc_c': 97.11761093533967, 'svc_gamma': 5.214642847343934}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:27:15,925]\u001b[0m Trial 86 finished with value: 0.518664047151277 and parameters: {'svc_c': 93.41005035166947, 'svc_gamma': 9.784236684810862}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:16,703]\u001b[0m Trial 87 finished with value: 0.5206286836935167 and parameters: {'svc_c': 89.18960831279237, 'svc_gamma': 6.735230397975969}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:17,290]\u001b[0m Trial 88 finished with value: 0.7072691552062869 and parameters: {'svc_c': 99.79013086322595, 'svc_gamma': 0.1363656847111731}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:18,012]\u001b[0m Trial 89 finished with value: 0.5225933202357563 and parameters: {'svc_c': 99.188480762663, 'svc_gamma': 3.1178324944259206}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:27:18,737]\u001b[0m Trial 90 finished with value: 0.518664047151277 and parameters: {'svc_c': 99.93412772189711, 'svc_gamma': 11.237329334841622}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:19,316]\u001b[0m Trial 91 finished with value: 0.7033398821218074 and parameters: {'svc_c': 96.19426017327754, 'svc_gamma': 0.1386025027712161}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:20,069]\u001b[0m Trial 92 finished with value: 0.5225933202357563 and parameters: {'svc_c': 96.47069356073555, 'svc_gamma': 5.079874365347976}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:20,744]\u001b[0m Trial 93 finished with value: 0.5225933202357563 and parameters: {'svc_c': 94.78209408786994, 'svc_gamma': 2.5769696062887344}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:21,310]\u001b[0m Trial 94 finished with value: 0.8055009823182712 and parameters: {'svc_c': 90.61491602965054, 'svc_gamma': 0.056687335341523176}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:21,985]\u001b[0m Trial 95 finished with value: 0.5225933202357563 and parameters: {'svc_c': 89.86911438475433, 'svc_gamma': 2.29904232584828}. Best is trial 53 with value: 0.8172888015717092.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:22,441]\u001b[0m Trial 96 finished with value: 0.8546168958742633 and parameters: {'svc_c': 93.52276100739736, 'svc_gamma': 0.012484331700783002}. Best is trial 96 with value: 0.8546168958742633.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:23,135]\u001b[0m Trial 97 finished with value: 0.5206286836935167 and parameters: {'svc_c': 93.52067651172094, 'svc_gamma': 6.937657598396883}. Best is trial 96 with value: 0.8546168958742633.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:23,848]\u001b[0m Trial 98 finished with value: 0.5225933202357563 and parameters: {'svc_c': 97.70511413629971, 'svc_gamma': 4.166376271969349}. Best is trial 96 with value: 0.8546168958742633.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 10:27:24,545]\u001b[0m Trial 99 finished with value: 0.518664047151277 and parameters: {'svc_c': 91.38094756755056, 'svc_gamma': 8.4665169800508}. Best is trial 96 with value: 0.8546168958742633.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:24,553]\u001b[0m A new study created in memory with name: no-name-e88831fc-a41e-4942-b63b-7140826fb6fe\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "index        APAAC  LogisticRegression             True   \n",
      "index        APAAC                 SVC             True   \n",
      "index        APAAC       XGBClassifier             True   \n",
      "index        APAAC      LGBMClassifier             True   \n",
      "index          CTD  LogisticRegression            False   \n",
      "index          CTD                 SVC            False   \n",
      "index          CTD       XGBClassifier            False   \n",
      "index          CTD      LGBMClassifier            False   \n",
      "index          CTD  LogisticRegression             True   \n",
      "index          CTD                 SVC             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "index  {'C': 0.09972241221770178, 'penalty': 'l1', 's...  0.893281   \n",
      "index  {'svc_c': 81.00794411499099, 'svc_gamma': 0.03...  0.859684   \n",
      "index  {'learning_rate': 0.21557448587004335, 'max_de...  0.891304   \n",
      "index  {'num_leaves': 2, 'max_depth': 43, 'learning_r...  0.893281   \n",
      "index                                               None  0.862764   \n",
      "index                                               None  0.846564   \n",
      "index                                               None  0.853410   \n",
      "index                                               None  0.851444   \n",
      "index  {'C': 0.0906600851039587, 'penalty': 'l2', 'so...  0.870334   \n",
      "index  {'svc_c': 93.52276100739736, 'svc_gamma': 0.01...  0.854617   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "index     0.885714     0.900383   0.893004  0.889344  0.786319   \n",
      "index     0.869388     0.850575   0.845238  0.857143  0.719608   \n",
      "index     0.885714     0.896552   0.889344  0.887526  0.782370   \n",
      "index     0.889796     0.896552   0.889796  0.889796  0.786348   \n",
      "index     0.869388     0.867424   0.858871  0.864097  0.736539   \n",
      "index     0.836735     0.875000   0.861345  0.848861  0.712738   \n",
      "index     0.844898     0.886364   0.873418  0.858921  0.732486   \n",
      "index     0.853061     0.893939   0.881857  0.867220  0.748251   \n",
      "index     0.881633     0.859848   0.853755  0.867470  0.740977   \n",
      "index     0.828571     0.878788   0.863830  0.845833  0.708950   \n",
      "\n",
      "                                           index  \n",
      "index      AAC_LogisticRegression_no_hypertuning  \n",
      "index                     AAC_SVC_no_hypertuning  \n",
      "index           AAC_XGBClassifier_no_hypertuning  \n",
      "index          AAC_LGBMClassifier_no_hypertuning  \n",
      "index    AAC_LogisticRegression_with_hypertuning  \n",
      "index                   AAC_SVC_with_hypertuning  \n",
      "index         AAC_XGBClassifier_with_hypertuning  \n",
      "index        AAC_LGBMClassifier_with_hypertuning  \n",
      "index    APAAC_LogisticRegression_no_hypertuning  \n",
      "index                   APAAC_SVC_no_hypertuning  \n",
      "index         APAAC_XGBClassifier_no_hypertuning  \n",
      "index        APAAC_LGBMClassifier_no_hypertuning  \n",
      "index  APAAC_LogisticRegression_with_hypertuning  \n",
      "index                 APAAC_SVC_with_hypertuning  \n",
      "index       APAAC_XGBClassifier_with_hypertuning  \n",
      "index      APAAC_LGBMClassifier_with_hypertuning  \n",
      "index      CTD_LogisticRegression_no_hypertuning  \n",
      "index                     CTD_SVC_no_hypertuning  \n",
      "index           CTD_XGBClassifier_no_hypertuning  \n",
      "index          CTD_LGBMClassifier_no_hypertuning  \n",
      "index    CTD_LogisticRegression_with_hypertuning  \n",
      "index                   CTD_SVC_with_hypertuning  \n",
      "Optimizing CTD XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 10:27:26,887]\u001b[0m Trial 0 finished with value: 0.8840864440078585 and parameters: {'learning_rate': 0.07452517271666802, 'max_depth': 5, 'n_estimators': 128}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:30,577]\u001b[0m Trial 1 finished with value: 0.8821218074656189 and parameters: {'learning_rate': 0.053746908740568505, 'max_depth': 5, 'n_estimators': 249}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:37,318]\u001b[0m Trial 2 finished with value: 0.8644400785854617 and parameters: {'learning_rate': 0.16636846154066057, 'max_depth': 6, 'n_estimators': 752}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:44,751]\u001b[0m Trial 3 finished with value: 0.8801571709233792 and parameters: {'learning_rate': 0.043711362983126986, 'max_depth': 5, 'n_estimators': 650}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:49,841]\u001b[0m Trial 4 finished with value: 0.8703339882121808 and parameters: {'learning_rate': 0.08754107233677845, 'max_depth': 2, 'n_estimators': 990}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:54,787]\u001b[0m Trial 5 finished with value: 0.862475442043222 and parameters: {'learning_rate': 0.25858219539606997, 'max_depth': 3, 'n_estimators': 768}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:27:58,568]\u001b[0m Trial 6 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.08175154235914331, 'max_depth': 6, 'n_estimators': 261}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:28:06,079]\u001b[0m Trial 7 finished with value: 0.8742632612966601 and parameters: {'learning_rate': 0.16406296319569516, 'max_depth': 4, 'n_estimators': 918}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:28:09,746]\u001b[0m Trial 8 finished with value: 0.8762278978388998 and parameters: {'learning_rate': 0.05001277466733091, 'max_depth': 3, 'n_estimators': 456}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:28:14,603]\u001b[0m Trial 9 finished with value: 0.8703339882121808 and parameters: {'learning_rate': 0.20279397009768757, 'max_depth': 3, 'n_estimators': 692}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:28:16,664]\u001b[0m Trial 10 finished with value: 0.8408644400785854 and parameters: {'learning_rate': 0.013566297990910671, 'max_depth': 5, 'n_estimators': 130}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:28:20,760]\u001b[0m Trial 11 finished with value: 0.8821218074656189 and parameters: {'learning_rate': 0.10502161210984423, 'max_depth': 5, 'n_estimators': 348}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:28:22,526]\u001b[0m Trial 12 finished with value: 0.8703339882121808 and parameters: {'learning_rate': 0.11163673871550467, 'max_depth': 4, 'n_estimators': 104}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:28:26,964]\u001b[0m Trial 13 finished with value: 0.8664047151277013 and parameters: {'learning_rate': 0.014108721954836957, 'max_depth': 5, 'n_estimators': 311}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:28:29,880]\u001b[0m Trial 14 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.12830254478363232, 'max_depth': 6, 'n_estimators': 198}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:28:34,423]\u001b[0m Trial 15 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.050094023360562644, 'max_depth': 4, 'n_estimators': 454}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:28:39,872]\u001b[0m Trial 16 finished with value: 0.8840864440078585 and parameters: {'learning_rate': 0.0712058903074369, 'max_depth': 5, 'n_estimators': 409}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:28:45,321]\u001b[0m Trial 17 finished with value: 0.8722986247544204 and parameters: {'learning_rate': 0.1330463988033696, 'max_depth': 6, 'n_estimators': 444}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:28:49,310]\u001b[0m Trial 18 finished with value: 0.8683693516699411 and parameters: {'learning_rate': 0.07703643523254793, 'max_depth': 4, 'n_estimators': 374}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:28:55,542]\u001b[0m Trial 19 finished with value: 0.8722986247544204 and parameters: {'learning_rate': 0.14415569559736768, 'max_depth': 5, 'n_estimators': 593}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:29:01,628]\u001b[0m Trial 20 finished with value: 0.8762278978388998 and parameters: {'learning_rate': 0.09959210643792464, 'max_depth': 6, 'n_estimators': 509}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:29:04,626]\u001b[0m Trial 21 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.05346568244714529, 'max_depth': 5, 'n_estimators': 215}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:29:07,604]\u001b[0m Trial 22 finished with value: 0.8664047151277013 and parameters: {'learning_rate': 0.0717430294103314, 'max_depth': 5, 'n_estimators': 184}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:29:11,066]\u001b[0m Trial 23 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.026998767107765137, 'max_depth': 4, 'n_estimators': 313}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:29:14,274]\u001b[0m Trial 24 finished with value: 0.8742632612966601 and parameters: {'learning_rate': 0.072025497424767, 'max_depth': 5, 'n_estimators': 252}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:29:19,300]\u001b[0m Trial 25 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.031203058098993573, 'max_depth': 5, 'n_estimators': 373}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:29:22,006]\u001b[0m Trial 26 finished with value: 0.8821218074656189 and parameters: {'learning_rate': 0.06384648783428004, 'max_depth': 6, 'n_estimators': 159}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:29:24,876]\u001b[0m Trial 27 finished with value: 0.8801571709233792 and parameters: {'learning_rate': 0.09394853021806265, 'max_depth': 4, 'n_estimators': 276}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:29:30,907]\u001b[0m Trial 28 finished with value: 0.8801571709233792 and parameters: {'learning_rate': 0.03419660361336648, 'max_depth': 5, 'n_estimators': 404}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:29:37,303]\u001b[0m Trial 29 finished with value: 0.8722986247544204 and parameters: {'learning_rate': 0.11394742021911125, 'max_depth': 6, 'n_estimators': 540}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:29:40,051]\u001b[0m Trial 30 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.06196332341324276, 'max_depth': 4, 'n_estimators': 226}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:29:43,927]\u001b[0m Trial 31 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.1138950392469431, 'max_depth': 5, 'n_estimators': 328}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:29:48,585]\u001b[0m Trial 32 finished with value: 0.8722986247544204 and parameters: {'learning_rate': 0.09352209451370297, 'max_depth': 5, 'n_estimators': 349}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:29:50,357]\u001b[0m Trial 33 finished with value: 0.8683693516699411 and parameters: {'learning_rate': 0.04489961135149063, 'max_depth': 5, 'n_estimators': 106}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:29:51,331]\u001b[0m Trial 34 finished with value: 0.8605108055009824 and parameters: {'learning_rate': 0.08230780363218138, 'max_depth': 2, 'n_estimators': 169}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:29:55,663]\u001b[0m Trial 35 finished with value: 0.8821218074656189 and parameters: {'learning_rate': 0.06980010199412175, 'max_depth': 6, 'n_estimators': 287}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:30:04,015]\u001b[0m Trial 36 finished with value: 0.8722986247544204 and parameters: {'learning_rate': 0.09225813450156561, 'max_depth': 5, 'n_estimators': 810}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:30:10,851]\u001b[0m Trial 37 finished with value: 0.8821218074656189 and parameters: {'learning_rate': 0.0583017675900316, 'max_depth': 6, 'n_estimators': 491}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:30:17,077]\u001b[0m Trial 38 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.036844764924735936, 'max_depth': 5, 'n_estimators': 425}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:30:21,861]\u001b[0m Trial 39 finished with value: 0.8703339882121808 and parameters: {'learning_rate': 0.10420487327999726, 'max_depth': 3, 'n_estimators': 600}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:30:24,640]\u001b[0m Trial 40 finished with value: 0.8742632612966601 and parameters: {'learning_rate': 0.08577593294187004, 'max_depth': 4, 'n_estimators': 246}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:30:26,931]\u001b[0m Trial 41 finished with value: 0.8801571709233792 and parameters: {'learning_rate': 0.0685479949650428, 'max_depth': 6, 'n_estimators': 135}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:30:29,519]\u001b[0m Trial 42 finished with value: 0.8801571709233792 and parameters: {'learning_rate': 0.05572218935334995, 'max_depth': 6, 'n_estimators': 155}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:30:32,814]\u001b[0m Trial 43 finished with value: 0.8860510805500982 and parameters: {'learning_rate': 0.08366859640552504, 'max_depth': 6, 'n_estimators': 196}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:30:35,543]\u001b[0m Trial 44 finished with value: 0.8722986247544204 and parameters: {'learning_rate': 0.17321189707552126, 'max_depth': 5, 'n_estimators': 216}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:30:39,719]\u001b[0m Trial 45 finished with value: 0.8821218074656189 and parameters: {'learning_rate': 0.07909961768026093, 'max_depth': 6, 'n_estimators': 286}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:30:45,122]\u001b[0m Trial 46 finished with value: 0.8821218074656189 and parameters: {'learning_rate': 0.04621307646424215, 'max_depth': 5, 'n_estimators': 388}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:30:49,065]\u001b[0m Trial 47 finished with value: 0.8742632612966601 and parameters: {'learning_rate': 0.1044706690776325, 'max_depth': 4, 'n_estimators': 341}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:30:50,898]\u001b[0m Trial 48 finished with value: 0.8487229862475442 and parameters: {'learning_rate': 0.020046312058531204, 'max_depth': 3, 'n_estimators': 196}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:31:06,644]\u001b[0m Trial 49 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.011004055962160149, 'max_depth': 6, 'n_estimators': 982}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:31:08,260]\u001b[0m Trial 50 finished with value: 0.8703339882121808 and parameters: {'learning_rate': 0.12156220476259133, 'max_depth': 5, 'n_estimators': 101}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:31:11,544]\u001b[0m Trial 51 finished with value: 0.8703339882121808 and parameters: {'learning_rate': 0.06227489338897159, 'max_depth': 6, 'n_estimators': 150}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:31:16,200]\u001b[0m Trial 52 finished with value: 0.8821218074656189 and parameters: {'learning_rate': 0.08939917105171649, 'max_depth': 6, 'n_estimators': 245}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:31:19,731]\u001b[0m Trial 53 finished with value: 0.8821218074656189 and parameters: {'learning_rate': 0.042137355036148974, 'max_depth': 6, 'n_estimators': 194}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:31:23,585]\u001b[0m Trial 54 finished with value: 0.8722986247544204 and parameters: {'learning_rate': 0.07929355509992249, 'max_depth': 5, 'n_estimators': 287}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:31:26,069]\u001b[0m Trial 55 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.10059725482339402, 'max_depth': 6, 'n_estimators': 148}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:31:28,717]\u001b[0m Trial 56 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.06365135132440249, 'max_depth': 5, 'n_estimators': 182}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:31:32,426]\u001b[0m Trial 57 finished with value: 0.8860510805500982 and parameters: {'learning_rate': 0.052014343480933686, 'max_depth': 5, 'n_estimators': 244}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:31:40,011]\u001b[0m Trial 58 finished with value: 0.8860510805500982 and parameters: {'learning_rate': 0.051849185159939665, 'max_depth': 4, 'n_estimators': 327}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:31:43,586]\u001b[0m Trial 59 finished with value: 0.8801571709233792 and parameters: {'learning_rate': 0.02742680255166606, 'max_depth': 4, 'n_estimators': 317}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:31:46,379]\u001b[0m Trial 60 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.04046675934531975, 'max_depth': 4, 'n_estimators': 237}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:31:52,602]\u001b[0m Trial 61 finished with value: 0.8742632612966601 and parameters: {'learning_rate': 0.053987838498499426, 'max_depth': 4, 'n_estimators': 355}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:31:59,167]\u001b[0m Trial 62 finished with value: 0.8801571709233792 and parameters: {'learning_rate': 0.07385189365731816, 'max_depth': 5, 'n_estimators': 482}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:32:05,064]\u001b[0m Trial 63 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.049353449450137137, 'max_depth': 5, 'n_estimators': 407}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:32:08,214]\u001b[0m Trial 64 finished with value: 0.8762278978388998 and parameters: {'learning_rate': 0.07927412392947952, 'max_depth': 4, 'n_estimators': 266}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:32:12,277]\u001b[0m Trial 65 finished with value: 0.8742632612966601 and parameters: {'learning_rate': 0.05437515179540889, 'max_depth': 5, 'n_estimators': 309}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:32:15,431]\u001b[0m Trial 66 finished with value: 0.8821218074656189 and parameters: {'learning_rate': 0.07010886449155031, 'max_depth': 3, 'n_estimators': 367}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:32:18,358]\u001b[0m Trial 67 finished with value: 0.8742632612966601 and parameters: {'learning_rate': 0.03605270701402136, 'max_depth': 4, 'n_estimators': 217}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:32:24,469]\u001b[0m Trial 68 finished with value: 0.8722986247544204 and parameters: {'learning_rate': 0.0852827422197908, 'max_depth': 5, 'n_estimators': 446}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:32:34,912]\u001b[0m Trial 69 finished with value: 0.8821218074656189 and parameters: {'learning_rate': 0.025798478592025456, 'max_depth': 5, 'n_estimators': 712}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:32:36,793]\u001b[0m Trial 70 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.062395239569717126, 'max_depth': 5, 'n_estimators': 121}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:32:40,754]\u001b[0m Trial 71 finished with value: 0.8722986247544204 and parameters: {'learning_rate': 0.04536066219100209, 'max_depth': 6, 'n_estimators': 182}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:32:44,415]\u001b[0m Trial 72 finished with value: 0.8821218074656189 and parameters: {'learning_rate': 0.06601505876714432, 'max_depth': 5, 'n_estimators': 264}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:32:48,219]\u001b[0m Trial 73 finished with value: 0.8840864440078585 and parameters: {'learning_rate': 0.07243773882690832, 'max_depth': 6, 'n_estimators': 230}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:32:52,173]\u001b[0m Trial 74 finished with value: 0.8840864440078585 and parameters: {'learning_rate': 0.09558790780944139, 'max_depth': 5, 'n_estimators': 304}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:32:56,000]\u001b[0m Trial 75 finished with value: 0.8762278978388998 and parameters: {'learning_rate': 0.0951054932423982, 'max_depth': 5, 'n_estimators': 294}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:32:59,784]\u001b[0m Trial 76 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.08479404773981722, 'max_depth': 6, 'n_estimators': 220}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:33:03,480]\u001b[0m Trial 77 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.05598681554960453, 'max_depth': 4, 'n_estimators': 331}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:33:06,862]\u001b[0m Trial 78 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.07299586769092797, 'max_depth': 5, 'n_estimators': 256}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:33:09,289]\u001b[0m Trial 79 finished with value: 0.8742632612966601 and parameters: {'learning_rate': 0.0961027807914594, 'max_depth': 6, 'n_estimators': 129}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:33:11,391]\u001b[0m Trial 80 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.05059216665741841, 'max_depth': 4, 'n_estimators': 170}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:33:16,524]\u001b[0m Trial 81 finished with value: 0.8722986247544204 and parameters: {'learning_rate': 0.07562258121994664, 'max_depth': 5, 'n_estimators': 408}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:33:20,591]\u001b[0m Trial 82 finished with value: 0.8722986247544204 and parameters: {'learning_rate': 0.09051100326197548, 'max_depth': 5, 'n_estimators': 309}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:33:22,728]\u001b[0m Trial 83 finished with value: 0.8664047151277013 and parameters: {'learning_rate': 0.10392754646601518, 'max_depth': 2, 'n_estimators': 380}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:33:27,349]\u001b[0m Trial 84 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.08257138280817126, 'max_depth': 5, 'n_estimators': 343}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:33:30,575]\u001b[0m Trial 85 finished with value: 0.8762278978388998 and parameters: {'learning_rate': 0.059560697207126596, 'max_depth': 5, 'n_estimators': 204}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:33:33,725]\u001b[0m Trial 86 finished with value: 0.8762278978388998 and parameters: {'learning_rate': 0.06606675848192249, 'max_depth': 5, 'n_estimators': 236}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:33:37,752]\u001b[0m Trial 87 finished with value: 0.8742632612966601 and parameters: {'learning_rate': 0.1109874969412763, 'max_depth': 6, 'n_estimators': 273}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:33:42,131]\u001b[0m Trial 88 finished with value: 0.8742632612966601 and parameters: {'learning_rate': 0.07212674537459478, 'max_depth': 5, 'n_estimators': 299}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:33:49,474]\u001b[0m Trial 89 finished with value: 0.8781925343811395 and parameters: {'learning_rate': 0.0885150622188715, 'max_depth': 6, 'n_estimators': 546}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:33:59,433]\u001b[0m Trial 90 finished with value: 0.8821218074656189 and parameters: {'learning_rate': 0.043127739058519535, 'max_depth': 5, 'n_estimators': 832}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:34:02,220]\u001b[0m Trial 91 finished with value: 0.8801571709233792 and parameters: {'learning_rate': 0.06002905705643153, 'max_depth': 6, 'n_estimators': 156}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:34:05,818]\u001b[0m Trial 92 finished with value: 0.8821218074656189 and parameters: {'learning_rate': 0.07993031092947658, 'max_depth': 6, 'n_estimators': 229}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:34:08,811]\u001b[0m Trial 93 finished with value: 0.8801571709233792 and parameters: {'learning_rate': 0.0667815776933488, 'max_depth': 6, 'n_estimators': 170}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:34:13,755]\u001b[0m Trial 94 finished with value: 0.8762278978388998 and parameters: {'learning_rate': 0.05405980432864579, 'max_depth': 6, 'n_estimators': 259}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:34:16,159]\u001b[0m Trial 95 finished with value: 0.8801571709233792 and parameters: {'learning_rate': 0.03655683242818933, 'max_depth': 4, 'n_estimators': 198}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:34:18,536]\u001b[0m Trial 96 finished with value: 0.8742632612966601 and parameters: {'learning_rate': 0.04858928920839031, 'max_depth': 6, 'n_estimators': 124}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:34:22,616]\u001b[0m Trial 97 finished with value: 0.8762278978388998 and parameters: {'learning_rate': 0.09743562407696815, 'max_depth': 5, 'n_estimators': 327}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:34:27,996]\u001b[0m Trial 98 finished with value: 0.8801571709233792 and parameters: {'learning_rate': 0.07519509846184182, 'max_depth': 5, 'n_estimators': 425}. Best is trial 43 with value: 0.8860510805500982.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:34:33,568]\u001b[0m Trial 99 finished with value: 0.888015717092338 and parameters: {'learning_rate': 0.06876980973052808, 'max_depth': 6, 'n_estimators': 360}. Best is trial 99 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:34:33,583]\u001b[0m A new study created in memory with name: no-name-0fb3e2ab-3f43-4ab9-acf6-155195b58156\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "index        APAAC  LogisticRegression             True   \n",
      "index        APAAC                 SVC             True   \n",
      "index        APAAC       XGBClassifier             True   \n",
      "index        APAAC      LGBMClassifier             True   \n",
      "index          CTD  LogisticRegression            False   \n",
      "index          CTD                 SVC            False   \n",
      "index          CTD       XGBClassifier            False   \n",
      "index          CTD      LGBMClassifier            False   \n",
      "index          CTD  LogisticRegression             True   \n",
      "index          CTD                 SVC             True   \n",
      "index          CTD       XGBClassifier             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "index  {'C': 0.09972241221770178, 'penalty': 'l1', 's...  0.893281   \n",
      "index  {'svc_c': 81.00794411499099, 'svc_gamma': 0.03...  0.859684   \n",
      "index  {'learning_rate': 0.21557448587004335, 'max_de...  0.891304   \n",
      "index  {'num_leaves': 2, 'max_depth': 43, 'learning_r...  0.893281   \n",
      "index                                               None  0.862764   \n",
      "index                                               None  0.846564   \n",
      "index                                               None  0.853410   \n",
      "index                                               None  0.851444   \n",
      "index  {'C': 0.0906600851039587, 'penalty': 'l2', 'so...  0.870334   \n",
      "index  {'svc_c': 93.52276100739736, 'svc_gamma': 0.01...  0.854617   \n",
      "index  {'learning_rate': 0.06876980973052808, 'max_de...  0.888016   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "index     0.885714     0.900383   0.893004  0.889344  0.786319   \n",
      "index     0.869388     0.850575   0.845238  0.857143  0.719608   \n",
      "index     0.885714     0.896552   0.889344  0.887526  0.782370   \n",
      "index     0.889796     0.896552   0.889796  0.889796  0.786348   \n",
      "index     0.869388     0.867424   0.858871  0.864097  0.736539   \n",
      "index     0.836735     0.875000   0.861345  0.848861  0.712738   \n",
      "index     0.844898     0.886364   0.873418  0.858921  0.732486   \n",
      "index     0.853061     0.893939   0.881857  0.867220  0.748251   \n",
      "index     0.881633     0.859848   0.853755  0.867470  0.740977   \n",
      "index     0.828571     0.878788   0.863830  0.845833  0.708950   \n",
      "index     0.865306     0.909091   0.898305  0.881497  0.775910   \n",
      "\n",
      "                                           index  \n",
      "index      AAC_LogisticRegression_no_hypertuning  \n",
      "index                     AAC_SVC_no_hypertuning  \n",
      "index           AAC_XGBClassifier_no_hypertuning  \n",
      "index          AAC_LGBMClassifier_no_hypertuning  \n",
      "index    AAC_LogisticRegression_with_hypertuning  \n",
      "index                   AAC_SVC_with_hypertuning  \n",
      "index         AAC_XGBClassifier_with_hypertuning  \n",
      "index        AAC_LGBMClassifier_with_hypertuning  \n",
      "index    APAAC_LogisticRegression_no_hypertuning  \n",
      "index                   APAAC_SVC_no_hypertuning  \n",
      "index         APAAC_XGBClassifier_no_hypertuning  \n",
      "index        APAAC_LGBMClassifier_no_hypertuning  \n",
      "index  APAAC_LogisticRegression_with_hypertuning  \n",
      "index                 APAAC_SVC_with_hypertuning  \n",
      "index       APAAC_XGBClassifier_with_hypertuning  \n",
      "index      APAAC_LGBMClassifier_with_hypertuning  \n",
      "index      CTD_LogisticRegression_no_hypertuning  \n",
      "index                     CTD_SVC_no_hypertuning  \n",
      "index           CTD_XGBClassifier_no_hypertuning  \n",
      "index          CTD_LGBMClassifier_no_hypertuning  \n",
      "index    CTD_LogisticRegression_with_hypertuning  \n",
      "index                   CTD_SVC_with_hypertuning  \n",
      "index         CTD_XGBClassifier_with_hypertuning  \n",
      "Optimizing CTD LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 10:34:34,288]\u001b[0m Trial 0 finished with value: 0.8585461689587426 and parameters: {'num_leaves': 87, 'max_depth': 2, 'learning_rate': 0.12299639310330228, 'n_estimators': 738}. Best is trial 0 with value: 0.8585461689587426.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:34:39,622]\u001b[0m Trial 1 finished with value: 0.8644400785854617 and parameters: {'num_leaves': 130, 'max_depth': 36, 'learning_rate': 0.20977921642169522, 'n_estimators': 1509}. Best is trial 1 with value: 0.8644400785854617.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:34:46,221]\u001b[0m Trial 2 finished with value: 0.8683693516699411 and parameters: {'num_leaves': 64, 'max_depth': 38, 'learning_rate': 0.08892516525735251, 'n_estimators': 1810}. Best is trial 2 with value: 0.8683693516699411.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:34:50,145]\u001b[0m Trial 3 finished with value: 0.8664047151277013 and parameters: {'num_leaves': 212, 'max_depth': 18, 'learning_rate': 0.21138729776864718, 'n_estimators': 895}. Best is trial 2 with value: 0.8683693516699411.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:35:03,445]\u001b[0m Trial 4 finished with value: 0.8742632612966601 and parameters: {'num_leaves': 96, 'max_depth': 41, 'learning_rate': 0.018550118103718958, 'n_estimators': 886}. Best is trial 4 with value: 0.8742632612966601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:35:09,133]\u001b[0m Trial 5 finished with value: 0.8683693516699411 and parameters: {'num_leaves': 156, 'max_depth': 50, 'learning_rate': 0.09025729785241968, 'n_estimators': 1032}. Best is trial 4 with value: 0.8742632612966601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:35:18,434]\u001b[0m Trial 6 finished with value: 0.8703339882121808 and parameters: {'num_leaves': 239, 'max_depth': 32, 'learning_rate': 0.11579116419517745, 'n_estimators': 1881}. Best is trial 4 with value: 0.8742632612966601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:35:23,800]\u001b[0m Trial 7 finished with value: 0.862475442043222 and parameters: {'num_leaves': 254, 'max_depth': 42, 'learning_rate': 0.26795423049843586, 'n_estimators': 560}. Best is trial 4 with value: 0.8742632612966601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:35:25,908]\u001b[0m Trial 8 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 52, 'max_depth': 8, 'learning_rate': 0.19583316438504422, 'n_estimators': 350}. Best is trial 4 with value: 0.8742632612966601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:35:27,570]\u001b[0m Trial 9 finished with value: 0.8683693516699411 and parameters: {'num_leaves': 213, 'max_depth': 25, 'learning_rate': 0.25433058544512105, 'n_estimators': 114}. Best is trial 4 with value: 0.8742632612966601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:35:30,885]\u001b[0m Trial 10 finished with value: 0.8467583497053045 and parameters: {'num_leaves': 7, 'max_depth': 50, 'learning_rate': 0.0025222572570716972, 'n_estimators': 1300}. Best is trial 4 with value: 0.8742632612966601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:35:33,069]\u001b[0m Trial 11 finished with value: 0.8801571709233792 and parameters: {'num_leaves': 54, 'max_depth': 7, 'learning_rate': 0.02036170312816678, 'n_estimators': 282}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:35:33,578]\u001b[0m Trial 12 finished with value: 0.8055009823182712 and parameters: {'num_leaves': 3, 'max_depth': 18, 'learning_rate': 0.0027397627872706616, 'n_estimators': 434}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:35:42,717]\u001b[0m Trial 13 finished with value: 0.8683693516699411 and parameters: {'num_leaves': 99, 'max_depth': 14, 'learning_rate': 0.041056177024921134, 'n_estimators': 1220}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:35:43,774]\u001b[0m Trial 14 finished with value: 0.8762278978388998 and parameters: {'num_leaves': 47, 'max_depth': 30, 'learning_rate': 0.05565346254716298, 'n_estimators': 104}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:35:46,972]\u001b[0m Trial 15 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 37, 'max_depth': 23, 'learning_rate': 0.05821616519797365, 'n_estimators': 242}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:35:48,761]\u001b[0m Trial 16 finished with value: 0.8664047151277013 and parameters: {'num_leaves': 152, 'max_depth': 28, 'learning_rate': 0.05261952477125387, 'n_estimators': 111}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:35:49,401]\u001b[0m Trial 17 finished with value: 0.862475442043222 and parameters: {'num_leaves': 41, 'max_depth': 2, 'learning_rate': 0.03761779422977714, 'n_estimators': 601}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:35:53,106]\u001b[0m Trial 18 finished with value: 0.862475442043222 and parameters: {'num_leaves': 72, 'max_depth': 11, 'learning_rate': 0.07326339465923606, 'n_estimators': 391}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:36:02,775]\u001b[0m Trial 19 finished with value: 0.8781925343811395 and parameters: {'num_leaves': 117, 'max_depth': 30, 'learning_rate': 0.029770187098469333, 'n_estimators': 603}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:36:12,118]\u001b[0m Trial 20 finished with value: 0.8683693516699411 and parameters: {'num_leaves': 118, 'max_depth': 22, 'learning_rate': 0.028199935699111306, 'n_estimators': 649}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:36:14,210]\u001b[0m Trial 21 finished with value: 0.8683693516699411 and parameters: {'num_leaves': 27, 'max_depth': 30, 'learning_rate': 0.06360192197337149, 'n_estimators': 238}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:36:21,717]\u001b[0m Trial 22 finished with value: 0.8781925343811395 and parameters: {'num_leaves': 177, 'max_depth': 32, 'learning_rate': 0.030567970568292933, 'n_estimators': 481}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:36:36,434]\u001b[0m Trial 23 finished with value: 0.8683693516699411 and parameters: {'num_leaves': 174, 'max_depth': 33, 'learning_rate': 0.02379312714274879, 'n_estimators': 759}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:36:43,326]\u001b[0m Trial 24 finished with value: 0.8644400785854617 and parameters: {'num_leaves': 192, 'max_depth': 45, 'learning_rate': 0.008588641899833788, 'n_estimators': 480}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:36:48,694]\u001b[0m Trial 25 finished with value: 0.8742632612966601 and parameters: {'num_leaves': 126, 'max_depth': 36, 'learning_rate': 0.03734537700460365, 'n_estimators': 327}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:36:54,216]\u001b[0m Trial 26 finished with value: 0.8664047151277013 and parameters: {'num_leaves': 156, 'max_depth': 21, 'learning_rate': 0.08332194293677575, 'n_estimators': 852}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:37:02,207]\u001b[0m Trial 27 finished with value: 0.8801571709233792 and parameters: {'num_leaves': 194, 'max_depth': 26, 'learning_rate': 0.02663004845674135, 'n_estimators': 533}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:37:06,893]\u001b[0m Trial 28 finished with value: 0.862475442043222 and parameters: {'num_leaves': 118, 'max_depth': 10, 'learning_rate': 0.10628617543022381, 'n_estimators': 1068}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:37:09,837]\u001b[0m Trial 29 finished with value: 0.8703339882121808 and parameters: {'num_leaves': 76, 'max_depth': 7, 'learning_rate': 0.1404888783970254, 'n_estimators': 702}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:37:10,426]\u001b[0m Trial 30 finished with value: 0.8605108055009824 and parameters: {'num_leaves': 90, 'max_depth': 2, 'learning_rate': 0.07482233037557792, 'n_estimators': 264}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:37:18,109]\u001b[0m Trial 31 finished with value: 0.8683693516699411 and parameters: {'num_leaves': 195, 'max_depth': 26, 'learning_rate': 0.02614546978980293, 'n_estimators': 500}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:37:26,744]\u001b[0m Trial 32 finished with value: 0.8742632612966601 and parameters: {'num_leaves': 175, 'max_depth': 34, 'learning_rate': 0.04562522492449727, 'n_estimators': 758}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:37:35,103]\u001b[0m Trial 33 finished with value: 0.8447937131630648 and parameters: {'num_leaves': 144, 'max_depth': 39, 'learning_rate': 0.0023727847372509193, 'n_estimators': 530}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:37:51,930]\u001b[0m Trial 34 finished with value: 0.8683693516699411 and parameters: {'num_leaves': 220, 'max_depth': 18, 'learning_rate': 0.02017864068097829, 'n_estimators': 1651}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:37:58,757]\u001b[0m Trial 35 finished with value: 0.8762278978388998 and parameters: {'num_leaves': 172, 'max_depth': 14, 'learning_rate': 0.04387525909298118, 'n_estimators': 610}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:38:04,019]\u001b[0m Trial 36 finished with value: 0.8605108055009824 and parameters: {'num_leaves': 194, 'max_depth': 28, 'learning_rate': 0.10138839915000784, 'n_estimators': 986}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:38:09,234]\u001b[0m Trial 37 finished with value: 0.8683693516699411 and parameters: {'num_leaves': 231, 'max_depth': 36, 'learning_rate': 0.06438576735286028, 'n_estimators': 408}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:38:14,447]\u001b[0m Trial 38 finished with value: 0.8781925343811395 and parameters: {'num_leaves': 139, 'max_depth': 45, 'learning_rate': 0.09117386376014391, 'n_estimators': 835}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:38:19,934]\u001b[0m Trial 39 finished with value: 0.8762278978388998 and parameters: {'num_leaves': 184, 'max_depth': 29, 'learning_rate': 0.030441027250099797, 'n_estimators': 317}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:38:22,638]\u001b[0m Trial 40 finished with value: 0.8781925343811395 and parameters: {'num_leaves': 110, 'max_depth': 5, 'learning_rate': 0.014182828674719143, 'n_estimators': 703}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:38:28,185]\u001b[0m Trial 41 finished with value: 0.8703339882121808 and parameters: {'num_leaves': 138, 'max_depth': 44, 'learning_rate': 0.08512234106771441, 'n_estimators': 925}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:38:41,426]\u001b[0m Trial 42 finished with value: 0.8742632612966601 and parameters: {'num_leaves': 137, 'max_depth': 48, 'learning_rate': 0.01954761537515569, 'n_estimators': 830}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:38:48,800]\u001b[0m Trial 43 finished with value: 0.8644400785854617 and parameters: {'num_leaves': 164, 'max_depth': 41, 'learning_rate': 0.04555582405524129, 'n_estimators': 549}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:38:53,381]\u001b[0m Trial 44 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 212, 'max_depth': 32, 'learning_rate': 0.0676098403819966, 'n_estimators': 200}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:38:58,861]\u001b[0m Trial 45 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 63, 'max_depth': 46, 'learning_rate': 0.015969680445579996, 'n_estimators': 459}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:39:07,347]\u001b[0m Trial 46 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 202, 'max_depth': 39, 'learning_rate': 0.05272228751840326, 'n_estimators': 1085}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:39:13,241]\u001b[0m Trial 47 finished with value: 0.8703339882121808 and parameters: {'num_leaves': 106, 'max_depth': 19, 'learning_rate': 0.0953089614243752, 'n_estimators': 1212}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:39:22,689]\u001b[0m Trial 48 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 148, 'max_depth': 24, 'learning_rate': 0.03368247772591052, 'n_estimators': 759}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:39:28,781]\u001b[0m Trial 49 finished with value: 0.8565815324165029 and parameters: {'num_leaves': 16, 'max_depth': 16, 'learning_rate': 0.0018420101663278107, 'n_estimators': 1398}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:39:36,161]\u001b[0m Trial 50 finished with value: 0.8742632612966601 and parameters: {'num_leaves': 127, 'max_depth': 43, 'learning_rate': 0.07696621211395929, 'n_estimators': 632}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:39:40,055]\u001b[0m Trial 51 finished with value: 0.8742632612966601 and parameters: {'num_leaves': 106, 'max_depth': 6, 'learning_rate': 0.014543361332464672, 'n_estimators': 689}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:39:43,104]\u001b[0m Trial 52 finished with value: 0.8801571709233792 and parameters: {'num_leaves': 82, 'max_depth': 5, 'learning_rate': 0.011439332910228795, 'n_estimators': 822}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:39:45,404]\u001b[0m Trial 53 finished with value: 0.8703339882121808 and parameters: {'num_leaves': 89, 'max_depth': 4, 'learning_rate': 0.03287082303516426, 'n_estimators': 945}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:39:52,779]\u001b[0m Trial 54 finished with value: 0.8801571709233792 and parameters: {'num_leaves': 77, 'max_depth': 14, 'learning_rate': 0.055940755261388225, 'n_estimators': 808}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:39:54,704]\u001b[0m Trial 55 finished with value: 0.8742632612966601 and parameters: {'num_leaves': 57, 'max_depth': 8, 'learning_rate': 0.05556218721881742, 'n_estimators': 185}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:39:59,231]\u001b[0m Trial 56 finished with value: 0.8801571709233792 and parameters: {'num_leaves': 79, 'max_depth': 10, 'learning_rate': 0.024630290115681762, 'n_estimators': 384}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:40:06,401]\u001b[0m Trial 57 finished with value: 0.8644400785854617 and parameters: {'num_leaves': 79, 'max_depth': 10, 'learning_rate': 0.012056471794850603, 'n_estimators': 365}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:40:15,197]\u001b[0m Trial 58 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 66, 'max_depth': 14, 'learning_rate': 0.04633266574490229, 'n_estimators': 550}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:40:19,677]\u001b[0m Trial 59 finished with value: 0.8762278978388998 and parameters: {'num_leaves': 48, 'max_depth': 11, 'learning_rate': 0.023804902051095027, 'n_estimators': 416}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:40:22,208]\u001b[0m Trial 60 finished with value: 0.8742632612966601 and parameters: {'num_leaves': 33, 'max_depth': 13, 'learning_rate': 0.03936108506442375, 'n_estimators': 304}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:40:27,297]\u001b[0m Trial 61 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 82, 'max_depth': 9, 'learning_rate': 0.027735984428537627, 'n_estimators': 456}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:40:29,027]\u001b[0m Trial 62 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 65, 'max_depth': 4, 'learning_rate': 0.012343787448808319, 'n_estimators': 577}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:40:59,890]\u001b[0m Trial 63 finished with value: 0.8526522593320236 and parameters: {'num_leaves': 95, 'max_depth': 27, 'learning_rate': 0.0011857898333761906, 'n_estimators': 1989}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:41:06,841]\u001b[0m Trial 64 finished with value: 0.8742632612966601 and parameters: {'num_leaves': 57, 'max_depth': 31, 'learning_rate': 0.03356832924750394, 'n_estimators': 656}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:41:10,027]\u001b[0m Trial 65 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 251, 'max_depth': 35, 'learning_rate': 0.0558098253400766, 'n_estimators': 166}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:41:17,555]\u001b[0m Trial 66 finished with value: 0.8762278978388998 and parameters: {'num_leaves': 84, 'max_depth': 12, 'learning_rate': 0.02381991580484706, 'n_estimators': 509}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:41:25,425]\u001b[0m Trial 67 finished with value: 0.8664047151277013 and parameters: {'num_leaves': 71, 'max_depth': 16, 'learning_rate': 0.043397098945386514, 'n_estimators': 786}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:41:28,152]\u001b[0m Trial 68 finished with value: 0.8487229862475442 and parameters: {'num_leaves': 97, 'max_depth': 7, 'learning_rate': 0.008161380280319246, 'n_estimators': 270}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:41:30,158]\u001b[0m Trial 69 finished with value: 0.8742632612966601 and parameters: {'num_leaves': 24, 'max_depth': 21, 'learning_rate': 0.06068008807213679, 'n_estimators': 342}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:41:30,870]\u001b[0m Trial 70 finished with value: 0.8644400785854617 and parameters: {'num_leaves': 115, 'max_depth': 2, 'learning_rate': 0.02115876382741183, 'n_estimators': 598}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:41:42,228]\u001b[0m Trial 71 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 181, 'max_depth': 38, 'learning_rate': 0.03481885426458925, 'n_estimators': 882}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:41:52,927]\u001b[0m Trial 72 finished with value: 0.8664047151277013 and parameters: {'num_leaves': 164, 'max_depth': 25, 'learning_rate': 0.048537579274344975, 'n_estimators': 834}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:42:00,767]\u001b[0m Trial 73 finished with value: 0.8644400785854617 and parameters: {'num_leaves': 45, 'max_depth': 8, 'learning_rate': 0.07297024050772756, 'n_estimators': 999}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:42:04,197]\u001b[0m Trial 74 finished with value: 0.8742632612966601 and parameters: {'num_leaves': 73, 'max_depth': 5, 'learning_rate': 0.03875677081600321, 'n_estimators': 682}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:42:14,640]\u001b[0m Trial 75 finished with value: 0.8703339882121808 and parameters: {'num_leaves': 122, 'max_depth': 50, 'learning_rate': 0.06222409192300196, 'n_estimators': 478}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:42:32,942]\u001b[0m Trial 76 finished with value: 0.8683693516699411 and parameters: {'num_leaves': 137, 'max_depth': 33, 'learning_rate': 0.027982180227743732, 'n_estimators': 1158}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:42:42,324]\u001b[0m Trial 77 finished with value: 0.8664047151277013 and parameters: {'num_leaves': 205, 'max_depth': 16, 'learning_rate': 0.051868005204697656, 'n_estimators': 800}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:42:56,285]\u001b[0m Trial 78 finished with value: 0.8801571709233792 and parameters: {'num_leaves': 160, 'max_depth': 10, 'learning_rate': 0.01914414953586116, 'n_estimators': 731}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:43:05,907]\u001b[0m Trial 79 finished with value: 0.8644400785854617 and parameters: {'num_leaves': 188, 'max_depth': 9, 'learning_rate': 0.00888538222860169, 'n_estimators': 731}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:43:22,478]\u001b[0m Trial 80 finished with value: 0.8683693516699411 and parameters: {'num_leaves': 168, 'max_depth': 30, 'learning_rate': 0.022144496694255784, 'n_estimators': 395}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:43:35,609]\u001b[0m Trial 81 finished with value: 0.8781925343811395 and parameters: {'num_leaves': 153, 'max_depth': 11, 'learning_rate': 0.017436560283322668, 'n_estimators': 890}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:43:53,026]\u001b[0m Trial 82 finished with value: 0.8703339882121808 and parameters: {'num_leaves': 159, 'max_depth': 48, 'learning_rate': 0.02885477014470968, 'n_estimators': 634}. Best is trial 11 with value: 0.8801571709233792.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:43:56,703]\u001b[0m Trial 83 finished with value: 0.8821218074656189 and parameters: {'num_leaves': 143, 'max_depth': 4, 'learning_rate': 0.04113347255836544, 'n_estimators': 513}. Best is trial 83 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:43:59,047]\u001b[0m Trial 84 finished with value: 0.8683693516699411 and parameters: {'num_leaves': 145, 'max_depth': 4, 'learning_rate': 0.008150794058279242, 'n_estimators': 533}. Best is trial 83 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:44:02,399]\u001b[0m Trial 85 finished with value: 0.8683693516699411 and parameters: {'num_leaves': 179, 'max_depth': 7, 'learning_rate': 0.03945440535697511, 'n_estimators': 457}. Best is trial 83 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:44:04,209]\u001b[0m Trial 86 finished with value: 0.8644400785854617 and parameters: {'num_leaves': 133, 'max_depth': 3, 'learning_rate': 0.01808734033659697, 'n_estimators': 587}. Best is trial 83 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:44:06,620]\u001b[0m Trial 87 finished with value: 0.8801571709233792 and parameters: {'num_leaves': 54, 'max_depth': 6, 'learning_rate': 0.04623181492376677, 'n_estimators': 288}. Best is trial 83 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:44:09,024]\u001b[0m Trial 88 finished with value: 0.8703339882121808 and parameters: {'num_leaves': 56, 'max_depth': 6, 'learning_rate': 0.044578638428998174, 'n_estimators': 232}. Best is trial 83 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:44:13,350]\u001b[0m Trial 89 finished with value: 0.8742632612966601 and parameters: {'num_leaves': 37, 'max_depth': 6, 'learning_rate': 0.05074525254790184, 'n_estimators': 379}. Best is trial 83 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:44:17,859]\u001b[0m Trial 90 finished with value: 0.8742632612966601 and parameters: {'num_leaves': 50, 'max_depth': 9, 'learning_rate': 0.03144180295903965, 'n_estimators': 289}. Best is trial 83 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:44:21,165]\u001b[0m Trial 91 finished with value: 0.8644400785854617 and parameters: {'num_leaves': 90, 'max_depth': 3, 'learning_rate': 0.023748483708230093, 'n_estimators': 422}. Best is trial 83 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:44:25,931]\u001b[0m Trial 92 finished with value: 0.8683693516699411 and parameters: {'num_leaves': 159, 'max_depth': 12, 'learning_rate': 0.037497440722448774, 'n_estimators': 150}. Best is trial 83 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:44:33,175]\u001b[0m Trial 93 finished with value: 0.8742632612966601 and parameters: {'num_leaves': 102, 'max_depth': 5, 'learning_rate': 0.008372172036341071, 'n_estimators': 502}. Best is trial 83 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:44:47,650]\u001b[0m Trial 94 finished with value: 0.8722986247544204 and parameters: {'num_leaves': 201, 'max_depth': 10, 'learning_rate': 0.01666535637519534, 'n_estimators': 728}. Best is trial 83 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:44:54,964]\u001b[0m Trial 95 finished with value: 0.8801571709233792 and parameters: {'num_leaves': 63, 'max_depth': 29, 'learning_rate': 0.030625774647688765, 'n_estimators': 326}. Best is trial 83 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:45:00,439]\u001b[0m Trial 96 finished with value: 0.8683693516699411 and parameters: {'num_leaves': 61, 'max_depth': 8, 'learning_rate': 0.043031981029202984, 'n_estimators': 363}. Best is trial 83 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:45:06,364]\u001b[0m Trial 97 finished with value: 0.8781925343811395 and parameters: {'num_leaves': 69, 'max_depth': 28, 'learning_rate': 0.057305215472288534, 'n_estimators': 321}. Best is trial 83 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:45:07,020]\u001b[0m Trial 98 finished with value: 0.862475442043222 and parameters: {'num_leaves': 79, 'max_depth': 3, 'learning_rate': 0.028963326140339193, 'n_estimators': 252}. Best is trial 83 with value: 0.8821218074656189.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:45:08,525]\u001b[0m Trial 99 finished with value: 0.8683693516699411 and parameters: {'num_leaves': 54, 'max_depth': 26, 'learning_rate': 0.03578066518852713, 'n_estimators': 121}. Best is trial 83 with value: 0.8821218074656189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "index        APAAC  LogisticRegression             True   \n",
      "index        APAAC                 SVC             True   \n",
      "index        APAAC       XGBClassifier             True   \n",
      "index        APAAC      LGBMClassifier             True   \n",
      "index          CTD  LogisticRegression            False   \n",
      "index          CTD                 SVC            False   \n",
      "index          CTD       XGBClassifier            False   \n",
      "index          CTD      LGBMClassifier            False   \n",
      "index          CTD  LogisticRegression             True   \n",
      "index          CTD                 SVC             True   \n",
      "index          CTD       XGBClassifier             True   \n",
      "index          CTD      LGBMClassifier             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "index  {'C': 0.09972241221770178, 'penalty': 'l1', 's...  0.893281   \n",
      "index  {'svc_c': 81.00794411499099, 'svc_gamma': 0.03...  0.859684   \n",
      "index  {'learning_rate': 0.21557448587004335, 'max_de...  0.891304   \n",
      "index  {'num_leaves': 2, 'max_depth': 43, 'learning_r...  0.893281   \n",
      "index                                               None  0.862764   \n",
      "index                                               None  0.846564   \n",
      "index                                               None  0.853410   \n",
      "index                                               None  0.851444   \n",
      "index  {'C': 0.0906600851039587, 'penalty': 'l2', 'so...  0.870334   \n",
      "index  {'svc_c': 93.52276100739736, 'svc_gamma': 0.01...  0.854617   \n",
      "index  {'learning_rate': 0.06876980973052808, 'max_de...  0.888016   \n",
      "index  {'num_leaves': 143, 'max_depth': 4, 'learning_...  0.882122   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "index     0.885714     0.900383   0.893004  0.889344  0.786319   \n",
      "index     0.869388     0.850575   0.845238  0.857143  0.719608   \n",
      "index     0.885714     0.896552   0.889344  0.887526  0.782370   \n",
      "index     0.889796     0.896552   0.889796  0.889796  0.786348   \n",
      "index     0.869388     0.867424   0.858871  0.864097  0.736539   \n",
      "index     0.836735     0.875000   0.861345  0.848861  0.712738   \n",
      "index     0.844898     0.886364   0.873418  0.858921  0.732486   \n",
      "index     0.853061     0.893939   0.881857  0.867220  0.748251   \n",
      "index     0.881633     0.859848   0.853755  0.867470  0.740977   \n",
      "index     0.828571     0.878788   0.863830  0.845833  0.708950   \n",
      "index     0.865306     0.909091   0.898305  0.881497  0.775910   \n",
      "index     0.865306     0.897727   0.887029  0.876033  0.763920   \n",
      "\n",
      "                                           index  \n",
      "index      AAC_LogisticRegression_no_hypertuning  \n",
      "index                     AAC_SVC_no_hypertuning  \n",
      "index           AAC_XGBClassifier_no_hypertuning  \n",
      "index          AAC_LGBMClassifier_no_hypertuning  \n",
      "index    AAC_LogisticRegression_with_hypertuning  \n",
      "index                   AAC_SVC_with_hypertuning  \n",
      "index         AAC_XGBClassifier_with_hypertuning  \n",
      "index        AAC_LGBMClassifier_with_hypertuning  \n",
      "index    APAAC_LogisticRegression_no_hypertuning  \n",
      "index                   APAAC_SVC_no_hypertuning  \n",
      "index         APAAC_XGBClassifier_no_hypertuning  \n",
      "index        APAAC_LGBMClassifier_no_hypertuning  \n",
      "index  APAAC_LogisticRegression_with_hypertuning  \n",
      "index                 APAAC_SVC_with_hypertuning  \n",
      "index       APAAC_XGBClassifier_with_hypertuning  \n",
      "index      APAAC_LGBMClassifier_with_hypertuning  \n",
      "index      CTD_LogisticRegression_no_hypertuning  \n",
      "index                     CTD_SVC_no_hypertuning  \n",
      "index           CTD_XGBClassifier_no_hypertuning  \n",
      "index          CTD_LGBMClassifier_no_hypertuning  \n",
      "index    CTD_LogisticRegression_with_hypertuning  \n",
      "index                   CTD_SVC_with_hypertuning  \n",
      "index         CTD_XGBClassifier_with_hypertuning  \n",
      "index        CTD_LGBMClassifier_with_hypertuning  \n",
      "Evaluating DPC LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "index        APAAC  LogisticRegression             True   \n",
      "index        APAAC                 SVC             True   \n",
      "index        APAAC       XGBClassifier             True   \n",
      "index        APAAC      LGBMClassifier             True   \n",
      "index          CTD  LogisticRegression            False   \n",
      "index          CTD                 SVC            False   \n",
      "index          CTD       XGBClassifier            False   \n",
      "index          CTD      LGBMClassifier            False   \n",
      "index          CTD  LogisticRegression             True   \n",
      "index          CTD                 SVC             True   \n",
      "index          CTD       XGBClassifier             True   \n",
      "index          CTD      LGBMClassifier             True   \n",
      "index          DPC  LogisticRegression            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "index  {'C': 0.09972241221770178, 'penalty': 'l1', 's...  0.893281   \n",
      "index  {'svc_c': 81.00794411499099, 'svc_gamma': 0.03...  0.859684   \n",
      "index  {'learning_rate': 0.21557448587004335, 'max_de...  0.891304   \n",
      "index  {'num_leaves': 2, 'max_depth': 43, 'learning_r...  0.893281   \n",
      "index                                               None  0.862764   \n",
      "index                                               None  0.846564   \n",
      "index                                               None  0.853410   \n",
      "index                                               None  0.851444   \n",
      "index  {'C': 0.0906600851039587, 'penalty': 'l2', 'so...  0.870334   \n",
      "index  {'svc_c': 93.52276100739736, 'svc_gamma': 0.01...  0.854617   \n",
      "index  {'learning_rate': 0.06876980973052808, 'max_de...  0.888016   \n",
      "index  {'num_leaves': 143, 'max_depth': 4, 'learning_...  0.882122   \n",
      "index                                               None  0.830298   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "index     0.885714     0.900383   0.893004  0.889344  0.786319   \n",
      "index     0.869388     0.850575   0.845238  0.857143  0.719608   \n",
      "index     0.885714     0.896552   0.889344  0.887526  0.782370   \n",
      "index     0.889796     0.896552   0.889796  0.889796  0.786348   \n",
      "index     0.869388     0.867424   0.858871  0.864097  0.736539   \n",
      "index     0.836735     0.875000   0.861345  0.848861  0.712738   \n",
      "index     0.844898     0.886364   0.873418  0.858921  0.732486   \n",
      "index     0.853061     0.893939   0.881857  0.867220  0.748251   \n",
      "index     0.881633     0.859848   0.853755  0.867470  0.740977   \n",
      "index     0.828571     0.878788   0.863830  0.845833  0.708950   \n",
      "index     0.865306     0.909091   0.898305  0.881497  0.775910   \n",
      "index     0.865306     0.897727   0.887029  0.876033  0.763920   \n",
      "index     0.861224     0.875000   0.864754  0.862986  0.736338   \n",
      "\n",
      "                                           index  \n",
      "index      AAC_LogisticRegression_no_hypertuning  \n",
      "index                     AAC_SVC_no_hypertuning  \n",
      "index           AAC_XGBClassifier_no_hypertuning  \n",
      "index          AAC_LGBMClassifier_no_hypertuning  \n",
      "index    AAC_LogisticRegression_with_hypertuning  \n",
      "index                   AAC_SVC_with_hypertuning  \n",
      "index         AAC_XGBClassifier_with_hypertuning  \n",
      "index        AAC_LGBMClassifier_with_hypertuning  \n",
      "index    APAAC_LogisticRegression_no_hypertuning  \n",
      "index                   APAAC_SVC_no_hypertuning  \n",
      "index         APAAC_XGBClassifier_no_hypertuning  \n",
      "index        APAAC_LGBMClassifier_no_hypertuning  \n",
      "index  APAAC_LogisticRegression_with_hypertuning  \n",
      "index                 APAAC_SVC_with_hypertuning  \n",
      "index       APAAC_XGBClassifier_with_hypertuning  \n",
      "index      APAAC_LGBMClassifier_with_hypertuning  \n",
      "index      CTD_LogisticRegression_no_hypertuning  \n",
      "index                     CTD_SVC_no_hypertuning  \n",
      "index           CTD_XGBClassifier_no_hypertuning  \n",
      "index          CTD_LGBMClassifier_no_hypertuning  \n",
      "index    CTD_LogisticRegression_with_hypertuning  \n",
      "index                   CTD_SVC_with_hypertuning  \n",
      "index         CTD_XGBClassifier_with_hypertuning  \n",
      "index        CTD_LGBMClassifier_with_hypertuning  \n",
      "index      DPC_LogisticRegression_no_hypertuning  \n",
      "Evaluating DPC SVC\n",
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "index        APAAC  LogisticRegression             True   \n",
      "index        APAAC                 SVC             True   \n",
      "index        APAAC       XGBClassifier             True   \n",
      "index        APAAC      LGBMClassifier             True   \n",
      "index          CTD  LogisticRegression            False   \n",
      "index          CTD                 SVC            False   \n",
      "index          CTD       XGBClassifier            False   \n",
      "index          CTD      LGBMClassifier            False   \n",
      "index          CTD  LogisticRegression             True   \n",
      "index          CTD                 SVC             True   \n",
      "index          CTD       XGBClassifier             True   \n",
      "index          CTD      LGBMClassifier             True   \n",
      "index          DPC  LogisticRegression            False   \n",
      "index          DPC                 SVC            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "index  {'C': 0.09972241221770178, 'penalty': 'l1', 's...  0.893281   \n",
      "index  {'svc_c': 81.00794411499099, 'svc_gamma': 0.03...  0.859684   \n",
      "index  {'learning_rate': 0.21557448587004335, 'max_de...  0.891304   \n",
      "index  {'num_leaves': 2, 'max_depth': 43, 'learning_r...  0.893281   \n",
      "index                                               None  0.862764   \n",
      "index                                               None  0.846564   \n",
      "index                                               None  0.853410   \n",
      "index                                               None  0.851444   \n",
      "index  {'C': 0.0906600851039587, 'penalty': 'l2', 'so...  0.870334   \n",
      "index  {'svc_c': 93.52276100739736, 'svc_gamma': 0.01...  0.854617   \n",
      "index  {'learning_rate': 0.06876980973052808, 'max_de...  0.888016   \n",
      "index  {'num_leaves': 143, 'max_depth': 4, 'learning_...  0.882122   \n",
      "index                                               None  0.830298   \n",
      "index                                               None  0.891290   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "index     0.885714     0.900383   0.893004  0.889344  0.786319   \n",
      "index     0.869388     0.850575   0.845238  0.857143  0.719608   \n",
      "index     0.885714     0.896552   0.889344  0.887526  0.782370   \n",
      "index     0.889796     0.896552   0.889796  0.889796  0.786348   \n",
      "index     0.869388     0.867424   0.858871  0.864097  0.736539   \n",
      "index     0.836735     0.875000   0.861345  0.848861  0.712738   \n",
      "index     0.844898     0.886364   0.873418  0.858921  0.732486   \n",
      "index     0.853061     0.893939   0.881857  0.867220  0.748251   \n",
      "index     0.881633     0.859848   0.853755  0.867470  0.740977   \n",
      "index     0.828571     0.878788   0.863830  0.845833  0.708950   \n",
      "index     0.865306     0.909091   0.898305  0.881497  0.775910   \n",
      "index     0.865306     0.897727   0.887029  0.876033  0.763920   \n",
      "index     0.861224     0.875000   0.864754  0.862986  0.736338   \n",
      "index     0.885714     0.931818   0.923404  0.904167  0.819371   \n",
      "\n",
      "                                           index  \n",
      "index      AAC_LogisticRegression_no_hypertuning  \n",
      "index                     AAC_SVC_no_hypertuning  \n",
      "index           AAC_XGBClassifier_no_hypertuning  \n",
      "index          AAC_LGBMClassifier_no_hypertuning  \n",
      "index    AAC_LogisticRegression_with_hypertuning  \n",
      "index                   AAC_SVC_with_hypertuning  \n",
      "index         AAC_XGBClassifier_with_hypertuning  \n",
      "index        AAC_LGBMClassifier_with_hypertuning  \n",
      "index    APAAC_LogisticRegression_no_hypertuning  \n",
      "index                   APAAC_SVC_no_hypertuning  \n",
      "index         APAAC_XGBClassifier_no_hypertuning  \n",
      "index        APAAC_LGBMClassifier_no_hypertuning  \n",
      "index  APAAC_LogisticRegression_with_hypertuning  \n",
      "index                 APAAC_SVC_with_hypertuning  \n",
      "index       APAAC_XGBClassifier_with_hypertuning  \n",
      "index      APAAC_LGBMClassifier_with_hypertuning  \n",
      "index      CTD_LogisticRegression_no_hypertuning  \n",
      "index                     CTD_SVC_no_hypertuning  \n",
      "index           CTD_XGBClassifier_no_hypertuning  \n",
      "index          CTD_LGBMClassifier_no_hypertuning  \n",
      "index    CTD_LogisticRegression_with_hypertuning  \n",
      "index                   CTD_SVC_with_hypertuning  \n",
      "index         CTD_XGBClassifier_with_hypertuning  \n",
      "index        CTD_LGBMClassifier_with_hypertuning  \n",
      "index      DPC_LogisticRegression_no_hypertuning  \n",
      "index                     DPC_SVC_no_hypertuning  \n",
      "Evaluating DPC XGBClassifier\n",
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "index        APAAC  LogisticRegression             True   \n",
      "index        APAAC                 SVC             True   \n",
      "index        APAAC       XGBClassifier             True   \n",
      "index        APAAC      LGBMClassifier             True   \n",
      "index          CTD  LogisticRegression            False   \n",
      "index          CTD                 SVC            False   \n",
      "index          CTD       XGBClassifier            False   \n",
      "index          CTD      LGBMClassifier            False   \n",
      "index          CTD  LogisticRegression             True   \n",
      "index          CTD                 SVC             True   \n",
      "index          CTD       XGBClassifier             True   \n",
      "index          CTD      LGBMClassifier             True   \n",
      "index          DPC  LogisticRegression            False   \n",
      "index          DPC                 SVC            False   \n",
      "index          DPC       XGBClassifier            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "index  {'C': 0.09972241221770178, 'penalty': 'l1', 's...  0.893281   \n",
      "index  {'svc_c': 81.00794411499099, 'svc_gamma': 0.03...  0.859684   \n",
      "index  {'learning_rate': 0.21557448587004335, 'max_de...  0.891304   \n",
      "index  {'num_leaves': 2, 'max_depth': 43, 'learning_r...  0.893281   \n",
      "index                                               None  0.862764   \n",
      "index                                               None  0.846564   \n",
      "index                                               None  0.853410   \n",
      "index                                               None  0.851444   \n",
      "index  {'C': 0.0906600851039587, 'penalty': 'l2', 'so...  0.870334   \n",
      "index  {'svc_c': 93.52276100739736, 'svc_gamma': 0.01...  0.854617   \n",
      "index  {'learning_rate': 0.06876980973052808, 'max_de...  0.888016   \n",
      "index  {'num_leaves': 143, 'max_depth': 4, 'learning_...  0.882122   \n",
      "index                                               None  0.830298   \n",
      "index                                               None  0.891290   \n",
      "index                                               None  0.870646   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "index     0.885714     0.900383   0.893004  0.889344  0.786319   \n",
      "index     0.869388     0.850575   0.845238  0.857143  0.719608   \n",
      "index     0.885714     0.896552   0.889344  0.887526  0.782370   \n",
      "index     0.889796     0.896552   0.889796  0.889796  0.786348   \n",
      "index     0.869388     0.867424   0.858871  0.864097  0.736539   \n",
      "index     0.836735     0.875000   0.861345  0.848861  0.712738   \n",
      "index     0.844898     0.886364   0.873418  0.858921  0.732486   \n",
      "index     0.853061     0.893939   0.881857  0.867220  0.748251   \n",
      "index     0.881633     0.859848   0.853755  0.867470  0.740977   \n",
      "index     0.828571     0.878788   0.863830  0.845833  0.708950   \n",
      "index     0.865306     0.909091   0.898305  0.881497  0.775910   \n",
      "index     0.865306     0.897727   0.887029  0.876033  0.763920   \n",
      "index     0.861224     0.875000   0.864754  0.862986  0.736338   \n",
      "index     0.885714     0.931818   0.923404  0.904167  0.819371   \n",
      "index     0.897959     0.912879   0.905350  0.901639  0.811101   \n",
      "\n",
      "                                           index  \n",
      "index      AAC_LogisticRegression_no_hypertuning  \n",
      "index                     AAC_SVC_no_hypertuning  \n",
      "index           AAC_XGBClassifier_no_hypertuning  \n",
      "index          AAC_LGBMClassifier_no_hypertuning  \n",
      "index    AAC_LogisticRegression_with_hypertuning  \n",
      "index                   AAC_SVC_with_hypertuning  \n",
      "index         AAC_XGBClassifier_with_hypertuning  \n",
      "index        AAC_LGBMClassifier_with_hypertuning  \n",
      "index    APAAC_LogisticRegression_no_hypertuning  \n",
      "index                   APAAC_SVC_no_hypertuning  \n",
      "index         APAAC_XGBClassifier_no_hypertuning  \n",
      "index        APAAC_LGBMClassifier_no_hypertuning  \n",
      "index  APAAC_LogisticRegression_with_hypertuning  \n",
      "index                 APAAC_SVC_with_hypertuning  \n",
      "index       APAAC_XGBClassifier_with_hypertuning  \n",
      "index      APAAC_LGBMClassifier_with_hypertuning  \n",
      "index      CTD_LogisticRegression_no_hypertuning  \n",
      "index                     CTD_SVC_no_hypertuning  \n",
      "index           CTD_XGBClassifier_no_hypertuning  \n",
      "index          CTD_LGBMClassifier_no_hypertuning  \n",
      "index    CTD_LogisticRegression_with_hypertuning  \n",
      "index                   CTD_SVC_with_hypertuning  \n",
      "index         CTD_XGBClassifier_with_hypertuning  \n",
      "index        CTD_LGBMClassifier_with_hypertuning  \n",
      "index      DPC_LogisticRegression_no_hypertuning  \n",
      "index                     DPC_SVC_no_hypertuning  \n",
      "index           DPC_XGBClassifier_no_hypertuning  \n",
      "Evaluating DPC LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 10:45:46,819]\u001b[0m A new study created in memory with name: no-name-f6a3ddf3-c85a-4d2a-82ad-9a284b80b8f5\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:45:46,916]\u001b[0m Trial 0 finished with value: 0.8840864440078585 and parameters: {'C': 0.09461855210914735, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 345}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "index        APAAC  LogisticRegression             True   \n",
      "index        APAAC                 SVC             True   \n",
      "index        APAAC       XGBClassifier             True   \n",
      "index        APAAC      LGBMClassifier             True   \n",
      "index          CTD  LogisticRegression            False   \n",
      "index          CTD                 SVC            False   \n",
      "index          CTD       XGBClassifier            False   \n",
      "index          CTD      LGBMClassifier            False   \n",
      "index          CTD  LogisticRegression             True   \n",
      "index          CTD                 SVC             True   \n",
      "index          CTD       XGBClassifier             True   \n",
      "index          CTD      LGBMClassifier             True   \n",
      "index          DPC  LogisticRegression            False   \n",
      "index          DPC                 SVC            False   \n",
      "index          DPC       XGBClassifier            False   \n",
      "index          DPC      LGBMClassifier            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "index  {'C': 0.09972241221770178, 'penalty': 'l1', 's...  0.893281   \n",
      "index  {'svc_c': 81.00794411499099, 'svc_gamma': 0.03...  0.859684   \n",
      "index  {'learning_rate': 0.21557448587004335, 'max_de...  0.891304   \n",
      "index  {'num_leaves': 2, 'max_depth': 43, 'learning_r...  0.893281   \n",
      "index                                               None  0.862764   \n",
      "index                                               None  0.846564   \n",
      "index                                               None  0.853410   \n",
      "index                                               None  0.851444   \n",
      "index  {'C': 0.0906600851039587, 'penalty': 'l2', 'so...  0.870334   \n",
      "index  {'svc_c': 93.52276100739736, 'svc_gamma': 0.01...  0.854617   \n",
      "index  {'learning_rate': 0.06876980973052808, 'max_de...  0.888016   \n",
      "index  {'num_leaves': 143, 'max_depth': 4, 'learning_...  0.882122   \n",
      "index                                               None  0.830298   \n",
      "index                                               None  0.891290   \n",
      "index                                               None  0.870646   \n",
      "index                                               None  0.868656   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "index     0.885714     0.900383   0.893004  0.889344  0.786319   \n",
      "index     0.869388     0.850575   0.845238  0.857143  0.719608   \n",
      "index     0.885714     0.896552   0.889344  0.887526  0.782370   \n",
      "index     0.889796     0.896552   0.889796  0.889796  0.786348   \n",
      "index     0.869388     0.867424   0.858871  0.864097  0.736539   \n",
      "index     0.836735     0.875000   0.861345  0.848861  0.712738   \n",
      "index     0.844898     0.886364   0.873418  0.858921  0.732486   \n",
      "index     0.853061     0.893939   0.881857  0.867220  0.748251   \n",
      "index     0.881633     0.859848   0.853755  0.867470  0.740977   \n",
      "index     0.828571     0.878788   0.863830  0.845833  0.708950   \n",
      "index     0.865306     0.909091   0.898305  0.881497  0.775910   \n",
      "index     0.865306     0.897727   0.887029  0.876033  0.763920   \n",
      "index     0.861224     0.875000   0.864754  0.862986  0.736338   \n",
      "index     0.885714     0.931818   0.923404  0.904167  0.819371   \n",
      "index     0.897959     0.912879   0.905350  0.901639  0.811101   \n",
      "index     0.877551     0.901515   0.892116  0.884774  0.779621   \n",
      "\n",
      "                                           index  \n",
      "index      AAC_LogisticRegression_no_hypertuning  \n",
      "index                     AAC_SVC_no_hypertuning  \n",
      "index           AAC_XGBClassifier_no_hypertuning  \n",
      "index          AAC_LGBMClassifier_no_hypertuning  \n",
      "index    AAC_LogisticRegression_with_hypertuning  \n",
      "index                   AAC_SVC_with_hypertuning  \n",
      "index         AAC_XGBClassifier_with_hypertuning  \n",
      "index        AAC_LGBMClassifier_with_hypertuning  \n",
      "index    APAAC_LogisticRegression_no_hypertuning  \n",
      "index                   APAAC_SVC_no_hypertuning  \n",
      "index         APAAC_XGBClassifier_no_hypertuning  \n",
      "index        APAAC_LGBMClassifier_no_hypertuning  \n",
      "index  APAAC_LogisticRegression_with_hypertuning  \n",
      "index                 APAAC_SVC_with_hypertuning  \n",
      "index       APAAC_XGBClassifier_with_hypertuning  \n",
      "index      APAAC_LGBMClassifier_with_hypertuning  \n",
      "index      CTD_LogisticRegression_no_hypertuning  \n",
      "index                     CTD_SVC_no_hypertuning  \n",
      "index           CTD_XGBClassifier_no_hypertuning  \n",
      "index          CTD_LGBMClassifier_no_hypertuning  \n",
      "index    CTD_LogisticRegression_with_hypertuning  \n",
      "index                   CTD_SVC_with_hypertuning  \n",
      "index         CTD_XGBClassifier_with_hypertuning  \n",
      "index        CTD_LGBMClassifier_with_hypertuning  \n",
      "index      DPC_LogisticRegression_no_hypertuning  \n",
      "index                     DPC_SVC_no_hypertuning  \n",
      "index           DPC_XGBClassifier_no_hypertuning  \n",
      "index          DPC_LGBMClassifier_no_hypertuning  \n",
      "Optimizing DPC LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:45:49,484]\u001b[0m Trial 1 finished with value: 0.8664047151277013 and parameters: {'C': 0.024675658691057936, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 175}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:45:49,697]\u001b[0m Trial 2 finished with value: 0.8722986247544204 and parameters: {'C': 0.02364714439598118, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 939}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:45:49,780]\u001b[0m Trial 3 finished with value: 0.8801571709233792 and parameters: {'C': 0.07403465571273415, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 105}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:45:53,017]\u001b[0m Trial 4 finished with value: 0.8664047151277013 and parameters: {'C': 0.029283459631848432, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 240}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:45:53,283]\u001b[0m Trial 5 finished with value: 0.8644400785854617 and parameters: {'C': 0.05324501698364195, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 437}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:45:53,337]\u001b[0m Trial 6 finished with value: 0.8428290766208252 and parameters: {'C': 0.010758593749988575, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 949}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:45:56,039]\u001b[0m Trial 7 finished with value: 0.8742632612966601 and parameters: {'C': 0.015544999920404126, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 711}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:03,749]\u001b[0m Trial 8 finished with value: 0.8742632612966601 and parameters: {'C': 0.07345172824124173, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 833}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:46:05,336]\u001b[0m Trial 9 finished with value: 0.8821218074656189 and parameters: {'C': 0.06201371168940615, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 116}. Best is trial 0 with value: 0.8840864440078585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:05,429]\u001b[0m Trial 10 finished with value: 0.888015717092338 and parameters: {'C': 0.09937622983327421, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 417}. Best is trial 10 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:05,516]\u001b[0m Trial 11 finished with value: 0.888015717092338 and parameters: {'C': 0.09974751314173688, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 441}. Best is trial 10 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:05,603]\u001b[0m Trial 12 finished with value: 0.888015717092338 and parameters: {'C': 0.09903092987539412, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 559}. Best is trial 10 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:05,693]\u001b[0m Trial 13 finished with value: 0.888015717092338 and parameters: {'C': 0.09936069093089678, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 552}. Best is trial 10 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:05,778]\u001b[0m Trial 14 finished with value: 0.8840864440078585 and parameters: {'C': 0.08780164522512382, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 399}. Best is trial 10 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:05,856]\u001b[0m Trial 15 finished with value: 0.8860510805500982 and parameters: {'C': 0.08242776570548226, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 674}. Best is trial 10 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:05,941]\u001b[0m Trial 16 finished with value: 0.8840864440078585 and parameters: {'C': 0.08684411475535334, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 292}. Best is trial 10 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:06,045]\u001b[0m Trial 17 finished with value: 0.8821218074656189 and parameters: {'C': 0.09199657362550406, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 474}. Best is trial 10 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:06,150]\u001b[0m Trial 18 finished with value: 0.8899803536345776 and parameters: {'C': 0.09993412239940018, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 717}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:06,253]\u001b[0m Trial 19 finished with value: 0.8821218074656189 and parameters: {'C': 0.08047062657104923, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 684}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:06,358]\u001b[0m Trial 20 finished with value: 0.8821218074656189 and parameters: {'C': 0.08933642788674862, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 791}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:06,471]\u001b[0m Trial 21 finished with value: 0.888015717092338 and parameters: {'C': 0.09932626014211607, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 502}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:06,575]\u001b[0m Trial 22 finished with value: 0.8821218074656189 and parameters: {'C': 0.09262600459492235, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 593}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:06,682]\u001b[0m Trial 23 finished with value: 0.888015717092338 and parameters: {'C': 0.09925262549807144, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 339}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:06,788]\u001b[0m Trial 24 finished with value: 0.8860510805500982 and parameters: {'C': 0.08307960686411141, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 605}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:06,890]\u001b[0m Trial 25 finished with value: 0.8821218074656189 and parameters: {'C': 0.0768248190173862, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 793}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:06,999]\u001b[0m Trial 26 finished with value: 0.8840864440078585 and parameters: {'C': 0.08899492412681512, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 390}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:46:12,918]\u001b[0m Trial 27 finished with value: 0.8742632612966601 and parameters: {'C': 0.09355827360134583, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 495}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:13,005]\u001b[0m Trial 28 finished with value: 0.8860510805500982 and parameters: {'C': 0.08499816314196974, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 624}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:13,096]\u001b[0m Trial 29 finished with value: 0.8821218074656189 and parameters: {'C': 0.09413775040374255, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 302}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:13,198]\u001b[0m Trial 30 finished with value: 0.8821218074656189 and parameters: {'C': 0.06953565249168167, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 878}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:13,305]\u001b[0m Trial 31 finished with value: 0.888015717092338 and parameters: {'C': 0.09905036725551739, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 556}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:13,399]\u001b[0m Trial 32 finished with value: 0.8840864440078585 and parameters: {'C': 0.09467359384919481, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 730}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:13,504]\u001b[0m Trial 33 finished with value: 0.8840864440078585 and parameters: {'C': 0.09454560662214662, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 439}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:13,602]\u001b[0m Trial 34 finished with value: 0.888015717092338 and parameters: {'C': 0.09947531278955522, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 240}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:19,622]\u001b[0m Trial 35 finished with value: 0.8821218074656189 and parameters: {'C': 0.08761717083361949, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 525}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:19,900]\u001b[0m Trial 36 finished with value: 0.8722986247544204 and parameters: {'C': 0.0789648975928085, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 634}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:19,995]\u001b[0m Trial 37 finished with value: 0.8821218074656189 and parameters: {'C': 0.09445603577840457, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 998}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:46:24,352]\u001b[0m Trial 38 finished with value: 0.8703339882121808 and parameters: {'C': 0.08250377750272384, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 369}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:24,478]\u001b[0m Trial 39 finished with value: 0.8801571709233792 and parameters: {'C': 0.09004560106317148, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 456}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:24,786]\u001b[0m Trial 40 finished with value: 0.8664047151277013 and parameters: {'C': 0.04394475513201432, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 421}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:24,905]\u001b[0m Trial 41 finished with value: 0.888015717092338 and parameters: {'C': 0.09936795903380632, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 558}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:25,026]\u001b[0m Trial 42 finished with value: 0.888015717092338 and parameters: {'C': 0.09641935336576535, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 574}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:25,143]\u001b[0m Trial 43 finished with value: 0.8801571709233792 and parameters: {'C': 0.090808583236444, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 525}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:25,238]\u001b[0m Trial 44 finished with value: 0.8840864440078585 and parameters: {'C': 0.08696030388125126, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 743}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:46:30,238]\u001b[0m Trial 45 finished with value: 0.888015717092338 and parameters: {'C': 0.09463142950841688, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 343}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:30,347]\u001b[0m Trial 46 finished with value: 0.8899803536345776 and parameters: {'C': 0.09990343796214693, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 655}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:30,441]\u001b[0m Trial 47 finished with value: 0.8860510805500982 and parameters: {'C': 0.08457205457669985, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 665}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:30,551]\u001b[0m Trial 48 finished with value: 0.8821218074656189 and parameters: {'C': 0.0915614134277254, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 644}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:46:39,816]\u001b[0m Trial 49 finished with value: 0.8762278978388998 and parameters: {'C': 0.09649618918446289, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 780}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:39,902]\u001b[0m Trial 50 finished with value: 0.8801571709233792 and parameters: {'C': 0.09053949028884782, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 846}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:40,011]\u001b[0m Trial 51 finished with value: 0.888015717092338 and parameters: {'C': 0.09945387736398897, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 694}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:40,113]\u001b[0m Trial 52 finished with value: 0.888015717092338 and parameters: {'C': 0.0997892007306788, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 479}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:40,248]\u001b[0m Trial 53 finished with value: 0.888015717092338 and parameters: {'C': 0.09565574385186938, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 528}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:40,370]\u001b[0m Trial 54 finished with value: 0.8840864440078585 and parameters: {'C': 0.08854061901119106, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 597}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:40,478]\u001b[0m Trial 55 finished with value: 0.888015717092338 and parameters: {'C': 0.09662623796846456, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 408}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:40,574]\u001b[0m Trial 56 finished with value: 0.8840864440078585 and parameters: {'C': 0.08567568092032787, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 750}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:40,683]\u001b[0m Trial 57 finished with value: 0.8821218074656189 and parameters: {'C': 0.09153982480630515, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 459}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:40,831]\u001b[0m Trial 58 finished with value: 0.888015717092338 and parameters: {'C': 0.09628281881996802, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 664}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:40,941]\u001b[0m Trial 59 finished with value: 0.8840864440078585 and parameters: {'C': 0.08061500245119384, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 584}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:41,302]\u001b[0m Trial 60 finished with value: 0.8742632612966601 and parameters: {'C': 0.09190241924158432, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 292}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:41,410]\u001b[0m Trial 61 finished with value: 0.8899803536345776 and parameters: {'C': 0.09989845011829632, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 499}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:41,504]\u001b[0m Trial 62 finished with value: 0.888015717092338 and parameters: {'C': 0.09728836904325425, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 509}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:41,595]\u001b[0m Trial 63 finished with value: 0.888015717092338 and parameters: {'C': 0.09982225387962294, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 708}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:41,680]\u001b[0m Trial 64 finished with value: 0.8821218074656189 and parameters: {'C': 0.09350541497329103, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 377}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:41,769]\u001b[0m Trial 65 finished with value: 0.888015717092338 and parameters: {'C': 0.09738776734726316, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 545}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:41,851]\u001b[0m Trial 66 finished with value: 0.8840864440078585 and parameters: {'C': 0.08801789054177786, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 612}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:47,851]\u001b[0m Trial 67 finished with value: 0.8860510805500982 and parameters: {'C': 0.09294214062001946, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 490}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:47,958]\u001b[0m Trial 68 finished with value: 0.888015717092338 and parameters: {'C': 0.09642435795892403, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 454}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:48,072]\u001b[0m Trial 69 finished with value: 0.8801571709233792 and parameters: {'C': 0.09047838567608407, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 420}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:48,194]\u001b[0m Trial 70 finished with value: 0.8860510805500982 and parameters: {'C': 0.08484075882010712, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 629}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:48,279]\u001b[0m Trial 71 finished with value: 0.888015717092338 and parameters: {'C': 0.09762415378129542, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 500}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:48,385]\u001b[0m Trial 72 finished with value: 0.8899803536345776 and parameters: {'C': 0.09983148989647914, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 550}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:48,499]\u001b[0m Trial 73 finished with value: 0.8821218074656189 and parameters: {'C': 0.09407417794524733, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 575}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:48,619]\u001b[0m Trial 74 finished with value: 0.888015717092338 and parameters: {'C': 0.09959037264348551, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 545}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:48,721]\u001b[0m Trial 75 finished with value: 0.8821218074656189 and parameters: {'C': 0.09296770044818652, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 651}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:48,819]\u001b[0m Trial 76 finished with value: 0.888015717092338 and parameters: {'C': 0.09777992813399503, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 524}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:49,069]\u001b[0m Trial 77 finished with value: 0.8742632612966601 and parameters: {'C': 0.08847047307898882, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 436}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 10:46:53,467]\u001b[0m Trial 78 finished with value: 0.888015717092338 and parameters: {'C': 0.09490467250867751, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 312}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:53,570]\u001b[0m Trial 79 finished with value: 0.888015717092338 and parameters: {'C': 0.09755132180991856, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 565}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:53,668]\u001b[0m Trial 80 finished with value: 0.8821218074656189 and parameters: {'C': 0.08956787818046026, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 149}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:53,768]\u001b[0m Trial 81 finished with value: 0.888015717092338 and parameters: {'C': 0.09937625666372651, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 481}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:53,873]\u001b[0m Trial 82 finished with value: 0.8860510805500982 and parameters: {'C': 0.09485253594487411, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 365}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:53,974]\u001b[0m Trial 83 finished with value: 0.8821218074656189 and parameters: {'C': 0.09270400996637959, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 512}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:54,065]\u001b[0m Trial 84 finished with value: 0.8899803536345776 and parameters: {'C': 0.09992742293035291, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 465}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:54,169]\u001b[0m Trial 85 finished with value: 0.888015717092338 and parameters: {'C': 0.09733751799792312, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 393}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:54,270]\u001b[0m Trial 86 finished with value: 0.8860510805500982 and parameters: {'C': 0.09509456327681422, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 435}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:54,368]\u001b[0m Trial 87 finished with value: 0.8821218074656189 and parameters: {'C': 0.09174885667258156, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 462}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:46:54,632]\u001b[0m Trial 88 finished with value: 0.8762278978388998 and parameters: {'C': 0.09794443068863308, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 601}. Best is trial 18 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:47:00,253]\u001b[0m Trial 89 finished with value: 0.8919449901768173 and parameters: {'C': 0.09979066114998196, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 727}. Best is trial 89 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:47:05,722]\u001b[0m Trial 90 finished with value: 0.888015717092338 and parameters: {'C': 0.09570217820139895, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 727}. Best is trial 89 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:47:11,338]\u001b[0m Trial 91 finished with value: 0.8919449901768173 and parameters: {'C': 0.09964693969879848, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 686}. Best is trial 89 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:47:16,907]\u001b[0m Trial 92 finished with value: 0.8919449901768173 and parameters: {'C': 0.0996506689732702, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 769}. Best is trial 89 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:47:22,511]\u001b[0m Trial 93 finished with value: 0.8919449901768173 and parameters: {'C': 0.09779479551735996, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 816}. Best is trial 89 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:47:28,181]\u001b[0m Trial 94 finished with value: 0.8919449901768173 and parameters: {'C': 0.0997944438469492, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 841}. Best is trial 89 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:47:33,892]\u001b[0m Trial 95 finished with value: 0.8919449901768173 and parameters: {'C': 0.09772863154869406, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 821}. Best is trial 89 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:47:39,461]\u001b[0m Trial 96 finished with value: 0.888015717092338 and parameters: {'C': 0.09586861422657136, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 896}. Best is trial 89 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:47:44,724]\u001b[0m Trial 97 finished with value: 0.8860510805500982 and parameters: {'C': 0.09295714851322916, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 829}. Best is trial 89 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:47:50,869]\u001b[0m Trial 98 finished with value: 0.8919449901768173 and parameters: {'C': 0.09792186354996053, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 776}. Best is trial 89 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:47:56,522]\u001b[0m Trial 99 finished with value: 0.8840864440078585 and parameters: {'C': 0.08999727117567596, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 783}. Best is trial 89 with value: 0.8919449901768173.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:47:56,531]\u001b[0m A new study created in memory with name: no-name-008eaf09-85ba-4d66-a5bd-73325d89a3bf\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "index        APAAC  LogisticRegression             True   \n",
      "index        APAAC                 SVC             True   \n",
      "index        APAAC       XGBClassifier             True   \n",
      "index        APAAC      LGBMClassifier             True   \n",
      "index          CTD  LogisticRegression            False   \n",
      "index          CTD                 SVC            False   \n",
      "index          CTD       XGBClassifier            False   \n",
      "index          CTD      LGBMClassifier            False   \n",
      "index          CTD  LogisticRegression             True   \n",
      "index          CTD                 SVC             True   \n",
      "index          CTD       XGBClassifier             True   \n",
      "index          CTD      LGBMClassifier             True   \n",
      "index          DPC  LogisticRegression            False   \n",
      "index          DPC                 SVC            False   \n",
      "index          DPC       XGBClassifier            False   \n",
      "index          DPC      LGBMClassifier            False   \n",
      "index          DPC  LogisticRegression             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "index  {'C': 0.09972241221770178, 'penalty': 'l1', 's...  0.893281   \n",
      "index  {'svc_c': 81.00794411499099, 'svc_gamma': 0.03...  0.859684   \n",
      "index  {'learning_rate': 0.21557448587004335, 'max_de...  0.891304   \n",
      "index  {'num_leaves': 2, 'max_depth': 43, 'learning_r...  0.893281   \n",
      "index                                               None  0.862764   \n",
      "index                                               None  0.846564   \n",
      "index                                               None  0.853410   \n",
      "index                                               None  0.851444   \n",
      "index  {'C': 0.0906600851039587, 'penalty': 'l2', 'so...  0.870334   \n",
      "index  {'svc_c': 93.52276100739736, 'svc_gamma': 0.01...  0.854617   \n",
      "index  {'learning_rate': 0.06876980973052808, 'max_de...  0.888016   \n",
      "index  {'num_leaves': 143, 'max_depth': 4, 'learning_...  0.882122   \n",
      "index                                               None  0.830298   \n",
      "index                                               None  0.891290   \n",
      "index                                               None  0.870646   \n",
      "index                                               None  0.868656   \n",
      "index  {'C': 0.09979066114998196, 'penalty': 'l1', 's...  0.891945   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "index     0.885714     0.900383   0.893004  0.889344  0.786319   \n",
      "index     0.869388     0.850575   0.845238  0.857143  0.719608   \n",
      "index     0.885714     0.896552   0.889344  0.887526  0.782370   \n",
      "index     0.889796     0.896552   0.889796  0.889796  0.786348   \n",
      "index     0.869388     0.867424   0.858871  0.864097  0.736539   \n",
      "index     0.836735     0.875000   0.861345  0.848861  0.712738   \n",
      "index     0.844898     0.886364   0.873418  0.858921  0.732486   \n",
      "index     0.853061     0.893939   0.881857  0.867220  0.748251   \n",
      "index     0.881633     0.859848   0.853755  0.867470  0.740977   \n",
      "index     0.828571     0.878788   0.863830  0.845833  0.708950   \n",
      "index     0.865306     0.909091   0.898305  0.881497  0.775910   \n",
      "index     0.865306     0.897727   0.887029  0.876033  0.763920   \n",
      "index     0.861224     0.875000   0.864754  0.862986  0.736338   \n",
      "index     0.885714     0.931818   0.923404  0.904167  0.819371   \n",
      "index     0.897959     0.912879   0.905350  0.901639  0.811101   \n",
      "index     0.877551     0.901515   0.892116  0.884774  0.779621   \n",
      "index     0.889796     0.893939   0.886179  0.887984  0.783626   \n",
      "\n",
      "                                           index  \n",
      "index      AAC_LogisticRegression_no_hypertuning  \n",
      "index                     AAC_SVC_no_hypertuning  \n",
      "index           AAC_XGBClassifier_no_hypertuning  \n",
      "index          AAC_LGBMClassifier_no_hypertuning  \n",
      "index    AAC_LogisticRegression_with_hypertuning  \n",
      "index                   AAC_SVC_with_hypertuning  \n",
      "index         AAC_XGBClassifier_with_hypertuning  \n",
      "index        AAC_LGBMClassifier_with_hypertuning  \n",
      "index    APAAC_LogisticRegression_no_hypertuning  \n",
      "index                   APAAC_SVC_no_hypertuning  \n",
      "index         APAAC_XGBClassifier_no_hypertuning  \n",
      "index        APAAC_LGBMClassifier_no_hypertuning  \n",
      "index  APAAC_LogisticRegression_with_hypertuning  \n",
      "index                 APAAC_SVC_with_hypertuning  \n",
      "index       APAAC_XGBClassifier_with_hypertuning  \n",
      "index      APAAC_LGBMClassifier_with_hypertuning  \n",
      "index      CTD_LogisticRegression_no_hypertuning  \n",
      "index                     CTD_SVC_no_hypertuning  \n",
      "index           CTD_XGBClassifier_no_hypertuning  \n",
      "index          CTD_LGBMClassifier_no_hypertuning  \n",
      "index    CTD_LogisticRegression_with_hypertuning  \n",
      "index                   CTD_SVC_with_hypertuning  \n",
      "index         CTD_XGBClassifier_with_hypertuning  \n",
      "index        CTD_LGBMClassifier_with_hypertuning  \n",
      "index      DPC_LogisticRegression_no_hypertuning  \n",
      "index                     DPC_SVC_no_hypertuning  \n",
      "index           DPC_XGBClassifier_no_hypertuning  \n",
      "index          DPC_LGBMClassifier_no_hypertuning  \n",
      "index    DPC_LogisticRegression_with_hypertuning  \n",
      "Optimizing DPC SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 10:47:58,585]\u001b[0m Trial 0 finished with value: 0.518664047151277 and parameters: {'svc_c': 55.42136569609044, 'svc_gamma': 70.56632598783725}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:00,571]\u001b[0m Trial 1 finished with value: 0.518664047151277 and parameters: {'svc_c': 93.06292440273856, 'svc_gamma': 27.26896977946329}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:02,509]\u001b[0m Trial 2 finished with value: 0.518664047151277 and parameters: {'svc_c': 96.43130283525338, 'svc_gamma': 48.15357264572661}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:04,418]\u001b[0m Trial 3 finished with value: 0.518664047151277 and parameters: {'svc_c': 33.609121812055314, 'svc_gamma': 53.21941787628768}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:06,358]\u001b[0m Trial 4 finished with value: 0.518664047151277 and parameters: {'svc_c': 98.38118033269531, 'svc_gamma': 79.17804956999501}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:08,382]\u001b[0m Trial 5 finished with value: 0.518664047151277 and parameters: {'svc_c': 3.4695390759530316, 'svc_gamma': 60.21069031781}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:10,479]\u001b[0m Trial 6 finished with value: 0.518664047151277 and parameters: {'svc_c': 40.72701892367843, 'svc_gamma': 70.05289638441047}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:12,656]\u001b[0m Trial 7 finished with value: 0.518664047151277 and parameters: {'svc_c': 69.40968036529455, 'svc_gamma': 10.072230887548521}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:14,609]\u001b[0m Trial 8 finished with value: 0.518664047151277 and parameters: {'svc_c': 79.32706064560124, 'svc_gamma': 19.31337702259601}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:16,607]\u001b[0m Trial 9 finished with value: 0.518664047151277 and parameters: {'svc_c': 63.15192871226651, 'svc_gamma': 77.64322462996134}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:18,631]\u001b[0m Trial 10 finished with value: 0.518664047151277 and parameters: {'svc_c': 55.15279411872185, 'svc_gamma': 97.29533573448485}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:20,549]\u001b[0m Trial 11 finished with value: 0.518664047151277 and parameters: {'svc_c': 81.88339268716737, 'svc_gamma': 22.67263902421649}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:22,500]\u001b[0m Trial 12 finished with value: 0.518664047151277 and parameters: {'svc_c': 48.82741691637921, 'svc_gamma': 35.86882119226665}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:24,421]\u001b[0m Trial 13 finished with value: 0.518664047151277 and parameters: {'svc_c': 81.51710599978364, 'svc_gamma': 35.53186019807325}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:26,410]\u001b[0m Trial 14 finished with value: 0.518664047151277 and parameters: {'svc_c': 30.39917828683129, 'svc_gamma': 6.88831874536239}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:28,436]\u001b[0m Trial 15 finished with value: 0.518664047151277 and parameters: {'svc_c': 60.98475309942826, 'svc_gamma': 38.30397345131754}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:30,558]\u001b[0m Trial 16 finished with value: 0.518664047151277 and parameters: {'svc_c': 99.46012457453756, 'svc_gamma': 2.0006095142740072}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:32,552]\u001b[0m Trial 17 finished with value: 0.518664047151277 and parameters: {'svc_c': 70.98266899211612, 'svc_gamma': 25.62628111199013}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:34,551]\u001b[0m Trial 18 finished with value: 0.518664047151277 and parameters: {'svc_c': 88.08717912279829, 'svc_gamma': 64.01940010724309}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:36,532]\u001b[0m Trial 19 finished with value: 0.518664047151277 and parameters: {'svc_c': 73.59206861485751, 'svc_gamma': 47.76640171344897}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:38,514]\u001b[0m Trial 20 finished with value: 0.518664047151277 and parameters: {'svc_c': 88.15949390725741, 'svc_gamma': 90.00010951220204}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:40,462]\u001b[0m Trial 21 finished with value: 0.518664047151277 and parameters: {'svc_c': 93.1000882833525, 'svc_gamma': 47.68938118412527}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:42,398]\u001b[0m Trial 22 finished with value: 0.518664047151277 and parameters: {'svc_c': 90.5035756417499, 'svc_gamma': 57.453843024738454}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:44,440]\u001b[0m Trial 23 finished with value: 0.518664047151277 and parameters: {'svc_c': 96.67916370144002, 'svc_gamma': 42.184414101184}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:46,448]\u001b[0m Trial 24 finished with value: 0.518664047151277 and parameters: {'svc_c': 83.55552090537725, 'svc_gamma': 52.533917162144334}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:48,709]\u001b[0m Trial 25 finished with value: 0.518664047151277 and parameters: {'svc_c': 99.73543916334935, 'svc_gamma': 31.691778614875723}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:51,183]\u001b[0m Trial 26 finished with value: 0.518664047151277 and parameters: {'svc_c': 76.78628010091289, 'svc_gamma': 65.90909433389547}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:53,547]\u001b[0m Trial 27 finished with value: 0.518664047151277 and parameters: {'svc_c': 88.87507341317743, 'svc_gamma': 55.040490971402164}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:55,584]\u001b[0m Trial 28 finished with value: 0.518664047151277 and parameters: {'svc_c': 72.91610938177158, 'svc_gamma': 43.75431095356303}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:57,669]\u001b[0m Trial 29 finished with value: 0.518664047151277 and parameters: {'svc_c': 92.68385300553268, 'svc_gamma': 50.35133103528456}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:48:59,801]\u001b[0m Trial 30 finished with value: 0.518664047151277 and parameters: {'svc_c': 66.50757590569528, 'svc_gamma': 16.396567451934082}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:01,967]\u001b[0m Trial 31 finished with value: 0.518664047151277 and parameters: {'svc_c': 34.396253089786214, 'svc_gamma': 71.94501092435922}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:04,090]\u001b[0m Trial 32 finished with value: 0.518664047151277 and parameters: {'svc_c': 19.936533518215974, 'svc_gamma': 59.70110762163697}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:06,123]\u001b[0m Trial 33 finished with value: 0.518664047151277 and parameters: {'svc_c': 51.3444204900392, 'svc_gamma': 30.897155122505502}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:08,124]\u001b[0m Trial 34 finished with value: 0.518664047151277 and parameters: {'svc_c': 43.21782553693113, 'svc_gamma': 61.78385478857001}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:10,147]\u001b[0m Trial 35 finished with value: 0.518664047151277 and parameters: {'svc_c': 62.137977945578484, 'svc_gamma': 55.088710439498186}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:12,256]\u001b[0m Trial 36 finished with value: 0.518664047151277 and parameters: {'svc_c': 75.55301583945344, 'svc_gamma': 71.13504082689668}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:14,261]\u001b[0m Trial 37 finished with value: 0.518664047151277 and parameters: {'svc_c': 57.243866258587666, 'svc_gamma': 77.25702787495064}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:16,189]\u001b[0m Trial 38 finished with value: 0.518664047151277 and parameters: {'svc_c': 68.7465284803371, 'svc_gamma': 67.27844925675579}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:18,127]\u001b[0m Trial 39 finished with value: 0.518664047151277 and parameters: {'svc_c': 84.54073109715203, 'svc_gamma': 43.32210925477029}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:20,220]\u001b[0m Trial 40 finished with value: 0.518664047151277 and parameters: {'svc_c': 79.44310919921405, 'svc_gamma': 58.72421793306591}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:22,264]\u001b[0m Trial 41 finished with value: 0.518664047151277 and parameters: {'svc_c': 95.11059423203548, 'svc_gamma': 80.09491173088259}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:24,281]\u001b[0m Trial 42 finished with value: 0.518664047151277 and parameters: {'svc_c': 99.79230086181052, 'svc_gamma': 82.3092801709075}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:26,332]\u001b[0m Trial 43 finished with value: 0.518664047151277 and parameters: {'svc_c': 94.78409688270362, 'svc_gamma': 73.74749727929736}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:28,255]\u001b[0m Trial 44 finished with value: 0.518664047151277 and parameters: {'svc_c': 84.49593761638525, 'svc_gamma': 63.819808022594074}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:30,187]\u001b[0m Trial 45 finished with value: 0.518664047151277 and parameters: {'svc_c': 77.73050608465302, 'svc_gamma': 86.84009384158074}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:32,051]\u001b[0m Trial 46 finished with value: 0.518664047151277 and parameters: {'svc_c': 66.12871272706813, 'svc_gamma': 67.66029274161538}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:34,016]\u001b[0m Trial 47 finished with value: 0.518664047151277 and parameters: {'svc_c': 87.02175018252626, 'svc_gamma': 73.57718675104596}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:36,103]\u001b[0m Trial 48 finished with value: 0.518664047151277 and parameters: {'svc_c': 92.06251823357364, 'svc_gamma': 51.05520767031396}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:38,214]\u001b[0m Trial 49 finished with value: 0.518664047151277 and parameters: {'svc_c': 80.76507169865971, 'svc_gamma': 38.63359126458511}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:40,500]\u001b[0m Trial 50 finished with value: 0.518664047151277 and parameters: {'svc_c': 46.03787334577051, 'svc_gamma': 99.80781676044703}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:42,560]\u001b[0m Trial 51 finished with value: 0.518664047151277 and parameters: {'svc_c': 2.6994188437445152, 'svc_gamma': 55.6741540403453}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:44,564]\u001b[0m Trial 52 finished with value: 0.518664047151277 and parameters: {'svc_c': 57.825820383350845, 'svc_gamma': 62.98201004004761}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:46,640]\u001b[0m Trial 53 finished with value: 0.518664047151277 and parameters: {'svc_c': 41.3480402284092, 'svc_gamma': 68.10716039914115}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:48,721]\u001b[0m Trial 54 finished with value: 0.518664047151277 and parameters: {'svc_c': 49.989518892547544, 'svc_gamma': 59.84438090440743}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:50,775]\u001b[0m Trial 55 finished with value: 0.518664047151277 and parameters: {'svc_c': 96.78886508396312, 'svc_gamma': 45.82842831394624}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:52,801]\u001b[0m Trial 56 finished with value: 0.518664047151277 and parameters: {'svc_c': 72.73800605424297, 'svc_gamma': 40.593116823175244}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:54,729]\u001b[0m Trial 57 finished with value: 0.518664047151277 and parameters: {'svc_c': 90.62087926209541, 'svc_gamma': 49.91537966459571}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:56,774]\u001b[0m Trial 58 finished with value: 0.518664047151277 and parameters: {'svc_c': 25.834833552708318, 'svc_gamma': 46.82860299057691}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:49:59,078]\u001b[0m Trial 59 finished with value: 0.518664047151277 and parameters: {'svc_c': 87.60498273816921, 'svc_gamma': 35.77024293358453}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:50:01,500]\u001b[0m Trial 60 finished with value: 0.518664047151277 and parameters: {'svc_c': 97.75039139582219, 'svc_gamma': 53.328501618200036}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:50:03,921]\u001b[0m Trial 61 finished with value: 0.518664047151277 and parameters: {'svc_c': 52.560440758665194, 'svc_gamma': 57.03099216726426}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:50:05,860]\u001b[0m Trial 62 finished with value: 0.518664047151277 and parameters: {'svc_c': 54.13153064351046, 'svc_gamma': 69.83628781851364}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:50:07,871]\u001b[0m Trial 63 finished with value: 0.518664047151277 and parameters: {'svc_c': 37.29360970659828, 'svc_gamma': 64.8529889748428}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:50:10,160]\u001b[0m Trial 64 finished with value: 0.518664047151277 and parameters: {'svc_c': 47.47853974804619, 'svc_gamma': 75.69527593942094}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:50:12,154]\u001b[0m Trial 65 finished with value: 0.518664047151277 and parameters: {'svc_c': 59.89498768018527, 'svc_gamma': 61.1890836960503}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:50:14,158]\u001b[0m Trial 66 finished with value: 0.518664047151277 and parameters: {'svc_c': 92.0416181143215, 'svc_gamma': 22.507021861246734}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:50:16,204]\u001b[0m Trial 67 finished with value: 0.518664047151277 and parameters: {'svc_c': 56.14308762755935, 'svc_gamma': 71.11473278528062}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:50:18,330]\u001b[0m Trial 68 finished with value: 0.518664047151277 and parameters: {'svc_c': 82.36933570386925, 'svc_gamma': 65.59726223435104}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:50:20,477]\u001b[0m Trial 69 finished with value: 0.518664047151277 and parameters: {'svc_c': 64.26372695170346, 'svc_gamma': 58.57383039587121}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:50:22,461]\u001b[0m Trial 70 finished with value: 0.518664047151277 and parameters: {'svc_c': 94.17722104301879, 'svc_gamma': 77.79720244700366}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:50:24,384]\u001b[0m Trial 71 finished with value: 0.518664047151277 and parameters: {'svc_c': 70.70280291379149, 'svc_gamma': 13.991705912807266}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:50:26,335]\u001b[0m Trial 72 finished with value: 0.518664047151277 and parameters: {'svc_c': 75.23967833805526, 'svc_gamma': 8.687354493938527}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:50:28,385]\u001b[0m Trial 73 finished with value: 0.518664047151277 and parameters: {'svc_c': 60.30968995065566, 'svc_gamma': 30.968131996546244}. Best is trial 0 with value: 0.518664047151277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:50:30,697]\u001b[0m Trial 74 finished with value: 0.5245579567779961 and parameters: {'svc_c': 99.74224595881739, 'svc_gamma': 0.20021951123695203}. Best is trial 74 with value: 0.5245579567779961.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:50:32,979]\u001b[0m Trial 75 finished with value: 0.518664047151277 and parameters: {'svc_c': 99.29410949405965, 'svc_gamma': 11.919262468751498}. Best is trial 74 with value: 0.5245579567779961.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:50:35,184]\u001b[0m Trial 76 finished with value: 0.518664047151277 and parameters: {'svc_c': 96.45246721864245, 'svc_gamma': 28.152060586957518}. Best is trial 74 with value: 0.5245579567779961.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:50:37,205]\u001b[0m Trial 77 finished with value: 0.518664047151277 and parameters: {'svc_c': 93.80995291823511, 'svc_gamma': 19.525699788418976}. Best is trial 74 with value: 0.5245579567779961.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:50:39,185]\u001b[0m Trial 78 finished with value: 0.5206286836935167 and parameters: {'svc_c': 89.14201553433878, 'svc_gamma': 0.37989791256642036}. Best is trial 74 with value: 0.5245579567779961.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:50:41,171]\u001b[0m Trial 79 finished with value: 0.518664047151277 and parameters: {'svc_c': 90.2424025961667, 'svc_gamma': 0.5698821027706339}. Best is trial 74 with value: 0.5245579567779961.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:50:43,406]\u001b[0m Trial 80 finished with value: 0.518664047151277 and parameters: {'svc_c': 85.65713607469426, 'svc_gamma': 5.990921738328018}. Best is trial 74 with value: 0.5245579567779961.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:50:46,233]\u001b[0m Trial 81 finished with value: 0.518664047151277 and parameters: {'svc_c': 97.61116502762883, 'svc_gamma': 1.667019592677168}. Best is trial 74 with value: 0.5245579567779961.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:50:48,467]\u001b[0m Trial 82 finished with value: 0.518664047151277 and parameters: {'svc_c': 89.6518659547625, 'svc_gamma': 7.780530261461751}. Best is trial 74 with value: 0.5245579567779961.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:50:50,711]\u001b[0m Trial 83 finished with value: 0.518664047151277 and parameters: {'svc_c': 93.67277828942495, 'svc_gamma': 17.43272109622754}. Best is trial 74 with value: 0.5245579567779961.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:50:52,821]\u001b[0m Trial 84 finished with value: 0.518664047151277 and parameters: {'svc_c': 86.18095667923222, 'svc_gamma': 33.71023103468721}. Best is trial 74 with value: 0.5245579567779961.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:50:54,861]\u001b[0m Trial 85 finished with value: 0.518664047151277 and parameters: {'svc_c': 80.98898562192555, 'svc_gamma': 3.8529861894991417}. Best is trial 74 with value: 0.5245579567779961.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:50:57,099]\u001b[0m Trial 86 finished with value: 0.518664047151277 and parameters: {'svc_c': 95.75440509539594, 'svc_gamma': 3.3976574096159013}. Best is trial 74 with value: 0.5245579567779961.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:50:59,269]\u001b[0m Trial 87 finished with value: 0.518664047151277 and parameters: {'svc_c': 99.95263621714679, 'svc_gamma': 62.21676700447111}. Best is trial 74 with value: 0.5245579567779961.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:51:01,345]\u001b[0m Trial 88 finished with value: 0.518664047151277 and parameters: {'svc_c': 83.54199504704896, 'svc_gamma': 5.825030301615967}. Best is trial 74 with value: 0.5245579567779961.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:51:03,554]\u001b[0m Trial 89 finished with value: 0.5206286836935167 and parameters: {'svc_c': 91.46543286278849, 'svc_gamma': 0.38276853312956133}. Best is trial 74 with value: 0.5245579567779961.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:51:05,458]\u001b[0m Trial 90 finished with value: 0.518664047151277 and parameters: {'svc_c': 88.28732293907623, 'svc_gamma': 10.622554028135092}. Best is trial 74 with value: 0.5245579567779961.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:51:07,524]\u001b[0m Trial 91 finished with value: 0.518664047151277 and parameters: {'svc_c': 91.67295349757384, 'svc_gamma': 1.0519161089846523}. Best is trial 74 with value: 0.5245579567779961.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:51:09,616]\u001b[0m Trial 92 finished with value: 0.518664047151277 and parameters: {'svc_c': 95.21075463134434, 'svc_gamma': 4.2030541615405586}. Best is trial 74 with value: 0.5245579567779961.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:51:11,931]\u001b[0m Trial 93 finished with value: 0.518664047151277 and parameters: {'svc_c': 92.22167173386096, 'svc_gamma': 5.82182727463979}. Best is trial 74 with value: 0.5245579567779961.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:51:14,116]\u001b[0m Trial 94 finished with value: 0.518664047151277 and parameters: {'svc_c': 89.70924248292955, 'svc_gamma': 9.324910953390877}. Best is trial 74 with value: 0.5245579567779961.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:51:16,144]\u001b[0m Trial 95 finished with value: 0.518664047151277 and parameters: {'svc_c': 78.5092740473988, 'svc_gamma': 3.0088308094427703}. Best is trial 74 with value: 0.5245579567779961.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:51:18,184]\u001b[0m Trial 96 finished with value: 0.518664047151277 and parameters: {'svc_c': 97.13423963324261, 'svc_gamma': 0.6562383075125414}. Best is trial 74 with value: 0.5245579567779961.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:51:20,302]\u001b[0m Trial 97 finished with value: 0.518664047151277 and parameters: {'svc_c': 41.01455774246537, 'svc_gamma': 53.87444106949606}. Best is trial 74 with value: 0.5245579567779961.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:51:22,422]\u001b[0m Trial 98 finished with value: 0.518664047151277 and parameters: {'svc_c': 30.767760665122637, 'svc_gamma': 13.468512957486606}. Best is trial 74 with value: 0.5245579567779961.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:51:24,433]\u001b[0m Trial 99 finished with value: 0.5304518664047151 and parameters: {'svc_c': 48.97185920584053, 'svc_gamma': 0.0884268416906478}. Best is trial 99 with value: 0.5304518664047151.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:51:24,444]\u001b[0m A new study created in memory with name: no-name-d550bf40-f2a9-4f9f-bcee-2c9abe2f6a70\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "index        APAAC  LogisticRegression             True   \n",
      "index        APAAC                 SVC             True   \n",
      "index        APAAC       XGBClassifier             True   \n",
      "index        APAAC      LGBMClassifier             True   \n",
      "index          CTD  LogisticRegression            False   \n",
      "index          CTD                 SVC            False   \n",
      "index          CTD       XGBClassifier            False   \n",
      "index          CTD      LGBMClassifier            False   \n",
      "index          CTD  LogisticRegression             True   \n",
      "index          CTD                 SVC             True   \n",
      "index          CTD       XGBClassifier             True   \n",
      "index          CTD      LGBMClassifier             True   \n",
      "index          DPC  LogisticRegression            False   \n",
      "index          DPC                 SVC            False   \n",
      "index          DPC       XGBClassifier            False   \n",
      "index          DPC      LGBMClassifier            False   \n",
      "index          DPC  LogisticRegression             True   \n",
      "index          DPC                 SVC             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "index  {'C': 0.09972241221770178, 'penalty': 'l1', 's...  0.893281   \n",
      "index  {'svc_c': 81.00794411499099, 'svc_gamma': 0.03...  0.859684   \n",
      "index  {'learning_rate': 0.21557448587004335, 'max_de...  0.891304   \n",
      "index  {'num_leaves': 2, 'max_depth': 43, 'learning_r...  0.893281   \n",
      "index                                               None  0.862764   \n",
      "index                                               None  0.846564   \n",
      "index                                               None  0.853410   \n",
      "index                                               None  0.851444   \n",
      "index  {'C': 0.0906600851039587, 'penalty': 'l2', 'so...  0.870334   \n",
      "index  {'svc_c': 93.52276100739736, 'svc_gamma': 0.01...  0.854617   \n",
      "index  {'learning_rate': 0.06876980973052808, 'max_de...  0.888016   \n",
      "index  {'num_leaves': 143, 'max_depth': 4, 'learning_...  0.882122   \n",
      "index                                               None  0.830298   \n",
      "index                                               None  0.891290   \n",
      "index                                               None  0.870646   \n",
      "index                                               None  0.868656   \n",
      "index  {'C': 0.09979066114998196, 'penalty': 'l1', 's...  0.891945   \n",
      "index  {'svc_c': 48.97185920584053, 'svc_gamma': 0.08...  0.530452   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "index     0.885714     0.900383   0.893004  0.889344  0.786319   \n",
      "index     0.869388     0.850575   0.845238  0.857143  0.719608   \n",
      "index     0.885714     0.896552   0.889344  0.887526  0.782370   \n",
      "index     0.889796     0.896552   0.889796  0.889796  0.786348   \n",
      "index     0.869388     0.867424   0.858871  0.864097  0.736539   \n",
      "index     0.836735     0.875000   0.861345  0.848861  0.712738   \n",
      "index     0.844898     0.886364   0.873418  0.858921  0.732486   \n",
      "index     0.853061     0.893939   0.881857  0.867220  0.748251   \n",
      "index     0.881633     0.859848   0.853755  0.867470  0.740977   \n",
      "index     0.828571     0.878788   0.863830  0.845833  0.708950   \n",
      "index     0.865306     0.909091   0.898305  0.881497  0.775910   \n",
      "index     0.865306     0.897727   0.887029  0.876033  0.763920   \n",
      "index     0.861224     0.875000   0.864754  0.862986  0.736338   \n",
      "index     0.885714     0.931818   0.923404  0.904167  0.819371   \n",
      "index     0.897959     0.912879   0.905350  0.901639  0.811101   \n",
      "index     0.877551     0.901515   0.892116  0.884774  0.779621   \n",
      "index     0.889796     0.893939   0.886179  0.887984  0.783626   \n",
      "index     0.028571     0.996212   0.875000  0.055336  0.099560   \n",
      "\n",
      "                                           index  \n",
      "index      AAC_LogisticRegression_no_hypertuning  \n",
      "index                     AAC_SVC_no_hypertuning  \n",
      "index           AAC_XGBClassifier_no_hypertuning  \n",
      "index          AAC_LGBMClassifier_no_hypertuning  \n",
      "index    AAC_LogisticRegression_with_hypertuning  \n",
      "index                   AAC_SVC_with_hypertuning  \n",
      "index         AAC_XGBClassifier_with_hypertuning  \n",
      "index        AAC_LGBMClassifier_with_hypertuning  \n",
      "index    APAAC_LogisticRegression_no_hypertuning  \n",
      "index                   APAAC_SVC_no_hypertuning  \n",
      "index         APAAC_XGBClassifier_no_hypertuning  \n",
      "index        APAAC_LGBMClassifier_no_hypertuning  \n",
      "index  APAAC_LogisticRegression_with_hypertuning  \n",
      "index                 APAAC_SVC_with_hypertuning  \n",
      "index       APAAC_XGBClassifier_with_hypertuning  \n",
      "index      APAAC_LGBMClassifier_with_hypertuning  \n",
      "index      CTD_LogisticRegression_no_hypertuning  \n",
      "index                     CTD_SVC_no_hypertuning  \n",
      "index           CTD_XGBClassifier_no_hypertuning  \n",
      "index          CTD_LGBMClassifier_no_hypertuning  \n",
      "index    CTD_LogisticRegression_with_hypertuning  \n",
      "index                   CTD_SVC_with_hypertuning  \n",
      "index         CTD_XGBClassifier_with_hypertuning  \n",
      "index        CTD_LGBMClassifier_with_hypertuning  \n",
      "index      DPC_LogisticRegression_no_hypertuning  \n",
      "index                     DPC_SVC_no_hypertuning  \n",
      "index           DPC_XGBClassifier_no_hypertuning  \n",
      "index          DPC_LGBMClassifier_no_hypertuning  \n",
      "index    DPC_LogisticRegression_with_hypertuning  \n",
      "index                   DPC_SVC_with_hypertuning  \n",
      "Optimizing DPC XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 10:51:37,915]\u001b[0m Trial 0 finished with value: 0.888015717092338 and parameters: {'learning_rate': 0.01612243747149858, 'max_depth': 5, 'n_estimators': 994}. Best is trial 0 with value: 0.888015717092338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:51:47,862]\u001b[0m Trial 1 finished with value: 0.9017681728880157 and parameters: {'learning_rate': 0.027802567766687936, 'max_depth': 4, 'n_estimators': 979}. Best is trial 1 with value: 0.9017681728880157.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:51:52,491]\u001b[0m Trial 2 finished with value: 0.8939096267190569 and parameters: {'learning_rate': 0.04225595772130987, 'max_depth': 5, 'n_estimators': 298}. Best is trial 1 with value: 0.9017681728880157.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:51:58,620]\u001b[0m Trial 3 finished with value: 0.8978388998035364 and parameters: {'learning_rate': 0.06465847871731155, 'max_depth': 5, 'n_estimators': 495}. Best is trial 1 with value: 0.9017681728880157.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:52:05,803]\u001b[0m Trial 4 finished with value: 0.8939096267190569 and parameters: {'learning_rate': 0.2602448317722039, 'max_depth': 4, 'n_estimators': 855}. Best is trial 1 with value: 0.9017681728880157.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:52:07,657]\u001b[0m Trial 5 finished with value: 0.8978388998035364 and parameters: {'learning_rate': 0.18693640092842145, 'max_depth': 3, 'n_estimators': 215}. Best is trial 1 with value: 0.9017681728880157.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:52:10,007]\u001b[0m Trial 6 finished with value: 0.9017681728880157 and parameters: {'learning_rate': 0.19639747031384036, 'max_depth': 2, 'n_estimators': 382}. Best is trial 1 with value: 0.9017681728880157.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:52:14,953]\u001b[0m Trial 7 finished with value: 0.9056974459724951 and parameters: {'learning_rate': 0.17174428055941268, 'max_depth': 3, 'n_estimators': 495}. Best is trial 7 with value: 0.9056974459724951.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:52:19,896]\u001b[0m Trial 8 finished with value: 0.8939096267190569 and parameters: {'learning_rate': 0.14452211736623996, 'max_depth': 2, 'n_estimators': 905}. Best is trial 7 with value: 0.9056974459724951.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:52:24,706]\u001b[0m Trial 9 finished with value: 0.8978388998035364 and parameters: {'learning_rate': 0.24874024377258822, 'max_depth': 2, 'n_estimators': 726}. Best is trial 7 with value: 0.9056974459724951.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:52:31,415]\u001b[0m Trial 10 finished with value: 0.9056974459724951 and parameters: {'learning_rate': 0.29608244119149285, 'max_depth': 6, 'n_estimators': 635}. Best is trial 7 with value: 0.9056974459724951.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:52:37,922]\u001b[0m Trial 11 finished with value: 0.9017681728880157 and parameters: {'learning_rate': 0.2947623173732835, 'max_depth': 6, 'n_estimators': 639}. Best is trial 7 with value: 0.9056974459724951.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:52:42,157]\u001b[0m Trial 12 finished with value: 0.9037328094302554 and parameters: {'learning_rate': 0.11622150731027042, 'max_depth': 3, 'n_estimators': 499}. Best is trial 7 with value: 0.9056974459724951.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:52:49,986]\u001b[0m Trial 13 finished with value: 0.9076620825147348 and parameters: {'learning_rate': 0.20890216307968318, 'max_depth': 6, 'n_estimators': 683}. Best is trial 13 with value: 0.9076620825147348.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:52:57,091]\u001b[0m Trial 14 finished with value: 0.899803536345776 and parameters: {'learning_rate': 0.2002190327394674, 'max_depth': 3, 'n_estimators': 750}. Best is trial 13 with value: 0.9076620825147348.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:52:59,152]\u001b[0m Trial 15 finished with value: 0.8939096267190569 and parameters: {'learning_rate': 0.11965295739917833, 'max_depth': 4, 'n_estimators': 121}. Best is trial 13 with value: 0.9076620825147348.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:53:05,627]\u001b[0m Trial 16 finished with value: 0.8978388998035364 and parameters: {'learning_rate': 0.17255666953302295, 'max_depth': 6, 'n_estimators': 422}. Best is trial 13 with value: 0.9076620825147348.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:53:11,729]\u001b[0m Trial 17 finished with value: 0.888015717092338 and parameters: {'learning_rate': 0.22175370092806473, 'max_depth': 3, 'n_estimators': 627}. Best is trial 13 with value: 0.9076620825147348.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:53:21,389]\u001b[0m Trial 18 finished with value: 0.8939096267190569 and parameters: {'learning_rate': 0.15848013566513564, 'max_depth': 4, 'n_estimators': 751}. Best is trial 13 with value: 0.9076620825147348.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:53:27,717]\u001b[0m Trial 19 finished with value: 0.8899803536345776 and parameters: {'learning_rate': 0.2241917981504265, 'max_depth': 5, 'n_estimators': 538}. Best is trial 13 with value: 0.9076620825147348.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:53:31,644]\u001b[0m Trial 20 finished with value: 0.8899803536345776 and parameters: {'learning_rate': 0.14247868208356212, 'max_depth': 3, 'n_estimators': 386}. Best is trial 13 with value: 0.9076620825147348.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:53:38,264]\u001b[0m Trial 21 finished with value: 0.8958742632612967 and parameters: {'learning_rate': 0.2978369881793351, 'max_depth': 6, 'n_estimators': 633}. Best is trial 13 with value: 0.9076620825147348.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:53:46,799]\u001b[0m Trial 22 finished with value: 0.8939096267190569 and parameters: {'learning_rate': 0.2668945552054658, 'max_depth': 6, 'n_estimators': 592}. Best is trial 13 with value: 0.9076620825147348.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:53:57,889]\u001b[0m Trial 23 finished with value: 0.9037328094302554 and parameters: {'learning_rate': 0.22738993891977552, 'max_depth': 6, 'n_estimators': 840}. Best is trial 13 with value: 0.9076620825147348.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:54:07,114]\u001b[0m Trial 24 finished with value: 0.8899803536345776 and parameters: {'learning_rate': 0.28043356076136716, 'max_depth': 5, 'n_estimators': 722}. Best is trial 13 with value: 0.9076620825147348.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:54:13,897]\u001b[0m Trial 25 finished with value: 0.9037328094302554 and parameters: {'learning_rate': 0.24669354855426429, 'max_depth': 6, 'n_estimators': 444}. Best is trial 13 with value: 0.9076620825147348.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:54:23,809]\u001b[0m Trial 26 finished with value: 0.9017681728880157 and parameters: {'learning_rate': 0.27557669527194184, 'max_depth': 5, 'n_estimators': 686}. Best is trial 13 with value: 0.9076620825147348.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:54:32,068]\u001b[0m Trial 27 finished with value: 0.9017681728880157 and parameters: {'learning_rate': 0.20771622974550882, 'max_depth': 4, 'n_estimators': 550}. Best is trial 13 with value: 0.9076620825147348.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:54:38,166]\u001b[0m Trial 28 finished with value: 0.8958742632612967 and parameters: {'learning_rate': 0.23926796640629344, 'max_depth': 6, 'n_estimators': 311}. Best is trial 13 with value: 0.9076620825147348.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:54:50,416]\u001b[0m Trial 29 finished with value: 0.8958742632612967 and parameters: {'learning_rate': 0.21202660383067246, 'max_depth': 5, 'n_estimators': 804}. Best is trial 13 with value: 0.9076620825147348.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:55:02,117]\u001b[0m Trial 30 finished with value: 0.8919449901768173 and parameters: {'learning_rate': 0.1805311131782529, 'max_depth': 5, 'n_estimators': 589}. Best is trial 13 with value: 0.9076620825147348.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:55:07,407]\u001b[0m Trial 31 finished with value: 0.9017681728880157 and parameters: {'learning_rate': 0.12305461158252998, 'max_depth': 3, 'n_estimators': 476}. Best is trial 13 with value: 0.9076620825147348.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:55:12,400]\u001b[0m Trial 32 finished with value: 0.899803536345776 and parameters: {'learning_rate': 0.17290837421570238, 'max_depth': 3, 'n_estimators': 507}. Best is trial 13 with value: 0.9076620825147348.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:55:17,566]\u001b[0m Trial 33 finished with value: 0.8939096267190569 and parameters: {'learning_rate': 0.09887890847652472, 'max_depth': 2, 'n_estimators': 684}. Best is trial 13 with value: 0.9076620825147348.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:55:23,251]\u001b[0m Trial 34 finished with value: 0.8939096267190569 and parameters: {'learning_rate': 0.1633525954373874, 'max_depth': 3, 'n_estimators': 567}. Best is trial 13 with value: 0.9076620825147348.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:55:28,408]\u001b[0m Trial 35 finished with value: 0.9096267190569745 and parameters: {'learning_rate': 0.19163336592189226, 'max_depth': 4, 'n_estimators': 321}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:55:33,382]\u001b[0m Trial 36 finished with value: 0.899803536345776 and parameters: {'learning_rate': 0.19381485961179998, 'max_depth': 4, 'n_estimators': 284}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:55:38,381]\u001b[0m Trial 37 finished with value: 0.9017681728880157 and parameters: {'learning_rate': 0.25608990032591905, 'max_depth': 4, 'n_estimators': 176}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:55:43,747]\u001b[0m Trial 38 finished with value: 0.8939096267190569 and parameters: {'learning_rate': 0.18773205505737578, 'max_depth': 5, 'n_estimators': 329}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:55:49,008]\u001b[0m Trial 39 finished with value: 0.8919449901768173 and parameters: {'learning_rate': 0.23314435504946407, 'max_depth': 4, 'n_estimators': 361}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:56:01,510]\u001b[0m Trial 40 finished with value: 0.8958742632612967 and parameters: {'learning_rate': 0.21413580038756633, 'max_depth': 5, 'n_estimators': 997}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:56:03,935]\u001b[0m Trial 41 finished with value: 0.8899803536345776 and parameters: {'learning_rate': 0.20500688340225875, 'max_depth': 3, 'n_estimators': 256}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:56:06,887]\u001b[0m Trial 42 finished with value: 0.9056974459724951 and parameters: {'learning_rate': 0.2415008255222369, 'max_depth': 2, 'n_estimators': 467}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:56:09,948]\u001b[0m Trial 43 finished with value: 0.9017681728880157 and parameters: {'learning_rate': 0.2413955943021102, 'max_depth': 2, 'n_estimators': 427}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:56:12,826]\u001b[0m Trial 44 finished with value: 0.9017681728880157 and parameters: {'learning_rate': 0.26202006249547594, 'max_depth': 2, 'n_estimators': 461}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:56:16,551]\u001b[0m Trial 45 finished with value: 0.8978388998035364 and parameters: {'learning_rate': 0.2826584405490098, 'max_depth': 2, 'n_estimators': 523}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:56:19,136]\u001b[0m Trial 46 finished with value: 0.899803536345776 and parameters: {'learning_rate': 0.1942090280988406, 'max_depth': 2, 'n_estimators': 397}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:56:26,846]\u001b[0m Trial 47 finished with value: 0.8978388998035364 and parameters: {'learning_rate': 0.25472483203626417, 'max_depth': 6, 'n_estimators': 682}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:56:36,101]\u001b[0m Trial 48 finished with value: 0.8958742632612967 and parameters: {'learning_rate': 0.23329766721310502, 'max_depth': 4, 'n_estimators': 899}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:56:37,749]\u001b[0m Trial 49 finished with value: 0.888015717092338 and parameters: {'learning_rate': 0.21705081257360787, 'max_depth': 2, 'n_estimators': 226}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:56:43,145]\u001b[0m Trial 50 finished with value: 0.8958742632612967 and parameters: {'learning_rate': 0.17933566125282224, 'max_depth': 3, 'n_estimators': 602}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:56:47,566]\u001b[0m Trial 51 finished with value: 0.8958742632612967 and parameters: {'learning_rate': 0.20445876953128073, 'max_depth': 3, 'n_estimators': 500}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:56:54,448]\u001b[0m Trial 52 finished with value: 0.9017681728880157 and parameters: {'learning_rate': 0.22214099346920196, 'max_depth': 4, 'n_estimators': 635}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:56:57,646]\u001b[0m Trial 53 finished with value: 0.888015717092338 and parameters: {'learning_rate': 0.2965282824893356, 'max_depth': 3, 'n_estimators': 365}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:57:08,452]\u001b[0m Trial 54 finished with value: 0.8958742632612967 and parameters: {'learning_rate': 0.1477390778271094, 'max_depth': 6, 'n_estimators': 787}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:57:15,169]\u001b[0m Trial 55 finished with value: 0.899803536345776 and parameters: {'learning_rate': 0.1684420174262091, 'max_depth': 4, 'n_estimators': 559}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:57:19,240]\u001b[0m Trial 56 finished with value: 0.8958742632612967 and parameters: {'learning_rate': 0.27026472993638295, 'max_depth': 3, 'n_estimators': 412}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:57:22,445]\u001b[0m Trial 57 finished with value: 0.8978388998035364 and parameters: {'learning_rate': 0.2481862302184063, 'max_depth': 2, 'n_estimators': 490}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:57:30,127]\u001b[0m Trial 58 finished with value: 0.899803536345776 and parameters: {'learning_rate': 0.2876994109442293, 'max_depth': 6, 'n_estimators': 717}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:57:40,270]\u001b[0m Trial 59 finished with value: 0.9017681728880157 and parameters: {'learning_rate': 0.19586092718525513, 'max_depth': 5, 'n_estimators': 453}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:57:47,004]\u001b[0m Trial 60 finished with value: 0.8978388998035364 and parameters: {'learning_rate': 0.26859653234107717, 'max_depth': 3, 'n_estimators': 649}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:57:57,793]\u001b[0m Trial 61 finished with value: 0.9056974459724951 and parameters: {'learning_rate': 0.22209315311655609, 'max_depth': 6, 'n_estimators': 859}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:58:09,894]\u001b[0m Trial 62 finished with value: 0.8958742632612967 and parameters: {'learning_rate': 0.22975840614854207, 'max_depth': 6, 'n_estimators': 762}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:58:20,814]\u001b[0m Trial 63 finished with value: 0.899803536345776 and parameters: {'learning_rate': 0.21745650439781142, 'max_depth': 6, 'n_estimators': 947}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:58:29,287]\u001b[0m Trial 64 finished with value: 0.899803536345776 and parameters: {'learning_rate': 0.18503422223593208, 'max_depth': 6, 'n_estimators': 537}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:58:39,938]\u001b[0m Trial 65 finished with value: 0.9056974459724951 and parameters: {'learning_rate': 0.20572577065141698, 'max_depth': 6, 'n_estimators': 871}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:58:50,812]\u001b[0m Trial 66 finished with value: 0.9017681728880157 and parameters: {'learning_rate': 0.2109096648603498, 'max_depth': 6, 'n_estimators': 874}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:59:01,206]\u001b[0m Trial 67 finished with value: 0.8958742632612967 and parameters: {'learning_rate': 0.20324477617137365, 'max_depth': 6, 'n_estimators': 833}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:59:11,480]\u001b[0m Trial 68 finished with value: 0.899803536345776 and parameters: {'learning_rate': 0.23904150572228605, 'max_depth': 6, 'n_estimators': 897}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:59:23,234]\u001b[0m Trial 69 finished with value: 0.8958742632612967 and parameters: {'learning_rate': 0.18863830715690755, 'max_depth': 6, 'n_estimators': 963}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:59:25,734]\u001b[0m Trial 70 finished with value: 0.9056974459724951 and parameters: {'learning_rate': 0.2231670804735013, 'max_depth': 5, 'n_estimators': 113}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:59:38,645]\u001b[0m Trial 71 finished with value: 0.9056974459724951 and parameters: {'learning_rate': 0.2215910121419457, 'max_depth': 5, 'n_estimators': 814}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:59:40,493]\u001b[0m Trial 72 finished with value: 0.8899803536345776 and parameters: {'learning_rate': 0.2011572194655971, 'max_depth': 5, 'n_estimators': 111}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:59:43,561]\u001b[0m Trial 73 finished with value: 0.8939096267190569 and parameters: {'learning_rate': 0.20983253930398718, 'max_depth': 6, 'n_estimators': 202}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:59:47,081]\u001b[0m Trial 74 finished with value: 0.8860510805500982 and parameters: {'learning_rate': 0.232388285963804, 'max_depth': 6, 'n_estimators': 145}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 10:59:57,972]\u001b[0m Trial 75 finished with value: 0.9017681728880157 and parameters: {'learning_rate': 0.22487893450667248, 'max_depth': 5, 'n_estimators': 927}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:00:05,977]\u001b[0m Trial 76 finished with value: 0.8899803536345776 and parameters: {'learning_rate': 0.17737380130760974, 'max_depth': 6, 'n_estimators': 343}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:00:14,490]\u001b[0m Trial 77 finished with value: 0.8978388998035364 and parameters: {'learning_rate': 0.2537884875471279, 'max_depth': 6, 'n_estimators': 862}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:00:18,186]\u001b[0m Trial 78 finished with value: 0.8919449901768173 and parameters: {'learning_rate': 0.2460006835679459, 'max_depth': 5, 'n_estimators': 279}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:00:27,539]\u001b[0m Trial 79 finished with value: 0.9017681728880157 and parameters: {'learning_rate': 0.19333284578934362, 'max_depth': 6, 'n_estimators': 661}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:00:34,983]\u001b[0m Trial 80 finished with value: 0.8919449901768173 and parameters: {'learning_rate': 0.21133387046622798, 'max_depth': 4, 'n_estimators': 715}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:00:43,541]\u001b[0m Trial 81 finished with value: 0.9017681728880157 and parameters: {'learning_rate': 0.219840107846617, 'max_depth': 5, 'n_estimators': 781}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:00:56,096]\u001b[0m Trial 82 finished with value: 0.8899803536345776 and parameters: {'learning_rate': 0.24116277208066117, 'max_depth': 5, 'n_estimators': 811}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:01:06,693]\u001b[0m Trial 83 finished with value: 0.9056974459724951 and parameters: {'learning_rate': 0.22695300164568022, 'max_depth': 6, 'n_estimators': 609}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:01:18,168]\u001b[0m Trial 84 finished with value: 0.8919449901768173 and parameters: {'learning_rate': 0.1993761692313865, 'max_depth': 5, 'n_estimators': 826}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:01:28,784]\u001b[0m Trial 85 finished with value: 0.899803536345776 and parameters: {'learning_rate': 0.21729444108539103, 'max_depth': 4, 'n_estimators': 585}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:01:39,783]\u001b[0m Trial 86 finished with value: 0.8958742632612967 and parameters: {'learning_rate': 0.23656909992330155, 'max_depth': 6, 'n_estimators': 740}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:01:50,345]\u001b[0m Trial 87 finished with value: 0.899803536345776 and parameters: {'learning_rate': 0.20658287539598053, 'max_depth': 4, 'n_estimators': 878}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:01:52,723]\u001b[0m Trial 88 finished with value: 0.8958742632612967 and parameters: {'learning_rate': 0.22329593090492406, 'max_depth': 5, 'n_estimators': 143}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:01:59,987]\u001b[0m Trial 89 finished with value: 0.8978388998035364 and parameters: {'learning_rate': 0.18524323531752082, 'max_depth': 6, 'n_estimators': 519}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:02:12,740]\u001b[0m Trial 90 finished with value: 0.9037328094302554 and parameters: {'learning_rate': 0.25835431940539905, 'max_depth': 6, 'n_estimators': 850}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:02:27,329]\u001b[0m Trial 91 finished with value: 0.8919449901768173 and parameters: {'learning_rate': 0.2245057409950103, 'max_depth': 6, 'n_estimators': 614}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:02:37,146]\u001b[0m Trial 92 finished with value: 0.9037328094302554 and parameters: {'learning_rate': 0.2284139422361322, 'max_depth': 6, 'n_estimators': 578}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:02:47,139]\u001b[0m Trial 93 finished with value: 0.8978388998035364 and parameters: {'learning_rate': 0.23303802248163372, 'max_depth': 6, 'n_estimators': 697}. Best is trial 35 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:02:57,553]\u001b[0m Trial 94 finished with value: 0.9174852652259332 and parameters: {'learning_rate': 0.21210841793732604, 'max_depth': 6, 'n_estimators': 649}. Best is trial 94 with value: 0.9174852652259332.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:03:07,208]\u001b[0m Trial 95 finished with value: 0.8958742632612967 and parameters: {'learning_rate': 0.19814502973031345, 'max_depth': 5, 'n_estimators': 678}. Best is trial 94 with value: 0.9174852652259332.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:03:19,560]\u001b[0m Trial 96 finished with value: 0.8939096267190569 and parameters: {'learning_rate': 0.20655932830401894, 'max_depth': 6, 'n_estimators': 921}. Best is trial 94 with value: 0.9174852652259332.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:03:24,016]\u001b[0m Trial 97 finished with value: 0.899803536345776 and parameters: {'learning_rate': 0.21504462152399292, 'max_depth': 2, 'n_estimators': 472}. Best is trial 94 with value: 0.9174852652259332.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:03:33,228]\u001b[0m Trial 98 finished with value: 0.8958742632612967 and parameters: {'learning_rate': 0.1888636919511338, 'max_depth': 3, 'n_estimators': 781}. Best is trial 94 with value: 0.9174852652259332.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:03:40,908]\u001b[0m Trial 99 finished with value: 0.899803536345776 and parameters: {'learning_rate': 0.264323368808373, 'max_depth': 6, 'n_estimators': 430}. Best is trial 94 with value: 0.9174852652259332.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:03:40,923]\u001b[0m A new study created in memory with name: no-name-efb9d49b-ed12-46d2-88b6-f5b301a656b1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "index        APAAC  LogisticRegression             True   \n",
      "index        APAAC                 SVC             True   \n",
      "index        APAAC       XGBClassifier             True   \n",
      "index        APAAC      LGBMClassifier             True   \n",
      "index          CTD  LogisticRegression            False   \n",
      "index          CTD                 SVC            False   \n",
      "index          CTD       XGBClassifier            False   \n",
      "index          CTD      LGBMClassifier            False   \n",
      "index          CTD  LogisticRegression             True   \n",
      "index          CTD                 SVC             True   \n",
      "index          CTD       XGBClassifier             True   \n",
      "index          CTD      LGBMClassifier             True   \n",
      "index          DPC  LogisticRegression            False   \n",
      "index          DPC                 SVC            False   \n",
      "index          DPC       XGBClassifier            False   \n",
      "index          DPC      LGBMClassifier            False   \n",
      "index          DPC  LogisticRegression             True   \n",
      "index          DPC                 SVC             True   \n",
      "index          DPC       XGBClassifier             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "index  {'C': 0.09972241221770178, 'penalty': 'l1', 's...  0.893281   \n",
      "index  {'svc_c': 81.00794411499099, 'svc_gamma': 0.03...  0.859684   \n",
      "index  {'learning_rate': 0.21557448587004335, 'max_de...  0.891304   \n",
      "index  {'num_leaves': 2, 'max_depth': 43, 'learning_r...  0.893281   \n",
      "index                                               None  0.862764   \n",
      "index                                               None  0.846564   \n",
      "index                                               None  0.853410   \n",
      "index                                               None  0.851444   \n",
      "index  {'C': 0.0906600851039587, 'penalty': 'l2', 'so...  0.870334   \n",
      "index  {'svc_c': 93.52276100739736, 'svc_gamma': 0.01...  0.854617   \n",
      "index  {'learning_rate': 0.06876980973052808, 'max_de...  0.888016   \n",
      "index  {'num_leaves': 143, 'max_depth': 4, 'learning_...  0.882122   \n",
      "index                                               None  0.830298   \n",
      "index                                               None  0.891290   \n",
      "index                                               None  0.870646   \n",
      "index                                               None  0.868656   \n",
      "index  {'C': 0.09979066114998196, 'penalty': 'l1', 's...  0.891945   \n",
      "index  {'svc_c': 48.97185920584053, 'svc_gamma': 0.08...  0.530452   \n",
      "index  {'learning_rate': 0.21210841793732604, 'max_de...  0.917485   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "index     0.885714     0.900383   0.893004  0.889344  0.786319   \n",
      "index     0.869388     0.850575   0.845238  0.857143  0.719608   \n",
      "index     0.885714     0.896552   0.889344  0.887526  0.782370   \n",
      "index     0.889796     0.896552   0.889796  0.889796  0.786348   \n",
      "index     0.869388     0.867424   0.858871  0.864097  0.736539   \n",
      "index     0.836735     0.875000   0.861345  0.848861  0.712738   \n",
      "index     0.844898     0.886364   0.873418  0.858921  0.732486   \n",
      "index     0.853061     0.893939   0.881857  0.867220  0.748251   \n",
      "index     0.881633     0.859848   0.853755  0.867470  0.740977   \n",
      "index     0.828571     0.878788   0.863830  0.845833  0.708950   \n",
      "index     0.865306     0.909091   0.898305  0.881497  0.775910   \n",
      "index     0.865306     0.897727   0.887029  0.876033  0.763920   \n",
      "index     0.861224     0.875000   0.864754  0.862986  0.736338   \n",
      "index     0.885714     0.931818   0.923404  0.904167  0.819371   \n",
      "index     0.897959     0.912879   0.905350  0.901639  0.811101   \n",
      "index     0.877551     0.901515   0.892116  0.884774  0.779621   \n",
      "index     0.889796     0.893939   0.886179  0.887984  0.783626   \n",
      "index     0.028571     0.996212   0.875000  0.055336  0.099560   \n",
      "index     0.910204     0.924242   0.917695  0.913934  0.834718   \n",
      "\n",
      "                                           index  \n",
      "index      AAC_LogisticRegression_no_hypertuning  \n",
      "index                     AAC_SVC_no_hypertuning  \n",
      "index           AAC_XGBClassifier_no_hypertuning  \n",
      "index          AAC_LGBMClassifier_no_hypertuning  \n",
      "index    AAC_LogisticRegression_with_hypertuning  \n",
      "index                   AAC_SVC_with_hypertuning  \n",
      "index         AAC_XGBClassifier_with_hypertuning  \n",
      "index        AAC_LGBMClassifier_with_hypertuning  \n",
      "index    APAAC_LogisticRegression_no_hypertuning  \n",
      "index                   APAAC_SVC_no_hypertuning  \n",
      "index         APAAC_XGBClassifier_no_hypertuning  \n",
      "index        APAAC_LGBMClassifier_no_hypertuning  \n",
      "index  APAAC_LogisticRegression_with_hypertuning  \n",
      "index                 APAAC_SVC_with_hypertuning  \n",
      "index       APAAC_XGBClassifier_with_hypertuning  \n",
      "index      APAAC_LGBMClassifier_with_hypertuning  \n",
      "index      CTD_LogisticRegression_no_hypertuning  \n",
      "index                     CTD_SVC_no_hypertuning  \n",
      "index           CTD_XGBClassifier_no_hypertuning  \n",
      "index          CTD_LGBMClassifier_no_hypertuning  \n",
      "index    CTD_LogisticRegression_with_hypertuning  \n",
      "index                   CTD_SVC_with_hypertuning  \n",
      "index         CTD_XGBClassifier_with_hypertuning  \n",
      "index        CTD_LGBMClassifier_with_hypertuning  \n",
      "index      DPC_LogisticRegression_no_hypertuning  \n",
      "index                     DPC_SVC_no_hypertuning  \n",
      "index           DPC_XGBClassifier_no_hypertuning  \n",
      "index          DPC_LGBMClassifier_no_hypertuning  \n",
      "index    DPC_LogisticRegression_with_hypertuning  \n",
      "index                   DPC_SVC_with_hypertuning  \n",
      "index         DPC_XGBClassifier_with_hypertuning  \n",
      "Optimizing DPC LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:03:47,538]\u001b[0m Trial 0 finished with value: 0.8899803536345776 and parameters: {'num_leaves': 94, 'max_depth': 21, 'learning_rate': 0.21372388317648344, 'n_estimators': 228}. Best is trial 0 with value: 0.8899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:03:53,770]\u001b[0m Trial 1 finished with value: 0.899803536345776 and parameters: {'num_leaves': 158, 'max_depth': 35, 'learning_rate': 0.2944440221886211, 'n_estimators': 521}. Best is trial 1 with value: 0.899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:04:07,348]\u001b[0m Trial 2 finished with value: 0.8958742632612967 and parameters: {'num_leaves': 75, 'max_depth': 23, 'learning_rate': 0.04975425488910087, 'n_estimators': 289}. Best is trial 1 with value: 0.899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:04:17,675]\u001b[0m Trial 3 finished with value: 0.8978388998035364 and parameters: {'num_leaves': 243, 'max_depth': 23, 'learning_rate': 0.19991268094580125, 'n_estimators': 1433}. Best is trial 1 with value: 0.899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:04:28,565]\u001b[0m Trial 4 finished with value: 0.8958742632612967 and parameters: {'num_leaves': 83, 'max_depth': 19, 'learning_rate': 0.1367771410679221, 'n_estimators': 1588}. Best is trial 1 with value: 0.899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:04:32,731]\u001b[0m Trial 5 finished with value: 0.8958742632612967 and parameters: {'num_leaves': 42, 'max_depth': 2, 'learning_rate': 0.06551322950860132, 'n_estimators': 854}. Best is trial 1 with value: 0.899803536345776.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:04:34,631]\u001b[0m Trial 6 finished with value: 0.9037328094302554 and parameters: {'num_leaves': 154, 'max_depth': 3, 'learning_rate': 0.29070695688756776, 'n_estimators': 327}. Best is trial 6 with value: 0.9037328094302554.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:04:43,625]\u001b[0m Trial 7 finished with value: 0.888015717092338 and parameters: {'num_leaves': 46, 'max_depth': 46, 'learning_rate': 0.10857281204744408, 'n_estimators': 1009}. Best is trial 6 with value: 0.9037328094302554.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:04:53,119]\u001b[0m Trial 8 finished with value: 0.899803536345776 and parameters: {'num_leaves': 109, 'max_depth': 35, 'learning_rate': 0.09246132488499215, 'n_estimators': 320}. Best is trial 6 with value: 0.9037328094302554.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:04:59,623]\u001b[0m Trial 9 finished with value: 0.9017681728880157 and parameters: {'num_leaves': 156, 'max_depth': 30, 'learning_rate': 0.23927517397859177, 'n_estimators': 678}. Best is trial 6 with value: 0.9037328094302554.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:05:03,903]\u001b[0m Trial 10 finished with value: 0.8939096267190569 and parameters: {'num_leaves': 228, 'max_depth': 2, 'learning_rate': 0.28323787270287026, 'n_estimators': 1993}. Best is trial 6 with value: 0.9037328094302554.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:05:08,132]\u001b[0m Trial 11 finished with value: 0.8821218074656189 and parameters: {'num_leaves': 170, 'max_depth': 12, 'learning_rate': 0.24277082847722842, 'n_estimators': 712}. Best is trial 6 with value: 0.9037328094302554.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:05:13,817]\u001b[0m Trial 12 finished with value: 0.8939096267190569 and parameters: {'num_leaves': 178, 'max_depth': 36, 'learning_rate': 0.1768142364916503, 'n_estimators': 570}. Best is trial 6 with value: 0.9037328094302554.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:05:16,337]\u001b[0m Trial 13 finished with value: 0.899803536345776 and parameters: {'num_leaves': 139, 'max_depth': 11, 'learning_rate': 0.25703033409408604, 'n_estimators': 116}. Best is trial 6 with value: 0.9037328094302554.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:05:53,209]\u001b[0m Trial 14 finished with value: 0.8821218074656189 and parameters: {'num_leaves': 200, 'max_depth': 31, 'learning_rate': 0.003727556579710384, 'n_estimators': 1313}. Best is trial 6 with value: 0.9037328094302554.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:05:59,772]\u001b[0m Trial 15 finished with value: 0.8919449901768173 and parameters: {'num_leaves': 128, 'max_depth': 45, 'learning_rate': 0.24382419234311276, 'n_estimators': 468}. Best is trial 6 with value: 0.9037328094302554.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:06:04,563]\u001b[0m Trial 16 finished with value: 0.9017681728880157 and parameters: {'num_leaves': 207, 'max_depth': 14, 'learning_rate': 0.2926041508020691, 'n_estimators': 851}. Best is trial 6 with value: 0.9037328094302554.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:06:09,560]\u001b[0m Trial 17 finished with value: 0.9037328094302554 and parameters: {'num_leaves': 14, 'max_depth': 29, 'learning_rate': 0.2178767546717141, 'n_estimators': 1080}. Best is trial 6 with value: 0.9037328094302554.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:06:15,013]\u001b[0m Trial 18 finished with value: 0.9056974459724951 and parameters: {'num_leaves': 13, 'max_depth': 40, 'learning_rate': 0.17086444497466757, 'n_estimators': 1146}. Best is trial 18 with value: 0.9056974459724951.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:06:22,717]\u001b[0m Trial 19 finished with value: 0.8939096267190569 and parameters: {'num_leaves': 54, 'max_depth': 50, 'learning_rate': 0.16535701127154148, 'n_estimators': 1212}. Best is trial 18 with value: 0.9056974459724951.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:06:42,910]\u001b[0m Trial 20 finished with value: 0.9056974459724951 and parameters: {'num_leaves': 12, 'max_depth': 41, 'learning_rate': 0.1916107886944879, 'n_estimators': 1714}. Best is trial 18 with value: 0.9056974459724951.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:06:45,302]\u001b[0m Trial 21 finished with value: 0.8958742632612967 and parameters: {'num_leaves': 2, 'max_depth': 41, 'learning_rate': 0.18416413363198084, 'n_estimators': 1774}. Best is trial 18 with value: 0.9056974459724951.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:06:54,411]\u001b[0m Trial 22 finished with value: 0.9017681728880157 and parameters: {'num_leaves': 26, 'max_depth': 40, 'learning_rate': 0.1515065626048721, 'n_estimators': 1614}. Best is trial 18 with value: 0.9056974459724951.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:07:03,277]\u001b[0m Trial 23 finished with value: 0.8958742632612967 and parameters: {'num_leaves': 67, 'max_depth': 40, 'learning_rate': 0.20358281956724883, 'n_estimators': 1971}. Best is trial 18 with value: 0.9056974459724951.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:07:11,246]\u001b[0m Trial 24 finished with value: 0.8919449901768173 and parameters: {'num_leaves': 28, 'max_depth': 49, 'learning_rate': 0.26588157270057927, 'n_estimators': 1463}. Best is trial 18 with value: 0.9056974459724951.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:07:30,151]\u001b[0m Trial 25 finished with value: 0.8978388998035364 and parameters: {'num_leaves': 113, 'max_depth': 44, 'learning_rate': 0.13792257608641031, 'n_estimators': 1783}. Best is trial 18 with value: 0.9056974459724951.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:07:32,878]\u001b[0m Trial 26 finished with value: 0.8958742632612967 and parameters: {'num_leaves': 4, 'max_depth': 7, 'learning_rate': 0.18856088426056944, 'n_estimators': 1156}. Best is trial 18 with value: 0.9056974459724951.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:07:51,915]\u001b[0m Trial 27 finished with value: 0.9056974459724951 and parameters: {'num_leaves': 133, 'max_depth': 17, 'learning_rate': 0.22401809806507222, 'n_estimators': 1011}. Best is trial 18 with value: 0.9056974459724951.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:08:01,733]\u001b[0m Trial 28 finished with value: 0.8958742632612967 and parameters: {'num_leaves': 96, 'max_depth': 17, 'learning_rate': 0.22598092658860192, 'n_estimators': 1378}. Best is trial 18 with value: 0.9056974459724951.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:08:08,612]\u001b[0m Trial 29 finished with value: 0.8919449901768173 and parameters: {'num_leaves': 63, 'max_depth': 27, 'learning_rate': 0.2106935784436983, 'n_estimators': 937}. Best is trial 18 with value: 0.9056974459724951.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:08:15,761]\u001b[0m Trial 30 finished with value: 0.8919449901768173 and parameters: {'num_leaves': 29, 'max_depth': 37, 'learning_rate': 0.16372808153104593, 'n_estimators': 1261}. Best is trial 18 with value: 0.9056974459724951.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:08:22,172]\u001b[0m Trial 31 finished with value: 0.9017681728880157 and parameters: {'num_leaves': 140, 'max_depth': 5, 'learning_rate': 0.2685064628090958, 'n_estimators': 1623}. Best is trial 18 with value: 0.9056974459724951.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:08:31,669]\u001b[0m Trial 32 finished with value: 0.888015717092338 and parameters: {'num_leaves': 122, 'max_depth': 9, 'learning_rate': 0.21390858999358253, 'n_estimators': 1809}. Best is trial 18 with value: 0.9056974459724951.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:08:36,514]\u001b[0m Trial 33 finished with value: 0.9056974459724951 and parameters: {'num_leaves': 94, 'max_depth': 23, 'learning_rate': 0.2271822692040077, 'n_estimators': 467}. Best is trial 18 with value: 0.9056974459724951.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:08:43,708]\u001b[0m Trial 34 finished with value: 0.899803536345776 and parameters: {'num_leaves': 91, 'max_depth': 23, 'learning_rate': 0.19823679703161143, 'n_estimators': 450}. Best is trial 18 with value: 0.9056974459724951.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:08:50,311]\u001b[0m Trial 35 finished with value: 0.8978388998035364 and parameters: {'num_leaves': 77, 'max_depth': 33, 'learning_rate': 0.23077380302798048, 'n_estimators': 682}. Best is trial 18 with value: 0.9056974459724951.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:08:56,268]\u001b[0m Trial 36 finished with value: 0.8958742632612967 and parameters: {'num_leaves': 40, 'max_depth': 20, 'learning_rate': 0.196597751056489, 'n_estimators': 859}. Best is trial 18 with value: 0.9056974459724951.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:09:06,030]\u001b[0m Trial 37 finished with value: 0.9096267190569745 and parameters: {'num_leaves': 99, 'max_depth': 17, 'learning_rate': 0.22134887206717663, 'n_estimators': 1090}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:09:16,024]\u001b[0m Trial 38 finished with value: 0.9076620825147348 and parameters: {'num_leaves': 18, 'max_depth': 16, 'learning_rate': 0.1801400641089428, 'n_estimators': 1101}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:09:37,903]\u001b[0m Trial 39 finished with value: 0.9037328094302554 and parameters: {'num_leaves': 17, 'max_depth': 17, 'learning_rate': 0.18156394798628597, 'n_estimators': 1483}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:09:47,585]\u001b[0m Trial 40 finished with value: 0.8978388998035364 and parameters: {'num_leaves': 47, 'max_depth': 27, 'learning_rate': 0.16886803425696684, 'n_estimators': 1172}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:09:54,749]\u001b[0m Trial 41 finished with value: 0.8958742632612967 and parameters: {'num_leaves': 16, 'max_depth': 15, 'learning_rate': 0.20556745286333405, 'n_estimators': 1060}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:10:01,257]\u001b[0m Trial 42 finished with value: 0.899803536345776 and parameters: {'num_leaves': 36, 'max_depth': 18, 'learning_rate': 0.1935732535687128, 'n_estimators': 954}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:10:12,997]\u001b[0m Trial 43 finished with value: 0.9017681728880157 and parameters: {'num_leaves': 57, 'max_depth': 21, 'learning_rate': 0.15709210572395876, 'n_estimators': 1123}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:10:24,207]\u001b[0m Trial 44 finished with value: 0.8899803536345776 and parameters: {'num_leaves': 110, 'max_depth': 12, 'learning_rate': 0.17195619420210856, 'n_estimators': 792}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:10:34,894]\u001b[0m Trial 45 finished with value: 0.899803536345776 and parameters: {'num_leaves': 141, 'max_depth': 43, 'learning_rate': 0.14947635257833705, 'n_estimators': 981}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:10:55,649]\u001b[0m Trial 46 finished with value: 0.9056974459724951 and parameters: {'num_leaves': 171, 'max_depth': 15, 'learning_rate': 0.18198775946132423, 'n_estimators': 1345}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:11:03,008]\u001b[0m Trial 47 finished with value: 0.9056974459724951 and parameters: {'num_leaves': 10, 'max_depth': 25, 'learning_rate': 0.22132944530632012, 'n_estimators': 1288}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:11:15,670]\u001b[0m Trial 48 finished with value: 0.899803536345776 and parameters: {'num_leaves': 192, 'max_depth': 48, 'learning_rate': 0.12111528537896282, 'n_estimators': 1558}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:11:21,097]\u001b[0m Trial 49 finished with value: 0.9037328094302554 and parameters: {'num_leaves': 23, 'max_depth': 9, 'learning_rate': 0.23926497898551138, 'n_estimators': 1044}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:11:27,436]\u001b[0m Trial 50 finished with value: 0.9056974459724951 and parameters: {'num_leaves': 245, 'max_depth': 38, 'learning_rate': 0.20977457097581073, 'n_estimators': 800}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:11:36,926]\u001b[0m Trial 51 finished with value: 0.9017681728880157 and parameters: {'num_leaves': 98, 'max_depth': 23, 'learning_rate': 0.22507101130530238, 'n_estimators': 593}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:11:40,829]\u001b[0m Trial 52 finished with value: 0.8958742632612967 and parameters: {'num_leaves': 81, 'max_depth': 20, 'learning_rate': 0.19384793265583525, 'n_estimators': 176}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:11:47,728]\u001b[0m Trial 53 finished with value: 0.8919449901768173 and parameters: {'num_leaves': 149, 'max_depth': 33, 'learning_rate': 0.17536183799946828, 'n_estimators': 362}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:11:56,100]\u001b[0m Trial 54 finished with value: 0.8860510805500982 and parameters: {'num_leaves': 118, 'max_depth': 23, 'learning_rate': 0.24780057597515615, 'n_estimators': 1235}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:12:08,196]\u001b[0m Trial 55 finished with value: 0.8978388998035364 and parameters: {'num_leaves': 101, 'max_depth': 14, 'learning_rate': 0.21523209455809295, 'n_estimators': 894}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:12:14,652]\u001b[0m Trial 56 finished with value: 0.9017681728880157 and parameters: {'num_leaves': 67, 'max_depth': 25, 'learning_rate': 0.22873182637728484, 'n_estimators': 743}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:12:26,113]\u001b[0m Trial 57 finished with value: 0.8919449901768173 and parameters: {'num_leaves': 127, 'max_depth': 18, 'learning_rate': 0.19715246992020657, 'n_estimators': 1399}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:12:42,438]\u001b[0m Trial 58 finished with value: 0.9056974459724951 and parameters: {'num_leaves': 256, 'max_depth': 29, 'learning_rate': 0.18525628109173145, 'n_estimators': 1887}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:12:51,445]\u001b[0m Trial 59 finished with value: 0.8958742632612967 and parameters: {'num_leaves': 34, 'max_depth': 42, 'learning_rate': 0.25117974975264623, 'n_estimators': 1547}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:13:03,276]\u001b[0m Trial 60 finished with value: 0.8919449901768173 and parameters: {'num_leaves': 88, 'max_depth': 14, 'learning_rate': 0.2344680678247957, 'n_estimators': 1711}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:13:18,347]\u001b[0m Trial 61 finished with value: 0.888015717092338 and parameters: {'num_leaves': 166, 'max_depth': 16, 'learning_rate': 0.18139852464595438, 'n_estimators': 1330}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:13:29,725]\u001b[0m Trial 62 finished with value: 0.8958742632612967 and parameters: {'num_leaves': 181, 'max_depth': 11, 'learning_rate': 0.20493481051954102, 'n_estimators': 1112}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:13:38,160]\u001b[0m Trial 63 finished with value: 0.9017681728880157 and parameters: {'num_leaves': 213, 'max_depth': 19, 'learning_rate': 0.21841610872554593, 'n_estimators': 1016}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:13:49,423]\u001b[0m Trial 64 finished with value: 0.9017681728880157 and parameters: {'num_leaves': 163, 'max_depth': 21, 'learning_rate': 0.18934504571004238, 'n_estimators': 1213}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:14:00,527]\u001b[0m Trial 65 finished with value: 0.8958742632612967 and parameters: {'num_leaves': 174, 'max_depth': 47, 'learning_rate': 0.17628952362743397, 'n_estimators': 1700}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:14:06,216]\u001b[0m Trial 66 finished with value: 0.8939096267190569 and parameters: {'num_leaves': 105, 'max_depth': 13, 'learning_rate': 0.1640886539883712, 'n_estimators': 1165}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:14:16,298]\u001b[0m Trial 67 finished with value: 0.8958742632612967 and parameters: {'num_leaves': 47, 'max_depth': 16, 'learning_rate': 0.20345356956641528, 'n_estimators': 1365}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:14:24,464]\u001b[0m Trial 68 finished with value: 0.9017681728880157 and parameters: {'num_leaves': 7, 'max_depth': 9, 'learning_rate': 0.23627298511290284, 'n_estimators': 1487}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:14:31,239]\u001b[0m Trial 69 finished with value: 0.9017681728880157 and parameters: {'num_leaves': 155, 'max_depth': 39, 'learning_rate': 0.21446927697905174, 'n_estimators': 1090}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:14:36,223]\u001b[0m Trial 70 finished with value: 0.8978388998035364 and parameters: {'num_leaves': 146, 'max_depth': 35, 'learning_rate': 0.1860363952529963, 'n_estimators': 896}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:14:39,835]\u001b[0m Trial 71 finished with value: 0.9056974459724951 and parameters: {'num_leaves': 12, 'max_depth': 26, 'learning_rate': 0.22251373140358235, 'n_estimators': 1290}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:14:44,025]\u001b[0m Trial 72 finished with value: 0.899803536345776 and parameters: {'num_leaves': 21, 'max_depth': 22, 'learning_rate': 0.2234084207530066, 'n_estimators': 1252}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:14:45,045]\u001b[0m Trial 73 finished with value: 0.8899803536345776 and parameters: {'num_leaves': 2, 'max_depth': 24, 'learning_rate': 0.20954368056400594, 'n_estimators': 1339}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:14:47,251]\u001b[0m Trial 74 finished with value: 0.8978388998035364 and parameters: {'num_leaves': 31, 'max_depth': 19, 'learning_rate': 0.24218929367294328, 'n_estimators': 611}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:14:50,433]\u001b[0m Trial 75 finished with value: 0.8978388998035364 and parameters: {'num_leaves': 10, 'max_depth': 31, 'learning_rate': 0.20066217593849836, 'n_estimators': 1147}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:14:58,314]\u001b[0m Trial 76 finished with value: 0.8978388998035364 and parameters: {'num_leaves': 130, 'max_depth': 15, 'learning_rate': 0.25838060174552463, 'n_estimators': 1016}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:15:04,934]\u001b[0m Trial 77 finished with value: 0.888015717092338 and parameters: {'num_leaves': 58, 'max_depth': 28, 'learning_rate': 0.2320087593224237, 'n_estimators': 1438}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:15:09,263]\u001b[0m Trial 78 finished with value: 0.8919449901768173 and parameters: {'num_leaves': 189, 'max_depth': 11, 'learning_rate': 0.19204938791221826, 'n_estimators': 1199}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:15:13,818]\u001b[0m Trial 79 finished with value: 0.8978388998035364 and parameters: {'num_leaves': 20, 'max_depth': 25, 'learning_rate': 0.2206865363888845, 'n_estimators': 1295}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:15:20,417]\u001b[0m Trial 80 finished with value: 0.888015717092338 and parameters: {'num_leaves': 72, 'max_depth': 17, 'learning_rate': 0.18019380035811666, 'n_estimators': 965}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:15:27,679]\u001b[0m Trial 81 finished with value: 0.9076620825147348 and parameters: {'num_leaves': 40, 'max_depth': 36, 'learning_rate': 0.2118673643655165, 'n_estimators': 518}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:15:33,957]\u001b[0m Trial 82 finished with value: 0.8978388998035364 and parameters: {'num_leaves': 25, 'max_depth': 40, 'learning_rate': 0.2085246820789126, 'n_estimators': 439}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:15:39,997]\u001b[0m Trial 83 finished with value: 0.9076620825147348 and parameters: {'num_leaves': 41, 'max_depth': 42, 'learning_rate': 0.17192283424546567, 'n_estimators': 546}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:15:46,615]\u001b[0m Trial 84 finished with value: 0.9037328094302554 and parameters: {'num_leaves': 40, 'max_depth': 44, 'learning_rate': 0.15640306189544717, 'n_estimators': 516}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:15:51,711]\u001b[0m Trial 85 finished with value: 0.8978388998035364 and parameters: {'num_leaves': 50, 'max_depth': 37, 'learning_rate': 0.17109214206953088, 'n_estimators': 264}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:15:59,446]\u001b[0m Trial 86 finished with value: 0.899803536345776 and parameters: {'num_leaves': 37, 'max_depth': 46, 'learning_rate': 0.19017263416240068, 'n_estimators': 636}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:16:08,542]\u001b[0m Trial 87 finished with value: 0.9096267190569745 and parameters: {'num_leaves': 88, 'max_depth': 42, 'learning_rate': 0.19810797120034382, 'n_estimators': 385}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:16:13,336]\u001b[0m Trial 88 finished with value: 0.8899803536345776 and parameters: {'num_leaves': 90, 'max_depth': 42, 'learning_rate': 0.1962113497122921, 'n_estimators': 363}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:16:19,731]\u001b[0m Trial 89 finished with value: 0.8919449901768173 and parameters: {'num_leaves': 116, 'max_depth': 41, 'learning_rate': 0.20089980576824196, 'n_estimators': 549}. Best is trial 37 with value: 0.9096267190569745.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:16:24,021]\u001b[0m Trial 90 finished with value: 0.9194499017681729 and parameters: {'num_leaves': 62, 'max_depth': 44, 'learning_rate': 0.21611453851253923, 'n_estimators': 484}. Best is trial 90 with value: 0.9194499017681729.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:16:30,496]\u001b[0m Trial 91 finished with value: 0.8899803536345776 and parameters: {'num_leaves': 84, 'max_depth': 45, 'learning_rate': 0.2143072875622636, 'n_estimators': 489}. Best is trial 90 with value: 0.9194499017681729.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:16:35,878]\u001b[0m Trial 92 finished with value: 0.8978388998035364 and parameters: {'num_leaves': 75, 'max_depth': 44, 'learning_rate': 0.23196260518547138, 'n_estimators': 374}. Best is trial 90 with value: 0.9194499017681729.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:16:40,896]\u001b[0m Trial 93 finished with value: 0.8958742632612967 and parameters: {'num_leaves': 60, 'max_depth': 42, 'learning_rate': 0.20697387180257937, 'n_estimators': 423}. Best is trial 90 with value: 0.9194499017681729.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:16:44,873]\u001b[0m Trial 94 finished with value: 0.9037328094302554 and parameters: {'num_leaves': 67, 'max_depth': 39, 'learning_rate': 0.17432510454048722, 'n_estimators': 277}. Best is trial 90 with value: 0.9194499017681729.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:16:48,322]\u001b[0m Trial 95 finished with value: 0.888015717092338 and parameters: {'num_leaves': 50, 'max_depth': 38, 'learning_rate': 0.1668615221576709, 'n_estimators': 189}. Best is trial 90 with value: 0.9194499017681729.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:16:55,722]\u001b[0m Trial 96 finished with value: 0.8978388998035364 and parameters: {'num_leaves': 132, 'max_depth': 41, 'learning_rate': 0.22856499988734885, 'n_estimators': 313}. Best is trial 90 with value: 0.9194499017681729.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:01,185]\u001b[0m Trial 97 finished with value: 0.9056974459724951 and parameters: {'num_leaves': 106, 'max_depth': 50, 'learning_rate': 0.18666458253962812, 'n_estimators': 396}. Best is trial 90 with value: 0.9194499017681729.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:06,041]\u001b[0m Trial 98 finished with value: 0.899803536345776 and parameters: {'num_leaves': 29, 'max_depth': 43, 'learning_rate': 0.20173972627387374, 'n_estimators': 528}. Best is trial 90 with value: 0.9194499017681729.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:10,988]\u001b[0m Trial 99 finished with value: 0.8978388998035364 and parameters: {'num_leaves': 42, 'max_depth': 46, 'learning_rate': 0.21187135862109518, 'n_estimators': 557}. Best is trial 90 with value: 0.9194499017681729.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "index        APAAC  LogisticRegression             True   \n",
      "index        APAAC                 SVC             True   \n",
      "index        APAAC       XGBClassifier             True   \n",
      "index        APAAC      LGBMClassifier             True   \n",
      "index          CTD  LogisticRegression            False   \n",
      "index          CTD                 SVC            False   \n",
      "index          CTD       XGBClassifier            False   \n",
      "index          CTD      LGBMClassifier            False   \n",
      "index          CTD  LogisticRegression             True   \n",
      "index          CTD                 SVC             True   \n",
      "index          CTD       XGBClassifier             True   \n",
      "index          CTD      LGBMClassifier             True   \n",
      "index          DPC  LogisticRegression            False   \n",
      "index          DPC                 SVC            False   \n",
      "index          DPC       XGBClassifier            False   \n",
      "index          DPC      LGBMClassifier            False   \n",
      "index          DPC  LogisticRegression             True   \n",
      "index          DPC                 SVC             True   \n",
      "index          DPC       XGBClassifier             True   \n",
      "index          DPC      LGBMClassifier             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "index  {'C': 0.09972241221770178, 'penalty': 'l1', 's...  0.893281   \n",
      "index  {'svc_c': 81.00794411499099, 'svc_gamma': 0.03...  0.859684   \n",
      "index  {'learning_rate': 0.21557448587004335, 'max_de...  0.891304   \n",
      "index  {'num_leaves': 2, 'max_depth': 43, 'learning_r...  0.893281   \n",
      "index                                               None  0.862764   \n",
      "index                                               None  0.846564   \n",
      "index                                               None  0.853410   \n",
      "index                                               None  0.851444   \n",
      "index  {'C': 0.0906600851039587, 'penalty': 'l2', 'so...  0.870334   \n",
      "index  {'svc_c': 93.52276100739736, 'svc_gamma': 0.01...  0.854617   \n",
      "index  {'learning_rate': 0.06876980973052808, 'max_de...  0.888016   \n",
      "index  {'num_leaves': 143, 'max_depth': 4, 'learning_...  0.882122   \n",
      "index                                               None  0.830298   \n",
      "index                                               None  0.891290   \n",
      "index                                               None  0.870646   \n",
      "index                                               None  0.868656   \n",
      "index  {'C': 0.09979066114998196, 'penalty': 'l1', 's...  0.891945   \n",
      "index  {'svc_c': 48.97185920584053, 'svc_gamma': 0.08...  0.530452   \n",
      "index  {'learning_rate': 0.21210841793732604, 'max_de...  0.917485   \n",
      "index  {'num_leaves': 62, 'max_depth': 44, 'learning_...  0.919450   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "index     0.885714     0.900383   0.893004  0.889344  0.786319   \n",
      "index     0.869388     0.850575   0.845238  0.857143  0.719608   \n",
      "index     0.885714     0.896552   0.889344  0.887526  0.782370   \n",
      "index     0.889796     0.896552   0.889796  0.889796  0.786348   \n",
      "index     0.869388     0.867424   0.858871  0.864097  0.736539   \n",
      "index     0.836735     0.875000   0.861345  0.848861  0.712738   \n",
      "index     0.844898     0.886364   0.873418  0.858921  0.732486   \n",
      "index     0.853061     0.893939   0.881857  0.867220  0.748251   \n",
      "index     0.881633     0.859848   0.853755  0.867470  0.740977   \n",
      "index     0.828571     0.878788   0.863830  0.845833  0.708950   \n",
      "index     0.865306     0.909091   0.898305  0.881497  0.775910   \n",
      "index     0.865306     0.897727   0.887029  0.876033  0.763920   \n",
      "index     0.861224     0.875000   0.864754  0.862986  0.736338   \n",
      "index     0.885714     0.931818   0.923404  0.904167  0.819371   \n",
      "index     0.897959     0.912879   0.905350  0.901639  0.811101   \n",
      "index     0.877551     0.901515   0.892116  0.884774  0.779621   \n",
      "index     0.889796     0.893939   0.886179  0.887984  0.783626   \n",
      "index     0.028571     0.996212   0.875000  0.055336  0.099560   \n",
      "index     0.910204     0.924242   0.917695  0.913934  0.834718   \n",
      "index     0.906122     0.931818   0.925000  0.915464  0.838719   \n",
      "\n",
      "                                           index  \n",
      "index      AAC_LogisticRegression_no_hypertuning  \n",
      "index                     AAC_SVC_no_hypertuning  \n",
      "index           AAC_XGBClassifier_no_hypertuning  \n",
      "index          AAC_LGBMClassifier_no_hypertuning  \n",
      "index    AAC_LogisticRegression_with_hypertuning  \n",
      "index                   AAC_SVC_with_hypertuning  \n",
      "index         AAC_XGBClassifier_with_hypertuning  \n",
      "index        AAC_LGBMClassifier_with_hypertuning  \n",
      "index    APAAC_LogisticRegression_no_hypertuning  \n",
      "index                   APAAC_SVC_no_hypertuning  \n",
      "index         APAAC_XGBClassifier_no_hypertuning  \n",
      "index        APAAC_LGBMClassifier_no_hypertuning  \n",
      "index  APAAC_LogisticRegression_with_hypertuning  \n",
      "index                 APAAC_SVC_with_hypertuning  \n",
      "index       APAAC_XGBClassifier_with_hypertuning  \n",
      "index      APAAC_LGBMClassifier_with_hypertuning  \n",
      "index      CTD_LogisticRegression_no_hypertuning  \n",
      "index                     CTD_SVC_no_hypertuning  \n",
      "index           CTD_XGBClassifier_no_hypertuning  \n",
      "index          CTD_LGBMClassifier_no_hypertuning  \n",
      "index    CTD_LogisticRegression_with_hypertuning  \n",
      "index                   CTD_SVC_with_hypertuning  \n",
      "index         CTD_XGBClassifier_with_hypertuning  \n",
      "index        CTD_LGBMClassifier_with_hypertuning  \n",
      "index      DPC_LogisticRegression_no_hypertuning  \n",
      "index                     DPC_SVC_no_hypertuning  \n",
      "index           DPC_XGBClassifier_no_hypertuning  \n",
      "index          DPC_LGBMClassifier_no_hypertuning  \n",
      "index    DPC_LogisticRegression_with_hypertuning  \n",
      "index                   DPC_SVC_with_hypertuning  \n",
      "index         DPC_XGBClassifier_with_hypertuning  \n",
      "index        DPC_LGBMClassifier_with_hypertuning  \n",
      "Evaluating PAAC LogisticRegression\n",
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "index        APAAC  LogisticRegression             True   \n",
      "index        APAAC                 SVC             True   \n",
      "index        APAAC       XGBClassifier             True   \n",
      "index        APAAC      LGBMClassifier             True   \n",
      "index          CTD  LogisticRegression            False   \n",
      "index          CTD                 SVC            False   \n",
      "index          CTD       XGBClassifier            False   \n",
      "index          CTD      LGBMClassifier            False   \n",
      "index          CTD  LogisticRegression             True   \n",
      "index          CTD                 SVC             True   \n",
      "index          CTD       XGBClassifier             True   \n",
      "index          CTD      LGBMClassifier             True   \n",
      "index          DPC  LogisticRegression            False   \n",
      "index          DPC                 SVC            False   \n",
      "index          DPC       XGBClassifier            False   \n",
      "index          DPC      LGBMClassifier            False   \n",
      "index          DPC  LogisticRegression             True   \n",
      "index          DPC                 SVC             True   \n",
      "index          DPC       XGBClassifier             True   \n",
      "index          DPC      LGBMClassifier             True   \n",
      "index         PAAC  LogisticRegression            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "index  {'C': 0.09972241221770178, 'penalty': 'l1', 's...  0.893281   \n",
      "index  {'svc_c': 81.00794411499099, 'svc_gamma': 0.03...  0.859684   \n",
      "index  {'learning_rate': 0.21557448587004335, 'max_de...  0.891304   \n",
      "index  {'num_leaves': 2, 'max_depth': 43, 'learning_r...  0.893281   \n",
      "index                                               None  0.862764   \n",
      "index                                               None  0.846564   \n",
      "index                                               None  0.853410   \n",
      "index                                               None  0.851444   \n",
      "index  {'C': 0.0906600851039587, 'penalty': 'l2', 'so...  0.870334   \n",
      "index  {'svc_c': 93.52276100739736, 'svc_gamma': 0.01...  0.854617   \n",
      "index  {'learning_rate': 0.06876980973052808, 'max_de...  0.888016   \n",
      "index  {'num_leaves': 143, 'max_depth': 4, 'learning_...  0.882122   \n",
      "index                                               None  0.830298   \n",
      "index                                               None  0.891290   \n",
      "index                                               None  0.870646   \n",
      "index                                               None  0.868656   \n",
      "index  {'C': 0.09979066114998196, 'penalty': 'l1', 's...  0.891945   \n",
      "index  {'svc_c': 48.97185920584053, 'svc_gamma': 0.08...  0.530452   \n",
      "index  {'learning_rate': 0.21210841793732604, 'max_de...  0.917485   \n",
      "index  {'num_leaves': 62, 'max_depth': 44, 'learning_...  0.919450   \n",
      "index                                               None  0.871480   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "index     0.885714     0.900383   0.893004  0.889344  0.786319   \n",
      "index     0.869388     0.850575   0.845238  0.857143  0.719608   \n",
      "index     0.885714     0.896552   0.889344  0.887526  0.782370   \n",
      "index     0.889796     0.896552   0.889796  0.889796  0.786348   \n",
      "index     0.869388     0.867424   0.858871  0.864097  0.736539   \n",
      "index     0.836735     0.875000   0.861345  0.848861  0.712738   \n",
      "index     0.844898     0.886364   0.873418  0.858921  0.732486   \n",
      "index     0.853061     0.893939   0.881857  0.867220  0.748251   \n",
      "index     0.881633     0.859848   0.853755  0.867470  0.740977   \n",
      "index     0.828571     0.878788   0.863830  0.845833  0.708950   \n",
      "index     0.865306     0.909091   0.898305  0.881497  0.775910   \n",
      "index     0.865306     0.897727   0.887029  0.876033  0.763920   \n",
      "index     0.861224     0.875000   0.864754  0.862986  0.736338   \n",
      "index     0.885714     0.931818   0.923404  0.904167  0.819371   \n",
      "index     0.897959     0.912879   0.905350  0.901639  0.811101   \n",
      "index     0.877551     0.901515   0.892116  0.884774  0.779621   \n",
      "index     0.889796     0.893939   0.886179  0.887984  0.783626   \n",
      "index     0.028571     0.996212   0.875000  0.055336  0.099560   \n",
      "index     0.910204     0.924242   0.917695  0.913934  0.834718   \n",
      "index     0.906122     0.931818   0.925000  0.915464  0.838719   \n",
      "index     0.873469     0.888889   0.880658  0.877049  0.762573   \n",
      "\n",
      "                                           index  \n",
      "index      AAC_LogisticRegression_no_hypertuning  \n",
      "index                     AAC_SVC_no_hypertuning  \n",
      "index           AAC_XGBClassifier_no_hypertuning  \n",
      "index          AAC_LGBMClassifier_no_hypertuning  \n",
      "index    AAC_LogisticRegression_with_hypertuning  \n",
      "index                   AAC_SVC_with_hypertuning  \n",
      "index         AAC_XGBClassifier_with_hypertuning  \n",
      "index        AAC_LGBMClassifier_with_hypertuning  \n",
      "index    APAAC_LogisticRegression_no_hypertuning  \n",
      "index                   APAAC_SVC_no_hypertuning  \n",
      "index         APAAC_XGBClassifier_no_hypertuning  \n",
      "index        APAAC_LGBMClassifier_no_hypertuning  \n",
      "index  APAAC_LogisticRegression_with_hypertuning  \n",
      "index                 APAAC_SVC_with_hypertuning  \n",
      "index       APAAC_XGBClassifier_with_hypertuning  \n",
      "index      APAAC_LGBMClassifier_with_hypertuning  \n",
      "index      CTD_LogisticRegression_no_hypertuning  \n",
      "index                     CTD_SVC_no_hypertuning  \n",
      "index           CTD_XGBClassifier_no_hypertuning  \n",
      "index          CTD_LGBMClassifier_no_hypertuning  \n",
      "index    CTD_LogisticRegression_with_hypertuning  \n",
      "index                   CTD_SVC_with_hypertuning  \n",
      "index         CTD_XGBClassifier_with_hypertuning  \n",
      "index        CTD_LGBMClassifier_with_hypertuning  \n",
      "index      DPC_LogisticRegression_no_hypertuning  \n",
      "index                     DPC_SVC_no_hypertuning  \n",
      "index           DPC_XGBClassifier_no_hypertuning  \n",
      "index          DPC_LGBMClassifier_no_hypertuning  \n",
      "index    DPC_LogisticRegression_with_hypertuning  \n",
      "index                   DPC_SVC_with_hypertuning  \n",
      "index         DPC_XGBClassifier_with_hypertuning  \n",
      "index        DPC_LGBMClassifier_with_hypertuning  \n",
      "index     PAAC_LogisticRegression_no_hypertuning  \n",
      "Evaluating PAAC SVC\n",
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "index        APAAC  LogisticRegression             True   \n",
      "index        APAAC                 SVC             True   \n",
      "index        APAAC       XGBClassifier             True   \n",
      "index        APAAC      LGBMClassifier             True   \n",
      "index          CTD  LogisticRegression            False   \n",
      "index          CTD                 SVC            False   \n",
      "index          CTD       XGBClassifier            False   \n",
      "index          CTD      LGBMClassifier            False   \n",
      "index          CTD  LogisticRegression             True   \n",
      "index          CTD                 SVC             True   \n",
      "index          CTD       XGBClassifier             True   \n",
      "index          CTD      LGBMClassifier             True   \n",
      "index          DPC  LogisticRegression            False   \n",
      "index          DPC                 SVC            False   \n",
      "index          DPC       XGBClassifier            False   \n",
      "index          DPC      LGBMClassifier            False   \n",
      "index          DPC  LogisticRegression             True   \n",
      "index          DPC                 SVC             True   \n",
      "index          DPC       XGBClassifier             True   \n",
      "index          DPC      LGBMClassifier             True   \n",
      "index         PAAC  LogisticRegression            False   \n",
      "index         PAAC                 SVC            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "index  {'C': 0.09972241221770178, 'penalty': 'l1', 's...  0.893281   \n",
      "index  {'svc_c': 81.00794411499099, 'svc_gamma': 0.03...  0.859684   \n",
      "index  {'learning_rate': 0.21557448587004335, 'max_de...  0.891304   \n",
      "index  {'num_leaves': 2, 'max_depth': 43, 'learning_r...  0.893281   \n",
      "index                                               None  0.862764   \n",
      "index                                               None  0.846564   \n",
      "index                                               None  0.853410   \n",
      "index                                               None  0.851444   \n",
      "index  {'C': 0.0906600851039587, 'penalty': 'l2', 'so...  0.870334   \n",
      "index  {'svc_c': 93.52276100739736, 'svc_gamma': 0.01...  0.854617   \n",
      "index  {'learning_rate': 0.06876980973052808, 'max_de...  0.888016   \n",
      "index  {'num_leaves': 143, 'max_depth': 4, 'learning_...  0.882122   \n",
      "index                                               None  0.830298   \n",
      "index                                               None  0.891290   \n",
      "index                                               None  0.870646   \n",
      "index                                               None  0.868656   \n",
      "index  {'C': 0.09979066114998196, 'penalty': 'l1', 's...  0.891945   \n",
      "index  {'svc_c': 48.97185920584053, 'svc_gamma': 0.08...  0.530452   \n",
      "index  {'learning_rate': 0.21210841793732604, 'max_de...  0.917485   \n",
      "index  {'num_leaves': 62, 'max_depth': 44, 'learning_...  0.919450   \n",
      "index                                               None  0.871480   \n",
      "index                                               None  0.882349   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "index     0.885714     0.900383   0.893004  0.889344  0.786319   \n",
      "index     0.869388     0.850575   0.845238  0.857143  0.719608   \n",
      "index     0.885714     0.896552   0.889344  0.887526  0.782370   \n",
      "index     0.889796     0.896552   0.889796  0.889796  0.786348   \n",
      "index     0.869388     0.867424   0.858871  0.864097  0.736539   \n",
      "index     0.836735     0.875000   0.861345  0.848861  0.712738   \n",
      "index     0.844898     0.886364   0.873418  0.858921  0.732486   \n",
      "index     0.853061     0.893939   0.881857  0.867220  0.748251   \n",
      "index     0.881633     0.859848   0.853755  0.867470  0.740977   \n",
      "index     0.828571     0.878788   0.863830  0.845833  0.708950   \n",
      "index     0.865306     0.909091   0.898305  0.881497  0.775910   \n",
      "index     0.865306     0.897727   0.887029  0.876033  0.763920   \n",
      "index     0.861224     0.875000   0.864754  0.862986  0.736338   \n",
      "index     0.885714     0.931818   0.923404  0.904167  0.819371   \n",
      "index     0.897959     0.912879   0.905350  0.901639  0.811101   \n",
      "index     0.877551     0.901515   0.892116  0.884774  0.779621   \n",
      "index     0.889796     0.893939   0.886179  0.887984  0.783626   \n",
      "index     0.028571     0.996212   0.875000  0.055336  0.099560   \n",
      "index     0.910204     0.924242   0.917695  0.913934  0.834718   \n",
      "index     0.906122     0.931818   0.925000  0.915464  0.838719   \n",
      "index     0.873469     0.888889   0.880658  0.877049  0.762573   \n",
      "index     0.877551     0.954023   0.947137  0.911017  0.835582   \n",
      "\n",
      "                                           index  \n",
      "index      AAC_LogisticRegression_no_hypertuning  \n",
      "index                     AAC_SVC_no_hypertuning  \n",
      "index           AAC_XGBClassifier_no_hypertuning  \n",
      "index          AAC_LGBMClassifier_no_hypertuning  \n",
      "index    AAC_LogisticRegression_with_hypertuning  \n",
      "index                   AAC_SVC_with_hypertuning  \n",
      "index         AAC_XGBClassifier_with_hypertuning  \n",
      "index        AAC_LGBMClassifier_with_hypertuning  \n",
      "index    APAAC_LogisticRegression_no_hypertuning  \n",
      "index                   APAAC_SVC_no_hypertuning  \n",
      "index         APAAC_XGBClassifier_no_hypertuning  \n",
      "index        APAAC_LGBMClassifier_no_hypertuning  \n",
      "index  APAAC_LogisticRegression_with_hypertuning  \n",
      "index                 APAAC_SVC_with_hypertuning  \n",
      "index       APAAC_XGBClassifier_with_hypertuning  \n",
      "index      APAAC_LGBMClassifier_with_hypertuning  \n",
      "index      CTD_LogisticRegression_no_hypertuning  \n",
      "index                     CTD_SVC_no_hypertuning  \n",
      "index           CTD_XGBClassifier_no_hypertuning  \n",
      "index          CTD_LGBMClassifier_no_hypertuning  \n",
      "index    CTD_LogisticRegression_with_hypertuning  \n",
      "index                   CTD_SVC_with_hypertuning  \n",
      "index         CTD_XGBClassifier_with_hypertuning  \n",
      "index        CTD_LGBMClassifier_with_hypertuning  \n",
      "index      DPC_LogisticRegression_no_hypertuning  \n",
      "index                     DPC_SVC_no_hypertuning  \n",
      "index           DPC_XGBClassifier_no_hypertuning  \n",
      "index          DPC_LGBMClassifier_no_hypertuning  \n",
      "index    DPC_LogisticRegression_with_hypertuning  \n",
      "index                   DPC_SVC_with_hypertuning  \n",
      "index         DPC_XGBClassifier_with_hypertuning  \n",
      "index        DPC_LGBMClassifier_with_hypertuning  \n",
      "index     PAAC_LogisticRegression_no_hypertuning  \n",
      "index                    PAAC_SVC_no_hypertuning  \n",
      "Evaluating PAAC XGBClassifier\n",
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "index        APAAC  LogisticRegression             True   \n",
      "index        APAAC                 SVC             True   \n",
      "index        APAAC       XGBClassifier             True   \n",
      "index        APAAC      LGBMClassifier             True   \n",
      "index          CTD  LogisticRegression            False   \n",
      "index          CTD                 SVC            False   \n",
      "index          CTD       XGBClassifier            False   \n",
      "index          CTD      LGBMClassifier            False   \n",
      "index          CTD  LogisticRegression             True   \n",
      "index          CTD                 SVC             True   \n",
      "index          CTD       XGBClassifier             True   \n",
      "index          CTD      LGBMClassifier             True   \n",
      "index          DPC  LogisticRegression            False   \n",
      "index          DPC                 SVC            False   \n",
      "index          DPC       XGBClassifier            False   \n",
      "index          DPC      LGBMClassifier            False   \n",
      "index          DPC  LogisticRegression             True   \n",
      "index          DPC                 SVC             True   \n",
      "index          DPC       XGBClassifier             True   \n",
      "index          DPC      LGBMClassifier             True   \n",
      "index         PAAC  LogisticRegression            False   \n",
      "index         PAAC                 SVC            False   \n",
      "index         PAAC       XGBClassifier            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "index  {'C': 0.09972241221770178, 'penalty': 'l1', 's...  0.893281   \n",
      "index  {'svc_c': 81.00794411499099, 'svc_gamma': 0.03...  0.859684   \n",
      "index  {'learning_rate': 0.21557448587004335, 'max_de...  0.891304   \n",
      "index  {'num_leaves': 2, 'max_depth': 43, 'learning_r...  0.893281   \n",
      "index                                               None  0.862764   \n",
      "index                                               None  0.846564   \n",
      "index                                               None  0.853410   \n",
      "index                                               None  0.851444   \n",
      "index  {'C': 0.0906600851039587, 'penalty': 'l2', 'so...  0.870334   \n",
      "index  {'svc_c': 93.52276100739736, 'svc_gamma': 0.01...  0.854617   \n",
      "index  {'learning_rate': 0.06876980973052808, 'max_de...  0.888016   \n",
      "index  {'num_leaves': 143, 'max_depth': 4, 'learning_...  0.882122   \n",
      "index                                               None  0.830298   \n",
      "index                                               None  0.891290   \n",
      "index                                               None  0.870646   \n",
      "index                                               None  0.868656   \n",
      "index  {'C': 0.09979066114998196, 'penalty': 'l1', 's...  0.891945   \n",
      "index  {'svc_c': 48.97185920584053, 'svc_gamma': 0.08...  0.530452   \n",
      "index  {'learning_rate': 0.21210841793732604, 'max_de...  0.917485   \n",
      "index  {'num_leaves': 62, 'max_depth': 44, 'learning_...  0.919450   \n",
      "index                                               None  0.871480   \n",
      "index                                               None  0.882349   \n",
      "index                                               None  0.880898   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "index     0.885714     0.900383   0.893004  0.889344  0.786319   \n",
      "index     0.869388     0.850575   0.845238  0.857143  0.719608   \n",
      "index     0.885714     0.896552   0.889344  0.887526  0.782370   \n",
      "index     0.889796     0.896552   0.889796  0.889796  0.786348   \n",
      "index     0.869388     0.867424   0.858871  0.864097  0.736539   \n",
      "index     0.836735     0.875000   0.861345  0.848861  0.712738   \n",
      "index     0.844898     0.886364   0.873418  0.858921  0.732486   \n",
      "index     0.853061     0.893939   0.881857  0.867220  0.748251   \n",
      "index     0.881633     0.859848   0.853755  0.867470  0.740977   \n",
      "index     0.828571     0.878788   0.863830  0.845833  0.708950   \n",
      "index     0.865306     0.909091   0.898305  0.881497  0.775910   \n",
      "index     0.865306     0.897727   0.887029  0.876033  0.763920   \n",
      "index     0.861224     0.875000   0.864754  0.862986  0.736338   \n",
      "index     0.885714     0.931818   0.923404  0.904167  0.819371   \n",
      "index     0.897959     0.912879   0.905350  0.901639  0.811101   \n",
      "index     0.877551     0.901515   0.892116  0.884774  0.779621   \n",
      "index     0.889796     0.893939   0.886179  0.887984  0.783626   \n",
      "index     0.028571     0.996212   0.875000  0.055336  0.099560   \n",
      "index     0.910204     0.924242   0.917695  0.913934  0.834718   \n",
      "index     0.906122     0.931818   0.925000  0.915464  0.838719   \n",
      "index     0.873469     0.888889   0.880658  0.877049  0.762573   \n",
      "index     0.877551     0.954023   0.947137  0.911017  0.835582   \n",
      "index     0.869388     0.896552   0.887500  0.878351  0.766569   \n",
      "\n",
      "                                           index  \n",
      "index      AAC_LogisticRegression_no_hypertuning  \n",
      "index                     AAC_SVC_no_hypertuning  \n",
      "index           AAC_XGBClassifier_no_hypertuning  \n",
      "index          AAC_LGBMClassifier_no_hypertuning  \n",
      "index    AAC_LogisticRegression_with_hypertuning  \n",
      "index                   AAC_SVC_with_hypertuning  \n",
      "index         AAC_XGBClassifier_with_hypertuning  \n",
      "index        AAC_LGBMClassifier_with_hypertuning  \n",
      "index    APAAC_LogisticRegression_no_hypertuning  \n",
      "index                   APAAC_SVC_no_hypertuning  \n",
      "index         APAAC_XGBClassifier_no_hypertuning  \n",
      "index        APAAC_LGBMClassifier_no_hypertuning  \n",
      "index  APAAC_LogisticRegression_with_hypertuning  \n",
      "index                 APAAC_SVC_with_hypertuning  \n",
      "index       APAAC_XGBClassifier_with_hypertuning  \n",
      "index      APAAC_LGBMClassifier_with_hypertuning  \n",
      "index      CTD_LogisticRegression_no_hypertuning  \n",
      "index                     CTD_SVC_no_hypertuning  \n",
      "index           CTD_XGBClassifier_no_hypertuning  \n",
      "index          CTD_LGBMClassifier_no_hypertuning  \n",
      "index    CTD_LogisticRegression_with_hypertuning  \n",
      "index                   CTD_SVC_with_hypertuning  \n",
      "index         CTD_XGBClassifier_with_hypertuning  \n",
      "index        CTD_LGBMClassifier_with_hypertuning  \n",
      "index      DPC_LogisticRegression_no_hypertuning  \n",
      "index                     DPC_SVC_no_hypertuning  \n",
      "index           DPC_XGBClassifier_no_hypertuning  \n",
      "index          DPC_LGBMClassifier_no_hypertuning  \n",
      "index    DPC_LogisticRegression_with_hypertuning  \n",
      "index                   DPC_SVC_with_hypertuning  \n",
      "index         DPC_XGBClassifier_with_hypertuning  \n",
      "index        DPC_LGBMClassifier_with_hypertuning  \n",
      "index     PAAC_LogisticRegression_no_hypertuning  \n",
      "index                    PAAC_SVC_no_hypertuning  \n",
      "index          PAAC_XGBClassifier_no_hypertuning  \n",
      "Evaluating PAAC LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:17:20,396]\u001b[0m A new study created in memory with name: no-name-61bc6b46-aa9b-4218-b8fa-89fb5d019aeb\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:20,497]\u001b[0m Trial 0 finished with value: 0.8735177865612648 and parameters: {'C': 0.04368021013276537, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 433}. Best is trial 0 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:20,525]\u001b[0m Trial 1 finished with value: 0.8656126482213439 and parameters: {'C': 0.013775483430216388, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 856}. Best is trial 0 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:20,554]\u001b[0m Trial 2 finished with value: 0.8537549407114624 and parameters: {'C': 0.010927987962956322, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 618}. Best is trial 0 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:20,581]\u001b[0m Trial 3 finished with value: 0.883399209486166 and parameters: {'C': 0.08325612286479676, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 730}. Best is trial 3 with value: 0.883399209486166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "index        APAAC  LogisticRegression             True   \n",
      "index        APAAC                 SVC             True   \n",
      "index        APAAC       XGBClassifier             True   \n",
      "index        APAAC      LGBMClassifier             True   \n",
      "index          CTD  LogisticRegression            False   \n",
      "index          CTD                 SVC            False   \n",
      "index          CTD       XGBClassifier            False   \n",
      "index          CTD      LGBMClassifier            False   \n",
      "index          CTD  LogisticRegression             True   \n",
      "index          CTD                 SVC             True   \n",
      "index          CTD       XGBClassifier             True   \n",
      "index          CTD      LGBMClassifier             True   \n",
      "index          DPC  LogisticRegression            False   \n",
      "index          DPC                 SVC            False   \n",
      "index          DPC       XGBClassifier            False   \n",
      "index          DPC      LGBMClassifier            False   \n",
      "index          DPC  LogisticRegression             True   \n",
      "index          DPC                 SVC             True   \n",
      "index          DPC       XGBClassifier             True   \n",
      "index          DPC      LGBMClassifier             True   \n",
      "index         PAAC  LogisticRegression            False   \n",
      "index         PAAC                 SVC            False   \n",
      "index         PAAC       XGBClassifier            False   \n",
      "index         PAAC      LGBMClassifier            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "index  {'C': 0.09972241221770178, 'penalty': 'l1', 's...  0.893281   \n",
      "index  {'svc_c': 81.00794411499099, 'svc_gamma': 0.03...  0.859684   \n",
      "index  {'learning_rate': 0.21557448587004335, 'max_de...  0.891304   \n",
      "index  {'num_leaves': 2, 'max_depth': 43, 'learning_r...  0.893281   \n",
      "index                                               None  0.862764   \n",
      "index                                               None  0.846564   \n",
      "index                                               None  0.853410   \n",
      "index                                               None  0.851444   \n",
      "index  {'C': 0.0906600851039587, 'penalty': 'l2', 'so...  0.870334   \n",
      "index  {'svc_c': 93.52276100739736, 'svc_gamma': 0.01...  0.854617   \n",
      "index  {'learning_rate': 0.06876980973052808, 'max_de...  0.888016   \n",
      "index  {'num_leaves': 143, 'max_depth': 4, 'learning_...  0.882122   \n",
      "index                                               None  0.830298   \n",
      "index                                               None  0.891290   \n",
      "index                                               None  0.870646   \n",
      "index                                               None  0.868656   \n",
      "index  {'C': 0.09979066114998196, 'penalty': 'l1', 's...  0.891945   \n",
      "index  {'svc_c': 48.97185920584053, 'svc_gamma': 0.08...  0.530452   \n",
      "index  {'learning_rate': 0.21210841793732604, 'max_de...  0.917485   \n",
      "index  {'num_leaves': 62, 'max_depth': 44, 'learning_...  0.919450   \n",
      "index                                               None  0.871480   \n",
      "index                                               None  0.882349   \n",
      "index                                               None  0.880898   \n",
      "index                                               None  0.884839   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "index     0.885714     0.900383   0.893004  0.889344  0.786319   \n",
      "index     0.869388     0.850575   0.845238  0.857143  0.719608   \n",
      "index     0.885714     0.896552   0.889344  0.887526  0.782370   \n",
      "index     0.889796     0.896552   0.889796  0.889796  0.786348   \n",
      "index     0.869388     0.867424   0.858871  0.864097  0.736539   \n",
      "index     0.836735     0.875000   0.861345  0.848861  0.712738   \n",
      "index     0.844898     0.886364   0.873418  0.858921  0.732486   \n",
      "index     0.853061     0.893939   0.881857  0.867220  0.748251   \n",
      "index     0.881633     0.859848   0.853755  0.867470  0.740977   \n",
      "index     0.828571     0.878788   0.863830  0.845833  0.708950   \n",
      "index     0.865306     0.909091   0.898305  0.881497  0.775910   \n",
      "index     0.865306     0.897727   0.887029  0.876033  0.763920   \n",
      "index     0.861224     0.875000   0.864754  0.862986  0.736338   \n",
      "index     0.885714     0.931818   0.923404  0.904167  0.819371   \n",
      "index     0.897959     0.912879   0.905350  0.901639  0.811101   \n",
      "index     0.877551     0.901515   0.892116  0.884774  0.779621   \n",
      "index     0.889796     0.893939   0.886179  0.887984  0.783626   \n",
      "index     0.028571     0.996212   0.875000  0.055336  0.099560   \n",
      "index     0.910204     0.924242   0.917695  0.913934  0.834718   \n",
      "index     0.906122     0.931818   0.925000  0.915464  0.838719   \n",
      "index     0.873469     0.888889   0.880658  0.877049  0.762573   \n",
      "index     0.877551     0.954023   0.947137  0.911017  0.835582   \n",
      "index     0.869388     0.896552   0.887500  0.878351  0.766569   \n",
      "index     0.881633     0.904215   0.896266  0.888889  0.786339   \n",
      "\n",
      "                                           index  \n",
      "index      AAC_LogisticRegression_no_hypertuning  \n",
      "index                     AAC_SVC_no_hypertuning  \n",
      "index           AAC_XGBClassifier_no_hypertuning  \n",
      "index          AAC_LGBMClassifier_no_hypertuning  \n",
      "index    AAC_LogisticRegression_with_hypertuning  \n",
      "index                   AAC_SVC_with_hypertuning  \n",
      "index         AAC_XGBClassifier_with_hypertuning  \n",
      "index        AAC_LGBMClassifier_with_hypertuning  \n",
      "index    APAAC_LogisticRegression_no_hypertuning  \n",
      "index                   APAAC_SVC_no_hypertuning  \n",
      "index         APAAC_XGBClassifier_no_hypertuning  \n",
      "index        APAAC_LGBMClassifier_no_hypertuning  \n",
      "index  APAAC_LogisticRegression_with_hypertuning  \n",
      "index                 APAAC_SVC_with_hypertuning  \n",
      "index       APAAC_XGBClassifier_with_hypertuning  \n",
      "index      APAAC_LGBMClassifier_with_hypertuning  \n",
      "index      CTD_LogisticRegression_no_hypertuning  \n",
      "index                     CTD_SVC_no_hypertuning  \n",
      "index           CTD_XGBClassifier_no_hypertuning  \n",
      "index          CTD_LGBMClassifier_no_hypertuning  \n",
      "index    CTD_LogisticRegression_with_hypertuning  \n",
      "index                   CTD_SVC_with_hypertuning  \n",
      "index         CTD_XGBClassifier_with_hypertuning  \n",
      "index        CTD_LGBMClassifier_with_hypertuning  \n",
      "index      DPC_LogisticRegression_no_hypertuning  \n",
      "index                     DPC_SVC_no_hypertuning  \n",
      "index           DPC_XGBClassifier_no_hypertuning  \n",
      "index          DPC_LGBMClassifier_no_hypertuning  \n",
      "index    DPC_LogisticRegression_with_hypertuning  \n",
      "index                   DPC_SVC_with_hypertuning  \n",
      "index         DPC_XGBClassifier_with_hypertuning  \n",
      "index        DPC_LGBMClassifier_with_hypertuning  \n",
      "index     PAAC_LogisticRegression_no_hypertuning  \n",
      "index                    PAAC_SVC_no_hypertuning  \n",
      "index          PAAC_XGBClassifier_no_hypertuning  \n",
      "index         PAAC_LGBMClassifier_no_hypertuning  \n",
      "Optimizing PAAC LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:17:20,686]\u001b[0m Trial 4 finished with value: 0.8695652173913043 and parameters: {'C': 0.07669323065355182, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 486}. Best is trial 3 with value: 0.883399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:20,715]\u001b[0m Trial 5 finished with value: 0.8774703557312253 and parameters: {'C': 0.06240933621775592, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 765}. Best is trial 3 with value: 0.883399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:20,753]\u001b[0m Trial 6 finished with value: 0.8754940711462451 and parameters: {'C': 0.04145235224852046, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 747}. Best is trial 3 with value: 0.883399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:20,856]\u001b[0m Trial 7 finished with value: 0.8656126482213439 and parameters: {'C': 0.01694069830811886, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 670}. Best is trial 3 with value: 0.883399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:20,975]\u001b[0m Trial 8 finished with value: 0.883399209486166 and parameters: {'C': 0.062147385777529006, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 231}. Best is trial 3 with value: 0.883399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:21,070]\u001b[0m Trial 9 finished with value: 0.8715415019762845 and parameters: {'C': 0.08761035994940608, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 656}. Best is trial 3 with value: 0.883399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:21,110]\u001b[0m Trial 10 finished with value: 0.8794466403162056 and parameters: {'C': 0.09775112664698198, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 978}. Best is trial 3 with value: 0.883399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:21,255]\u001b[0m Trial 11 finished with value: 0.883399209486166 and parameters: {'C': 0.07079733510878196, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 141}. Best is trial 3 with value: 0.883399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:21,410]\u001b[0m Trial 12 finished with value: 0.8814229249011858 and parameters: {'C': 0.08070009994438736, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 281}. Best is trial 3 with value: 0.883399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:21,444]\u001b[0m Trial 13 finished with value: 0.883399209486166 and parameters: {'C': 0.061190543774158, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 325}. Best is trial 3 with value: 0.883399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:21,622]\u001b[0m Trial 14 finished with value: 0.883399209486166 and parameters: {'C': 0.096922589105093, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 122}. Best is trial 3 with value: 0.883399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:21,663]\u001b[0m Trial 15 finished with value: 0.8853754940711462 and parameters: {'C': 0.07140778733444259, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 344}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:21,704]\u001b[0m Trial 16 finished with value: 0.8794466403162056 and parameters: {'C': 0.08785522291166578, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 435}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:21,742]\u001b[0m Trial 17 finished with value: 0.8853754940711462 and parameters: {'C': 0.07420214525041587, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 546}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:21,783]\u001b[0m Trial 18 finished with value: 0.883399209486166 and parameters: {'C': 0.07591334240774059, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 374}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:21,824]\u001b[0m Trial 19 finished with value: 0.8853754940711462 and parameters: {'C': 0.0681226405472278, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 544}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:21,861]\u001b[0m Trial 20 finished with value: 0.8774703557312253 and parameters: {'C': 0.05177945752086465, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 554}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:21,900]\u001b[0m Trial 21 finished with value: 0.8853754940711462 and parameters: {'C': 0.06727821236997689, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 543}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:21,942]\u001b[0m Trial 22 finished with value: 0.8853754940711462 and parameters: {'C': 0.07339011658475762, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 539}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:21,988]\u001b[0m Trial 23 finished with value: 0.8853754940711462 and parameters: {'C': 0.06900987125915402, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 382}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:22,031]\u001b[0m Trial 24 finished with value: 0.8814229249011858 and parameters: {'C': 0.05678929439515945, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 466}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:22,074]\u001b[0m Trial 25 finished with value: 0.883399209486166 and parameters: {'C': 0.08061520372028831, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 214}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:22,113]\u001b[0m Trial 26 finished with value: 0.8853754940711462 and parameters: {'C': 0.07070836840384874, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 609}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:22,158]\u001b[0m Trial 27 finished with value: 0.8794466403162056 and parameters: {'C': 0.0882012984764389, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 359}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:22,202]\u001b[0m Trial 28 finished with value: 0.8794466403162056 and parameters: {'C': 0.05375314594564343, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 826}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:22,246]\u001b[0m Trial 29 finished with value: 0.883399209486166 and parameters: {'C': 0.07759881632577777, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 502}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:22,286]\u001b[0m Trial 30 finished with value: 0.8853754940711462 and parameters: {'C': 0.06477907709496485, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 421}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:22,334]\u001b[0m Trial 31 finished with value: 0.8853754940711462 and parameters: {'C': 0.06825616418542862, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 562}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:22,376]\u001b[0m Trial 32 finished with value: 0.8853754940711462 and parameters: {'C': 0.06671642660854599, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 523}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:22,424]\u001b[0m Trial 33 finished with value: 0.8853754940711462 and parameters: {'C': 0.07350246308427756, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 652}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:22,468]\u001b[0m Trial 34 finished with value: 0.8774703557312253 and parameters: {'C': 0.06634232176440073, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 422}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:22,518]\u001b[0m Trial 35 finished with value: 0.883399209486166 and parameters: {'C': 0.07651691126044974, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 591}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:22,558]\u001b[0m Trial 36 finished with value: 0.8774703557312253 and parameters: {'C': 0.0582741443138888, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 694}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:22,598]\u001b[0m Trial 37 finished with value: 0.8774703557312253 and parameters: {'C': 0.04840041751889246, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 303}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:22,644]\u001b[0m Trial 38 finished with value: 0.8774703557312253 and parameters: {'C': 0.05947056654028841, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 483}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:22,685]\u001b[0m Trial 39 finished with value: 0.8853754940711462 and parameters: {'C': 0.06390340552664657, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 717}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:22,726]\u001b[0m Trial 40 finished with value: 0.883399209486166 and parameters: {'C': 0.083012313244194, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 866}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:22,772]\u001b[0m Trial 41 finished with value: 0.8853754940711462 and parameters: {'C': 0.0729046454050784, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 530}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:22,817]\u001b[0m Trial 42 finished with value: 0.8853754940711462 and parameters: {'C': 0.07322707865234687, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 605}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:22,859]\u001b[0m Trial 43 finished with value: 0.8853754940711462 and parameters: {'C': 0.06829289783788713, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 574}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:23,006]\u001b[0m Trial 44 finished with value: 0.883399209486166 and parameters: {'C': 0.06281353224443355, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 638}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:23,048]\u001b[0m Trial 45 finished with value: 0.8735177865612648 and parameters: {'C': 0.0780234890812015, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 456}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:23,090]\u001b[0m Trial 46 finished with value: 0.8853754940711462 and parameters: {'C': 0.07209344878776591, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 799}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:23,235]\u001b[0m Trial 47 finished with value: 0.883399209486166 and parameters: {'C': 0.06156969182274639, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 233}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:23,277]\u001b[0m Trial 48 finished with value: 0.8853754940711462 and parameters: {'C': 0.06545929634627047, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 499}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:23,319]\u001b[0m Trial 49 finished with value: 0.8774703557312253 and parameters: {'C': 0.055592314286931184, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 916}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:23,493]\u001b[0m Trial 50 finished with value: 0.8814229249011858 and parameters: {'C': 0.08347049391463451, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 681}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:23,530]\u001b[0m Trial 51 finished with value: 0.8853754940711462 and parameters: {'C': 0.06952353978973237, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 384}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:23,574]\u001b[0m Trial 52 finished with value: 0.8853754940711462 and parameters: {'C': 0.06941562559069131, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 343}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:23,618]\u001b[0m Trial 53 finished with value: 0.8853754940711462 and parameters: {'C': 0.07317331757481411, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 397}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:23,664]\u001b[0m Trial 54 finished with value: 0.883399209486166 and parameters: {'C': 0.06124455832523217, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 254}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:23,713]\u001b[0m Trial 55 finished with value: 0.8853754940711462 and parameters: {'C': 0.06656061527279476, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 163}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:23,762]\u001b[0m Trial 56 finished with value: 0.8853754940711462 and parameters: {'C': 0.0750607451461627, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 535}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:23,816]\u001b[0m Trial 57 finished with value: 0.883399209486166 and parameters: {'C': 0.07894582790274579, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 459}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:23,964]\u001b[0m Trial 58 finished with value: 0.883399209486166 and parameters: {'C': 0.07052590664267781, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 275}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:24,012]\u001b[0m Trial 59 finished with value: 0.8853754940711462 and parameters: {'C': 0.07541261443523267, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 328}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:24,063]\u001b[0m Trial 60 finished with value: 0.883399209486166 and parameters: {'C': 0.058275050521421415, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 620}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:24,111]\u001b[0m Trial 61 finished with value: 0.8853754940711462 and parameters: {'C': 0.07080700705895464, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 603}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:24,162]\u001b[0m Trial 62 finished with value: 0.8853754940711462 and parameters: {'C': 0.06510367378238924, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 527}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:24,206]\u001b[0m Trial 63 finished with value: 0.8853754940711462 and parameters: {'C': 0.06861713878880325, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 565}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:24,248]\u001b[0m Trial 64 finished with value: 0.8853754940711462 and parameters: {'C': 0.07540263481306723, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 435}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:24,297]\u001b[0m Trial 65 finished with value: 0.883399209486166 and parameters: {'C': 0.07957402835412854, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 637}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:24,343]\u001b[0m Trial 66 finished with value: 0.8853754940711462 and parameters: {'C': 0.07145577396873008, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 485}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:24,388]\u001b[0m Trial 67 finished with value: 0.8774703557312253 and parameters: {'C': 0.06254355706529846, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 744}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:24,432]\u001b[0m Trial 68 finished with value: 0.8853754940711462 and parameters: {'C': 0.06528553270400882, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 410}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:24,480]\u001b[0m Trial 69 finished with value: 0.8853754940711462 and parameters: {'C': 0.0681085147995448, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 580}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:24,533]\u001b[0m Trial 70 finished with value: 0.8853754940711462 and parameters: {'C': 0.07683964080553073, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 546}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:24,579]\u001b[0m Trial 71 finished with value: 0.8853754940711462 and parameters: {'C': 0.06484077282713585, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 436}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:24,631]\u001b[0m Trial 72 finished with value: 0.8853754940711462 and parameters: {'C': 0.07393140562689297, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 497}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:24,676]\u001b[0m Trial 73 finished with value: 0.8853754940711462 and parameters: {'C': 0.07047691151037859, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 364}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:24,717]\u001b[0m Trial 74 finished with value: 0.883399209486166 and parameters: {'C': 0.05960276520972539, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 459}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:24,764]\u001b[0m Trial 75 finished with value: 0.8853754940711462 and parameters: {'C': 0.06767235040730198, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 516}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:24,928]\u001b[0m Trial 76 finished with value: 0.883399209486166 and parameters: {'C': 0.07258288262684602, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 617}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:24,979]\u001b[0m Trial 77 finished with value: 0.8774703557312253 and parameters: {'C': 0.06507917982399156, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 318}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:25,027]\u001b[0m Trial 78 finished with value: 0.883399209486166 and parameters: {'C': 0.08148771730065096, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 405}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:25,071]\u001b[0m Trial 79 finished with value: 0.8853754940711462 and parameters: {'C': 0.061652919667710734, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 664}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:25,129]\u001b[0m Trial 80 finished with value: 0.883399209486166 and parameters: {'C': 0.07725321641930748, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 698}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:25,181]\u001b[0m Trial 81 finished with value: 0.8853754940711462 and parameters: {'C': 0.06882949306886836, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 588}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:25,229]\u001b[0m Trial 82 finished with value: 0.8853754940711462 and parameters: {'C': 0.06664544658403947, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 547}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:25,277]\u001b[0m Trial 83 finished with value: 0.8853754940711462 and parameters: {'C': 0.07187514917987022, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 551}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:25,324]\u001b[0m Trial 84 finished with value: 0.8853754940711462 and parameters: {'C': 0.06384823906266011, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 472}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:25,378]\u001b[0m Trial 85 finished with value: 0.8853754940711462 and parameters: {'C': 0.07403747411506081, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 515}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:25,429]\u001b[0m Trial 86 finished with value: 0.8853754940711462 and parameters: {'C': 0.06714119224399916, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 639}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:25,580]\u001b[0m Trial 87 finished with value: 0.883399209486166 and parameters: {'C': 0.06951445626437036, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 569}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:25,626]\u001b[0m Trial 88 finished with value: 0.8735177865612648 and parameters: {'C': 0.07525438157072041, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 382}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:25,672]\u001b[0m Trial 89 finished with value: 0.8853754940711462 and parameters: {'C': 0.06400103083617978, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 435}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:25,719]\u001b[0m Trial 90 finished with value: 0.883399209486166 and parameters: {'C': 0.06017156656193311, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 346}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:25,762]\u001b[0m Trial 91 finished with value: 0.8853754940711462 and parameters: {'C': 0.07080990086730016, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 517}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:25,809]\u001b[0m Trial 92 finished with value: 0.8853754940711462 and parameters: {'C': 0.06825335538487334, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 484}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:25,858]\u001b[0m Trial 93 finished with value: 0.8853754940711462 and parameters: {'C': 0.06648962845319241, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 608}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:25,906]\u001b[0m Trial 94 finished with value: 0.8853754940711462 and parameters: {'C': 0.07247563832525344, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 592}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:25,955]\u001b[0m Trial 95 finished with value: 0.883399209486166 and parameters: {'C': 0.07832062761653341, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 558}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:26,006]\u001b[0m Trial 96 finished with value: 0.8814229249011858 and parameters: {'C': 0.05769162058510375, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 510}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:26,055]\u001b[0m Trial 97 finished with value: 0.8853754940711462 and parameters: {'C': 0.06268813371851638, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 534}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:26,104]\u001b[0m Trial 98 finished with value: 0.8853754940711462 and parameters: {'C': 0.06978712080013287, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 452}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:26,258]\u001b[0m Trial 99 finished with value: 0.8814229249011858 and parameters: {'C': 0.07467515960370397, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 303}. Best is trial 15 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:26,270]\u001b[0m A new study created in memory with name: no-name-d0bde1b6-a27a-4dc7-996e-f25db2f78e86\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "index        APAAC  LogisticRegression             True   \n",
      "index        APAAC                 SVC             True   \n",
      "index        APAAC       XGBClassifier             True   \n",
      "index        APAAC      LGBMClassifier             True   \n",
      "index          CTD  LogisticRegression            False   \n",
      "index          CTD                 SVC            False   \n",
      "index          CTD       XGBClassifier            False   \n",
      "index          CTD      LGBMClassifier            False   \n",
      "index          CTD  LogisticRegression             True   \n",
      "index          CTD                 SVC             True   \n",
      "index          CTD       XGBClassifier             True   \n",
      "index          CTD      LGBMClassifier             True   \n",
      "index          DPC  LogisticRegression            False   \n",
      "index          DPC                 SVC            False   \n",
      "index          DPC       XGBClassifier            False   \n",
      "index          DPC      LGBMClassifier            False   \n",
      "index          DPC  LogisticRegression             True   \n",
      "index          DPC                 SVC             True   \n",
      "index          DPC       XGBClassifier             True   \n",
      "index          DPC      LGBMClassifier             True   \n",
      "index         PAAC  LogisticRegression            False   \n",
      "index         PAAC                 SVC            False   \n",
      "index         PAAC       XGBClassifier            False   \n",
      "index         PAAC      LGBMClassifier            False   \n",
      "index         PAAC  LogisticRegression             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "index  {'C': 0.09972241221770178, 'penalty': 'l1', 's...  0.893281   \n",
      "index  {'svc_c': 81.00794411499099, 'svc_gamma': 0.03...  0.859684   \n",
      "index  {'learning_rate': 0.21557448587004335, 'max_de...  0.891304   \n",
      "index  {'num_leaves': 2, 'max_depth': 43, 'learning_r...  0.893281   \n",
      "index                                               None  0.862764   \n",
      "index                                               None  0.846564   \n",
      "index                                               None  0.853410   \n",
      "index                                               None  0.851444   \n",
      "index  {'C': 0.0906600851039587, 'penalty': 'l2', 'so...  0.870334   \n",
      "index  {'svc_c': 93.52276100739736, 'svc_gamma': 0.01...  0.854617   \n",
      "index  {'learning_rate': 0.06876980973052808, 'max_de...  0.888016   \n",
      "index  {'num_leaves': 143, 'max_depth': 4, 'learning_...  0.882122   \n",
      "index                                               None  0.830298   \n",
      "index                                               None  0.891290   \n",
      "index                                               None  0.870646   \n",
      "index                                               None  0.868656   \n",
      "index  {'C': 0.09979066114998196, 'penalty': 'l1', 's...  0.891945   \n",
      "index  {'svc_c': 48.97185920584053, 'svc_gamma': 0.08...  0.530452   \n",
      "index  {'learning_rate': 0.21210841793732604, 'max_de...  0.917485   \n",
      "index  {'num_leaves': 62, 'max_depth': 44, 'learning_...  0.919450   \n",
      "index                                               None  0.871480   \n",
      "index                                               None  0.882349   \n",
      "index                                               None  0.880898   \n",
      "index                                               None  0.884839   \n",
      "index  {'C': 0.07140778733444259, 'penalty': 'l1', 's...  0.885375   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "index     0.885714     0.900383   0.893004  0.889344  0.786319   \n",
      "index     0.869388     0.850575   0.845238  0.857143  0.719608   \n",
      "index     0.885714     0.896552   0.889344  0.887526  0.782370   \n",
      "index     0.889796     0.896552   0.889796  0.889796  0.786348   \n",
      "index     0.869388     0.867424   0.858871  0.864097  0.736539   \n",
      "index     0.836735     0.875000   0.861345  0.848861  0.712738   \n",
      "index     0.844898     0.886364   0.873418  0.858921  0.732486   \n",
      "index     0.853061     0.893939   0.881857  0.867220  0.748251   \n",
      "index     0.881633     0.859848   0.853755  0.867470  0.740977   \n",
      "index     0.828571     0.878788   0.863830  0.845833  0.708950   \n",
      "index     0.865306     0.909091   0.898305  0.881497  0.775910   \n",
      "index     0.865306     0.897727   0.887029  0.876033  0.763920   \n",
      "index     0.861224     0.875000   0.864754  0.862986  0.736338   \n",
      "index     0.885714     0.931818   0.923404  0.904167  0.819371   \n",
      "index     0.897959     0.912879   0.905350  0.901639  0.811101   \n",
      "index     0.877551     0.901515   0.892116  0.884774  0.779621   \n",
      "index     0.889796     0.893939   0.886179  0.887984  0.783626   \n",
      "index     0.028571     0.996212   0.875000  0.055336  0.099560   \n",
      "index     0.910204     0.924242   0.917695  0.913934  0.834718   \n",
      "index     0.906122     0.931818   0.925000  0.915464  0.838719   \n",
      "index     0.873469     0.888889   0.880658  0.877049  0.762573   \n",
      "index     0.877551     0.954023   0.947137  0.911017  0.835582   \n",
      "index     0.869388     0.896552   0.887500  0.878351  0.766569   \n",
      "index     0.881633     0.904215   0.896266  0.888889  0.786339   \n",
      "index     0.885714     0.885057   0.878543  0.882114  0.770603   \n",
      "\n",
      "                                           index  \n",
      "index      AAC_LogisticRegression_no_hypertuning  \n",
      "index                     AAC_SVC_no_hypertuning  \n",
      "index           AAC_XGBClassifier_no_hypertuning  \n",
      "index          AAC_LGBMClassifier_no_hypertuning  \n",
      "index    AAC_LogisticRegression_with_hypertuning  \n",
      "index                   AAC_SVC_with_hypertuning  \n",
      "index         AAC_XGBClassifier_with_hypertuning  \n",
      "index        AAC_LGBMClassifier_with_hypertuning  \n",
      "index    APAAC_LogisticRegression_no_hypertuning  \n",
      "index                   APAAC_SVC_no_hypertuning  \n",
      "index         APAAC_XGBClassifier_no_hypertuning  \n",
      "index        APAAC_LGBMClassifier_no_hypertuning  \n",
      "index  APAAC_LogisticRegression_with_hypertuning  \n",
      "index                 APAAC_SVC_with_hypertuning  \n",
      "index       APAAC_XGBClassifier_with_hypertuning  \n",
      "index      APAAC_LGBMClassifier_with_hypertuning  \n",
      "index      CTD_LogisticRegression_no_hypertuning  \n",
      "index                     CTD_SVC_no_hypertuning  \n",
      "index           CTD_XGBClassifier_no_hypertuning  \n",
      "index          CTD_LGBMClassifier_no_hypertuning  \n",
      "index    CTD_LogisticRegression_with_hypertuning  \n",
      "index                   CTD_SVC_with_hypertuning  \n",
      "index         CTD_XGBClassifier_with_hypertuning  \n",
      "index        CTD_LGBMClassifier_with_hypertuning  \n",
      "index      DPC_LogisticRegression_no_hypertuning  \n",
      "index                     DPC_SVC_no_hypertuning  \n",
      "index           DPC_XGBClassifier_no_hypertuning  \n",
      "index          DPC_LGBMClassifier_no_hypertuning  \n",
      "index    DPC_LogisticRegression_with_hypertuning  \n",
      "index                   DPC_SVC_with_hypertuning  \n",
      "index         DPC_XGBClassifier_with_hypertuning  \n",
      "index        DPC_LGBMClassifier_with_hypertuning  \n",
      "index     PAAC_LogisticRegression_no_hypertuning  \n",
      "index                    PAAC_SVC_no_hypertuning  \n",
      "index          PAAC_XGBClassifier_no_hypertuning  \n",
      "index         PAAC_LGBMClassifier_no_hypertuning  \n",
      "index   PAAC_LogisticRegression_with_hypertuning  \n",
      "Optimizing PAAC SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:17:26,860]\u001b[0m Trial 0 finished with value: 0.5197628458498024 and parameters: {'svc_c': 58.44307061377046, 'svc_gamma': 23.55141792853813}. Best is trial 0 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:27,317]\u001b[0m Trial 1 finished with value: 0.5138339920948617 and parameters: {'svc_c': 14.359849470028351, 'svc_gamma': 74.40481223481555}. Best is trial 0 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:27,794]\u001b[0m Trial 2 finished with value: 0.5138339920948617 and parameters: {'svc_c': 95.78584081703389, 'svc_gamma': 71.2932693493338}. Best is trial 0 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:28,257]\u001b[0m Trial 3 finished with value: 0.5138339920948617 and parameters: {'svc_c': 44.58732977269384, 'svc_gamma': 93.96163021949464}. Best is trial 0 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:28,822]\u001b[0m Trial 4 finished with value: 0.5197628458498024 and parameters: {'svc_c': 33.192096078162166, 'svc_gamma': 25.104883490114638}. Best is trial 0 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:29,386]\u001b[0m Trial 5 finished with value: 0.5197628458498024 and parameters: {'svc_c': 5.313062794482634, 'svc_gamma': 34.42484586462665}. Best is trial 0 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:29,989]\u001b[0m Trial 6 finished with value: 0.5197628458498024 and parameters: {'svc_c': 18.97928121231316, 'svc_gamma': 18.503051293465234}. Best is trial 0 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:30,539]\u001b[0m Trial 7 finished with value: 0.5197628458498024 and parameters: {'svc_c': 80.20771421437341, 'svc_gamma': 41.27787271523692}. Best is trial 0 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:30,908]\u001b[0m Trial 8 finished with value: 0.8735177865612648 and parameters: {'svc_c': 1.2847332148055919, 'svc_gamma': 0.21070268333508838}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:31,446]\u001b[0m Trial 9 finished with value: 0.5197628458498024 and parameters: {'svc_c': 6.119035138487789, 'svc_gamma': 36.84799011566739}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:31,862]\u001b[0m Trial 10 finished with value: 0.6719367588932806 and parameters: {'svc_c': 0.9441430252309644, 'svc_gamma': 0.6537365716783874}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:32,409]\u001b[0m Trial 11 finished with value: 0.5217391304347826 and parameters: {'svc_c': 4.351340465536243, 'svc_gamma': 6.100109992379533}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:32,866]\u001b[0m Trial 12 finished with value: 0.5968379446640316 and parameters: {'svc_c': 23.79882015461279, 'svc_gamma': 1.1212170425423977}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 11:17:33,285]\u001b[0m Trial 13 finished with value: 0.5158102766798419 and parameters: {'svc_c': 0.39876873834126725, 'svc_gamma': 3.3680749822487916}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:33,894]\u001b[0m Trial 14 finished with value: 0.5197628458498024 and parameters: {'svc_c': 25.02360252568083, 'svc_gamma': 14.260431202162527}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:34,382]\u001b[0m Trial 15 finished with value: 0.6126482213438735 and parameters: {'svc_c': 38.31443457775818, 'svc_gamma': 1.0627527655322047}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:34,960]\u001b[0m Trial 16 finished with value: 0.5197628458498024 and parameters: {'svc_c': 14.79784007486754, 'svc_gamma': 13.096398111462616}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:35,683]\u001b[0m Trial 17 finished with value: 0.5197628458498024 and parameters: {'svc_c': 52.99007515905308, 'svc_gamma': 26.02398792038203}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:36,230]\u001b[0m Trial 18 finished with value: 0.5197628458498024 and parameters: {'svc_c': 31.502025471981607, 'svc_gamma': 13.206276943096634}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:36,731]\u001b[0m Trial 19 finished with value: 0.5177865612648221 and parameters: {'svc_c': 15.76797856614489, 'svc_gamma': 51.116124580688876}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:37,294]\u001b[0m Trial 20 finished with value: 0.5217391304347826 and parameters: {'svc_c': 1.7450964816590067, 'svc_gamma': 9.335302941979826}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:37,747]\u001b[0m Trial 21 finished with value: 0.8260869565217391 and parameters: {'svc_c': 37.374751094824205, 'svc_gamma': 0.3016129596925156}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:38,261]\u001b[0m Trial 22 finished with value: 0.5513833992094862 and parameters: {'svc_c': 11.018929271207957, 'svc_gamma': 1.6991949226071217}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:38,858]\u001b[0m Trial 23 finished with value: 0.5197628458498024 and parameters: {'svc_c': 24.52014141180292, 'svc_gamma': 12.493112633183372}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:39,281]\u001b[0m Trial 24 finished with value: 0.6383399209486166 and parameters: {'svc_c': 10.982686806965301, 'svc_gamma': 0.9512611471652661}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 11:17:39,810]\u001b[0m Trial 25 finished with value: 0.5158102766798419 and parameters: {'svc_c': 0.16004345146858867, 'svc_gamma': 19.47645084413595}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:40,286]\u001b[0m Trial 26 finished with value: 0.5217391304347826 and parameters: {'svc_c': 20.06079283929239, 'svc_gamma': 6.8735266503311205}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:40,799]\u001b[0m Trial 27 finished with value: 0.5197628458498024 and parameters: {'svc_c': 9.985224810661158, 'svc_gamma': 10.569629232553819}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:41,368]\u001b[0m Trial 28 finished with value: 0.5197628458498024 and parameters: {'svc_c': 30.67522746698427, 'svc_gamma': 17.860541444941195}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:41,961]\u001b[0m Trial 29 finished with value: 0.5197628458498024 and parameters: {'svc_c': 58.59965828286924, 'svc_gamma': 26.587485742906384}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:42,421]\u001b[0m Trial 30 finished with value: 0.5217391304347826 and parameters: {'svc_c': 8.917047394049307, 'svc_gamma': 7.651943055576319}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:42,871]\u001b[0m Trial 31 finished with value: 0.5217391304347826 and parameters: {'svc_c': 10.249470907456548, 'svc_gamma': 5.454868713407131}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:43,363]\u001b[0m Trial 32 finished with value: 0.5276679841897233 and parameters: {'svc_c': 15.881572967629557, 'svc_gamma': 4.373649251388839}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:43,790]\u001b[0m Trial 33 finished with value: 0.7628458498023716 and parameters: {'svc_c': 7.754746105601157, 'svc_gamma': 0.49334123330190094}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 11:17:44,298]\u001b[0m Trial 34 finished with value: 0.5158102766798419 and parameters: {'svc_c': 0.032047599523437276, 'svc_gamma': 18.448305544288804}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:44,714]\u001b[0m Trial 35 finished with value: 0.8399209486166008 and parameters: {'svc_c': 6.876324836925751, 'svc_gamma': 0.2632256998535457}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:45,298]\u001b[0m Trial 36 finished with value: 0.5217391304347826 and parameters: {'svc_c': 20.543272129184004, 'svc_gamma': 8.830212190059605}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:45,897]\u001b[0m Trial 37 finished with value: 0.5197628458498024 and parameters: {'svc_c': 13.998900194134489, 'svc_gamma': 22.212949903723295}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:46,429]\u001b[0m Trial 38 finished with value: 0.5197628458498024 and parameters: {'svc_c': 6.5611477218696015, 'svc_gamma': 10.299354479794363}. Best is trial 8 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:46,708]\u001b[0m Trial 39 finished with value: 0.8952569169960475 and parameters: {'svc_c': 39.94252882393517, 'svc_gamma': 0.02416838819806605}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:47,245]\u001b[0m Trial 40 finished with value: 0.5197628458498024 and parameters: {'svc_c': 38.76424636367179, 'svc_gamma': 30.191496888952397}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:47,727]\u001b[0m Trial 41 finished with value: 0.5217391304347826 and parameters: {'svc_c': 45.8323696002226, 'svc_gamma': 5.735053209194284}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:48,200]\u001b[0m Trial 42 finished with value: 0.7628458498023716 and parameters: {'svc_c': 5.928402970977552, 'svc_gamma': 0.4751521502006142}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:48,748]\u001b[0m Trial 43 finished with value: 0.5197628458498024 and parameters: {'svc_c': 28.142819193675514, 'svc_gamma': 14.293762429443708}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:49,114]\u001b[0m Trial 44 finished with value: 0.8517786561264822 and parameters: {'svc_c': 35.104862332416964, 'svc_gamma': 0.23757304177030747}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:49,568]\u001b[0m Trial 45 finished with value: 0.5217391304347826 and parameters: {'svc_c': 36.096842030928386, 'svc_gamma': 6.179156085506908}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:50,101]\u001b[0m Trial 46 finished with value: 0.5197628458498024 and parameters: {'svc_c': 42.63177904325209, 'svc_gamma': 16.065810942480148}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:50,626]\u001b[0m Trial 47 finished with value: 0.5197628458498024 and parameters: {'svc_c': 34.39634965799426, 'svc_gamma': 21.885465708518954}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:51,111]\u001b[0m Trial 48 finished with value: 0.5217391304347826 and parameters: {'svc_c': 27.045832773479304, 'svc_gamma': 9.15860862081139}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:51,544]\u001b[0m Trial 49 finished with value: 0.5217391304347826 and parameters: {'svc_c': 30.62555715032011, 'svc_gamma': 4.952764488050469}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:52,176]\u001b[0m Trial 50 finished with value: 0.5197628458498024 and parameters: {'svc_c': 20.73131406675011, 'svc_gamma': 15.478414011845123}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:52,672]\u001b[0m Trial 51 finished with value: 0.5434782608695652 and parameters: {'svc_c': 4.8146007820872105, 'svc_gamma': 1.856147084074118}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:53,141]\u001b[0m Trial 52 finished with value: 0.6462450592885376 and parameters: {'svc_c': 16.92533364310698, 'svc_gamma': 0.8896375910763092}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:53,678]\u001b[0m Trial 53 finished with value: 0.5197628458498024 and parameters: {'svc_c': 22.009154956487254, 'svc_gamma': 10.920775723112463}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:54,189]\u001b[0m Trial 54 finished with value: 0.5276679841897233 and parameters: {'svc_c': 25.967004469080695, 'svc_gamma': 3.839170880104443}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:54,670]\u001b[0m Trial 55 finished with value: 0.5217391304347826 and parameters: {'svc_c': 4.6758369166250375, 'svc_gamma': 7.877614709334974}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:55,050]\u001b[0m Trial 56 finished with value: 0.8695652173913043 and parameters: {'svc_c': 18.290359307929698, 'svc_gamma': 0.21334841074981445}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:55,524]\u001b[0m Trial 57 finished with value: 0.5276679841897233 and parameters: {'svc_c': 13.713305858122425, 'svc_gamma': 4.33407971194468}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:55,877]\u001b[0m Trial 58 finished with value: 0.8932806324110671 and parameters: {'svc_c': 37.929476519200975, 'svc_gamma': 0.08218976681140891}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:56,416]\u001b[0m Trial 59 finished with value: 0.5197628458498024 and parameters: {'svc_c': 40.93542900399963, 'svc_gamma': 13.455634510310212}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:56,966]\u001b[0m Trial 60 finished with value: 0.5197628458498024 and parameters: {'svc_c': 33.46682858309976, 'svc_gamma': 12.299403847156425}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:57,421]\u001b[0m Trial 61 finished with value: 0.5276679841897233 and parameters: {'svc_c': 46.22598002578043, 'svc_gamma': 3.4538897039688194}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:57,890]\u001b[0m Trial 62 finished with value: 0.5217391304347826 and parameters: {'svc_c': 37.094380883057546, 'svc_gamma': 7.0138784970546535}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:58,334]\u001b[0m Trial 63 finished with value: 0.7252964426877471 and parameters: {'svc_c': 49.572052760638364, 'svc_gamma': 0.6267466781897463}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:58,848]\u001b[0m Trial 64 finished with value: 0.5217391304347826 and parameters: {'svc_c': 29.21000999948905, 'svc_gamma': 9.62452991021791}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:59,291]\u001b[0m Trial 65 finished with value: 0.525691699604743 and parameters: {'svc_c': 33.44642554348097, 'svc_gamma': 4.426709178735114}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:17:59,618]\u001b[0m Trial 66 finished with value: 0.8873517786561265 and parameters: {'svc_c': 24.66617489167562, 'svc_gamma': 0.09057074628163503}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:00,069]\u001b[0m Trial 67 finished with value: 0.5276679841897233 and parameters: {'svc_c': 24.411176537338548, 'svc_gamma': 3.468421904871799}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:00,527]\u001b[0m Trial 68 finished with value: 0.5217391304347826 and parameters: {'svc_c': 18.15606306354166, 'svc_gamma': 6.787514554654813}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:01,048]\u001b[0m Trial 69 finished with value: 0.5197628458498024 and parameters: {'svc_c': 2.8943803596223776, 'svc_gamma': 11.330690077117554}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:01,375]\u001b[0m Trial 70 finished with value: 0.8853754940711462 and parameters: {'svc_c': 23.217760985619883, 'svc_gamma': 0.09443319828971121}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:01,736]\u001b[0m Trial 71 finished with value: 0.8814229249011858 and parameters: {'svc_c': 23.178751803790547, 'svc_gamma': 0.17206764169489283}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:02,140]\u001b[0m Trial 72 finished with value: 0.5296442687747036 and parameters: {'svc_c': 21.928686085221194, 'svc_gamma': 3.3282437885060037}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:02,642]\u001b[0m Trial 73 finished with value: 0.5217391304347826 and parameters: {'svc_c': 27.72383527984799, 'svc_gamma': 8.008251494286368}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:03,084]\u001b[0m Trial 74 finished with value: 0.5316205533596838 and parameters: {'svc_c': 24.073243377995578, 'svc_gamma': 2.8036505084548735}. Best is trial 39 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:03,478]\u001b[0m Trial 75 finished with value: 0.8972332015810277 and parameters: {'svc_c': 12.727542881518724, 'svc_gamma': 0.11187760797331123}. Best is trial 75 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:03,987]\u001b[0m Trial 76 finished with value: 0.5217391304347826 and parameters: {'svc_c': 12.335955686150866, 'svc_gamma': 6.056890379904891}. Best is trial 75 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:04,496]\u001b[0m Trial 77 finished with value: 0.5197628458498024 and parameters: {'svc_c': 18.470515091982342, 'svc_gamma': 11.370410849169915}. Best is trial 75 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:05,050]\u001b[0m Trial 78 finished with value: 0.5197628458498024 and parameters: {'svc_c': 17.79195740872961, 'svc_gamma': 15.870458117855797}. Best is trial 75 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:05,287]\u001b[0m Trial 79 finished with value: 0.9031620553359684 and parameters: {'svc_c': 11.898134185830205, 'svc_gamma': 0.04466491935824293}. Best is trial 79 with value: 0.9031620553359684.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:05,782]\u001b[0m Trial 80 finished with value: 0.5217391304347826 and parameters: {'svc_c': 9.833827701708156, 'svc_gamma': 7.929676471613294}. Best is trial 79 with value: 0.9031620553359684.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:06,148]\u001b[0m Trial 81 finished with value: 0.8893280632411067 and parameters: {'svc_c': 14.765552834198326, 'svc_gamma': 0.14840235370610302}. Best is trial 79 with value: 0.9031620553359684.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:06,618]\u001b[0m Trial 82 finished with value: 0.5276679841897233 and parameters: {'svc_c': 13.579109698978172, 'svc_gamma': 3.980540038731484}. Best is trial 79 with value: 0.9031620553359684.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:07,090]\u001b[0m Trial 83 finished with value: 0.5375494071146245 and parameters: {'svc_c': 15.480958947635376, 'svc_gamma': 2.5033782166484992}. Best is trial 79 with value: 0.9031620553359684.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:07,553]\u001b[0m Trial 84 finished with value: 0.5217391304347826 and parameters: {'svc_c': 11.226564885482087, 'svc_gamma': 6.09838385019853}. Best is trial 79 with value: 0.9031620553359684.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:08,008]\u001b[0m Trial 85 finished with value: 0.5335968379446641 and parameters: {'svc_c': 7.894712881989252, 'svc_gamma': 2.5941190029106287}. Best is trial 79 with value: 0.9031620553359684.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:08,556]\u001b[0m Trial 86 finished with value: 0.5217391304347826 and parameters: {'svc_c': 21.607108428766466, 'svc_gamma': 9.351180695164565}. Best is trial 79 with value: 0.9031620553359684.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:08,731]\u001b[0m Trial 87 finished with value: 0.9150197628458498 and parameters: {'svc_c': 3.114257154045845, 'svc_gamma': 0.01833678313630284}. Best is trial 87 with value: 0.9150197628458498.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:09,129]\u001b[0m Trial 88 finished with value: 0.8656126482213439 and parameters: {'svc_c': 15.40358023358565, 'svc_gamma': 0.22476619857576285}. Best is trial 87 with value: 0.9150197628458498.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:09,601]\u001b[0m Trial 89 finished with value: 0.5217391304347826 and parameters: {'svc_c': 12.193372395341667, 'svc_gamma': 5.483359771893734}. Best is trial 87 with value: 0.9150197628458498.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:10,006]\u001b[0m Trial 90 finished with value: 0.5375494071146245 and parameters: {'svc_c': 8.495527577535652, 'svc_gamma': 2.312206470547813}. Best is trial 87 with value: 0.9150197628458498.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:10,469]\u001b[0m Trial 91 finished with value: 0.5375494071146245 and parameters: {'svc_c': 2.5160057181987314, 'svc_gamma': 2.4237410947736002}. Best is trial 87 with value: 0.9150197628458498.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:10,965]\u001b[0m Trial 92 finished with value: 0.5217391304347826 and parameters: {'svc_c': 30.912667226045727, 'svc_gamma': 5.511933989560913}. Best is trial 87 with value: 0.9150197628458498.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:11,479]\u001b[0m Trial 93 finished with value: 0.5217391304347826 and parameters: {'svc_c': 1.768850626540349, 'svc_gamma': 9.228609690311968}. Best is trial 87 with value: 0.9150197628458498.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:11,912]\u001b[0m Trial 94 finished with value: 0.5217391304347826 and parameters: {'svc_c': 6.27758925238948, 'svc_gamma': 7.633496208237107}. Best is trial 87 with value: 0.9150197628458498.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:12,302]\u001b[0m Trial 95 finished with value: 0.5375494071146245 and parameters: {'svc_c': 3.797529085772453, 'svc_gamma': 2.3747173274165263}. Best is trial 87 with value: 0.9150197628458498.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:12,871]\u001b[0m Trial 96 finished with value: 0.5197628458498024 and parameters: {'svc_c': 26.358887056942837, 'svc_gamma': 12.607294751681433}. Best is trial 87 with value: 0.9150197628458498.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:13,232]\u001b[0m Trial 97 finished with value: 0.8794466403162056 and parameters: {'svc_c': 22.603249688178096, 'svc_gamma': 0.17375175711378493}. Best is trial 87 with value: 0.9150197628458498.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:13,713]\u001b[0m Trial 98 finished with value: 0.5217391304347826 and parameters: {'svc_c': 20.51100181419583, 'svc_gamma': 4.953515716985929}. Best is trial 87 with value: 0.9150197628458498.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:14,148]\u001b[0m Trial 99 finished with value: 0.5375494071146245 and parameters: {'svc_c': 23.25044650101416, 'svc_gamma': 2.490572594928988}. Best is trial 87 with value: 0.9150197628458498.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:14,157]\u001b[0m A new study created in memory with name: no-name-92fd0161-4624-4bda-803e-bb3f12182946\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "index        APAAC  LogisticRegression             True   \n",
      "index        APAAC                 SVC             True   \n",
      "index        APAAC       XGBClassifier             True   \n",
      "index        APAAC      LGBMClassifier             True   \n",
      "index          CTD  LogisticRegression            False   \n",
      "index          CTD                 SVC            False   \n",
      "index          CTD       XGBClassifier            False   \n",
      "index          CTD      LGBMClassifier            False   \n",
      "index          CTD  LogisticRegression             True   \n",
      "index          CTD                 SVC             True   \n",
      "index          CTD       XGBClassifier             True   \n",
      "index          CTD      LGBMClassifier             True   \n",
      "index          DPC  LogisticRegression            False   \n",
      "index          DPC                 SVC            False   \n",
      "index          DPC       XGBClassifier            False   \n",
      "index          DPC      LGBMClassifier            False   \n",
      "index          DPC  LogisticRegression             True   \n",
      "index          DPC                 SVC             True   \n",
      "index          DPC       XGBClassifier             True   \n",
      "index          DPC      LGBMClassifier             True   \n",
      "index         PAAC  LogisticRegression            False   \n",
      "index         PAAC                 SVC            False   \n",
      "index         PAAC       XGBClassifier            False   \n",
      "index         PAAC      LGBMClassifier            False   \n",
      "index         PAAC  LogisticRegression             True   \n",
      "index         PAAC                 SVC             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "index  {'C': 0.09972241221770178, 'penalty': 'l1', 's...  0.893281   \n",
      "index  {'svc_c': 81.00794411499099, 'svc_gamma': 0.03...  0.859684   \n",
      "index  {'learning_rate': 0.21557448587004335, 'max_de...  0.891304   \n",
      "index  {'num_leaves': 2, 'max_depth': 43, 'learning_r...  0.893281   \n",
      "index                                               None  0.862764   \n",
      "index                                               None  0.846564   \n",
      "index                                               None  0.853410   \n",
      "index                                               None  0.851444   \n",
      "index  {'C': 0.0906600851039587, 'penalty': 'l2', 'so...  0.870334   \n",
      "index  {'svc_c': 93.52276100739736, 'svc_gamma': 0.01...  0.854617   \n",
      "index  {'learning_rate': 0.06876980973052808, 'max_de...  0.888016   \n",
      "index  {'num_leaves': 143, 'max_depth': 4, 'learning_...  0.882122   \n",
      "index                                               None  0.830298   \n",
      "index                                               None  0.891290   \n",
      "index                                               None  0.870646   \n",
      "index                                               None  0.868656   \n",
      "index  {'C': 0.09979066114998196, 'penalty': 'l1', 's...  0.891945   \n",
      "index  {'svc_c': 48.97185920584053, 'svc_gamma': 0.08...  0.530452   \n",
      "index  {'learning_rate': 0.21210841793732604, 'max_de...  0.917485   \n",
      "index  {'num_leaves': 62, 'max_depth': 44, 'learning_...  0.919450   \n",
      "index                                               None  0.871480   \n",
      "index                                               None  0.882349   \n",
      "index                                               None  0.880898   \n",
      "index                                               None  0.884839   \n",
      "index  {'C': 0.07140778733444259, 'penalty': 'l1', 's...  0.885375   \n",
      "index  {'svc_c': 3.114257154045845, 'svc_gamma': 0.01...  0.915020   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "index     0.885714     0.900383   0.893004  0.889344  0.786319   \n",
      "index     0.869388     0.850575   0.845238  0.857143  0.719608   \n",
      "index     0.885714     0.896552   0.889344  0.887526  0.782370   \n",
      "index     0.889796     0.896552   0.889796  0.889796  0.786348   \n",
      "index     0.869388     0.867424   0.858871  0.864097  0.736539   \n",
      "index     0.836735     0.875000   0.861345  0.848861  0.712738   \n",
      "index     0.844898     0.886364   0.873418  0.858921  0.732486   \n",
      "index     0.853061     0.893939   0.881857  0.867220  0.748251   \n",
      "index     0.881633     0.859848   0.853755  0.867470  0.740977   \n",
      "index     0.828571     0.878788   0.863830  0.845833  0.708950   \n",
      "index     0.865306     0.909091   0.898305  0.881497  0.775910   \n",
      "index     0.865306     0.897727   0.887029  0.876033  0.763920   \n",
      "index     0.861224     0.875000   0.864754  0.862986  0.736338   \n",
      "index     0.885714     0.931818   0.923404  0.904167  0.819371   \n",
      "index     0.897959     0.912879   0.905350  0.901639  0.811101   \n",
      "index     0.877551     0.901515   0.892116  0.884774  0.779621   \n",
      "index     0.889796     0.893939   0.886179  0.887984  0.783626   \n",
      "index     0.028571     0.996212   0.875000  0.055336  0.099560   \n",
      "index     0.910204     0.924242   0.917695  0.913934  0.834718   \n",
      "index     0.906122     0.931818   0.925000  0.915464  0.838719   \n",
      "index     0.873469     0.888889   0.880658  0.877049  0.762573   \n",
      "index     0.877551     0.954023   0.947137  0.911017  0.835582   \n",
      "index     0.869388     0.896552   0.887500  0.878351  0.766569   \n",
      "index     0.881633     0.904215   0.896266  0.888889  0.786339   \n",
      "index     0.885714     0.885057   0.878543  0.882114  0.770603   \n",
      "index     0.897959     0.931034   0.924370  0.910973  0.830039   \n",
      "\n",
      "                                           index  \n",
      "index      AAC_LogisticRegression_no_hypertuning  \n",
      "index                     AAC_SVC_no_hypertuning  \n",
      "index           AAC_XGBClassifier_no_hypertuning  \n",
      "index          AAC_LGBMClassifier_no_hypertuning  \n",
      "index    AAC_LogisticRegression_with_hypertuning  \n",
      "index                   AAC_SVC_with_hypertuning  \n",
      "index         AAC_XGBClassifier_with_hypertuning  \n",
      "index        AAC_LGBMClassifier_with_hypertuning  \n",
      "index    APAAC_LogisticRegression_no_hypertuning  \n",
      "index                   APAAC_SVC_no_hypertuning  \n",
      "index         APAAC_XGBClassifier_no_hypertuning  \n",
      "index        APAAC_LGBMClassifier_no_hypertuning  \n",
      "index  APAAC_LogisticRegression_with_hypertuning  \n",
      "index                 APAAC_SVC_with_hypertuning  \n",
      "index       APAAC_XGBClassifier_with_hypertuning  \n",
      "index      APAAC_LGBMClassifier_with_hypertuning  \n",
      "index      CTD_LogisticRegression_no_hypertuning  \n",
      "index                     CTD_SVC_no_hypertuning  \n",
      "index           CTD_XGBClassifier_no_hypertuning  \n",
      "index          CTD_LGBMClassifier_no_hypertuning  \n",
      "index    CTD_LogisticRegression_with_hypertuning  \n",
      "index                   CTD_SVC_with_hypertuning  \n",
      "index         CTD_XGBClassifier_with_hypertuning  \n",
      "index        CTD_LGBMClassifier_with_hypertuning  \n",
      "index      DPC_LogisticRegression_no_hypertuning  \n",
      "index                     DPC_SVC_no_hypertuning  \n",
      "index           DPC_XGBClassifier_no_hypertuning  \n",
      "index          DPC_LGBMClassifier_no_hypertuning  \n",
      "index    DPC_LogisticRegression_with_hypertuning  \n",
      "index                   DPC_SVC_with_hypertuning  \n",
      "index         DPC_XGBClassifier_with_hypertuning  \n",
      "index        DPC_LGBMClassifier_with_hypertuning  \n",
      "index     PAAC_LogisticRegression_no_hypertuning  \n",
      "index                    PAAC_SVC_no_hypertuning  \n",
      "index          PAAC_XGBClassifier_no_hypertuning  \n",
      "index         PAAC_LGBMClassifier_no_hypertuning  \n",
      "index   PAAC_LogisticRegression_with_hypertuning  \n",
      "index                  PAAC_SVC_with_hypertuning  \n",
      "Optimizing PAAC XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:18:15,177]\u001b[0m Trial 0 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.2619850011443755, 'max_depth': 2, 'n_estimators': 587}. Best is trial 0 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:16,030]\u001b[0m Trial 1 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.21638737361637084, 'max_depth': 2, 'n_estimators': 448}. Best is trial 0 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:17,753]\u001b[0m Trial 2 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.09799562429942851, 'max_depth': 3, 'n_estimators': 535}. Best is trial 2 with value: 0.8992094861660079.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:19,494]\u001b[0m Trial 3 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.10373571257505594, 'max_depth': 5, 'n_estimators': 422}. Best is trial 2 with value: 0.8992094861660079.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:20,306]\u001b[0m Trial 4 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.27986375169709904, 'max_depth': 2, 'n_estimators': 431}. Best is trial 2 with value: 0.8992094861660079.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:23,128]\u001b[0m Trial 5 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.06558564728115929, 'max_depth': 5, 'n_estimators': 723}. Best is trial 2 with value: 0.8992094861660079.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:25,931]\u001b[0m Trial 6 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.2976751864822694, 'max_depth': 5, 'n_estimators': 975}. Best is trial 2 with value: 0.8992094861660079.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:28,973]\u001b[0m Trial 7 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.13676075495503456, 'max_depth': 3, 'n_estimators': 985}. Best is trial 2 with value: 0.8992094861660079.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:31,334]\u001b[0m Trial 8 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.09855666425903278, 'max_depth': 3, 'n_estimators': 540}. Best is trial 2 with value: 0.8992094861660079.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:32,005]\u001b[0m Trial 9 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.021171527975797327, 'max_depth': 6, 'n_estimators': 100}. Best is trial 2 with value: 0.8992094861660079.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:32,881]\u001b[0m Trial 10 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.1808088067463022, 'max_depth': 4, 'n_estimators': 189}. Best is trial 2 with value: 0.8992094861660079.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:34,832]\u001b[0m Trial 11 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.2257459004728515, 'max_depth': 3, 'n_estimators': 704}. Best is trial 2 with value: 0.8992094861660079.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:36,921]\u001b[0m Trial 12 finished with value: 0.9011857707509882 and parameters: {'learning_rate': 0.15844444662560303, 'max_depth': 2, 'n_estimators': 720}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:42,117]\u001b[0m Trial 13 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.14771597838460218, 'max_depth': 3, 'n_estimators': 837}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:48,183]\u001b[0m Trial 14 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.16988862687977363, 'max_depth': 4, 'n_estimators': 711}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:49,206]\u001b[0m Trial 15 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.1172163932962607, 'max_depth': 2, 'n_estimators': 292}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:51,596]\u001b[0m Trial 16 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.07264238003206827, 'max_depth': 3, 'n_estimators': 589}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:55,115]\u001b[0m Trial 17 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.18239201383952602, 'max_depth': 2, 'n_estimators': 820}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:18:58,577]\u001b[0m Trial 18 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.1540424517799315, 'max_depth': 4, 'n_estimators': 849}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:19:01,050]\u001b[0m Trial 19 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.1307564604555151, 'max_depth': 4, 'n_estimators': 520}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:19:02,109]\u001b[0m Trial 20 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.08378507503479227, 'max_depth': 3, 'n_estimators': 304}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:19:04,416]\u001b[0m Trial 21 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.25962628497635265, 'max_depth': 2, 'n_estimators': 606}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:19:06,099]\u001b[0m Trial 22 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.24178646211400398, 'max_depth': 2, 'n_estimators': 646}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:19:07,401]\u001b[0m Trial 23 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.18600718855628007, 'max_depth': 2, 'n_estimators': 498}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:19:09,623]\u001b[0m Trial 24 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.20899565493459898, 'max_depth': 3, 'n_estimators': 771}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:19:11,428]\u001b[0m Trial 25 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.26581559529569143, 'max_depth': 2, 'n_estimators': 648}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:19:12,768]\u001b[0m Trial 26 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.23849684719245112, 'max_depth': 3, 'n_estimators': 342}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:19:14,976]\u001b[0m Trial 27 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.2033837891114088, 'max_depth': 2, 'n_estimators': 913}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:19:17,363]\u001b[0m Trial 28 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.16131001806568213, 'max_depth': 3, 'n_estimators': 595}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:19:20,421]\u001b[0m Trial 29 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.19952227105949633, 'max_depth': 2, 'n_estimators': 481}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:19:23,461]\u001b[0m Trial 30 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.2227659706393964, 'max_depth': 2, 'n_estimators': 651}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:19:29,258]\u001b[0m Trial 31 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.06467298500038733, 'max_depth': 5, 'n_estimators': 725}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:19:34,176]\u001b[0m Trial 32 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.0481411625011436, 'max_depth': 6, 'n_estimators': 761}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:19:36,393]\u001b[0m Trial 33 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.10993667314247929, 'max_depth': 5, 'n_estimators': 391}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:19:38,777]\u001b[0m Trial 34 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.09645005350859989, 'max_depth': 5, 'n_estimators': 560}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:19:40,780]\u001b[0m Trial 35 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.12901158129017956, 'max_depth': 6, 'n_estimators': 447}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:19:42,717]\u001b[0m Trial 36 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.2930884239411556, 'max_depth': 4, 'n_estimators': 666}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:19:46,235]\u001b[0m Trial 37 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.11736966637245713, 'max_depth': 5, 'n_estimators': 914}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:19:48,582]\u001b[0m Trial 38 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.04318070500017582, 'max_depth': 3, 'n_estimators': 783}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:19:49,416]\u001b[0m Trial 39 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.14061300851722452, 'max_depth': 2, 'n_estimators': 405}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:19:51,507]\u001b[0m Trial 40 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.09379861752548559, 'max_depth': 4, 'n_estimators': 562}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:19:53,409]\u001b[0m Trial 41 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.22819881738874653, 'max_depth': 3, 'n_estimators': 709}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:19:55,529]\u001b[0m Trial 42 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.2619195139643467, 'max_depth': 3, 'n_estimators': 721}. Best is trial 12 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:19:57,903]\u001b[0m Trial 43 finished with value: 0.9071146245059288 and parameters: {'learning_rate': 0.16656707795533288, 'max_depth': 4, 'n_estimators': 685}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:20:00,081]\u001b[0m Trial 44 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.16828563048360967, 'max_depth': 4, 'n_estimators': 675}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:20:02,979]\u001b[0m Trial 45 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.14790180706715425, 'max_depth': 5, 'n_estimators': 870}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:20:06,010]\u001b[0m Trial 46 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.1916769276286765, 'max_depth': 4, 'n_estimators': 794}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:20:09,831]\u001b[0m Trial 47 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.16867104453427836, 'max_depth': 5, 'n_estimators': 611}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:20:13,316]\u001b[0m Trial 48 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.12060805405224277, 'max_depth': 6, 'n_estimators': 528}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:20:16,413]\u001b[0m Trial 49 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.12312608437851308, 'max_depth': 6, 'n_estimators': 486}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:20:18,780]\u001b[0m Trial 50 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.13990090649016867, 'max_depth': 2, 'n_estimators': 547}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:20:24,003]\u001b[0m Trial 51 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.10939441659605773, 'max_depth': 6, 'n_estimators': 625}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:20:28,657]\u001b[0m Trial 52 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.15853759123399797, 'max_depth': 6, 'n_estimators': 520}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:20:33,120]\u001b[0m Trial 53 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.13096302370300042, 'max_depth': 4, 'n_estimators': 686}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:20:40,146]\u001b[0m Trial 54 finished with value: 0.9011857707509882 and parameters: {'learning_rate': 0.09798147536227453, 'max_depth': 6, 'n_estimators': 745}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:20:45,759]\u001b[0m Trial 55 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.10987554363712268, 'max_depth': 6, 'n_estimators': 734}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:20:48,728]\u001b[0m Trial 56 finished with value: 0.9011857707509882 and parameters: {'learning_rate': 0.17683642803023533, 'max_depth': 6, 'n_estimators': 459}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:20:51,853]\u001b[0m Trial 57 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.18020491619743262, 'max_depth': 6, 'n_estimators': 459}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:20:54,677]\u001b[0m Trial 58 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.14703365954943923, 'max_depth': 6, 'n_estimators': 351}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:20:58,184]\u001b[0m Trial 59 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.12422563218623554, 'max_depth': 6, 'n_estimators': 577}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:20:59,787]\u001b[0m Trial 60 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.08974282715663882, 'max_depth': 6, 'n_estimators': 194}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:21:02,866]\u001b[0m Trial 61 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.10412191949456372, 'max_depth': 3, 'n_estimators': 522}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:21:04,864]\u001b[0m Trial 62 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.1742572962421001, 'max_depth': 2, 'n_estimators': 427}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:21:08,799]\u001b[0m Trial 63 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.19207165869328321, 'max_depth': 5, 'n_estimators': 622}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:21:12,068]\u001b[0m Trial 64 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.15982051524105753, 'max_depth': 6, 'n_estimators': 749}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:21:13,322]\u001b[0m Trial 65 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.1528659651333757, 'max_depth': 2, 'n_estimators': 470}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:21:15,584]\u001b[0m Trial 66 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.13494304045139824, 'max_depth': 2, 'n_estimators': 589}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:21:17,518]\u001b[0m Trial 67 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.11740470916899799, 'max_depth': 3, 'n_estimators': 517}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:21:20,711]\u001b[0m Trial 68 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.1428142141598216, 'max_depth': 6, 'n_estimators': 642}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:21:25,862]\u001b[0m Trial 69 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.08452365761286473, 'max_depth': 5, 'n_estimators': 801}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:21:28,941]\u001b[0m Trial 70 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.21126369919908985, 'max_depth': 4, 'n_estimators': 692}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:21:33,496]\u001b[0m Trial 71 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.0775707434920525, 'max_depth': 5, 'n_estimators': 832}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:21:38,290]\u001b[0m Trial 72 finished with value: 0.9031620553359684 and parameters: {'learning_rate': 0.07444400239764218, 'max_depth': 6, 'n_estimators': 751}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:21:42,798]\u001b[0m Trial 73 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.10012239300142076, 'max_depth': 6, 'n_estimators': 865}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:21:47,806]\u001b[0m Trial 74 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.070315326811706, 'max_depth': 6, 'n_estimators': 752}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:21:50,340]\u001b[0m Trial 75 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.09124473769321993, 'max_depth': 6, 'n_estimators': 378}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:21:55,788]\u001b[0m Trial 76 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.10258911563305051, 'max_depth': 6, 'n_estimators': 541}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:21:58,908]\u001b[0m Trial 77 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.16553028188044214, 'max_depth': 2, 'n_estimators': 808}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:22:04,485]\u001b[0m Trial 78 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.17907834083513527, 'max_depth': 6, 'n_estimators': 658}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:22:06,584]\u001b[0m Trial 79 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.2512884937217401, 'max_depth': 3, 'n_estimators': 573}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:22:10,252]\u001b[0m Trial 80 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.27471240780897704, 'max_depth': 2, 'n_estimators': 495}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:22:20,716]\u001b[0m Trial 81 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.0605421211433002, 'max_depth': 5, 'n_estimators': 773}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:22:27,887]\u001b[0m Trial 82 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.08032516074214276, 'max_depth': 6, 'n_estimators': 697}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:22:31,919]\u001b[0m Trial 83 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.09379443518269176, 'max_depth': 4, 'n_estimators': 721}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:22:36,632]\u001b[0m Trial 84 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.17285981714298737, 'max_depth': 5, 'n_estimators': 635}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:22:40,164]\u001b[0m Trial 85 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.1544806860285699, 'max_depth': 6, 'n_estimators': 440}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:22:44,617]\u001b[0m Trial 86 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.08532608928006936, 'max_depth': 5, 'n_estimators': 602}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:22:49,140]\u001b[0m Trial 87 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.21952691834145005, 'max_depth': 6, 'n_estimators': 739}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:22:52,635]\u001b[0m Trial 88 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.29461766839884146, 'max_depth': 3, 'n_estimators': 672}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:22:55,626]\u001b[0m Trial 89 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.2874696382823226, 'max_depth': 3, 'n_estimators': 679}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:22:57,296]\u001b[0m Trial 90 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.2935422193284662, 'max_depth': 2, 'n_estimators': 669}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:22:59,998]\u001b[0m Trial 91 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.27621115195512275, 'max_depth': 4, 'n_estimators': 769}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:23:02,879]\u001b[0m Trial 92 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.28184687025647914, 'max_depth': 4, 'n_estimators': 705}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:23:05,055]\u001b[0m Trial 93 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.2978829520619283, 'max_depth': 6, 'n_estimators': 506}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:23:07,395]\u001b[0m Trial 94 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.23352756207019507, 'max_depth': 3, 'n_estimators': 721}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:23:09,687]\u001b[0m Trial 95 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.2349146315687299, 'max_depth': 3, 'n_estimators': 784}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:23:13,232]\u001b[0m Trial 96 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.2522727093862558, 'max_depth': 3, 'n_estimators': 738}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:23:15,587]\u001b[0m Trial 97 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.26698909467049975, 'max_depth': 3, 'n_estimators': 560}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:23:17,525]\u001b[0m Trial 98 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.22911714292007246, 'max_depth': 3, 'n_estimators': 532}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:23:19,353]\u001b[0m Trial 99 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.1635613773945723, 'max_depth': 2, 'n_estimators': 610}. Best is trial 43 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:23:19,370]\u001b[0m A new study created in memory with name: no-name-4fb2373c-8521-4335-9589-da78d5790085\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "index        APAAC  LogisticRegression             True   \n",
      "index        APAAC                 SVC             True   \n",
      "index        APAAC       XGBClassifier             True   \n",
      "index        APAAC      LGBMClassifier             True   \n",
      "index          CTD  LogisticRegression            False   \n",
      "index          CTD                 SVC            False   \n",
      "index          CTD       XGBClassifier            False   \n",
      "index          CTD      LGBMClassifier            False   \n",
      "index          CTD  LogisticRegression             True   \n",
      "index          CTD                 SVC             True   \n",
      "index          CTD       XGBClassifier             True   \n",
      "index          CTD      LGBMClassifier             True   \n",
      "index          DPC  LogisticRegression            False   \n",
      "index          DPC                 SVC            False   \n",
      "index          DPC       XGBClassifier            False   \n",
      "index          DPC      LGBMClassifier            False   \n",
      "index          DPC  LogisticRegression             True   \n",
      "index          DPC                 SVC             True   \n",
      "index          DPC       XGBClassifier             True   \n",
      "index          DPC      LGBMClassifier             True   \n",
      "index         PAAC  LogisticRegression            False   \n",
      "index         PAAC                 SVC            False   \n",
      "index         PAAC       XGBClassifier            False   \n",
      "index         PAAC      LGBMClassifier            False   \n",
      "index         PAAC  LogisticRegression             True   \n",
      "index         PAAC                 SVC             True   \n",
      "index         PAAC       XGBClassifier             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "index  {'C': 0.09972241221770178, 'penalty': 'l1', 's...  0.893281   \n",
      "index  {'svc_c': 81.00794411499099, 'svc_gamma': 0.03...  0.859684   \n",
      "index  {'learning_rate': 0.21557448587004335, 'max_de...  0.891304   \n",
      "index  {'num_leaves': 2, 'max_depth': 43, 'learning_r...  0.893281   \n",
      "index                                               None  0.862764   \n",
      "index                                               None  0.846564   \n",
      "index                                               None  0.853410   \n",
      "index                                               None  0.851444   \n",
      "index  {'C': 0.0906600851039587, 'penalty': 'l2', 'so...  0.870334   \n",
      "index  {'svc_c': 93.52276100739736, 'svc_gamma': 0.01...  0.854617   \n",
      "index  {'learning_rate': 0.06876980973052808, 'max_de...  0.888016   \n",
      "index  {'num_leaves': 143, 'max_depth': 4, 'learning_...  0.882122   \n",
      "index                                               None  0.830298   \n",
      "index                                               None  0.891290   \n",
      "index                                               None  0.870646   \n",
      "index                                               None  0.868656   \n",
      "index  {'C': 0.09979066114998196, 'penalty': 'l1', 's...  0.891945   \n",
      "index  {'svc_c': 48.97185920584053, 'svc_gamma': 0.08...  0.530452   \n",
      "index  {'learning_rate': 0.21210841793732604, 'max_de...  0.917485   \n",
      "index  {'num_leaves': 62, 'max_depth': 44, 'learning_...  0.919450   \n",
      "index                                               None  0.871480   \n",
      "index                                               None  0.882349   \n",
      "index                                               None  0.880898   \n",
      "index                                               None  0.884839   \n",
      "index  {'C': 0.07140778733444259, 'penalty': 'l1', 's...  0.885375   \n",
      "index  {'svc_c': 3.114257154045845, 'svc_gamma': 0.01...  0.915020   \n",
      "index  {'learning_rate': 0.16656707795533288, 'max_de...  0.907115   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "index     0.885714     0.900383   0.893004  0.889344  0.786319   \n",
      "index     0.869388     0.850575   0.845238  0.857143  0.719608   \n",
      "index     0.885714     0.896552   0.889344  0.887526  0.782370   \n",
      "index     0.889796     0.896552   0.889796  0.889796  0.786348   \n",
      "index     0.869388     0.867424   0.858871  0.864097  0.736539   \n",
      "index     0.836735     0.875000   0.861345  0.848861  0.712738   \n",
      "index     0.844898     0.886364   0.873418  0.858921  0.732486   \n",
      "index     0.853061     0.893939   0.881857  0.867220  0.748251   \n",
      "index     0.881633     0.859848   0.853755  0.867470  0.740977   \n",
      "index     0.828571     0.878788   0.863830  0.845833  0.708950   \n",
      "index     0.865306     0.909091   0.898305  0.881497  0.775910   \n",
      "index     0.865306     0.897727   0.887029  0.876033  0.763920   \n",
      "index     0.861224     0.875000   0.864754  0.862986  0.736338   \n",
      "index     0.885714     0.931818   0.923404  0.904167  0.819371   \n",
      "index     0.897959     0.912879   0.905350  0.901639  0.811101   \n",
      "index     0.877551     0.901515   0.892116  0.884774  0.779621   \n",
      "index     0.889796     0.893939   0.886179  0.887984  0.783626   \n",
      "index     0.028571     0.996212   0.875000  0.055336  0.099560   \n",
      "index     0.910204     0.924242   0.917695  0.913934  0.834718   \n",
      "index     0.906122     0.931818   0.925000  0.915464  0.838719   \n",
      "index     0.873469     0.888889   0.880658  0.877049  0.762573   \n",
      "index     0.877551     0.954023   0.947137  0.911017  0.835582   \n",
      "index     0.869388     0.896552   0.887500  0.878351  0.766569   \n",
      "index     0.881633     0.904215   0.896266  0.888889  0.786339   \n",
      "index     0.885714     0.885057   0.878543  0.882114  0.770603   \n",
      "index     0.897959     0.931034   0.924370  0.910973  0.830039   \n",
      "index     0.897959     0.915709   0.909091  0.903491  0.814031   \n",
      "\n",
      "                                           index  \n",
      "index      AAC_LogisticRegression_no_hypertuning  \n",
      "index                     AAC_SVC_no_hypertuning  \n",
      "index           AAC_XGBClassifier_no_hypertuning  \n",
      "index          AAC_LGBMClassifier_no_hypertuning  \n",
      "index    AAC_LogisticRegression_with_hypertuning  \n",
      "index                   AAC_SVC_with_hypertuning  \n",
      "index         AAC_XGBClassifier_with_hypertuning  \n",
      "index        AAC_LGBMClassifier_with_hypertuning  \n",
      "index    APAAC_LogisticRegression_no_hypertuning  \n",
      "index                   APAAC_SVC_no_hypertuning  \n",
      "index         APAAC_XGBClassifier_no_hypertuning  \n",
      "index        APAAC_LGBMClassifier_no_hypertuning  \n",
      "index  APAAC_LogisticRegression_with_hypertuning  \n",
      "index                 APAAC_SVC_with_hypertuning  \n",
      "index       APAAC_XGBClassifier_with_hypertuning  \n",
      "index      APAAC_LGBMClassifier_with_hypertuning  \n",
      "index      CTD_LogisticRegression_no_hypertuning  \n",
      "index                     CTD_SVC_no_hypertuning  \n",
      "index           CTD_XGBClassifier_no_hypertuning  \n",
      "index          CTD_LGBMClassifier_no_hypertuning  \n",
      "index    CTD_LogisticRegression_with_hypertuning  \n",
      "index                   CTD_SVC_with_hypertuning  \n",
      "index         CTD_XGBClassifier_with_hypertuning  \n",
      "index        CTD_LGBMClassifier_with_hypertuning  \n",
      "index      DPC_LogisticRegression_no_hypertuning  \n",
      "index                     DPC_SVC_no_hypertuning  \n",
      "index           DPC_XGBClassifier_no_hypertuning  \n",
      "index          DPC_LGBMClassifier_no_hypertuning  \n",
      "index    DPC_LogisticRegression_with_hypertuning  \n",
      "index                   DPC_SVC_with_hypertuning  \n",
      "index         DPC_XGBClassifier_with_hypertuning  \n",
      "index        DPC_LGBMClassifier_with_hypertuning  \n",
      "index     PAAC_LogisticRegression_no_hypertuning  \n",
      "index                    PAAC_SVC_no_hypertuning  \n",
      "index          PAAC_XGBClassifier_no_hypertuning  \n",
      "index         PAAC_LGBMClassifier_no_hypertuning  \n",
      "index   PAAC_LogisticRegression_with_hypertuning  \n",
      "index                  PAAC_SVC_with_hypertuning  \n",
      "index        PAAC_XGBClassifier_with_hypertuning  \n",
      "Optimizing PAAC LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:23:23,453]\u001b[0m Trial 0 finished with value: 0.9071146245059288 and parameters: {'num_leaves': 151, 'max_depth': 16, 'learning_rate': 0.23393208125638126, 'n_estimators': 1876}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:23:24,660]\u001b[0m Trial 1 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 19, 'max_depth': 13, 'learning_rate': 0.2325634678118051, 'n_estimators': 264}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:23:25,500]\u001b[0m Trial 2 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 183, 'max_depth': 34, 'learning_rate': 0.29455523636689307, 'n_estimators': 242}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:23:27,917]\u001b[0m Trial 3 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 186, 'max_depth': 48, 'learning_rate': 0.12323717380960289, 'n_estimators': 957}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:23:31,246]\u001b[0m Trial 4 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 136, 'max_depth': 31, 'learning_rate': 0.17507973536352484, 'n_estimators': 1193}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:23:33,706]\u001b[0m Trial 5 finished with value: 0.8992094861660079 and parameters: {'num_leaves': 192, 'max_depth': 8, 'learning_rate': 0.2618760821934061, 'n_estimators': 1643}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:23:36,356]\u001b[0m Trial 6 finished with value: 0.9011857707509882 and parameters: {'num_leaves': 240, 'max_depth': 33, 'learning_rate': 0.19683012001080238, 'n_estimators': 1721}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:23:38,568]\u001b[0m Trial 7 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 194, 'max_depth': 24, 'learning_rate': 0.2826744143278098, 'n_estimators': 1881}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:23:45,243]\u001b[0m Trial 8 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 207, 'max_depth': 28, 'learning_rate': 0.01602656816599233, 'n_estimators': 917}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:23:46,342]\u001b[0m Trial 9 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 60, 'max_depth': 44, 'learning_rate': 0.1965470149642969, 'n_estimators': 308}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:23:47,138]\u001b[0m Trial 10 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 104, 'max_depth': 2, 'learning_rate': 0.12389255498097801, 'n_estimators': 1341}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:23:50,368]\u001b[0m Trial 11 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 253, 'max_depth': 19, 'learning_rate': 0.21938758216684193, 'n_estimators': 1961}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:23:57,281]\u001b[0m Trial 12 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 254, 'max_depth': 37, 'learning_rate': 0.2323488246675947, 'n_estimators': 1580}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:24:02,036]\u001b[0m Trial 13 finished with value: 0.9071146245059288 and parameters: {'num_leaves': 131, 'max_depth': 19, 'learning_rate': 0.16245577668150124, 'n_estimators': 1622}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:24:06,521]\u001b[0m Trial 14 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 129, 'max_depth': 17, 'learning_rate': 0.15894139506668176, 'n_estimators': 1415}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:24:09,004]\u001b[0m Trial 15 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 140, 'max_depth': 22, 'learning_rate': 0.12492566017893363, 'n_estimators': 606}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:24:11,188]\u001b[0m Trial 16 finished with value: 0.9031620553359684 and parameters: {'num_leaves': 87, 'max_depth': 12, 'learning_rate': 0.2545851895325956, 'n_estimators': 1843}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:24:12,173]\u001b[0m Trial 17 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 149, 'max_depth': 3, 'learning_rate': 0.1715203715692984, 'n_estimators': 1525}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:24:15,385]\u001b[0m Trial 18 finished with value: 0.9031620553359684 and parameters: {'num_leaves': 66, 'max_depth': 15, 'learning_rate': 0.07435422176180001, 'n_estimators': 1144}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:24:16,669]\u001b[0m Trial 19 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 165, 'max_depth': 7, 'learning_rate': 0.198382527514341, 'n_estimators': 747}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:24:19,585]\u001b[0m Trial 20 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 111, 'max_depth': 23, 'learning_rate': 0.2611040797550279, 'n_estimators': 1776}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:24:22,272]\u001b[0m Trial 21 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 79, 'max_depth': 12, 'learning_rate': 0.25876365774544735, 'n_estimators': 1966}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:24:25,048]\u001b[0m Trial 22 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 98, 'max_depth': 10, 'learning_rate': 0.23600188164715932, 'n_estimators': 1793}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:24:27,700]\u001b[0m Trial 23 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 29, 'max_depth': 18, 'learning_rate': 0.29499819861490073, 'n_estimators': 1373}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:24:31,019]\u001b[0m Trial 24 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 45, 'max_depth': 20, 'learning_rate': 0.21102151361778035, 'n_estimators': 1546}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:24:34,352]\u001b[0m Trial 25 finished with value: 0.9011857707509882 and parameters: {'num_leaves': 117, 'max_depth': 27, 'learning_rate': 0.2621626472401561, 'n_estimators': 1825}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:24:41,923]\u001b[0m Trial 26 finished with value: 0.883399209486166 and parameters: {'num_leaves': 81, 'max_depth': 6, 'learning_rate': 0.2391474856209827, 'n_estimators': 1987}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:24:44,684]\u001b[0m Trial 27 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 162, 'max_depth': 16, 'learning_rate': 0.18532811224838827, 'n_estimators': 1690}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:24:47,030]\u001b[0m Trial 28 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 160, 'max_depth': 14, 'learning_rate': 0.1482333470689007, 'n_estimators': 1248}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:24:49,893]\u001b[0m Trial 29 finished with value: 0.9051383399209486 and parameters: {'num_leaves': 10, 'max_depth': 10, 'learning_rate': 0.20945230840340334, 'n_estimators': 1425}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:24:51,554]\u001b[0m Trial 30 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 3, 'max_depth': 11, 'learning_rate': 0.21600975384256182, 'n_estimators': 1475}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:24:53,445]\u001b[0m Trial 31 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 29, 'max_depth': 12, 'learning_rate': 0.2400111365859764, 'n_estimators': 1641}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:24:56,702]\u001b[0m Trial 32 finished with value: 0.9011857707509882 and parameters: {'num_leaves': 91, 'max_depth': 9, 'learning_rate': 0.21678692981165681, 'n_estimators': 1850}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:24:57,985]\u001b[0m Trial 33 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 5, 'max_depth': 5, 'learning_rate': 0.2733821696279596, 'n_estimators': 1710}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:24:59,682]\u001b[0m Trial 34 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 119, 'max_depth': 14, 'learning_rate': 0.2976410936352865, 'n_estimators': 1280}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:25:01,399]\u001b[0m Trial 35 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 214, 'max_depth': 20, 'learning_rate': 0.24600787544215835, 'n_estimators': 1036}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:25:03,543]\u001b[0m Trial 36 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 176, 'max_depth': 9, 'learning_rate': 0.280181642077733, 'n_estimators': 1464}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:25:06,115]\u001b[0m Trial 37 finished with value: 0.9031620553359684 and parameters: {'num_leaves': 141, 'max_depth': 30, 'learning_rate': 0.18365311227649833, 'n_estimators': 1615}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:25:08,569]\u001b[0m Trial 38 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 52, 'max_depth': 24, 'learning_rate': 0.22809111170968524, 'n_estimators': 1877}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:25:09,003]\u001b[0m Trial 39 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 38, 'max_depth': 17, 'learning_rate': 0.2054483405945854, 'n_estimators': 107}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:25:12,444]\u001b[0m Trial 40 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 128, 'max_depth': 50, 'learning_rate': 0.2538939724937081, 'n_estimators': 1733}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:25:18,697]\u001b[0m Trial 41 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 71, 'max_depth': 16, 'learning_rate': 0.069333218208784, 'n_estimators': 1133}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:25:22,002]\u001b[0m Trial 42 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 13, 'max_depth': 14, 'learning_rate': 0.10673254706854948, 'n_estimators': 852}. Best is trial 0 with value: 0.9071146245059288.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:25:25,013]\u001b[0m Trial 43 finished with value: 0.9090909090909091 and parameters: {'num_leaves': 60, 'max_depth': 21, 'learning_rate': 0.1946220094042559, 'n_estimators': 1160}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:25:27,489]\u001b[0m Trial 44 finished with value: 0.8992094861660079 and parameters: {'num_leaves': 87, 'max_depth': 21, 'learning_rate': 0.2237194859976426, 'n_estimators': 1283}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:25:31,624]\u001b[0m Trial 45 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 60, 'max_depth': 25, 'learning_rate': 0.18898050768123056, 'n_estimators': 1897}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:25:34,703]\u001b[0m Trial 46 finished with value: 0.9011857707509882 and parameters: {'num_leaves': 107, 'max_depth': 19, 'learning_rate': 0.21072837935050232, 'n_estimators': 1028}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:25:37,532]\u001b[0m Trial 47 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 26, 'max_depth': 29, 'learning_rate': 0.1679597382718649, 'n_estimators': 1467}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:25:40,379]\u001b[0m Trial 48 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 149, 'max_depth': 36, 'learning_rate': 0.1961253726698215, 'n_estimators': 1577}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:25:42,386]\u001b[0m Trial 49 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 97, 'max_depth': 4, 'learning_rate': 0.2304976875684318, 'n_estimators': 1356}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:25:45,446]\u001b[0m Trial 50 finished with value: 0.9011857707509882 and parameters: {'num_leaves': 123, 'max_depth': 32, 'learning_rate': 0.248286962129108, 'n_estimators': 1686}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:25:47,974]\u001b[0m Trial 51 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 64, 'max_depth': 15, 'learning_rate': 0.20265983106047475, 'n_estimators': 1149}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:25:50,356]\u001b[0m Trial 52 finished with value: 0.9051383399209486 and parameters: {'num_leaves': 50, 'max_depth': 12, 'learning_rate': 0.174961781983851, 'n_estimators': 949}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:25:51,961]\u001b[0m Trial 53 finished with value: 0.9051383399209486 and parameters: {'num_leaves': 41, 'max_depth': 12, 'learning_rate': 0.1740998179060969, 'n_estimators': 696}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:25:53,186]\u001b[0m Trial 54 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 20, 'max_depth': 22, 'learning_rate': 0.17435992065331993, 'n_estimators': 629}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:25:54,804]\u001b[0m Trial 55 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 44, 'max_depth': 18, 'learning_rate': 0.1579463781080279, 'n_estimators': 454}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:25:58,041]\u001b[0m Trial 56 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 37, 'max_depth': 8, 'learning_rate': 0.18122372776942489, 'n_estimators': 833}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:26:00,271]\u001b[0m Trial 57 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 13, 'max_depth': 41, 'learning_rate': 0.19483481734478209, 'n_estimators': 676}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:26:02,972]\u001b[0m Trial 58 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 50, 'max_depth': 11, 'learning_rate': 0.16197342956407873, 'n_estimators': 511}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:26:03,442]\u001b[0m Trial 59 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 177, 'max_depth': 2, 'learning_rate': 0.14539911303260267, 'n_estimators': 945}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:26:04,930]\u001b[0m Trial 60 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 72, 'max_depth': 7, 'learning_rate': 0.17969708868700454, 'n_estimators': 742}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:26:08,968]\u001b[0m Trial 61 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 56, 'max_depth': 13, 'learning_rate': 0.2084313962048999, 'n_estimators': 1903}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:26:11,581]\u001b[0m Trial 62 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 152, 'max_depth': 12, 'learning_rate': 0.2207279413482466, 'n_estimators': 1775}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:26:14,136]\u001b[0m Trial 63 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 38, 'max_depth': 10, 'learning_rate': 0.18935004203584513, 'n_estimators': 1093}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:26:15,988]\u001b[0m Trial 64 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 77, 'max_depth': 16, 'learning_rate': 0.1710707203845136, 'n_estimators': 876}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:26:18,639]\u001b[0m Trial 65 finished with value: 0.8992094861660079 and parameters: {'num_leaves': 24, 'max_depth': 13, 'learning_rate': 0.19855608119269688, 'n_estimators': 1206}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:26:20,522]\u001b[0m Trial 66 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 130, 'max_depth': 18, 'learning_rate': 0.2257822888297194, 'n_estimators': 777}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:26:22,661]\u001b[0m Trial 67 finished with value: 0.9011857707509882 and parameters: {'num_leaves': 10, 'max_depth': 21, 'learning_rate': 0.23815209786631925, 'n_estimators': 1403}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:26:25,694]\u001b[0m Trial 68 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 36, 'max_depth': 26, 'learning_rate': 0.21697847914622106, 'n_estimators': 987}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:26:31,154]\u001b[0m Trial 69 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 112, 'max_depth': 10, 'learning_rate': 0.20420553165831945, 'n_estimators': 1943}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:26:34,926]\u001b[0m Trial 70 finished with value: 0.8992094861660079 and parameters: {'num_leaves': 136, 'max_depth': 6, 'learning_rate': 0.19009433772861897, 'n_estimators': 1793}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:26:41,905]\u001b[0m Trial 71 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 63, 'max_depth': 15, 'learning_rate': 0.14502417371471493, 'n_estimators': 1200}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:26:48,424]\u001b[0m Trial 72 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 67, 'max_depth': 12, 'learning_rate': 0.17792730318932462, 'n_estimators': 1526}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:26:52,200]\u001b[0m Trial 73 finished with value: 0.9011857707509882 and parameters: {'num_leaves': 47, 'max_depth': 17, 'learning_rate': 0.15664859569852535, 'n_estimators': 1295}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:26:55,552]\u001b[0m Trial 74 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 88, 'max_depth': 15, 'learning_rate': 0.13511579771394658, 'n_estimators': 1126}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:26:59,315]\u001b[0m Trial 75 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 56, 'max_depth': 20, 'learning_rate': 0.16680389018835026, 'n_estimators': 1638}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:27:01,719]\u001b[0m Trial 76 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 98, 'max_depth': 23, 'learning_rate': 0.2690798115924683, 'n_estimators': 1087}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:27:09,529]\u001b[0m Trial 77 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 79, 'max_depth': 9, 'learning_rate': 0.21303044033740048, 'n_estimators': 904}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:27:13,438]\u001b[0m Trial 78 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 33, 'max_depth': 14, 'learning_rate': 0.1752041194557744, 'n_estimators': 1000}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:27:15,314]\u001b[0m Trial 79 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 167, 'max_depth': 11, 'learning_rate': 0.2322981782530662, 'n_estimators': 508}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:27:16,949]\u001b[0m Trial 80 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 197, 'max_depth': 19, 'learning_rate': 0.18434153098000972, 'n_estimators': 321}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:27:21,010]\u001b[0m Trial 81 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 151, 'max_depth': 30, 'learning_rate': 0.16474711199098657, 'n_estimators': 1648}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:27:24,776]\u001b[0m Trial 82 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 133, 'max_depth': 27, 'learning_rate': 0.18783268870031586, 'n_estimators': 1438}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:27:29,499]\u001b[0m Trial 83 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 122, 'max_depth': 16, 'learning_rate': 0.20003877452042243, 'n_estimators': 1578}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:27:33,657]\u001b[0m Trial 84 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 158, 'max_depth': 33, 'learning_rate': 0.17189694579922746, 'n_estimators': 1841}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:27:39,422]\u001b[0m Trial 85 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 142, 'max_depth': 13, 'learning_rate': 0.15424188266077252, 'n_estimators': 1997}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:27:43,307]\u001b[0m Trial 86 finished with value: 0.9011857707509882 and parameters: {'num_leaves': 45, 'max_depth': 35, 'learning_rate': 0.19310055572468157, 'n_estimators': 1751}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:27:46,398]\u001b[0m Trial 87 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 140, 'max_depth': 8, 'learning_rate': 0.1795362172923528, 'n_estimators': 1502}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:27:50,053]\u001b[0m Trial 88 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 72, 'max_depth': 17, 'learning_rate': 0.24671283945027292, 'n_estimators': 1605}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:27:55,566]\u001b[0m Trial 89 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 54, 'max_depth': 25, 'learning_rate': 0.207038573364673, 'n_estimators': 1236}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:27:59,079]\u001b[0m Trial 90 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 146, 'max_depth': 22, 'learning_rate': 0.16385298247721722, 'n_estimators': 1932}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:28:02,087]\u001b[0m Trial 91 finished with value: 0.8992094861660079 and parameters: {'num_leaves': 250, 'max_depth': 32, 'learning_rate': 0.2221231132371745, 'n_estimators': 1696}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:28:05,954]\u001b[0m Trial 92 finished with value: 0.9011857707509882 and parameters: {'num_leaves': 221, 'max_depth': 37, 'learning_rate': 0.18257177715708184, 'n_estimators': 1837}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:28:09,725]\u001b[0m Trial 93 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 236, 'max_depth': 38, 'learning_rate': 0.1973253102995232, 'n_estimators': 1743}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:28:13,155]\u001b[0m Trial 94 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 85, 'max_depth': 28, 'learning_rate': 0.20244617464913733, 'n_estimators': 1328}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:28:16,713]\u001b[0m Trial 95 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 60, 'max_depth': 30, 'learning_rate': 0.18590166617181964, 'n_estimators': 1650}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:28:19,475]\u001b[0m Trial 96 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 21, 'max_depth': 10, 'learning_rate': 0.21699261468651967, 'n_estimators': 1808}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:28:22,914]\u001b[0m Trial 97 finished with value: 0.8992094861660079 and parameters: {'num_leaves': 168, 'max_depth': 19, 'learning_rate': 0.2090680027853424, 'n_estimators': 1883}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:28:26,898]\u001b[0m Trial 98 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 111, 'max_depth': 14, 'learning_rate': 0.17157889147332833, 'n_estimators': 1164}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:28:27,663]\u001b[0m Trial 99 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 2, 'max_depth': 11, 'learning_rate': 0.19442694331051405, 'n_estimators': 1709}. Best is trial 43 with value: 0.9090909090909091.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning   \n",
      "index          AAC  LogisticRegression            False  \\\n",
      "index          AAC                 SVC            False   \n",
      "index          AAC       XGBClassifier            False   \n",
      "index          AAC      LGBMClassifier            False   \n",
      "index          AAC  LogisticRegression             True   \n",
      "index          AAC                 SVC             True   \n",
      "index          AAC       XGBClassifier             True   \n",
      "index          AAC      LGBMClassifier             True   \n",
      "index        APAAC  LogisticRegression            False   \n",
      "index        APAAC                 SVC            False   \n",
      "index        APAAC       XGBClassifier            False   \n",
      "index        APAAC      LGBMClassifier            False   \n",
      "index        APAAC  LogisticRegression             True   \n",
      "index        APAAC                 SVC             True   \n",
      "index        APAAC       XGBClassifier             True   \n",
      "index        APAAC      LGBMClassifier             True   \n",
      "index          CTD  LogisticRegression            False   \n",
      "index          CTD                 SVC            False   \n",
      "index          CTD       XGBClassifier            False   \n",
      "index          CTD      LGBMClassifier            False   \n",
      "index          CTD  LogisticRegression             True   \n",
      "index          CTD                 SVC             True   \n",
      "index          CTD       XGBClassifier             True   \n",
      "index          CTD      LGBMClassifier             True   \n",
      "index          DPC  LogisticRegression            False   \n",
      "index          DPC                 SVC            False   \n",
      "index          DPC       XGBClassifier            False   \n",
      "index          DPC      LGBMClassifier            False   \n",
      "index          DPC  LogisticRegression             True   \n",
      "index          DPC                 SVC             True   \n",
      "index          DPC       XGBClassifier             True   \n",
      "index          DPC      LGBMClassifier             True   \n",
      "index         PAAC  LogisticRegression            False   \n",
      "index         PAAC                 SVC            False   \n",
      "index         PAAC       XGBClassifier            False   \n",
      "index         PAAC      LGBMClassifier            False   \n",
      "index         PAAC  LogisticRegression             True   \n",
      "index         PAAC                 SVC             True   \n",
      "index         PAAC       XGBClassifier             True   \n",
      "index         PAAC      LGBMClassifier             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.875077  \\\n",
      "index                                               None  0.897209   \n",
      "index                                               None  0.890297   \n",
      "index                                               None  0.883399   \n",
      "index  {'C': 0.03277840391147581, 'penalty': 'l1', 's...  0.858546   \n",
      "index  {'svc_c': 7.554678737818476, 'svc_gamma': 0.02...  0.882122   \n",
      "index  {'learning_rate': 0.011048009324978417, 'max_d...  0.891945   \n",
      "index  {'num_leaves': 202, 'max_depth': 31, 'learning...  0.888016   \n",
      "index                                               None  0.868517   \n",
      "index                                               None  0.868017   \n",
      "index                                               None  0.884834   \n",
      "index                                               None  0.882837   \n",
      "index  {'C': 0.09972241221770178, 'penalty': 'l1', 's...  0.893281   \n",
      "index  {'svc_c': 81.00794411499099, 'svc_gamma': 0.03...  0.859684   \n",
      "index  {'learning_rate': 0.21557448587004335, 'max_de...  0.891304   \n",
      "index  {'num_leaves': 2, 'max_depth': 43, 'learning_r...  0.893281   \n",
      "index                                               None  0.862764   \n",
      "index                                               None  0.846564   \n",
      "index                                               None  0.853410   \n",
      "index                                               None  0.851444   \n",
      "index  {'C': 0.0906600851039587, 'penalty': 'l2', 'so...  0.870334   \n",
      "index  {'svc_c': 93.52276100739736, 'svc_gamma': 0.01...  0.854617   \n",
      "index  {'learning_rate': 0.06876980973052808, 'max_de...  0.888016   \n",
      "index  {'num_leaves': 143, 'max_depth': 4, 'learning_...  0.882122   \n",
      "index                                               None  0.830298   \n",
      "index                                               None  0.891290   \n",
      "index                                               None  0.870646   \n",
      "index                                               None  0.868656   \n",
      "index  {'C': 0.09979066114998196, 'penalty': 'l1', 's...  0.891945   \n",
      "index  {'svc_c': 48.97185920584053, 'svc_gamma': 0.08...  0.530452   \n",
      "index  {'learning_rate': 0.21210841793732604, 'max_de...  0.917485   \n",
      "index  {'num_leaves': 62, 'max_depth': 44, 'learning_...  0.919450   \n",
      "index                                               None  0.871480   \n",
      "index                                               None  0.882349   \n",
      "index                                               None  0.880898   \n",
      "index                                               None  0.884839   \n",
      "index  {'C': 0.07140778733444259, 'penalty': 'l1', 's...  0.885375   \n",
      "index  {'svc_c': 3.114257154045845, 'svc_gamma': 0.01...  0.915020   \n",
      "index  {'learning_rate': 0.16656707795533288, 'max_de...  0.907115   \n",
      "index  {'num_leaves': 60, 'max_depth': 21, 'learning_...  0.909091   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.791837     0.901515   0.881818  0.834409  0.699324  \\\n",
      "index     0.836735     0.931818   0.919283  0.876068  0.773969   \n",
      "index     0.828571     0.928030   0.914414  0.869379  0.762316   \n",
      "index     0.840816     0.909091   0.895652  0.867368  0.752881   \n",
      "index     0.820408     0.893939   0.877729  0.848101  0.717460   \n",
      "index     0.840816     0.920455   0.907489  0.872881  0.765221   \n",
      "index     0.840816     0.939394   0.927928  0.882227  0.786103   \n",
      "index     0.840816     0.931818   0.919643  0.878465  0.777701   \n",
      "index     0.869388     0.908046   0.898734  0.883817  0.778604   \n",
      "index     0.861224     0.896552   0.886555  0.873706  0.758732   \n",
      "index     0.873469     0.881226   0.873469  0.873469  0.754695   \n",
      "index     0.885714     0.908046   0.900415  0.893004  0.794257   \n",
      "index     0.885714     0.900383   0.893004  0.889344  0.786319   \n",
      "index     0.869388     0.850575   0.845238  0.857143  0.719608   \n",
      "index     0.885714     0.896552   0.889344  0.887526  0.782370   \n",
      "index     0.889796     0.896552   0.889796  0.889796  0.786348   \n",
      "index     0.869388     0.867424   0.858871  0.864097  0.736539   \n",
      "index     0.836735     0.875000   0.861345  0.848861  0.712738   \n",
      "index     0.844898     0.886364   0.873418  0.858921  0.732486   \n",
      "index     0.853061     0.893939   0.881857  0.867220  0.748251   \n",
      "index     0.881633     0.859848   0.853755  0.867470  0.740977   \n",
      "index     0.828571     0.878788   0.863830  0.845833  0.708950   \n",
      "index     0.865306     0.909091   0.898305  0.881497  0.775910   \n",
      "index     0.865306     0.897727   0.887029  0.876033  0.763920   \n",
      "index     0.861224     0.875000   0.864754  0.862986  0.736338   \n",
      "index     0.885714     0.931818   0.923404  0.904167  0.819371   \n",
      "index     0.897959     0.912879   0.905350  0.901639  0.811101   \n",
      "index     0.877551     0.901515   0.892116  0.884774  0.779621   \n",
      "index     0.889796     0.893939   0.886179  0.887984  0.783626   \n",
      "index     0.028571     0.996212   0.875000  0.055336  0.099560   \n",
      "index     0.910204     0.924242   0.917695  0.913934  0.834718   \n",
      "index     0.906122     0.931818   0.925000  0.915464  0.838719   \n",
      "index     0.873469     0.888889   0.880658  0.877049  0.762573   \n",
      "index     0.877551     0.954023   0.947137  0.911017  0.835582   \n",
      "index     0.869388     0.896552   0.887500  0.878351  0.766569   \n",
      "index     0.881633     0.904215   0.896266  0.888889  0.786339   \n",
      "index     0.885714     0.885057   0.878543  0.882114  0.770603   \n",
      "index     0.897959     0.931034   0.924370  0.910973  0.830039   \n",
      "index     0.897959     0.915709   0.909091  0.903491  0.814031   \n",
      "index     0.897959     0.919540   0.912863  0.905350  0.818011   \n",
      "\n",
      "                                           index  \n",
      "index      AAC_LogisticRegression_no_hypertuning  \n",
      "index                     AAC_SVC_no_hypertuning  \n",
      "index           AAC_XGBClassifier_no_hypertuning  \n",
      "index          AAC_LGBMClassifier_no_hypertuning  \n",
      "index    AAC_LogisticRegression_with_hypertuning  \n",
      "index                   AAC_SVC_with_hypertuning  \n",
      "index         AAC_XGBClassifier_with_hypertuning  \n",
      "index        AAC_LGBMClassifier_with_hypertuning  \n",
      "index    APAAC_LogisticRegression_no_hypertuning  \n",
      "index                   APAAC_SVC_no_hypertuning  \n",
      "index         APAAC_XGBClassifier_no_hypertuning  \n",
      "index        APAAC_LGBMClassifier_no_hypertuning  \n",
      "index  APAAC_LogisticRegression_with_hypertuning  \n",
      "index                 APAAC_SVC_with_hypertuning  \n",
      "index       APAAC_XGBClassifier_with_hypertuning  \n",
      "index      APAAC_LGBMClassifier_with_hypertuning  \n",
      "index      CTD_LogisticRegression_no_hypertuning  \n",
      "index                     CTD_SVC_no_hypertuning  \n",
      "index           CTD_XGBClassifier_no_hypertuning  \n",
      "index          CTD_LGBMClassifier_no_hypertuning  \n",
      "index    CTD_LogisticRegression_with_hypertuning  \n",
      "index                   CTD_SVC_with_hypertuning  \n",
      "index         CTD_XGBClassifier_with_hypertuning  \n",
      "index        CTD_LGBMClassifier_with_hypertuning  \n",
      "index      DPC_LogisticRegression_no_hypertuning  \n",
      "index                     DPC_SVC_no_hypertuning  \n",
      "index           DPC_XGBClassifier_no_hypertuning  \n",
      "index          DPC_LGBMClassifier_no_hypertuning  \n",
      "index    DPC_LogisticRegression_with_hypertuning  \n",
      "index                   DPC_SVC_with_hypertuning  \n",
      "index         DPC_XGBClassifier_with_hypertuning  \n",
      "index        DPC_LGBMClassifier_with_hypertuning  \n",
      "index     PAAC_LogisticRegression_no_hypertuning  \n",
      "index                    PAAC_SVC_no_hypertuning  \n",
      "index          PAAC_XGBClassifier_no_hypertuning  \n",
      "index         PAAC_LGBMClassifier_no_hypertuning  \n",
      "index   PAAC_LogisticRegression_with_hypertuning  \n",
      "index                  PAAC_SVC_with_hypertuning  \n",
      "index        PAAC_XGBClassifier_with_hypertuning  \n",
      "index       PAAC_LGBMClassifier_with_hypertuning  \n"
     ]
    }
   ],
   "source": [
    "# empty dataframe to store results with the columns feature_type, model, with_hypertuning, accuracy, sensitivity, specificity, precision, f1, mcc\n",
    "results = pd.DataFrame(columns=['feature_type', 'model', 'with_hypertuning', 'best_params', 'accuracy', 'sensitivity', 'specificity', 'precision', 'f1', 'mcc', 'index'])\n",
    "feature_types = ['AAC', 'APAAC', 'CTD', 'DPC', 'PAAC']\n",
    "for feature_type in feature_types:\n",
    "\n",
    "    # Load the training dataset\n",
    "    data = pd.read_csv(f'{data_dir}/TR_{feature_type}.csv')\n",
    "\n",
    "    # Separate features and target\n",
    "    X = data.drop(columns=['label', 'id'], axis=1)\n",
    "    y = data['label']\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Evaluate models without hyperparameters tuning\n",
    "    for name, model in models.items():\n",
    "        print(f\"Evaluating {feature_type} {name}\")\n",
    "        results = evaluate_model(name, model, X_train, y_train, X_test, y_test, results, feature_type)\n",
    "        print(results)\n",
    "\n",
    "    # Optimize hyperparameters\n",
    "    for name, model in models_.items():\n",
    "        objective = objectives.get(name)\n",
    "        if objective is not None:\n",
    "            print(f\"Optimizing {feature_type} {name}\")\n",
    "            results = optimize_hyperparameters(name, model, objective, trials=100, results_dataframe=results, feature_type=feature_type, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)\n",
    "            print(results)\n",
    "\n",
    "results.to_csv('results_v2.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating selected_features_all_best20 LogisticRegression\n",
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "\n",
      "      best_params  accuracy  sensitivity  specificity  precision        f1   \n",
      "index        None   0.86163     0.832653     0.850575   0.839506  0.836066  \\\n",
      "\n",
      "           mcc                                              index  \n",
      "index  0.68342  selected_features_all_best20_LogisticRegressio...  \n",
      "Evaluating selected_features_all_best20 SVC\n",
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "\n",
      "      best_params  accuracy  sensitivity  specificity  precision        f1   \n",
      "index        None  0.861630     0.832653     0.850575   0.839506  0.836066  \\\n",
      "index        None  0.884356     0.816327     0.915709   0.900901  0.856531   \n",
      "\n",
      "            mcc                                              index  \n",
      "index  0.683420  selected_features_all_best20_LogisticRegressio...  \n",
      "index  0.737224    selected_features_all_best20_SVC_no_hypertuning  \n",
      "Evaluating selected_features_all_best20 XGBClassifier\n",
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "\n",
      "      best_params  accuracy  sensitivity  specificity  precision        f1   \n",
      "index        None  0.861630     0.832653     0.850575   0.839506  0.836066  \\\n",
      "index        None  0.884356     0.816327     0.915709   0.900901  0.856531   \n",
      "index        None  0.865564     0.840816     0.908046   0.895652  0.867368   \n",
      "\n",
      "            mcc                                              index  \n",
      "index  0.683420  selected_features_all_best20_LogisticRegressio...  \n",
      "index  0.737224    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  0.751600  selected_features_all_best20_XGBClassifier_no_...  \n",
      "Evaluating selected_features_all_best20 LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:32:32,517]\u001b[0m A new study created in memory with name: no-name-3df58edf-44c6-4cf2-9751-20d6cafa617a\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:32,628]\u001b[0m Trial 0 finished with value: 0.857707509881423 and parameters: {'C': 0.07403839557995674, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 496}. Best is trial 0 with value: 0.857707509881423.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:32,657]\u001b[0m Trial 1 finished with value: 0.8537549407114624 and parameters: {'C': 0.0810939833636358, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 522}. Best is trial 0 with value: 0.857707509881423.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:32,684]\u001b[0m Trial 2 finished with value: 0.857707509881423 and parameters: {'C': 0.08162923941197098, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 802}. Best is trial 0 with value: 0.857707509881423.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "\n",
      "      best_params  accuracy  sensitivity  specificity  precision        f1   \n",
      "index        None  0.861630     0.832653     0.850575   0.839506  0.836066  \\\n",
      "index        None  0.884356     0.816327     0.915709   0.900901  0.856531   \n",
      "index        None  0.865564     0.840816     0.908046   0.895652  0.867368   \n",
      "index        None  0.870999     0.832653     0.919540   0.906667  0.868085   \n",
      "\n",
      "            mcc                                              index  \n",
      "index  0.683420  selected_features_all_best20_LogisticRegressio...  \n",
      "index  0.737224    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  0.751600  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  0.756464  selected_features_all_best20_LGBMClassifier_no...  \n",
      "Optimizing selected_features_all_best20 LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:32:32,872]\u001b[0m Trial 3 finished with value: 0.8596837944664032 and parameters: {'C': 0.06441953223187927, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 574}. Best is trial 3 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:32,897]\u001b[0m Trial 4 finished with value: 0.857707509881423 and parameters: {'C': 0.040412568834002696, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 939}. Best is trial 3 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:32,923]\u001b[0m Trial 5 finished with value: 0.857707509881423 and parameters: {'C': 0.026477898873890016, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 184}. Best is trial 3 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:33,059]\u001b[0m Trial 6 finished with value: 0.8616600790513834 and parameters: {'C': 0.03342895231698814, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 773}. Best is trial 6 with value: 0.8616600790513834.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:33,079]\u001b[0m Trial 7 finished with value: 0.8537549407114624 and parameters: {'C': 0.047323057418438036, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 133}. Best is trial 6 with value: 0.8616600790513834.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:33,106]\u001b[0m Trial 8 finished with value: 0.8636363636363636 and parameters: {'C': 0.05772645471274076, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 445}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:32:33,260]\u001b[0m Trial 9 finished with value: 0.8596837944664032 and parameters: {'C': 0.06977402770709727, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 149}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:33,290]\u001b[0m Trial 10 finished with value: 0.8300395256916996 and parameters: {'C': 0.01045672514208975, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 339}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:33,669]\u001b[0m Trial 11 finished with value: 0.857707509881423 and parameters: {'C': 0.09786449680425763, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 736}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:33,839]\u001b[0m Trial 12 finished with value: 0.8596837944664032 and parameters: {'C': 0.05673096506439872, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 693}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,020]\u001b[0m Trial 13 finished with value: 0.8596837944664032 and parameters: {'C': 0.03912418381532872, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 338}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,064]\u001b[0m Trial 14 finished with value: 0.8616600790513834 and parameters: {'C': 0.050731051144353126, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 948}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,200]\u001b[0m Trial 15 finished with value: 0.8616600790513834 and parameters: {'C': 0.029122413372611355, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 391}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,240]\u001b[0m Trial 16 finished with value: 0.8636363636363636 and parameters: {'C': 0.05909741496270693, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 634}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,275]\u001b[0m Trial 17 finished with value: 0.8636363636363636 and parameters: {'C': 0.05909782949408206, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 611}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,314]\u001b[0m Trial 18 finished with value: 0.8616600790513834 and parameters: {'C': 0.05953245981467457, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 460}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,355]\u001b[0m Trial 19 finished with value: 0.8616600790513834 and parameters: {'C': 0.04830236258863719, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 248}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,404]\u001b[0m Trial 20 finished with value: 0.8596837944664032 and parameters: {'C': 0.06628959410164054, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 678}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,446]\u001b[0m Trial 21 finished with value: 0.8636363636363636 and parameters: {'C': 0.05700908742113705, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 622}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,499]\u001b[0m Trial 22 finished with value: 0.8636363636363636 and parameters: {'C': 0.05656047716055376, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 623}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,546]\u001b[0m Trial 23 finished with value: 0.8616600790513834 and parameters: {'C': 0.06320678006102545, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 841}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,581]\u001b[0m Trial 24 finished with value: 0.8616600790513834 and parameters: {'C': 0.05157302869820576, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 429}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,631]\u001b[0m Trial 25 finished with value: 0.8596837944664032 and parameters: {'C': 0.06983993712954922, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 605}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,682]\u001b[0m Trial 26 finished with value: 0.8616600790513834 and parameters: {'C': 0.06116895491329644, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 547}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,720]\u001b[0m Trial 27 finished with value: 0.8557312252964426 and parameters: {'C': 0.04501655941833319, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 670}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,762]\u001b[0m Trial 28 finished with value: 0.8616600790513834 and parameters: {'C': 0.05380360215530175, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 881}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,810]\u001b[0m Trial 29 finished with value: 0.8557312252964426 and parameters: {'C': 0.07300244558210409, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 465}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,861]\u001b[0m Trial 30 finished with value: 0.857707509881423 and parameters: {'C': 0.07811063042909394, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 288}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,910]\u001b[0m Trial 31 finished with value: 0.8636363636363636 and parameters: {'C': 0.057564029478763316, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 637}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,954]\u001b[0m Trial 32 finished with value: 0.8616600790513834 and parameters: {'C': 0.053901423287986125, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 522}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,992]\u001b[0m Trial 33 finished with value: 0.8616600790513834 and parameters: {'C': 0.06301016156055417, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 508}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,030]\u001b[0m Trial 34 finished with value: 0.8596837944664032 and parameters: {'C': 0.0670352445660587, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 573}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,072]\u001b[0m Trial 35 finished with value: 0.8557312252964426 and parameters: {'C': 0.07600306213540742, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 736}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,116]\u001b[0m Trial 36 finished with value: 0.8616600790513834 and parameters: {'C': 0.0609482947484404, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 399}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,156]\u001b[0m Trial 37 finished with value: 0.8596837944664032 and parameters: {'C': 0.04471814766412548, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 590}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,195]\u001b[0m Trial 38 finished with value: 0.8537549407114624 and parameters: {'C': 0.05357015309371175, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 778}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,239]\u001b[0m Trial 39 finished with value: 0.8596837944664032 and parameters: {'C': 0.07069962486828466, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 543}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,334]\u001b[0m Trial 40 finished with value: 0.8557312252964426 and parameters: {'C': 0.06424951737346378, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 716}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,381]\u001b[0m Trial 41 finished with value: 0.8636363636363636 and parameters: {'C': 0.059120329147581537, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 633}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,422]\u001b[0m Trial 42 finished with value: 0.8636363636363636 and parameters: {'C': 0.05648859154715334, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 635}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,460]\u001b[0m Trial 43 finished with value: 0.8616600790513834 and parameters: {'C': 0.049779418766912956, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 485}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,507]\u001b[0m Trial 44 finished with value: 0.8636363636363636 and parameters: {'C': 0.056415753791393214, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 612}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,557]\u001b[0m Trial 45 finished with value: 0.8596837944664032 and parameters: {'C': 0.06713146885240931, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 564}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,720]\u001b[0m Trial 46 finished with value: 0.8596837944664032 and parameters: {'C': 0.042724927261083706, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 663}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,766]\u001b[0m Trial 47 finished with value: 0.8616600790513834 and parameters: {'C': 0.04842347453305687, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 804}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,811]\u001b[0m Trial 48 finished with value: 0.8537549407114624 and parameters: {'C': 0.03894975348864854, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 708}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,017]\u001b[0m Trial 49 finished with value: 0.8596837944664032 and parameters: {'C': 0.0590074332598247, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 503}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,057]\u001b[0m Trial 50 finished with value: 0.8616600790513834 and parameters: {'C': 0.052676148953571, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 350}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,101]\u001b[0m Trial 51 finished with value: 0.8636363636363636 and parameters: {'C': 0.05667115812863114, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 662}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,156]\u001b[0m Trial 52 finished with value: 0.8616600790513834 and parameters: {'C': 0.06345199782986052, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 620}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,193]\u001b[0m Trial 53 finished with value: 0.8616600790513834 and parameters: {'C': 0.0505863129124692, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 751}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,231]\u001b[0m Trial 54 finished with value: 0.8636363636363636 and parameters: {'C': 0.05875716260990708, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 538}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,275]\u001b[0m Trial 55 finished with value: 0.8636363636363636 and parameters: {'C': 0.05549344169205558, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 448}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,326]\u001b[0m Trial 56 finished with value: 0.8596837944664032 and parameters: {'C': 0.0663261297000495, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 648}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,383]\u001b[0m Trial 57 finished with value: 0.8616600790513834 and parameters: {'C': 0.061589905226694434, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 994}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,478]\u001b[0m Trial 58 finished with value: 0.8557312252964426 and parameters: {'C': 0.0470993842766634, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 591}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,525]\u001b[0m Trial 59 finished with value: 0.8636363636363636 and parameters: {'C': 0.05785954353456705, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 712}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,574]\u001b[0m Trial 60 finished with value: 0.8616600790513834 and parameters: {'C': 0.0532887915406989, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 410}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,627]\u001b[0m Trial 61 finished with value: 0.8616600790513834 and parameters: {'C': 0.05940366950075743, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 633}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,674]\u001b[0m Trial 62 finished with value: 0.8616600790513834 and parameters: {'C': 0.059753311435161875, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 686}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,739]\u001b[0m Trial 63 finished with value: 0.8616600790513834 and parameters: {'C': 0.06433652071713634, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 584}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,800]\u001b[0m Trial 64 finished with value: 0.8616600790513834 and parameters: {'C': 0.051066512589696376, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 613}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,846]\u001b[0m Trial 65 finished with value: 0.8636363636363636 and parameters: {'C': 0.05662395503355684, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 475}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,895]\u001b[0m Trial 66 finished with value: 0.8616600790513834 and parameters: {'C': 0.06166710946790731, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 567}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,948]\u001b[0m Trial 67 finished with value: 0.8616600790513834 and parameters: {'C': 0.05482933670915175, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 524}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,993]\u001b[0m Trial 68 finished with value: 0.8557312252964426 and parameters: {'C': 0.06850600842807479, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 643}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,053]\u001b[0m Trial 69 finished with value: 0.8596837944664032 and parameters: {'C': 0.07108667159267099, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 372}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,300]\u001b[0m Trial 70 finished with value: 0.8596837944664032 and parameters: {'C': 0.065571955581536, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 758}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,344]\u001b[0m Trial 71 finished with value: 0.8636363636363636 and parameters: {'C': 0.0563483275817598, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 643}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,392]\u001b[0m Trial 72 finished with value: 0.8616600790513834 and parameters: {'C': 0.06223470677964912, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 604}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,437]\u001b[0m Trial 73 finished with value: 0.8616600790513834 and parameters: {'C': 0.05283654206859812, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 102}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,494]\u001b[0m Trial 74 finished with value: 0.8636363636363636 and parameters: {'C': 0.05877689028573643, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 689}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,544]\u001b[0m Trial 75 finished with value: 0.8616600790513834 and parameters: {'C': 0.054926022671086164, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 563}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,591]\u001b[0m Trial 76 finished with value: 0.8616600790513834 and parameters: {'C': 0.060732137450273525, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 662}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,635]\u001b[0m Trial 77 finished with value: 0.8616600790513834 and parameters: {'C': 0.04942150016807421, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 727}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,680]\u001b[0m Trial 78 finished with value: 0.8616600790513834 and parameters: {'C': 0.06428413210178302, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 279}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,726]\u001b[0m Trial 79 finished with value: 0.8537549407114624 and parameters: {'C': 0.05731897448629699, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 633}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,772]\u001b[0m Trial 80 finished with value: 0.8616600790513834 and parameters: {'C': 0.05195692462407146, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 790}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,817]\u001b[0m Trial 81 finished with value: 0.8636363636363636 and parameters: {'C': 0.05567969222463778, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 609}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,860]\u001b[0m Trial 82 finished with value: 0.8636363636363636 and parameters: {'C': 0.05821560454490869, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 698}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,908]\u001b[0m Trial 83 finished with value: 0.8616600790513834 and parameters: {'C': 0.061091479302426865, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 547}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,959]\u001b[0m Trial 84 finished with value: 0.8616600790513834 and parameters: {'C': 0.05419522389078348, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 592}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:38,005]\u001b[0m Trial 85 finished with value: 0.8616600790513834 and parameters: {'C': 0.06319373859716235, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 623}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:38,177]\u001b[0m Trial 86 finished with value: 0.8596837944664032 and parameters: {'C': 0.047512048335398474, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 675}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:38,218]\u001b[0m Trial 87 finished with value: 0.8616600790513834 and parameters: {'C': 0.050866962556988124, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 519}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:38,261]\u001b[0m Trial 88 finished with value: 0.8596837944664032 and parameters: {'C': 0.06809937442602666, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 573}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:38,314]\u001b[0m Trial 89 finished with value: 0.8636363636363636 and parameters: {'C': 0.05737565461068901, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 494}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:38,358]\u001b[0m Trial 90 finished with value: 0.8596837944664032 and parameters: {'C': 0.0655125793356484, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 652}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:38,404]\u001b[0m Trial 91 finished with value: 0.8636363636363636 and parameters: {'C': 0.05643774879582355, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 678}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:38,453]\u001b[0m Trial 92 finished with value: 0.8616600790513834 and parameters: {'C': 0.05988862293052031, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 626}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:38,501]\u001b[0m Trial 93 finished with value: 0.8616600790513834 and parameters: {'C': 0.05294996774956759, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 599}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:38,555]\u001b[0m Trial 94 finished with value: 0.8636363636363636 and parameters: {'C': 0.05501538496634102, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 658}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:38,607]\u001b[0m Trial 95 finished with value: 0.8636363636363636 and parameters: {'C': 0.05783250309769649, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 703}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:38,674]\u001b[0m Trial 96 finished with value: 0.8557312252964426 and parameters: {'C': 0.06234971992648308, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 729}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:38,744]\u001b[0m Trial 97 finished with value: 0.8616600790513834 and parameters: {'C': 0.06039678449749958, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 440}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:38,970]\u001b[0m Trial 98 finished with value: 0.8596837944664032 and parameters: {'C': 0.052031240101354265, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 553}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:39,021]\u001b[0m Trial 99 finished with value: 0.8636363636363636 and parameters: {'C': 0.05636027470366541, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 585}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:39,032]\u001b[0m A new study created in memory with name: no-name-ac209f18-8a93-42f6-a994-2e4e315bde4a\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "Optimizing selected_features_all_best20 SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:32:39,517]\u001b[0m Trial 0 finished with value: 0.5177865612648221 and parameters: {'svc_c': 10.7533945146195, 'svc_gamma': 73.75896312119299}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:39,983]\u001b[0m Trial 1 finished with value: 0.5177865612648221 and parameters: {'svc_c': 13.280062430077226, 'svc_gamma': 79.73462726837084}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:40,413]\u001b[0m Trial 2 finished with value: 0.5177865612648221 and parameters: {'svc_c': 88.65711768594213, 'svc_gamma': 70.64852112597094}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:40,929]\u001b[0m Trial 3 finished with value: 0.5177865612648221 and parameters: {'svc_c': 18.089833877835254, 'svc_gamma': 67.08274284473659}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:41,457]\u001b[0m Trial 4 finished with value: 0.5177865612648221 and parameters: {'svc_c': 86.76762802466011, 'svc_gamma': 86.261841557179}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:42,000]\u001b[0m Trial 5 finished with value: 0.5177865612648221 and parameters: {'svc_c': 45.0111788401077, 'svc_gamma': 76.43167762851253}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:42,429]\u001b[0m Trial 6 finished with value: 0.5197628458498024 and parameters: {'svc_c': 94.03484798817581, 'svc_gamma': 10.646903345225624}. Best is trial 6 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:42,838]\u001b[0m Trial 7 finished with value: 0.5177865612648221 and parameters: {'svc_c': 93.73765019017729, 'svc_gamma': 66.87758981210082}. Best is trial 6 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:43,452]\u001b[0m Trial 8 finished with value: 0.5177865612648221 and parameters: {'svc_c': 16.776081739552335, 'svc_gamma': 40.054696861872394}. Best is trial 6 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:43,961]\u001b[0m Trial 9 finished with value: 0.5177865612648221 and parameters: {'svc_c': 66.4061807406478, 'svc_gamma': 46.22185414175125}. Best is trial 6 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:44,525]\u001b[0m Trial 10 finished with value: 0.6877470355731226 and parameters: {'svc_c': 70.14142241951059, 'svc_gamma': 2.5841367782986424}. Best is trial 10 with value: 0.6877470355731226.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:44,885]\u001b[0m Trial 11 finished with value: 0.5928853754940712 and parameters: {'svc_c': 69.16368691756455, 'svc_gamma': 3.7843237063995527}. Best is trial 10 with value: 0.6877470355731226.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:45,303]\u001b[0m Trial 12 finished with value: 0.7786561264822134 and parameters: {'svc_c': 66.51417984992877, 'svc_gamma': 1.3825927313893445}. Best is trial 12 with value: 0.7786561264822134.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:45,894]\u001b[0m Trial 13 finished with value: 0.5177865612648221 and parameters: {'svc_c': 48.73317223378904, 'svc_gamma': 19.263257922469663}. Best is trial 12 with value: 0.7786561264822134.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:46,415]\u001b[0m Trial 14 finished with value: 0.5177865612648221 and parameters: {'svc_c': 68.0864725917972, 'svc_gamma': 23.596225845879882}. Best is trial 12 with value: 0.7786561264822134.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:46,789]\u001b[0m Trial 15 finished with value: 0.7154150197628458 and parameters: {'svc_c': 59.8463176149895, 'svc_gamma': 2.249974916929832}. Best is trial 12 with value: 0.7786561264822134.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:47,041]\u001b[0m Trial 16 finished with value: 0.8181818181818182 and parameters: {'svc_c': 37.07489737871984, 'svc_gamma': 0.15944008985926517}. Best is trial 16 with value: 0.8181818181818182.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:47,497]\u001b[0m Trial 17 finished with value: 0.5177865612648221 and parameters: {'svc_c': 34.01942409690148, 'svc_gamma': 29.33101475359978}. Best is trial 16 with value: 0.8181818181818182.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:48,022]\u001b[0m Trial 18 finished with value: 0.5197628458498024 and parameters: {'svc_c': 33.56648011867069, 'svc_gamma': 18.336076106883407}. Best is trial 16 with value: 0.8181818181818182.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:48,470]\u001b[0m Trial 19 finished with value: 0.5177865612648221 and parameters: {'svc_c': 37.718549468181365, 'svc_gamma': 34.4861166046813}. Best is trial 16 with value: 0.8181818181818182.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 11:32:48,950]\u001b[0m Trial 20 finished with value: 0.5158102766798419 and parameters: {'svc_c': 0.40170932567681916, 'svc_gamma': 14.796108462597267}. Best is trial 16 with value: 0.8181818181818182.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:49,390]\u001b[0m Trial 21 finished with value: 0.7569169960474308 and parameters: {'svc_c': 57.34739705424128, 'svc_gamma': 1.664686918095824}. Best is trial 16 with value: 0.8181818181818182.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:49,794]\u001b[0m Trial 22 finished with value: 0.5197628458498024 and parameters: {'svc_c': 53.16229073351222, 'svc_gamma': 10.160821830026793}. Best is trial 16 with value: 0.8181818181818182.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:50,121]\u001b[0m Trial 23 finished with value: 0.8023715415019763 and parameters: {'svc_c': 77.99642194333231, 'svc_gamma': 1.0192954158328704}. Best is trial 16 with value: 0.8181818181818182.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:50,617]\u001b[0m Trial 24 finished with value: 0.5177865612648221 and parameters: {'svc_c': 78.24236363330536, 'svc_gamma': 25.95015641254531}. Best is trial 16 with value: 0.8181818181818182.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:50,967]\u001b[0m Trial 25 finished with value: 0.5197628458498024 and parameters: {'svc_c': 83.75031476936752, 'svc_gamma': 9.911331149526994}. Best is trial 16 with value: 0.8181818181818182.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:51,553]\u001b[0m Trial 26 finished with value: 0.5197628458498024 and parameters: {'svc_c': 79.69023725884426, 'svc_gamma': 15.98596604673967}. Best is trial 16 with value: 0.8181818181818182.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:51,953]\u001b[0m Trial 27 finished with value: 0.5276679841897233 and parameters: {'svc_c': 75.90133889263825, 'svc_gamma': 7.8450475691114345}. Best is trial 16 with value: 0.8181818181818182.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:52,213]\u001b[0m Trial 28 finished with value: 0.8241106719367589 and parameters: {'svc_c': 97.89965014124971, 'svc_gamma': 0.08045326609782855}. Best is trial 28 with value: 0.8241106719367589.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:52,639]\u001b[0m Trial 29 finished with value: 0.5177865612648221 and parameters: {'svc_c': 95.45814207166197, 'svc_gamma': 22.5606170868493}. Best is trial 28 with value: 0.8241106719367589.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:53,066]\u001b[0m Trial 30 finished with value: 0.5197628458498024 and parameters: {'svc_c': 88.96076131473404, 'svc_gamma': 13.924463210000388}. Best is trial 28 with value: 0.8241106719367589.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:53,465]\u001b[0m Trial 31 finished with value: 0.5355731225296443 and parameters: {'svc_c': 75.57050081122048, 'svc_gamma': 6.607584786690114}. Best is trial 28 with value: 0.8241106719367589.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:53,837]\u001b[0m Trial 32 finished with value: 0.8102766798418972 and parameters: {'svc_c': 99.92198145182225, 'svc_gamma': 0.7821446225772153}. Best is trial 28 with value: 0.8241106719367589.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:54,184]\u001b[0m Trial 33 finished with value: 0.8280632411067194 and parameters: {'svc_c': 98.69873448040302, 'svc_gamma': 0.4643593113155191}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:54,570]\u001b[0m Trial 34 finished with value: 0.525691699604743 and parameters: {'svc_c': 99.04149325979189, 'svc_gamma': 8.82532568394795}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:54,944]\u001b[0m Trial 35 finished with value: 0.5197628458498024 and parameters: {'svc_c': 89.7355711856678, 'svc_gamma': 13.54210573218669}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:55,309]\u001b[0m Trial 36 finished with value: 0.5355731225296443 and parameters: {'svc_c': 95.67177782938037, 'svc_gamma': 6.727379117242995}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:55,763]\u001b[0m Trial 37 finished with value: 0.5177865612648221 and parameters: {'svc_c': 98.65020793539023, 'svc_gamma': 19.474118615372397}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:56,200]\u001b[0m Trial 38 finished with value: 0.5197628458498024 and parameters: {'svc_c': 99.93687696187162, 'svc_gamma': 13.129946711367358}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:56,496]\u001b[0m Trial 39 finished with value: 0.8181818181818182 and parameters: {'svc_c': 84.7928760855722, 'svc_gamma': 0.12183800881659967}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:56,884]\u001b[0m Trial 40 finished with value: 0.5355731225296443 and parameters: {'svc_c': 85.97370797152502, 'svc_gamma': 6.131646295869807}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:57,207]\u001b[0m Trial 41 finished with value: 0.8280632411067194 and parameters: {'svc_c': 91.77681043257584, 'svc_gamma': 0.4788014321308523}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:57,511]\u001b[0m Trial 42 finished with value: 0.8162055335968379 and parameters: {'svc_c': 90.73680131429393, 'svc_gamma': 0.11202916566958396}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:57,923]\u001b[0m Trial 43 finished with value: 0.5355731225296443 and parameters: {'svc_c': 93.05727110447582, 'svc_gamma': 6.164337021419281}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:58,326]\u001b[0m Trial 44 finished with value: 0.5197628458498024 and parameters: {'svc_c': 85.14660518655492, 'svc_gamma': 10.23032804228235}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:58,757]\u001b[0m Trial 45 finished with value: 0.541501976284585 and parameters: {'svc_c': 91.4504679351348, 'svc_gamma': 5.56659427138406}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:59,213]\u001b[0m Trial 46 finished with value: 0.5197628458498024 and parameters: {'svc_c': 82.81087128768797, 'svc_gamma': 12.821159127570136}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:59,708]\u001b[0m Trial 47 finished with value: 0.5177865612648221 and parameters: {'svc_c': 87.34600935308919, 'svc_gamma': 50.98253587305013}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:00,060]\u001b[0m Trial 48 finished with value: 0.5592885375494071 and parameters: {'svc_c': 94.33411769755047, 'svc_gamma': 4.710795974128629}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:00,500]\u001b[0m Trial 49 finished with value: 0.5197628458498024 and parameters: {'svc_c': 81.85683352824181, 'svc_gamma': 16.77037313596435}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:00,873]\u001b[0m Trial 50 finished with value: 0.5691699604743083 and parameters: {'svc_c': 88.19076376550295, 'svc_gamma': 4.277209973303253}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:01,340]\u001b[0m Trial 51 finished with value: 0.5197628458498024 and parameters: {'svc_c': 91.72545217495508, 'svc_gamma': 9.88448942785941}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:01,695]\u001b[0m Trial 52 finished with value: 0.8221343873517787 and parameters: {'svc_c': 90.68835778706655, 'svc_gamma': 0.12809606599435977}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:02,062]\u001b[0m Trial 53 finished with value: 0.8201581027667985 and parameters: {'svc_c': 96.45161575704608, 'svc_gamma': 0.674088794229222}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:02,382]\u001b[0m Trial 54 finished with value: 0.5810276679841897 and parameters: {'svc_c': 96.02895318238393, 'svc_gamma': 4.108095971387438}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:02,750]\u001b[0m Trial 55 finished with value: 0.8221343873517787 and parameters: {'svc_c': 96.30150614209674, 'svc_gamma': 0.6144119479848883}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:03,135]\u001b[0m Trial 56 finished with value: 0.5197628458498024 and parameters: {'svc_c': 95.60836123451662, 'svc_gamma': 10.064339239515501}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:03,532]\u001b[0m Trial 57 finished with value: 0.5849802371541502 and parameters: {'svc_c': 91.16997747996747, 'svc_gamma': 4.01038021343521}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:03,965]\u001b[0m Trial 58 finished with value: 0.5177865612648221 and parameters: {'svc_c': 97.25596255814766, 'svc_gamma': 20.503938493325872}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:04,520]\u001b[0m Trial 59 finished with value: 0.5197628458498024 and parameters: {'svc_c': 92.69882161965323, 'svc_gamma': 17.523151340283334}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:04,843]\u001b[0m Trial 60 finished with value: 0.6185770750988142 and parameters: {'svc_c': 87.9994262611391, 'svc_gamma': 3.363929557438099}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:05,128]\u001b[0m Trial 61 finished with value: 0.83399209486166 and parameters: {'svc_c': 95.94113392322917, 'svc_gamma': 0.23308824330559652}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:05,444]\u001b[0m Trial 62 finished with value: 0.8162055335968379 and parameters: {'svc_c': 96.78479916822002, 'svc_gamma': 0.3216122718296851}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:05,822]\u001b[0m Trial 63 finished with value: 0.5276679841897233 and parameters: {'svc_c': 94.66737245833846, 'svc_gamma': 7.7145749426867285}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:06,221]\u001b[0m Trial 64 finished with value: 0.5197628458498024 and parameters: {'svc_c': 92.38059216091821, 'svc_gamma': 11.50644558414048}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:06,548]\u001b[0m Trial 65 finished with value: 0.6185770750988142 and parameters: {'svc_c': 98.46855413744521, 'svc_gamma': 3.3536225560758575}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:06,952]\u001b[0m Trial 66 finished with value: 0.5276679841897233 and parameters: {'svc_c': 89.34562793337453, 'svc_gamma': 8.05716114831784}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:07,357]\u001b[0m Trial 67 finished with value: 0.5197628458498024 and parameters: {'svc_c': 99.96388552998269, 'svc_gamma': 14.483651916687343}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:07,673]\u001b[0m Trial 68 finished with value: 0.6897233201581028 and parameters: {'svc_c': 81.67500128235184, 'svc_gamma': 2.5520193585105884}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:08,046]\u001b[0m Trial 69 finished with value: 0.5355731225296443 and parameters: {'svc_c': 87.32219711877846, 'svc_gamma': 6.75239932015311}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:08,337]\u001b[0m Trial 70 finished with value: 0.8181818181818182 and parameters: {'svc_c': 93.9828253656245, 'svc_gamma': 0.3081195943750008}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:08,720]\u001b[0m Trial 71 finished with value: 0.5988142292490118 and parameters: {'svc_c': 95.76924262365897, 'svc_gamma': 3.6990970758586683}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:09,109]\u001b[0m Trial 72 finished with value: 0.5197628458498024 and parameters: {'svc_c': 97.13892567311967, 'svc_gamma': 11.756908377542382}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:09,521]\u001b[0m Trial 73 finished with value: 0.6818181818181818 and parameters: {'svc_c': 90.24760600490184, 'svc_gamma': 2.65450088552239}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:09,910]\u001b[0m Trial 74 finished with value: 0.5276679841897233 and parameters: {'svc_c': 85.36637347073923, 'svc_gamma': 7.699248057675818}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:10,226]\u001b[0m Trial 75 finished with value: 0.83399209486166 and parameters: {'svc_c': 92.89666907314263, 'svc_gamma': 0.23085825484084396}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:10,592]\u001b[0m Trial 76 finished with value: 0.5434782608695652 and parameters: {'svc_c': 93.24100362145701, 'svc_gamma': 5.322857621318447}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:10,940]\u001b[0m Trial 77 finished with value: 0.8221343873517787 and parameters: {'svc_c': 99.86737439717268, 'svc_gamma': 0.26632861929353957}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:11,298]\u001b[0m Trial 78 finished with value: 0.525691699604743 and parameters: {'svc_c': 99.11130281353404, 'svc_gamma': 8.337090409729594}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:11,799]\u001b[0m Trial 79 finished with value: 0.5197628458498024 and parameters: {'svc_c': 88.8347907286161, 'svc_gamma': 15.77133734486739}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:12,173]\u001b[0m Trial 80 finished with value: 0.5197628458498024 and parameters: {'svc_c': 99.98593159486062, 'svc_gamma': 11.357348990468681}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:12,446]\u001b[0m Trial 81 finished with value: 0.8241106719367589 and parameters: {'svc_c': 97.04722184799567, 'svc_gamma': 0.15347001297696627}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:12,802]\u001b[0m Trial 82 finished with value: 0.691699604743083 and parameters: {'svc_c': 93.39824999059394, 'svc_gamma': 2.5155010768215544}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:13,146]\u001b[0m Trial 83 finished with value: 0.8260869565217391 and parameters: {'svc_c': 97.45415674467023, 'svc_gamma': 0.08510194647479126}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:13,497]\u001b[0m Trial 84 finished with value: 0.541501976284585 and parameters: {'svc_c': 90.62213251219914, 'svc_gamma': 5.557487700381568}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:13,823]\u001b[0m Trial 85 finished with value: 0.6877470355731226 and parameters: {'svc_c': 86.49992232705637, 'svc_gamma': 2.59048944880009}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:14,179]\u001b[0m Trial 86 finished with value: 0.5355731225296443 and parameters: {'svc_c': 97.14760724768588, 'svc_gamma': 5.7835805707036005}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:14,538]\u001b[0m Trial 87 finished with value: 0.5276679841897233 and parameters: {'svc_c': 94.21960826085106, 'svc_gamma': 7.801374138105444}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:14,785]\u001b[0m Trial 88 finished with value: 0.8201581027667985 and parameters: {'svc_c': 84.24270038225359, 'svc_gamma': 0.13707962404309176}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:15,147]\u001b[0m Trial 89 finished with value: 0.5197628458498024 and parameters: {'svc_c': 90.84833948108498, 'svc_gamma': 10.050539756162127}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:15,557]\u001b[0m Trial 90 finished with value: 0.66600790513834 and parameters: {'svc_c': 97.3342981668992, 'svc_gamma': 2.804740467826482}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:15,863]\u001b[0m Trial 91 finished with value: 0.7351778656126482 and parameters: {'svc_c': 95.38863518576392, 'svc_gamma': 1.962202207381119}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:16,104]\u001b[0m Trial 92 finished with value: 0.8221343873517787 and parameters: {'svc_c': 98.37431520248686, 'svc_gamma': 0.07321286626343651}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:16,467]\u001b[0m Trial 93 finished with value: 0.5454545454545454 and parameters: {'svc_c': 92.62809110555759, 'svc_gamma': 5.209637227282405}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:16,829]\u001b[0m Trial 94 finished with value: 0.525691699604743 and parameters: {'svc_c': 94.35313148052809, 'svc_gamma': 8.80714114366759}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:17,189]\u001b[0m Trial 95 finished with value: 0.5474308300395256 and parameters: {'svc_c': 89.44031434406187, 'svc_gamma': 5.155424679466674}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:17,503]\u001b[0m Trial 96 finished with value: 0.7371541501976284 and parameters: {'svc_c': 99.96491768683912, 'svc_gamma': 1.8508059313742953}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:17,860]\u001b[0m Trial 97 finished with value: 0.5197628458498024 and parameters: {'svc_c': 97.32360899780586, 'svc_gamma': 13.209326426429326}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:18,167]\u001b[0m Trial 98 finished with value: 0.5830039525691699 and parameters: {'svc_c': 92.22289218667083, 'svc_gamma': 4.017876880603733}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:18,581]\u001b[0m Trial 99 finished with value: 0.5276679841897233 and parameters: {'svc_c': 86.71775497587264, 'svc_gamma': 7.673433538008205}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:18,589]\u001b[0m A new study created in memory with name: no-name-4ae08fcf-ddf1-483c-9f1b-c951d687d314\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "Optimizing selected_features_all_best20 XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:33:19,624]\u001b[0m Trial 0 finished with value: 0.8656126482213439 and parameters: {'learning_rate': 0.07874189857592591, 'max_depth': 6, 'n_estimators': 154}. Best is trial 0 with value: 0.8656126482213439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:20,400]\u001b[0m Trial 1 finished with value: 0.8596837944664032 and parameters: {'learning_rate': 0.1705788115114957, 'max_depth': 3, 'n_estimators': 484}. Best is trial 0 with value: 0.8656126482213439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:20,881]\u001b[0m Trial 2 finished with value: 0.8557312252964426 and parameters: {'learning_rate': 0.07877682785006325, 'max_depth': 2, 'n_estimators': 451}. Best is trial 0 with value: 0.8656126482213439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:21,344]\u001b[0m Trial 3 finished with value: 0.8537549407114624 and parameters: {'learning_rate': 0.14347569237428598, 'max_depth': 4, 'n_estimators': 268}. Best is trial 0 with value: 0.8656126482213439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:22,881]\u001b[0m Trial 4 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.05161809525480359, 'max_depth': 6, 'n_estimators': 585}. Best is trial 4 with value: 0.8715415019762845.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:23,242]\u001b[0m Trial 5 finished with value: 0.8616600790513834 and parameters: {'learning_rate': 0.013162697927781046, 'max_depth': 5, 'n_estimators': 118}. Best is trial 4 with value: 0.8715415019762845.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:23,477]\u001b[0m Trial 6 finished with value: 0.8636363636363636 and parameters: {'learning_rate': 0.08295048218460643, 'max_depth': 2, 'n_estimators': 182}. Best is trial 4 with value: 0.8715415019762845.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:24,179]\u001b[0m Trial 7 finished with value: 0.8596837944664032 and parameters: {'learning_rate': 0.14642728790901208, 'max_depth': 3, 'n_estimators': 397}. Best is trial 4 with value: 0.8715415019762845.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:26,269]\u001b[0m Trial 8 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.2617326999844464, 'max_depth': 6, 'n_estimators': 965}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:29,311]\u001b[0m Trial 9 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.025277742178529496, 'max_depth': 5, 'n_estimators': 794}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:31,144]\u001b[0m Trial 10 finished with value: 0.8636363636363636 and parameters: {'learning_rate': 0.2980374976006557, 'max_depth': 5, 'n_estimators': 1000}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:33,167]\u001b[0m Trial 11 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.2603462316372846, 'max_depth': 5, 'n_estimators': 958}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:34,860]\u001b[0m Trial 12 finished with value: 0.8675889328063241 and parameters: {'learning_rate': 0.21032268256858289, 'max_depth': 6, 'n_estimators': 770}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:37,039]\u001b[0m Trial 13 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.2244137696294578, 'max_depth': 5, 'n_estimators': 825}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:39,084]\u001b[0m Trial 14 finished with value: 0.8636363636363636 and parameters: {'learning_rate': 0.010212228899937434, 'max_depth': 4, 'n_estimators': 705}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:41,538]\u001b[0m Trial 15 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.11067463668384378, 'max_depth': 6, 'n_estimators': 879}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:42,978]\u001b[0m Trial 16 finished with value: 0.8636363636363636 and parameters: {'learning_rate': 0.18735981315298436, 'max_depth': 5, 'n_estimators': 657}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:45,099]\u001b[0m Trial 17 finished with value: 0.8656126482213439 and parameters: {'learning_rate': 0.1273270174768016, 'max_depth': 6, 'n_estimators': 885}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:47,013]\u001b[0m Trial 18 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.17656097791808784, 'max_depth': 4, 'n_estimators': 756}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:48,568]\u001b[0m Trial 19 finished with value: 0.8675889328063241 and parameters: {'learning_rate': 0.25695150372928693, 'max_depth': 5, 'n_estimators': 601}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:50,115]\u001b[0m Trial 20 finished with value: 0.8636363636363636 and parameters: {'learning_rate': 0.1254420815492506, 'max_depth': 3, 'n_estimators': 916}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:52,485]\u001b[0m Trial 21 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.25547410884348415, 'max_depth': 5, 'n_estimators': 997}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:54,205]\u001b[0m Trial 22 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.2153314593196333, 'max_depth': 5, 'n_estimators': 827}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:56,199]\u001b[0m Trial 23 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.29249740921169115, 'max_depth': 6, 'n_estimators': 999}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:58,279]\u001b[0m Trial 24 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.28421135863099634, 'max_depth': 6, 'n_estimators': 998}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:00,544]\u001b[0m Trial 25 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.26429909843093646, 'max_depth': 6, 'n_estimators': 922}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:02,445]\u001b[0m Trial 26 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.2417674411104334, 'max_depth': 6, 'n_estimators': 858}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:04,395]\u001b[0m Trial 27 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.2974508497247197, 'max_depth': 6, 'n_estimators': 957}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:06,734]\u001b[0m Trial 28 finished with value: 0.8656126482213439 and parameters: {'learning_rate': 0.23734514358278647, 'max_depth': 5, 'n_estimators': 689}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:08,543]\u001b[0m Trial 29 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.279636757923362, 'max_depth': 4, 'n_estimators': 936}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:10,324]\u001b[0m Trial 30 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.27592430251570627, 'max_depth': 6, 'n_estimators': 733}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:12,287]\u001b[0m Trial 31 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.27644292952919736, 'max_depth': 6, 'n_estimators': 733}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:14,463]\u001b[0m Trial 32 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.24565944294167458, 'max_depth': 6, 'n_estimators': 993}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:16,342]\u001b[0m Trial 33 finished with value: 0.8675889328063241 and parameters: {'learning_rate': 0.2733695450368448, 'max_depth': 6, 'n_estimators': 865}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:18,176]\u001b[0m Trial 34 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.2993867863611667, 'max_depth': 6, 'n_estimators': 523}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:19,374]\u001b[0m Trial 35 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.26004438273438757, 'max_depth': 5, 'n_estimators': 425}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:21,068]\u001b[0m Trial 36 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.23328706034672236, 'max_depth': 6, 'n_estimators': 624}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:21,977]\u001b[0m Trial 37 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.25113938086699555, 'max_depth': 6, 'n_estimators': 303}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:22,767]\u001b[0m Trial 38 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.20347044987622895, 'max_depth': 4, 'n_estimators': 330}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:23,410]\u001b[0m Trial 39 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.2275917381491373, 'max_depth': 5, 'n_estimators': 202}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:23,860]\u001b[0m Trial 40 finished with value: 0.849802371541502 and parameters: {'learning_rate': 0.24746608869035874, 'max_depth': 2, 'n_estimators': 342}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:24,486]\u001b[0m Trial 41 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.283746337027493, 'max_depth': 6, 'n_estimators': 223}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:25,255]\u001b[0m Trial 42 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.25402771852509903, 'max_depth': 6, 'n_estimators': 274}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:25,637]\u001b[0m Trial 43 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.2907521184563967, 'max_depth': 6, 'n_estimators': 104}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:26,345]\u001b[0m Trial 44 finished with value: 0.8656126482213439 and parameters: {'learning_rate': 0.2691802327567147, 'max_depth': 6, 'n_estimators': 255}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:27,483]\u001b[0m Trial 45 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.2849439434503215, 'max_depth': 5, 'n_estimators': 482}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:28,377]\u001b[0m Trial 46 finished with value: 0.8616600790513834 and parameters: {'learning_rate': 0.26349920216857203, 'max_depth': 6, 'n_estimators': 146}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:29,017]\u001b[0m Trial 47 finished with value: 0.8656126482213439 and parameters: {'learning_rate': 0.24953383425626025, 'max_depth': 5, 'n_estimators': 224}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:29,920]\u001b[0m Trial 48 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.28937230766416355, 'max_depth': 6, 'n_estimators': 322}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:30,464]\u001b[0m Trial 49 finished with value: 0.8596837944664032 and parameters: {'learning_rate': 0.2678695277282534, 'max_depth': 5, 'n_estimators': 158}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:31,578]\u001b[0m Trial 50 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.22509475841819404, 'max_depth': 6, 'n_estimators': 368}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:33,821]\u001b[0m Trial 51 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.27611698841673643, 'max_depth': 6, 'n_estimators': 965}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:35,624]\u001b[0m Trial 52 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.2864574636954692, 'max_depth': 6, 'n_estimators': 565}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:37,125]\u001b[0m Trial 53 finished with value: 0.8636363636363636 and parameters: {'learning_rate': 0.2881079183458681, 'max_depth': 6, 'n_estimators': 551}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:37,857]\u001b[0m Trial 54 finished with value: 0.8616600790513834 and parameters: {'learning_rate': 0.29843033374905076, 'max_depth': 5, 'n_estimators': 262}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:39,810]\u001b[0m Trial 55 finished with value: 0.8675889328063241 and parameters: {'learning_rate': 0.25500388200099694, 'max_depth': 6, 'n_estimators': 816}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:42,176]\u001b[0m Trial 56 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.23701446978109836, 'max_depth': 6, 'n_estimators': 895}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:43,011]\u001b[0m Trial 57 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.26513891556880287, 'max_depth': 6, 'n_estimators': 301}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:43,987]\u001b[0m Trial 58 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.28522614465555995, 'max_depth': 5, 'n_estimators': 407}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:45,516]\u001b[0m Trial 59 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.25855416451868046, 'max_depth': 3, 'n_estimators': 954}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:47,473]\u001b[0m Trial 60 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.24789833102121456, 'max_depth': 6, 'n_estimators': 906}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:49,828]\u001b[0m Trial 61 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.24742414623196107, 'max_depth': 6, 'n_estimators': 906}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:51,971]\u001b[0m Trial 62 finished with value: 0.8596837944664032 and parameters: {'learning_rate': 0.2721089104882582, 'max_depth': 6, 'n_estimators': 970}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:53,876]\u001b[0m Trial 63 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.278464324831182, 'max_depth': 6, 'n_estimators': 927}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:56,455]\u001b[0m Trial 64 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.21635813539103937, 'max_depth': 6, 'n_estimators': 986}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:58,356]\u001b[0m Trial 65 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.2418813994401231, 'max_depth': 6, 'n_estimators': 846}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:00,171]\u001b[0m Trial 66 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.29163177673120777, 'max_depth': 4, 'n_estimators': 945}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:02,348]\u001b[0m Trial 67 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.2530441854025399, 'max_depth': 6, 'n_estimators': 786}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:03,951]\u001b[0m Trial 68 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.2532537947329484, 'max_depth': 5, 'n_estimators': 776}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:05,493]\u001b[0m Trial 69 finished with value: 0.8675889328063241 and parameters: {'learning_rate': 0.2362924479319226, 'max_depth': 6, 'n_estimators': 636}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:06,673]\u001b[0m Trial 70 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.26251676266459134, 'max_depth': 6, 'n_estimators': 467}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:08,430]\u001b[0m Trial 71 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.2802979597722225, 'max_depth': 6, 'n_estimators': 520}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:09,745]\u001b[0m Trial 72 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.2796125977020901, 'max_depth': 6, 'n_estimators': 517}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:11,809]\u001b[0m Trial 73 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.26975267508751966, 'max_depth': 6, 'n_estimators': 676}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:13,297]\u001b[0m Trial 74 finished with value: 0.8636363636363636 and parameters: {'learning_rate': 0.2543393607567899, 'max_depth': 6, 'n_estimators': 577}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:15,249]\u001b[0m Trial 75 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.24415215820600253, 'max_depth': 6, 'n_estimators': 799}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:16,241]\u001b[0m Trial 76 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.2818405125664437, 'max_depth': 5, 'n_estimators': 375}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:16,944]\u001b[0m Trial 77 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.261147250137779, 'max_depth': 6, 'n_estimators': 213}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:18,918]\u001b[0m Trial 78 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.271851720208209, 'max_depth': 6, 'n_estimators': 713}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:20,159]\u001b[0m Trial 79 finished with value: 0.8656126482213439 and parameters: {'learning_rate': 0.23198244556335407, 'max_depth': 5, 'n_estimators': 433}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:22,173]\u001b[0m Trial 80 finished with value: 0.8636363636363636 and parameters: {'learning_rate': 0.29878266039717405, 'max_depth': 6, 'n_estimators': 884}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:24,600]\u001b[0m Trial 81 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.28193586941527515, 'max_depth': 6, 'n_estimators': 917}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:27,004]\u001b[0m Trial 82 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.28952431410518936, 'max_depth': 6, 'n_estimators': 992}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:29,109]\u001b[0m Trial 83 finished with value: 0.8675889328063241 and parameters: {'learning_rate': 0.26763037908072423, 'max_depth': 6, 'n_estimators': 848}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:31,550]\u001b[0m Trial 84 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.2928252307486335, 'max_depth': 6, 'n_estimators': 965}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:33,059]\u001b[0m Trial 85 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.25124021856451617, 'max_depth': 6, 'n_estimators': 512}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:34,667]\u001b[0m Trial 86 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.25061694235663196, 'max_depth': 6, 'n_estimators': 609}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:35,376]\u001b[0m Trial 87 finished with value: 0.857707509881423 and parameters: {'learning_rate': 0.2419677797064207, 'max_depth': 2, 'n_estimators': 530}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:37,299]\u001b[0m Trial 88 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.256425770525542, 'max_depth': 6, 'n_estimators': 569}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:38,399]\u001b[0m Trial 89 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.26328306422697295, 'max_depth': 4, 'n_estimators': 500}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:39,011]\u001b[0m Trial 90 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.2721033000899167, 'max_depth': 6, 'n_estimators': 175}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:40,260]\u001b[0m Trial 91 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.27925593040688024, 'max_depth': 6, 'n_estimators': 458}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:42,839]\u001b[0m Trial 92 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.28431764236068297, 'max_depth': 6, 'n_estimators': 940}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:45,149]\u001b[0m Trial 93 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.24851721384374387, 'max_depth': 6, 'n_estimators': 1000}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:46,530]\u001b[0m Trial 94 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.2944304873360692, 'max_depth': 6, 'n_estimators': 551}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:49,003]\u001b[0m Trial 95 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.27344717350005954, 'max_depth': 6, 'n_estimators': 900}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:49,669]\u001b[0m Trial 96 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.25878831186680146, 'max_depth': 5, 'n_estimators': 230}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:50,332]\u001b[0m Trial 97 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.25815752205395237, 'max_depth': 4, 'n_estimators': 281}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:51,082]\u001b[0m Trial 98 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.2284895698380962, 'max_depth': 5, 'n_estimators': 245}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:51,910]\u001b[0m Trial 99 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.23996016096811634, 'max_depth': 5, 'n_estimators': 294}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:51,924]\u001b[0m A new study created in memory with name: no-name-07143fb0-2c41-4081-a2dd-ac0fba87b50d\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "Optimizing selected_features_all_best20 LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:35:53,434]\u001b[0m Trial 0 finished with value: 0.8754940711462451 and parameters: {'num_leaves': 103, 'max_depth': 11, 'learning_rate': 0.03276897858896604, 'n_estimators': 488}. Best is trial 0 with value: 0.8754940711462451.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:54,516]\u001b[0m Trial 1 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 139, 'max_depth': 18, 'learning_rate': 0.20546953893784983, 'n_estimators': 633}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:55,226]\u001b[0m Trial 2 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 45, 'max_depth': 10, 'learning_rate': 0.060968532596519846, 'n_estimators': 334}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:56,912]\u001b[0m Trial 3 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 211, 'max_depth': 48, 'learning_rate': 0.046618425613169104, 'n_estimators': 312}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:59,155]\u001b[0m Trial 4 finished with value: 0.8656126482213439 and parameters: {'num_leaves': 236, 'max_depth': 43, 'learning_rate': 0.13229915296175454, 'n_estimators': 1993}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:02,288]\u001b[0m Trial 5 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 210, 'max_depth': 19, 'learning_rate': 0.0486461978936011, 'n_estimators': 1554}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:03,646]\u001b[0m Trial 6 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 38, 'max_depth': 23, 'learning_rate': 0.14784622249836266, 'n_estimators': 1297}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:03,835]\u001b[0m Trial 7 finished with value: 0.857707509881423 and parameters: {'num_leaves': 5, 'max_depth': 15, 'learning_rate': 0.12351697313538491, 'n_estimators': 312}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:05,355]\u001b[0m Trial 8 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 238, 'max_depth': 50, 'learning_rate': 0.16512210404267277, 'n_estimators': 996}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:07,914]\u001b[0m Trial 9 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 109, 'max_depth': 49, 'learning_rate': 0.06859561999845833, 'n_estimators': 1968}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:08,784]\u001b[0m Trial 10 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 156, 'max_depth': 33, 'learning_rate': 0.25117121719933, 'n_estimators': 731}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:09,035]\u001b[0m Trial 11 finished with value: 0.8517786561264822 and parameters: {'num_leaves': 111, 'max_depth': 2, 'learning_rate': 0.012500627462193766, 'n_estimators': 713}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:09,880]\u001b[0m Trial 12 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 157, 'max_depth': 32, 'learning_rate': 0.22696531776261009, 'n_estimators': 659}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:10,210]\u001b[0m Trial 13 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 79, 'max_depth': 8, 'learning_rate': 0.2863436481070751, 'n_estimators': 146}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:11,425]\u001b[0m Trial 14 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 153, 'max_depth': 28, 'learning_rate': 0.199578614140898, 'n_estimators': 980}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:13,680]\u001b[0m Trial 15 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 85, 'max_depth': 14, 'learning_rate': 0.006788437281460613, 'n_estimators': 534}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:14,825]\u001b[0m Trial 16 finished with value: 0.8616600790513834 and parameters: {'num_leaves': 182, 'max_depth': 6, 'learning_rate': 0.11308493420810542, 'n_estimators': 1164}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:16,194]\u001b[0m Trial 17 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 126, 'max_depth': 21, 'learning_rate': 0.17365403110423594, 'n_estimators': 494}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:18,443]\u001b[0m Trial 18 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 73, 'max_depth': 14, 'learning_rate': 0.10055754610316785, 'n_estimators': 852}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:18,548]\u001b[0m Trial 19 finished with value: 0.857707509881423 and parameters: {'num_leaves': 180, 'max_depth': 2, 'learning_rate': 0.18606685123075306, 'n_estimators': 100}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:20,544]\u001b[0m Trial 20 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 104, 'max_depth': 27, 'learning_rate': 0.08840248915282073, 'n_estimators': 1520}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:22,882]\u001b[0m Trial 21 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 211, 'max_depth': 39, 'learning_rate': 0.033789637453431914, 'n_estimators': 382}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:25,262]\u001b[0m Trial 22 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 191, 'max_depth': 38, 'learning_rate': 0.03068440909362141, 'n_estimators': 481}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:27,023]\u001b[0m Trial 23 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 137, 'max_depth': 17, 'learning_rate': 0.07695935698549804, 'n_estimators': 632}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:28,737]\u001b[0m Trial 24 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 251, 'max_depth': 39, 'learning_rate': 0.014141998764718864, 'n_estimators': 394}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:30,012]\u001b[0m Trial 25 finished with value: 0.8754940711462451 and parameters: {'num_leaves': 50, 'max_depth': 11, 'learning_rate': 0.09578500036776277, 'n_estimators': 765}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:31,005]\u001b[0m Trial 26 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 134, 'max_depth': 24, 'learning_rate': 0.033501097463203365, 'n_estimators': 224}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:33,402]\u001b[0m Trial 27 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 203, 'max_depth': 30, 'learning_rate': 0.06476482739388424, 'n_estimators': 847}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:34,602]\u001b[0m Trial 28 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 167, 'max_depth': 42, 'learning_rate': 0.143492324803507, 'n_estimators': 492}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:35,733]\u001b[0m Trial 29 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 57, 'max_depth': 11, 'learning_rate': 0.05530059909908009, 'n_estimators': 372}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:37,556]\u001b[0m Trial 30 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 99, 'max_depth': 6, 'learning_rate': 0.08326190318841924, 'n_estimators': 592}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:38,801]\u001b[0m Trial 31 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 33, 'max_depth': 11, 'learning_rate': 0.11035095151388082, 'n_estimators': 821}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:39,061]\u001b[0m Trial 32 finished with value: 0.8656126482213439 and parameters: {'num_leaves': 10, 'max_depth': 18, 'learning_rate': 0.029937533801905135, 'n_estimators': 258}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:41,115]\u001b[0m Trial 33 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 61, 'max_depth': 12, 'learning_rate': 0.05075210067240751, 'n_estimators': 779}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:42,259]\u001b[0m Trial 34 finished with value: 0.8656126482213439 and parameters: {'num_leaves': 221, 'max_depth': 8, 'learning_rate': 0.0021643944720928163, 'n_estimators': 408}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:44,526]\u001b[0m Trial 35 finished with value: 0.8656126482213439 and parameters: {'num_leaves': 122, 'max_depth': 22, 'learning_rate': 0.09207341297451598, 'n_estimators': 1114}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:45,590]\u001b[0m Trial 36 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 22, 'max_depth': 19, 'learning_rate': 0.12900397208941752, 'n_estimators': 921}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:47,086]\u001b[0m Trial 37 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 49, 'max_depth': 16, 'learning_rate': 0.059208888810784184, 'n_estimators': 573}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:50,066]\u001b[0m Trial 38 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 220, 'max_depth': 36, 'learning_rate': 0.07713607513075317, 'n_estimators': 1312}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:50,825]\u001b[0m Trial 39 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 143, 'max_depth': 46, 'learning_rate': 0.15495670807252596, 'n_estimators': 235}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:52,590]\u001b[0m Trial 40 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 92, 'max_depth': 25, 'learning_rate': 0.04185228799214488, 'n_estimators': 404}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:54,888]\u001b[0m Trial 41 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 232, 'max_depth': 48, 'learning_rate': 0.06750676096374679, 'n_estimators': 683}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:56,357]\u001b[0m Trial 42 finished with value: 0.8656126482213439 and parameters: {'num_leaves': 205, 'max_depth': 41, 'learning_rate': 0.023767049013347065, 'n_estimators': 305}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:59,700]\u001b[0m Trial 43 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 69, 'max_depth': 44, 'learning_rate': 0.042225868782817, 'n_estimators': 1898}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:00,457]\u001b[0m Trial 44 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 255, 'max_depth': 34, 'learning_rate': 0.016380836563279433, 'n_estimators': 187}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:01,906]\u001b[0m Trial 45 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 174, 'max_depth': 50, 'learning_rate': 0.045532894542348226, 'n_estimators': 307}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:03,438]\u001b[0m Trial 46 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 116, 'max_depth': 9, 'learning_rate': 0.05675920221814258, 'n_estimators': 762}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:04,047]\u001b[0m Trial 47 finished with value: 0.8754940711462451 and parameters: {'num_leaves': 189, 'max_depth': 5, 'learning_rate': 0.021276202856070285, 'n_estimators': 636}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:04,706]\u001b[0m Trial 48 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 195, 'max_depth': 5, 'learning_rate': 0.025305225706015164, 'n_estimators': 676}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:05,384]\u001b[0m Trial 49 finished with value: 0.8616600790513834 and parameters: {'num_leaves': 148, 'max_depth': 4, 'learning_rate': 0.0072906378203621055, 'n_estimators': 967}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:07,781]\u001b[0m Trial 50 finished with value: 0.8656126482213439 and parameters: {'num_leaves': 163, 'max_depth': 13, 'learning_rate': 0.0015367799759276185, 'n_estimators': 565}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:08,919]\u001b[0m Trial 51 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 219, 'max_depth': 9, 'learning_rate': 0.03905748337068561, 'n_estimators': 453}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:09,948]\u001b[0m Trial 52 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 216, 'max_depth': 8, 'learning_rate': 0.036718097105493445, 'n_estimators': 453}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:11,852]\u001b[0m Trial 53 finished with value: 0.8636363636363636 and parameters: {'num_leaves': 230, 'max_depth': 10, 'learning_rate': 0.045627959096287043, 'n_estimators': 533}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:14,587]\u001b[0m Trial 54 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 242, 'max_depth': 15, 'learning_rate': 0.02568024831718879, 'n_estimators': 624}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:18,366]\u001b[0m Trial 55 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 187, 'max_depth': 20, 'learning_rate': 0.01679069157339014, 'n_estimators': 738}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:18,696]\u001b[0m Trial 56 finished with value: 0.857707509881423 and parameters: {'num_leaves': 197, 'max_depth': 2, 'learning_rate': 0.05927673707730456, 'n_estimators': 890}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:19,523]\u001b[0m Trial 57 finished with value: 0.8636363636363636 and parameters: {'num_leaves': 210, 'max_depth': 7, 'learning_rate': 0.07499996657729463, 'n_estimators': 471}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:19,823]\u001b[0m Trial 58 finished with value: 0.857707509881423 and parameters: {'num_leaves': 81, 'max_depth': 4, 'learning_rate': 0.015580131833725676, 'n_estimators': 337}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:23,415]\u001b[0m Trial 59 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 175, 'max_depth': 13, 'learning_rate': 0.03648346496215998, 'n_estimators': 1064}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:24,736]\u001b[0m Trial 60 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 244, 'max_depth': 10, 'learning_rate': 0.0940127229213565, 'n_estimators': 637}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:26,701]\u001b[0m Trial 61 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 226, 'max_depth': 47, 'learning_rate': 0.048207311075776874, 'n_estimators': 433}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:28,640]\u001b[0m Trial 62 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 202, 'max_depth': 17, 'learning_rate': 0.06876239497865114, 'n_estimators': 505}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:29,427]\u001b[0m Trial 63 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 213, 'max_depth': 30, 'learning_rate': 0.034533615861514794, 'n_estimators': 172}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:29,922]\u001b[0m Trial 64 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 187, 'max_depth': 45, 'learning_rate': 0.021467961797443508, 'n_estimators': 127}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:30,838]\u001b[0m Trial 65 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 90, 'max_depth': 40, 'learning_rate': 0.11220002718460148, 'n_estimators': 271}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:31,830]\u001b[0m Trial 66 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 97, 'max_depth': 38, 'learning_rate': 0.13805572503783978, 'n_estimators': 324}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:34,907]\u001b[0m Trial 67 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 94, 'max_depth': 39, 'learning_rate': 0.12134299985518639, 'n_estimators': 351}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:36,073]\u001b[0m Trial 68 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 108, 'max_depth': 36, 'learning_rate': 0.13927269453216046, 'n_estimators': 280}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:37,255]\u001b[0m Trial 69 finished with value: 0.8636363636363636 and parameters: {'num_leaves': 119, 'max_depth': 41, 'learning_rate': 0.13891419577177583, 'n_estimators': 371}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:38,667]\u001b[0m Trial 70 finished with value: 0.8656126482213439 and parameters: {'num_leaves': 129, 'max_depth': 37, 'learning_rate': 0.10360326788631942, 'n_estimators': 205}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:39,639]\u001b[0m Trial 71 finished with value: 0.8754940711462451 and parameters: {'num_leaves': 90, 'max_depth': 33, 'learning_rate': 0.15328634604704008, 'n_estimators': 570}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:41,102]\u001b[0m Trial 72 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 73, 'max_depth': 40, 'learning_rate': 0.11407446636539742, 'n_estimators': 438}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:42,986]\u001b[0m Trial 73 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 99, 'max_depth': 12, 'learning_rate': 0.08391286449814628, 'n_estimators': 262}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:43,742]\u001b[0m Trial 74 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 39, 'max_depth': 6, 'learning_rate': 0.12809706846130442, 'n_estimators': 705}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:45,261]\u001b[0m Trial 75 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 64, 'max_depth': 43, 'learning_rate': 0.09896267150167808, 'n_estimators': 812}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:45,664]\u001b[0m Trial 76 finished with value: 0.8656126482213439 and parameters: {'num_leaves': 54, 'max_depth': 4, 'learning_rate': 0.12120014577676431, 'n_estimators': 513}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:48,407]\u001b[0m Trial 77 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 137, 'max_depth': 15, 'learning_rate': 0.010041059680015878, 'n_estimators': 627}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:49,592]\u001b[0m Trial 78 finished with value: 0.8656126482213439 and parameters: {'num_leaves': 85, 'max_depth': 35, 'learning_rate': 0.171706990487361, 'n_estimators': 385}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:51,105]\u001b[0m Trial 79 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 107, 'max_depth': 29, 'learning_rate': 0.20706716301884107, 'n_estimators': 1286}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:51,665]\u001b[0m Trial 80 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 28, 'max_depth': 38, 'learning_rate': 0.052462432849149046, 'n_estimators': 319}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:52,754]\u001b[0m Trial 81 finished with value: 0.8636363636363636 and parameters: {'num_leaves': 92, 'max_depth': 31, 'learning_rate': 0.16267721512658753, 'n_estimators': 571}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:53,671]\u001b[0m Trial 82 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 85, 'max_depth': 33, 'learning_rate': 0.15183634358100354, 'n_estimators': 528}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:54,922]\u001b[0m Trial 83 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 116, 'max_depth': 26, 'learning_rate': 0.13505716533700998, 'n_estimators': 583}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:56,518]\u001b[0m Trial 84 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 103, 'max_depth': 9, 'learning_rate': 0.13251009080701984, 'n_estimators': 671}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:57,435]\u001b[0m Trial 85 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 74, 'max_depth': 42, 'learning_rate': 0.14454699530506654, 'n_estimators': 458}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:58,801]\u001b[0m Trial 86 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 95, 'max_depth': 11, 'learning_rate': 0.030722647249520382, 'n_estimators': 417}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:59,805]\u001b[0m Trial 87 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 44, 'max_depth': 38, 'learning_rate': 0.10547643222307156, 'n_estimators': 732}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:02,061]\u001b[0m Trial 88 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 125, 'max_depth': 33, 'learning_rate': 0.11644256119822269, 'n_estimators': 1718}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:03,302]\u001b[0m Trial 89 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 113, 'max_depth': 7, 'learning_rate': 0.0881461073549341, 'n_estimators': 781}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:04,317]\u001b[0m Trial 90 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 146, 'max_depth': 35, 'learning_rate': 0.14875534622742198, 'n_estimators': 611}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:05,531]\u001b[0m Trial 91 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 224, 'max_depth': 49, 'learning_rate': 0.039574053170642304, 'n_estimators': 253}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:07,199]\u001b[0m Trial 92 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 207, 'max_depth': 22, 'learning_rate': 0.05206128210875799, 'n_estimators': 343}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:07,791]\u001b[0m Trial 93 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 13, 'max_depth': 44, 'learning_rate': 0.06187043635938776, 'n_estimators': 481}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:08,275]\u001b[0m Trial 94 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 218, 'max_depth': 40, 'learning_rate': 0.02753101679173727, 'n_estimators': 109}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:09,735]\u001b[0m Trial 95 finished with value: 0.8616600790513834 and parameters: {'num_leaves': 232, 'max_depth': 9, 'learning_rate': 0.017520690963150985, 'n_estimators': 543}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:10,159]\u001b[0m Trial 96 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 193, 'max_depth': 5, 'learning_rate': 0.042573434258777715, 'n_estimators': 383}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:10,881]\u001b[0m Trial 97 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 161, 'max_depth': 46, 'learning_rate': 0.10798439881688172, 'n_estimators': 169}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:12,719]\u001b[0m Trial 98 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 201, 'max_depth': 14, 'learning_rate': 0.034691771086145864, 'n_estimators': 291}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:14,366]\u001b[0m Trial 99 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 78, 'max_depth': 14, 'learning_rate': 0.03325394180621997, 'n_estimators': 432}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "Evaluating selected_features_all_best30 LogisticRegression\n",
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "Evaluating selected_features_all_best30 SVC\n",
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "Evaluating selected_features_all_best30 XGBClassifier\n",
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "index  selected_features_all_best30       XGBClassifier            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "Evaluating selected_features_all_best30 LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:38:23,091]\u001b[0m A new study created in memory with name: no-name-c0c0039d-afa3-4213-8124-122d20179b0c\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:23,130]\u001b[0m Trial 0 finished with value: 0.8893280632411067 and parameters: {'C': 0.09688479766360383, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 289}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "index  selected_features_all_best30       XGBClassifier            False   \n",
      "index  selected_features_all_best30      LGBMClassifier            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "Optimizing selected_features_all_best30 LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:38:23,387]\u001b[0m Trial 1 finished with value: 0.8893280632411067 and parameters: {'C': 0.08105103415050194, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 562}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:23,415]\u001b[0m Trial 2 finished with value: 0.8873517786561265 and parameters: {'C': 0.046218227368261915, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 907}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:23,444]\u001b[0m Trial 3 finished with value: 0.8873517786561265 and parameters: {'C': 0.05199988061090262, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 492}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:38:23,967]\u001b[0m Trial 4 finished with value: 0.8853754940711462 and parameters: {'C': 0.06651836663093466, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 333}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:24,171]\u001b[0m Trial 5 finished with value: 0.8893280632411067 and parameters: {'C': 0.07979345064311186, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 569}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:24,206]\u001b[0m Trial 6 finished with value: 0.883399209486166 and parameters: {'C': 0.08392487529460053, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 808}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:24,373]\u001b[0m Trial 7 finished with value: 0.8893280632411067 and parameters: {'C': 0.05793875465843212, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 501}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:24,398]\u001b[0m Trial 8 finished with value: 0.8814229249011858 and parameters: {'C': 0.04824785317518836, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 644}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:25,213]\u001b[0m Trial 9 finished with value: 0.8853754940711462 and parameters: {'C': 0.05475304646639717, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 860}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:25,253]\u001b[0m Trial 10 finished with value: 0.8893280632411067 and parameters: {'C': 0.09979625616881578, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 127}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:25,357]\u001b[0m Trial 11 finished with value: 0.8754940711462451 and parameters: {'C': 0.017393311451135297, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 258}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:25,395]\u001b[0m Trial 12 finished with value: 0.8893280632411067 and parameters: {'C': 0.09504522020623751, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 348}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:25,610]\u001b[0m Trial 13 finished with value: 0.8893280632411067 and parameters: {'C': 0.08519052750958146, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 713}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:38:25,795]\u001b[0m Trial 14 finished with value: 0.8893280632411067 and parameters: {'C': 0.09676528485511153, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 130}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:25,843]\u001b[0m Trial 15 finished with value: 0.8893280632411067 and parameters: {'C': 0.07926755464198076, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 390}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:26,040]\u001b[0m Trial 16 finished with value: 0.8913043478260869 and parameters: {'C': 0.0722445950942323, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 1000}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:26,090]\u001b[0m Trial 17 finished with value: 0.8893280632411067 and parameters: {'C': 0.06861839793324258, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 751}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:27,013]\u001b[0m Trial 18 finished with value: 0.8873517786561265 and parameters: {'C': 0.08867263893111527, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 998}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:27,062]\u001b[0m Trial 19 finished with value: 0.8873517786561265 and parameters: {'C': 0.07215526948962023, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 228}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:27,110]\u001b[0m Trial 20 finished with value: 0.8913043478260869 and parameters: {'C': 0.09281586663509098, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 970}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:27,152]\u001b[0m Trial 21 finished with value: 0.8913043478260869 and parameters: {'C': 0.08950953842748537, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 1000}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:27,200]\u001b[0m Trial 22 finished with value: 0.8913043478260869 and parameters: {'C': 0.08953998818441548, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 995}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:27,245]\u001b[0m Trial 23 finished with value: 0.8913043478260869 and parameters: {'C': 0.09033258398889629, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 916}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:27,285]\u001b[0m Trial 24 finished with value: 0.8893280632411067 and parameters: {'C': 0.07617447533968723, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 935}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:27,329]\u001b[0m Trial 25 finished with value: 0.8913043478260869 and parameters: {'C': 0.088314941228041, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 826}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:27,578]\u001b[0m Trial 26 finished with value: 0.8893280632411067 and parameters: {'C': 0.09984335914599755, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 752}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:27,639]\u001b[0m Trial 27 finished with value: 0.883399209486166 and parameters: {'C': 0.07453668468644857, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 941}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:27,852]\u001b[0m Trial 28 finished with value: 0.8893280632411067 and parameters: {'C': 0.09225458658818822, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 999}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:27,893]\u001b[0m Trial 29 finished with value: 0.8913043478260869 and parameters: {'C': 0.08475979569133607, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 887}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:27,934]\u001b[0m Trial 30 finished with value: 0.8893280632411067 and parameters: {'C': 0.09486508478099327, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 664}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:27,977]\u001b[0m Trial 31 finished with value: 0.8913043478260869 and parameters: {'C': 0.09003986362631705, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 990}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:28,023]\u001b[0m Trial 32 finished with value: 0.8913043478260869 and parameters: {'C': 0.08225124967237799, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 832}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:28,073]\u001b[0m Trial 33 finished with value: 0.8913043478260869 and parameters: {'C': 0.09224071136056185, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 944}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:28,125]\u001b[0m Trial 34 finished with value: 0.8893280632411067 and parameters: {'C': 0.08043144785927425, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 892}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:28,172]\u001b[0m Trial 35 finished with value: 0.8913043478260869 and parameters: {'C': 0.08692363012289911, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 974}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:28,375]\u001b[0m Trial 36 finished with value: 0.8913043478260869 and parameters: {'C': 0.07682412128104629, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 777}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:28,426]\u001b[0m Trial 37 finished with value: 0.883399209486166 and parameters: {'C': 0.09518547612564986, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 855}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:28,611]\u001b[0m Trial 38 finished with value: 0.8873517786561265 and parameters: {'C': 0.06498163134490617, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 951}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:28,657]\u001b[0m Trial 39 finished with value: 0.8893280632411067 and parameters: {'C': 0.0808864976324435, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 881}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:28,704]\u001b[0m Trial 40 finished with value: 0.8853754940711462 and parameters: {'C': 0.0715216526981884, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 921}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:28,749]\u001b[0m Trial 41 finished with value: 0.8913043478260869 and parameters: {'C': 0.09083131859974918, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 914}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:28,799]\u001b[0m Trial 42 finished with value: 0.8913043478260869 and parameters: {'C': 0.08567439636080386, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 998}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:28,849]\u001b[0m Trial 43 finished with value: 0.8913043478260869 and parameters: {'C': 0.09198890791583919, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 954}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:28,898]\u001b[0m Trial 44 finished with value: 0.8913043478260869 and parameters: {'C': 0.08375391989018764, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 803}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:29,125]\u001b[0m Trial 45 finished with value: 0.8893280632411067 and parameters: {'C': 0.09841892049584278, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 865}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:29,171]\u001b[0m Trial 46 finished with value: 0.8913043478260869 and parameters: {'C': 0.08816773199232608, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 606}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:29,223]\u001b[0m Trial 47 finished with value: 0.8893280632411067 and parameters: {'C': 0.09518637115804471, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 506}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:29,427]\u001b[0m Trial 48 finished with value: 0.8893280632411067 and parameters: {'C': 0.08319425643982649, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 905}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:29,482]\u001b[0m Trial 49 finished with value: 0.883399209486166 and parameters: {'C': 0.07885511737423206, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 702}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:29,659]\u001b[0m Trial 50 finished with value: 0.8873517786561265 and parameters: {'C': 0.06214675585424576, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 958}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:29,703]\u001b[0m Trial 51 finished with value: 0.8913043478260869 and parameters: {'C': 0.08863533926647708, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 819}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:29,748]\u001b[0m Trial 52 finished with value: 0.8913043478260869 and parameters: {'C': 0.08708605380318553, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 855}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:29,793]\u001b[0m Trial 53 finished with value: 0.8893280632411067 and parameters: {'C': 0.09784154994338735, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 919}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:29,838]\u001b[0m Trial 54 finished with value: 0.8913043478260869 and parameters: {'C': 0.09246323726115643, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 971}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:29,880]\u001b[0m Trial 55 finished with value: 0.8893280632411067 and parameters: {'C': 0.07898842509891725, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 838}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:29,925]\u001b[0m Trial 56 finished with value: 0.8913043478260869 and parameters: {'C': 0.08618006756724493, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 787}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:30,165]\u001b[0m Trial 57 finished with value: 0.8893280632411067 and parameters: {'C': 0.09936811100461149, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 969}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:30,218]\u001b[0m Trial 58 finished with value: 0.8853754940711462 and parameters: {'C': 0.07411311973239079, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 909}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:30,263]\u001b[0m Trial 59 finished with value: 0.8913043478260869 and parameters: {'C': 0.09422942310516268, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 997}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:30,307]\u001b[0m Trial 60 finished with value: 0.8893280632411067 and parameters: {'C': 0.08187745013087575, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 881}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:30,356]\u001b[0m Trial 61 finished with value: 0.8913043478260869 and parameters: {'C': 0.08975201520809827, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 939}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:30,405]\u001b[0m Trial 62 finished with value: 0.8913043478260869 and parameters: {'C': 0.0831749480739995, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 876}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:30,455]\u001b[0m Trial 63 finished with value: 0.8913043478260869 and parameters: {'C': 0.08555460734260809, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 904}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:30,505]\u001b[0m Trial 64 finished with value: 0.8913043478260869 and parameters: {'C': 0.09006777536651368, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 964}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:30,554]\u001b[0m Trial 65 finished with value: 0.8893280632411067 and parameters: {'C': 0.09663000670799662, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 436}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:30,786]\u001b[0m Trial 66 finished with value: 0.8893280632411067 and parameters: {'C': 0.09265984242612328, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 837}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:30,837]\u001b[0m Trial 67 finished with value: 0.8913043478260869 and parameters: {'C': 0.0882630007234697, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 759}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:30,882]\u001b[0m Trial 68 finished with value: 0.8893280632411067 and parameters: {'C': 0.07719165263652522, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 711}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:31,786]\u001b[0m Trial 69 finished with value: 0.8873517786561265 and parameters: {'C': 0.0850788983115437, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 981}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:31,843]\u001b[0m Trial 70 finished with value: 0.8913043478260869 and parameters: {'C': 0.09396581958047945, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 937}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:31,902]\u001b[0m Trial 71 finished with value: 0.8913043478260869 and parameters: {'C': 0.08966411659996543, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 997}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:31,958]\u001b[0m Trial 72 finished with value: 0.8893280632411067 and parameters: {'C': 0.09652968488280647, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 937}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:32,004]\u001b[0m Trial 73 finished with value: 0.8913043478260869 and parameters: {'C': 0.09048742734404658, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 976}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:32,054]\u001b[0m Trial 74 finished with value: 0.8913043478260869 and parameters: {'C': 0.08412718313249985, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 928}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:32,105]\u001b[0m Trial 75 finished with value: 0.8893280632411067 and parameters: {'C': 0.08057024036101641, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 887}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:32,157]\u001b[0m Trial 76 finished with value: 0.8913043478260869 and parameters: {'C': 0.08703566664401269, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 185}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:32,213]\u001b[0m Trial 77 finished with value: 0.8913043478260869 and parameters: {'C': 0.0922737319646602, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 979}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:32,426]\u001b[0m Trial 78 finished with value: 0.8893280632411067 and parameters: {'C': 0.08187874556945501, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 954}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:32,479]\u001b[0m Trial 79 finished with value: 0.8893280632411067 and parameters: {'C': 0.09673110843159129, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 897}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:32,527]\u001b[0m Trial 80 finished with value: 0.8853754940711462 and parameters: {'C': 0.09971352226287279, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 852}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:32,577]\u001b[0m Trial 81 finished with value: 0.8913043478260869 and parameters: {'C': 0.08842155829257906, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 998}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:32,627]\u001b[0m Trial 82 finished with value: 0.8913043478260869 and parameters: {'C': 0.08376557971406026, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 826}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:32,678]\u001b[0m Trial 83 finished with value: 0.8913043478260869 and parameters: {'C': 0.08669678353468813, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 804}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:32,733]\u001b[0m Trial 84 finished with value: 0.8913043478260869 and parameters: {'C': 0.09131822151996723, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 931}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:32,785]\u001b[0m Trial 85 finished with value: 0.8893280632411067 and parameters: {'C': 0.08113411868756211, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 733}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:33,017]\u001b[0m Trial 86 finished with value: 0.8893280632411067 and parameters: {'C': 0.09406035693374726, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 955}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:33,067]\u001b[0m Trial 87 finished with value: 0.8893280632411067 and parameters: {'C': 0.0772727053100038, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 868}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:33,119]\u001b[0m Trial 88 finished with value: 0.8913043478260869 and parameters: {'C': 0.08554999855580532, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 910}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:33,179]\u001b[0m Trial 89 finished with value: 0.8913043478260869 and parameters: {'C': 0.0898784157617974, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 681}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:33,393]\u001b[0m Trial 90 finished with value: 0.8893280632411067 and parameters: {'C': 0.07861155300766187, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 984}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:33,452]\u001b[0m Trial 91 finished with value: 0.8913043478260869 and parameters: {'C': 0.09315295756060238, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 950}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:33,506]\u001b[0m Trial 92 finished with value: 0.8913043478260869 and parameters: {'C': 0.09130091257056328, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 919}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:33,562]\u001b[0m Trial 93 finished with value: 0.8913043478260869 and parameters: {'C': 0.0876498602691753, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 891}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:33,614]\u001b[0m Trial 94 finished with value: 0.8893280632411067 and parameters: {'C': 0.0952062104878643, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 964}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:33,669]\u001b[0m Trial 95 finished with value: 0.8913043478260869 and parameters: {'C': 0.08308928169997379, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 326}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:33,716]\u001b[0m Trial 96 finished with value: 0.883399209486166 and parameters: {'C': 0.08841648440830982, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 848}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:33,763]\u001b[0m Trial 97 finished with value: 0.8913043478260869 and parameters: {'C': 0.09153181190173958, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 607}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:33,809]\u001b[0m Trial 98 finished with value: 0.8913043478260869 and parameters: {'C': 0.0846461835869865, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 1000}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:34,033]\u001b[0m Trial 99 finished with value: 0.8893280632411067 and parameters: {'C': 0.09578467292227531, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 870}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:34,044]\u001b[0m A new study created in memory with name: no-name-09302117-de2e-4053-b5ed-a1ab958005a2\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "index  selected_features_all_best30       XGBClassifier            False   \n",
      "index  selected_features_all_best30      LGBMClassifier            False   \n",
      "index  selected_features_all_best30  LogisticRegression             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "Optimizing selected_features_all_best30 SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:38:34,655]\u001b[0m Trial 0 finished with value: 0.5177865612648221 and parameters: {'svc_c': 45.48258663520493, 'svc_gamma': 29.982864410821676}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:35,190]\u001b[0m Trial 1 finished with value: 0.5177865612648221 and parameters: {'svc_c': 69.03665719583451, 'svc_gamma': 63.58316045628349}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:35,674]\u001b[0m Trial 2 finished with value: 0.5138339920948617 and parameters: {'svc_c': 10.981700362263517, 'svc_gamma': 92.44976306738184}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:36,196]\u001b[0m Trial 3 finished with value: 0.5177865612648221 and parameters: {'svc_c': 45.78783115598922, 'svc_gamma': 6.90138642611082}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:36,757]\u001b[0m Trial 4 finished with value: 0.5177865612648221 and parameters: {'svc_c': 11.490446606635224, 'svc_gamma': 20.115057674413546}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:37,209]\u001b[0m Trial 5 finished with value: 0.5177865612648221 and parameters: {'svc_c': 67.50347472615543, 'svc_gamma': 70.20902309080607}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:37,741]\u001b[0m Trial 6 finished with value: 0.5177865612648221 and parameters: {'svc_c': 68.40945446928782, 'svc_gamma': 14.164106880385923}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:38,253]\u001b[0m Trial 7 finished with value: 0.5177865612648221 and parameters: {'svc_c': 45.93499843337403, 'svc_gamma': 33.22328107913082}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:38,688]\u001b[0m Trial 8 finished with value: 0.5158102766798419 and parameters: {'svc_c': 66.49863428320074, 'svc_gamma': 89.7492346948768}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:39,193]\u001b[0m Trial 9 finished with value: 0.5177865612648221 and parameters: {'svc_c': 9.713994652121837, 'svc_gamma': 11.632307786539249}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:39,753]\u001b[0m Trial 10 finished with value: 0.5177865612648221 and parameters: {'svc_c': 96.32032272009538, 'svc_gamma': 39.706998633041216}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:40,252]\u001b[0m Trial 11 finished with value: 0.5177865612648221 and parameters: {'svc_c': 32.38022143375902, 'svc_gamma': 53.70038763480426}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:40,807]\u001b[0m Trial 12 finished with value: 0.5177865612648221 and parameters: {'svc_c': 85.99514531908538, 'svc_gamma': 60.18265161206364}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:41,361]\u001b[0m Trial 13 finished with value: 0.5177865612648221 and parameters: {'svc_c': 32.814348082647356, 'svc_gamma': 37.46218864034215}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:41,845]\u001b[0m Trial 14 finished with value: 0.5177865612648221 and parameters: {'svc_c': 59.75202047459656, 'svc_gamma': 70.90728020843892}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:42,406]\u001b[0m Trial 15 finished with value: 0.5177865612648221 and parameters: {'svc_c': 82.16640665707472, 'svc_gamma': 24.623854577789473}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:42,897]\u001b[0m Trial 16 finished with value: 0.5177865612648221 and parameters: {'svc_c': 56.52724306502789, 'svc_gamma': 46.20460440053172}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:43,307]\u001b[0m Trial 17 finished with value: 0.6818181818181818 and parameters: {'svc_c': 77.37138590892467, 'svc_gamma': 1.1703614860118705}. Best is trial 17 with value: 0.6818181818181818.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:43,767]\u001b[0m Trial 18 finished with value: 0.6996047430830039 and parameters: {'svc_c': 85.91942883897018, 'svc_gamma': 1.0428954629460672}. Best is trial 18 with value: 0.6996047430830039.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:44,254]\u001b[0m Trial 19 finished with value: 0.6541501976284585 and parameters: {'svc_c': 99.68899194167612, 'svc_gamma': 1.3506704781663856}. Best is trial 18 with value: 0.6996047430830039.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:44,705]\u001b[0m Trial 20 finished with value: 0.525691699604743 and parameters: {'svc_c': 79.94733652823398, 'svc_gamma': 3.9062244048926598}. Best is trial 18 with value: 0.6996047430830039.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:45,219]\u001b[0m Trial 21 finished with value: 0.525691699604743 and parameters: {'svc_c': 99.4102411564393, 'svc_gamma': 3.9919871428856846}. Best is trial 18 with value: 0.6996047430830039.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:45,678]\u001b[0m Trial 22 finished with value: 0.541501976284585 and parameters: {'svc_c': 92.71542521177835, 'svc_gamma': 2.927654316656664}. Best is trial 18 with value: 0.6996047430830039.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:46,053]\u001b[0m Trial 23 finished with value: 0.8478260869565217 and parameters: {'svc_c': 87.16748444581143, 'svc_gamma': 0.2406386614453394}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:46,577]\u001b[0m Trial 24 finished with value: 0.5177865612648221 and parameters: {'svc_c': 77.52123351238913, 'svc_gamma': 15.55100989635695}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:47,172]\u001b[0m Trial 25 finished with value: 0.5177865612648221 and parameters: {'svc_c': 88.57477501485069, 'svc_gamma': 24.16865585313952}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:47,704]\u001b[0m Trial 26 finished with value: 0.5177865612648221 and parameters: {'svc_c': 89.71280687879967, 'svc_gamma': 12.21113686286158}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:48,052]\u001b[0m Trial 27 finished with value: 0.8478260869565217 and parameters: {'svc_c': 76.54177076248392, 'svc_gamma': 0.19355182630180542}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:48,560]\u001b[0m Trial 28 finished with value: 0.5177865612648221 and parameters: {'svc_c': 86.028866556259, 'svc_gamma': 9.583822899806997}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:49,078]\u001b[0m Trial 29 finished with value: 0.5177865612648221 and parameters: {'svc_c': 91.59911457709465, 'svc_gamma': 21.327522558862018}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:49,612]\u001b[0m Trial 30 finished with value: 0.5177865612648221 and parameters: {'svc_c': 72.91544035987002, 'svc_gamma': 16.188487716604616}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:49,962]\u001b[0m Trial 31 finished with value: 0.841897233201581 and parameters: {'svc_c': 77.97820115765317, 'svc_gamma': 0.1798407975423284}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:50,454]\u001b[0m Trial 32 finished with value: 0.5177865612648221 and parameters: {'svc_c': 82.86434991776875, 'svc_gamma': 8.209430742327152}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:50,853]\u001b[0m Trial 33 finished with value: 0.8320158102766798 and parameters: {'svc_c': 77.31362285428145, 'svc_gamma': 0.3217799952653145}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:51,314]\u001b[0m Trial 34 finished with value: 0.5177865612648221 and parameters: {'svc_c': 74.25335439116041, 'svc_gamma': 8.096879166168371}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:51,822]\u001b[0m Trial 35 finished with value: 0.5177865612648221 and parameters: {'svc_c': 73.91700518319605, 'svc_gamma': 26.92346489336291}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:52,391]\u001b[0m Trial 36 finished with value: 0.5177865612648221 and parameters: {'svc_c': 79.42077036050077, 'svc_gamma': 19.22475242395663}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:52,863]\u001b[0m Trial 37 finished with value: 0.5177865612648221 and parameters: {'svc_c': 62.95429688954195, 'svc_gamma': 8.051600488505468}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:53,396]\u001b[0m Trial 38 finished with value: 0.5177865612648221 and parameters: {'svc_c': 70.61376127662791, 'svc_gamma': 16.67731884201437}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:53,806]\u001b[0m Trial 39 finished with value: 0.7944664031620553 and parameters: {'svc_c': 92.66031591533701, 'svc_gamma': 0.5330813097115876}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:54,308]\u001b[0m Trial 40 finished with value: 0.5177865612648221 and parameters: {'svc_c': 66.37939891512042, 'svc_gamma': 12.420644107635447}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:54,755]\u001b[0m Trial 41 finished with value: 0.5177865612648221 and parameters: {'svc_c': 94.20058803551494, 'svc_gamma': 5.582081455035478}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:55,122]\u001b[0m Trial 42 finished with value: 0.7272727272727273 and parameters: {'svc_c': 83.72268792934942, 'svc_gamma': 0.9360961248652081}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:55,541]\u001b[0m Trial 43 finished with value: 0.5177865612648221 and parameters: {'svc_c': 89.65253917105153, 'svc_gamma': 6.504201233736848}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:55,897]\u001b[0m Trial 44 finished with value: 0.8438735177865613 and parameters: {'svc_c': 94.25687526097914, 'svc_gamma': 0.17548137315324816}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:56,368]\u001b[0m Trial 45 finished with value: 0.5177865612648221 and parameters: {'svc_c': 75.71896843670355, 'svc_gamma': 11.674996973605653}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:56,802]\u001b[0m Trial 46 finished with value: 0.5177865612648221 and parameters: {'svc_c': 96.3644197216184, 'svc_gamma': 6.667731990287301}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:57,342]\u001b[0m Trial 47 finished with value: 0.5177865612648221 and parameters: {'svc_c': 81.18845607912836, 'svc_gamma': 19.47470727073788}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:57,939]\u001b[0m Trial 48 finished with value: 0.5177865612648221 and parameters: {'svc_c': 69.84454641185893, 'svc_gamma': 13.780934612225378}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:58,228]\u001b[0m Trial 49 finished with value: 0.8438735177865613 and parameters: {'svc_c': 86.99932590025634, 'svc_gamma': 0.09400740759157292}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:58,790]\u001b[0m Trial 50 finished with value: 0.5177865612648221 and parameters: {'svc_c': 87.61170653227539, 'svc_gamma': 28.88043131343466}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:59,183]\u001b[0m Trial 51 finished with value: 0.5217391304347826 and parameters: {'svc_c': 83.50464955973712, 'svc_gamma': 4.805141810824943}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:59,640]\u001b[0m Trial 52 finished with value: 0.5177865612648221 and parameters: {'svc_c': 79.15619068984142, 'svc_gamma': 9.891066565563074}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:00,039]\u001b[0m Trial 53 finished with value: 0.525691699604743 and parameters: {'svc_c': 95.05600464057467, 'svc_gamma': 3.969941093733127}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:00,394]\u001b[0m Trial 54 finished with value: 0.6561264822134387 and parameters: {'svc_c': 86.75018408699152, 'svc_gamma': 1.3373625071500947}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:00,736]\u001b[0m Trial 55 finished with value: 0.8162055335968379 and parameters: {'svc_c': 76.32560603128174, 'svc_gamma': 0.42093227868556926}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:01,220]\u001b[0m Trial 56 finished with value: 0.5177865612648221 and parameters: {'svc_c': 90.646427253239, 'svc_gamma': 9.941723850699761}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:01,649]\u001b[0m Trial 57 finished with value: 0.5177865612648221 and parameters: {'svc_c': 97.5055068775598, 'svc_gamma': 5.291284210590642}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:02,104]\u001b[0m Trial 58 finished with value: 0.5177865612648221 and parameters: {'svc_c': 83.76186714616547, 'svc_gamma': 12.806695157832005}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:02,362]\u001b[0m Trial 59 finished with value: 0.8399209486166008 and parameters: {'svc_c': 79.46496557088942, 'svc_gamma': 0.11282937854458226}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:02,836]\u001b[0m Trial 60 finished with value: 0.5177865612648221 and parameters: {'svc_c': 98.81903782932514, 'svc_gamma': 5.61832985250744}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:03,216]\u001b[0m Trial 61 finished with value: 0.5296442687747036 and parameters: {'svc_c': 79.58068809622803, 'svc_gamma': 3.3260827094494285}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:03,709]\u001b[0m Trial 62 finished with value: 0.5177865612648221 and parameters: {'svc_c': 86.39840799265123, 'svc_gamma': 10.121096530718182}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:04,102]\u001b[0m Trial 63 finished with value: 0.841897233201581 and parameters: {'svc_c': 72.79220685235457, 'svc_gamma': 0.163263291541208}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:04,525]\u001b[0m Trial 64 finished with value: 0.5276679841897233 and parameters: {'svc_c': 73.01254517513537, 'svc_gamma': 3.697027625347165}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:04,820]\u001b[0m Trial 65 finished with value: 0.8537549407114624 and parameters: {'svc_c': 91.89133569306787, 'svc_gamma': 0.03375857107899616}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:05,347]\u001b[0m Trial 66 finished with value: 0.5177865612648221 and parameters: {'svc_c': 92.40252501622723, 'svc_gamma': 8.730925486534154}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:05,950]\u001b[0m Trial 67 finished with value: 0.5177865612648221 and parameters: {'svc_c': 89.16985398351636, 'svc_gamma': 15.533641860212795}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:06,491]\u001b[0m Trial 68 finished with value: 0.5177865612648221 and parameters: {'svc_c': 94.61287550467502, 'svc_gamma': 7.039065280646691}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:06,966]\u001b[0m Trial 69 finished with value: 0.525691699604743 and parameters: {'svc_c': 84.27777575230625, 'svc_gamma': 3.854808582551045}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:07,533]\u001b[0m Trial 70 finished with value: 0.5177865612648221 and parameters: {'svc_c': 99.84608634136055, 'svc_gamma': 13.110828415688395}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:07,941]\u001b[0m Trial 71 finished with value: 0.7391304347826086 and parameters: {'svc_c': 80.6898897705361, 'svc_gamma': 0.8491080301751474}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:08,200]\u001b[0m Trial 72 finished with value: 0.83399209486166 and parameters: {'svc_c': 89.5378549063662, 'svc_gamma': 0.0575616160843706}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:08,655]\u001b[0m Trial 73 finished with value: 0.5296442687747036 and parameters: {'svc_c': 82.38528400207757, 'svc_gamma': 3.268559316741283}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:09,155]\u001b[0m Trial 74 finished with value: 0.5177865612648221 and parameters: {'svc_c': 77.29763618399154, 'svc_gamma': 7.521665148567761}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:09,614]\u001b[0m Trial 75 finished with value: 0.5296442687747036 and parameters: {'svc_c': 85.60794397376866, 'svc_gamma': 3.501519669690061}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:10,115]\u001b[0m Trial 76 finished with value: 0.5177865612648221 and parameters: {'svc_c': 71.63486406261426, 'svc_gamma': 9.37686439753802}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:10,371]\u001b[0m Trial 77 finished with value: 0.8438735177865613 and parameters: {'svc_c': 92.92504331161464, 'svc_gamma': 0.08223598906474278}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:10,783]\u001b[0m Trial 78 finished with value: 0.5177865612648221 and parameters: {'svc_c': 90.30837910394078, 'svc_gamma': 5.713915742365072}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:11,282]\u001b[0m Trial 79 finished with value: 0.5177865612648221 and parameters: {'svc_c': 93.40438300276396, 'svc_gamma': 17.96635902190414}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:11,833]\u001b[0m Trial 80 finished with value: 0.5177865612648221 and parameters: {'svc_c': 95.84086155877696, 'svc_gamma': 14.7008156474346}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:12,242]\u001b[0m Trial 81 finished with value: 0.5474308300395256 and parameters: {'svc_c': 86.91828231327588, 'svc_gamma': 2.4916152166608976}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:12,605]\u001b[0m Trial 82 finished with value: 0.841897233201581 and parameters: {'svc_c': 92.04429940353245, 'svc_gamma': 0.2644287688855034}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:13,074]\u001b[0m Trial 83 finished with value: 0.5177865612648221 and parameters: {'svc_c': 91.61922621907122, 'svc_gamma': 6.264804945896755}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:13,598]\u001b[0m Trial 84 finished with value: 0.5177865612648221 and parameters: {'svc_c': 96.72298795366042, 'svc_gamma': 11.075722836814212}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:14,071]\u001b[0m Trial 85 finished with value: 0.5454545454545454 and parameters: {'svc_c': 93.19553735885214, 'svc_gamma': 2.6437608180264642}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:14,573]\u001b[0m Trial 86 finished with value: 0.5177865612648221 and parameters: {'svc_c': 87.73227503141142, 'svc_gamma': 7.466300180912838}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:14,984]\u001b[0m Trial 87 finished with value: 0.5474308300395256 and parameters: {'svc_c': 81.68625890094104, 'svc_gamma': 2.486580707502646}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:15,417]\u001b[0m Trial 88 finished with value: 0.5177865612648221 and parameters: {'svc_c': 96.95283641270436, 'svc_gamma': 5.474726558701071}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:15,928]\u001b[0m Trial 89 finished with value: 0.5177865612648221 and parameters: {'svc_c': 85.25436380978641, 'svc_gamma': 11.28598716242542}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:16,440]\u001b[0m Trial 90 finished with value: 0.5177865612648221 and parameters: {'svc_c': 88.42619739777825, 'svc_gamma': 8.41125985525686}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:16,836]\u001b[0m Trial 91 finished with value: 0.8438735177865613 and parameters: {'svc_c': 91.19719628142487, 'svc_gamma': 0.2515833462400049}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:17,204]\u001b[0m Trial 92 finished with value: 0.8438735177865613 and parameters: {'svc_c': 91.23933069265385, 'svc_gamma': 0.1761835640258373}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:17,635]\u001b[0m Trial 93 finished with value: 0.5474308300395256 and parameters: {'svc_c': 94.34874521650181, 'svc_gamma': 2.561909508033491}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:18,080]\u001b[0m Trial 94 finished with value: 0.5177865612648221 and parameters: {'svc_c': 74.7746816954322, 'svc_gamma': 5.419095217667932}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:18,595]\u001b[0m Trial 95 finished with value: 0.5434782608695652 and parameters: {'svc_c': 89.57213608876381, 'svc_gamma': 2.7244043843318804}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:18,943]\u001b[0m Trial 96 finished with value: 0.8399209486166008 and parameters: {'svc_c': 84.16031933674066, 'svc_gamma': 0.13814990885488615}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:19,390]\u001b[0m Trial 97 finished with value: 0.5197628458498024 and parameters: {'svc_c': 91.42950566974825, 'svc_gamma': 4.93476295601378}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:19,816]\u001b[0m Trial 98 finished with value: 0.5177865612648221 and parameters: {'svc_c': 98.30244586687475, 'svc_gamma': 7.544069978300236}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:20,262]\u001b[0m Trial 99 finished with value: 0.5177865612648221 and parameters: {'svc_c': 87.55919129919242, 'svc_gamma': 9.907378178807395}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:20,270]\u001b[0m A new study created in memory with name: no-name-39b321f9-5702-4f41-9342-47421ec59254\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "index  selected_features_all_best30       XGBClassifier            False   \n",
      "index  selected_features_all_best30      LGBMClassifier            False   \n",
      "index  selected_features_all_best30  LogisticRegression             True   \n",
      "index  selected_features_all_best30                 SVC             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "Optimizing selected_features_all_best30 XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:39:22,560]\u001b[0m Trial 0 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.15309337268637435, 'max_depth': 3, 'n_estimators': 993}. Best is trial 0 with value: 0.883399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:23,772]\u001b[0m Trial 1 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.22028169260786543, 'max_depth': 3, 'n_estimators': 496}. Best is trial 1 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:24,947]\u001b[0m Trial 2 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.14942829827562668, 'max_depth': 4, 'n_estimators': 392}. Best is trial 1 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:26,892]\u001b[0m Trial 3 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.04132576060911622, 'max_depth': 4, 'n_estimators': 502}. Best is trial 3 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:29,048]\u001b[0m Trial 4 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.20691986423971134, 'max_depth': 3, 'n_estimators': 966}. Best is trial 3 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:29,750]\u001b[0m Trial 5 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.1331776796999549, 'max_depth': 4, 'n_estimators': 216}. Best is trial 3 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:34,025]\u001b[0m Trial 6 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.01692933565588608, 'max_depth': 6, 'n_estimators': 824}. Best is trial 3 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:36,465]\u001b[0m Trial 7 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.1638122019388684, 'max_depth': 3, 'n_estimators': 823}. Best is trial 3 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:38,125]\u001b[0m Trial 8 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.27684692348726875, 'max_depth': 3, 'n_estimators': 680}. Best is trial 3 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:41,003]\u001b[0m Trial 9 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.1159715719060044, 'max_depth': 4, 'n_estimators': 981}. Best is trial 3 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:41,780]\u001b[0m Trial 10 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.014806307424100416, 'max_depth': 6, 'n_estimators': 109}. Best is trial 3 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:42,777]\u001b[0m Trial 11 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.07689986005498053, 'max_depth': 5, 'n_estimators': 226}. Best is trial 3 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:44,505]\u001b[0m Trial 12 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.07499909022825951, 'max_depth': 5, 'n_estimators': 327}. Best is trial 3 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:45,671]\u001b[0m Trial 13 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.056486770986670674, 'max_depth': 2, 'n_estimators': 576}. Best is trial 3 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:46,535]\u001b[0m Trial 14 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.10204292905866474, 'max_depth': 5, 'n_estimators': 206}. Best is trial 3 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:47,993]\u001b[0m Trial 15 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.05223640009387301, 'max_depth': 4, 'n_estimators': 425}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:49,041]\u001b[0m Trial 16 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.04853356355909669, 'max_depth': 2, 'n_estimators': 484}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:51,962]\u001b[0m Trial 17 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.043204507970566235, 'max_depth': 5, 'n_estimators': 627}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:54,382]\u001b[0m Trial 18 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.09542186631562881, 'max_depth': 5, 'n_estimators': 638}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:58,336]\u001b[0m Trial 19 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.015295342853059501, 'max_depth': 6, 'n_estimators': 722}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:59,907]\u001b[0m Trial 20 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.07541165005648509, 'max_depth': 5, 'n_estimators': 340}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:01,689]\u001b[0m Trial 21 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.041415126655961455, 'max_depth': 4, 'n_estimators': 458}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:03,944]\u001b[0m Trial 22 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.05556549111390849, 'max_depth': 4, 'n_estimators': 579}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:05,837]\u001b[0m Trial 23 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.06141184160596341, 'max_depth': 4, 'n_estimators': 574}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:09,063]\u001b[0m Trial 24 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.03285729279367465, 'max_depth': 5, 'n_estimators': 747}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:13,116]\u001b[0m Trial 25 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.023502010408716953, 'max_depth': 5, 'n_estimators': 776}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:16,728]\u001b[0m Trial 26 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.03832566062804142, 'max_depth': 6, 'n_estimators': 653}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:19,577]\u001b[0m Trial 27 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.08335952321883838, 'max_depth': 5, 'n_estimators': 739}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:23,380]\u001b[0m Trial 28 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.03215578148788725, 'max_depth': 5, 'n_estimators': 842}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:25,402]\u001b[0m Trial 29 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.0630922733594748, 'max_depth': 6, 'n_estimators': 410}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:28,319]\u001b[0m Trial 30 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.09845224135532113, 'max_depth': 5, 'n_estimators': 888}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:30,868]\u001b[0m Trial 31 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.010350215868469542, 'max_depth': 4, 'n_estimators': 598}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:32,793]\u001b[0m Trial 32 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.0552854870804811, 'max_depth': 4, 'n_estimators': 527}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:35,245]\u001b[0m Trial 33 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.031009371951054326, 'max_depth': 4, 'n_estimators': 625}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:37,611]\u001b[0m Trial 34 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.04064547733632328, 'max_depth': 3, 'n_estimators': 698}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:39,500]\u001b[0m Trial 35 finished with value: 0.9011857707509882 and parameters: {'learning_rate': 0.05933139707386613, 'max_depth': 4, 'n_estimators': 540}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:41,109]\u001b[0m Trial 36 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.035262629827263775, 'max_depth': 4, 'n_estimators': 429}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:42,257]\u001b[0m Trial 37 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.07045007043160426, 'max_depth': 3, 'n_estimators': 353}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:44,440]\u001b[0m Trial 38 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.04976108346394982, 'max_depth': 4, 'n_estimators': 525}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:48,100]\u001b[0m Trial 39 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.02582040716339055, 'max_depth': 5, 'n_estimators': 930}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:49,949]\u001b[0m Trial 40 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.12370929424233504, 'max_depth': 4, 'n_estimators': 463}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:51,459]\u001b[0m Trial 41 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.12638882167173518, 'max_depth': 4, 'n_estimators': 463}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:52,520]\u001b[0m Trial 42 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.12934441364567123, 'max_depth': 4, 'n_estimators': 285}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:54,208]\u001b[0m Trial 43 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.15343270747476392, 'max_depth': 3, 'n_estimators': 465}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:55,547]\u001b[0m Trial 44 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.16943173217739743, 'max_depth': 4, 'n_estimators': 396}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:56,958]\u001b[0m Trial 45 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.12846963141277673, 'max_depth': 3, 'n_estimators': 516}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:58,824]\u001b[0m Trial 46 finished with value: 0.9011857707509882 and parameters: {'learning_rate': 0.09254639621451684, 'max_depth': 4, 'n_estimators': 451}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:59,795]\u001b[0m Trial 47 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.09151882280184646, 'max_depth': 4, 'n_estimators': 293}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:00,746]\u001b[0m Trial 48 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.10811827422766677, 'max_depth': 3, 'n_estimators': 371}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:02,352]\u001b[0m Trial 49 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.0877771125623509, 'max_depth': 4, 'n_estimators': 441}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:04,386]\u001b[0m Trial 50 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.11082581960271255, 'max_depth': 4, 'n_estimators': 537}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:06,273]\u001b[0m Trial 51 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.1194828232008539, 'max_depth': 4, 'n_estimators': 483}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:07,603]\u001b[0m Trial 52 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.0837303963128758, 'max_depth': 4, 'n_estimators': 390}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:09,359]\u001b[0m Trial 53 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.0632441595450512, 'max_depth': 4, 'n_estimators': 505}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:11,278]\u001b[0m Trial 54 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.0712302833139265, 'max_depth': 4, 'n_estimators': 423}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:12,126]\u001b[0m Trial 55 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.14122632385628336, 'max_depth': 3, 'n_estimators': 309}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:16,145]\u001b[0m Trial 56 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.10188969833705805, 'max_depth': 5, 'n_estimators': 560}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:17,958]\u001b[0m Trial 57 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.11962581263867618, 'max_depth': 4, 'n_estimators': 471}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:18,637]\u001b[0m Trial 58 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.08237146279889011, 'max_depth': 3, 'n_estimators': 243}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:19,306]\u001b[0m Trial 59 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.0947942440694526, 'max_depth': 2, 'n_estimators': 368}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:21,155]\u001b[0m Trial 60 finished with value: 0.9011857707509882 and parameters: {'learning_rate': 0.048429943326810096, 'max_depth': 4, 'n_estimators': 446}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:22,757]\u001b[0m Trial 61 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.0468605058796996, 'max_depth': 4, 'n_estimators': 448}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:24,578]\u001b[0m Trial 62 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.02117081718053298, 'max_depth': 4, 'n_estimators': 493}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:26,356]\u001b[0m Trial 63 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.0631874197620102, 'max_depth': 4, 'n_estimators': 403}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:28,808]\u001b[0m Trial 64 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.05064102330809582, 'max_depth': 5, 'n_estimators': 602}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:30,703]\u001b[0m Trial 65 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.0736871193651559, 'max_depth': 4, 'n_estimators': 555}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:32,341]\u001b[0m Trial 66 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.028582026533660557, 'max_depth': 4, 'n_estimators': 455}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:35,177]\u001b[0m Trial 67 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.04321979066814, 'max_depth': 4, 'n_estimators': 770}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:37,410]\u001b[0m Trial 68 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.05726475691377695, 'max_depth': 5, 'n_estimators': 491}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:37,943]\u001b[0m Trial 69 finished with value: 0.8636363636363636 and parameters: {'learning_rate': 0.010052887324637251, 'max_depth': 4, 'n_estimators': 137}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:40,382]\u001b[0m Trial 70 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.06581792352871052, 'max_depth': 4, 'n_estimators': 657}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:40,982]\u001b[0m Trial 71 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.14274990225330567, 'max_depth': 2, 'n_estimators': 308}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:41,663]\u001b[0m Trial 72 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.14696584152875394, 'max_depth': 3, 'n_estimators': 252}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:42,517]\u001b[0m Trial 73 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.08117540425773286, 'max_depth': 3, 'n_estimators': 343}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:43,331]\u001b[0m Trial 74 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.0329390534756944, 'max_depth': 3, 'n_estimators': 321}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:45,521]\u001b[0m Trial 75 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.019997727911287753, 'max_depth': 6, 'n_estimators': 419}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:46,758]\u001b[0m Trial 76 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.13594459486708027, 'max_depth': 4, 'n_estimators': 370}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:48,965]\u001b[0m Trial 77 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.1655606340465659, 'max_depth': 5, 'n_estimators': 537}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:50,323]\u001b[0m Trial 78 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.09391488677993196, 'max_depth': 2, 'n_estimators': 598}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:51,177]\u001b[0m Trial 79 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.05297582895924331, 'max_depth': 5, 'n_estimators': 185}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:52,551]\u001b[0m Trial 80 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.10479132467159438, 'max_depth': 3, 'n_estimators': 512}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:55,743]\u001b[0m Trial 81 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.03903602454440884, 'max_depth': 5, 'n_estimators': 696}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:59,200]\u001b[0m Trial 82 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.03354611218785408, 'max_depth': 5, 'n_estimators': 777}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:02,358]\u001b[0m Trial 83 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.0409081127232557, 'max_depth': 5, 'n_estimators': 731}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:05,531]\u001b[0m Trial 84 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.05602833420165163, 'max_depth': 4, 'n_estimators': 795}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:08,488]\u001b[0m Trial 85 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.06574854749627393, 'max_depth': 6, 'n_estimators': 685}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:10,331]\u001b[0m Trial 86 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.04519412475700863, 'max_depth': 4, 'n_estimators': 476}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:13,499]\u001b[0m Trial 87 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.027127749334393998, 'max_depth': 4, 'n_estimators': 886}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:15,238]\u001b[0m Trial 88 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.11455087021644941, 'max_depth': 5, 'n_estimators': 433}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:17,259]\u001b[0m Trial 89 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.03852960777030704, 'max_depth': 4, 'n_estimators': 568}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:21,423]\u001b[0m Trial 90 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.01635664496864219, 'max_depth': 5, 'n_estimators': 849}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:24,791]\u001b[0m Trial 91 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.026333154759437274, 'max_depth': 4, 'n_estimators': 925}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:27,841]\u001b[0m Trial 92 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.04883018182791316, 'max_depth': 4, 'n_estimators': 853}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:31,303]\u001b[0m Trial 93 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.025585673228515824, 'max_depth': 4, 'n_estimators': 881}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:32,866]\u001b[0m Trial 94 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.03386851366219143, 'max_depth': 4, 'n_estimators': 391}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:35,468]\u001b[0m Trial 95 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.05792721010014622, 'max_depth': 4, 'n_estimators': 713}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:39,335]\u001b[0m Trial 96 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.07660692201605775, 'max_depth': 4, 'n_estimators': 952}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:41,313]\u001b[0m Trial 97 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.03750443692974461, 'max_depth': 4, 'n_estimators': 446}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:43,260]\u001b[0m Trial 98 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.0453011580863542, 'max_depth': 4, 'n_estimators': 544}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:46,234]\u001b[0m Trial 99 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.06946784152509414, 'max_depth': 5, 'n_estimators': 653}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:46,249]\u001b[0m A new study created in memory with name: no-name-6cb86842-649f-48d1-9777-aa98bae4a598\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "index  selected_features_all_best30       XGBClassifier            False   \n",
      "index  selected_features_all_best30      LGBMClassifier            False   \n",
      "index  selected_features_all_best30  LogisticRegression             True   \n",
      "index  selected_features_all_best30                 SVC             True   \n",
      "index  selected_features_all_best30       XGBClassifier             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "Optimizing selected_features_all_best30 LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:42:48,639]\u001b[0m Trial 0 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 151, 'max_depth': 46, 'learning_rate': 0.124478597224429, 'n_estimators': 1893}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:50,784]\u001b[0m Trial 1 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 137, 'max_depth': 18, 'learning_rate': 0.13594225171487398, 'n_estimators': 1698}. Best is trial 1 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:51,333]\u001b[0m Trial 2 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 141, 'max_depth': 11, 'learning_rate': 0.25414532320145833, 'n_estimators': 187}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:54,517]\u001b[0m Trial 3 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 219, 'max_depth': 45, 'learning_rate': 0.060002349042560445, 'n_estimators': 1210}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:55,893]\u001b[0m Trial 4 finished with value: 0.883399209486166 and parameters: {'num_leaves': 176, 'max_depth': 33, 'learning_rate': 0.10800270883786339, 'n_estimators': 333}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:56,579]\u001b[0m Trial 5 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 227, 'max_depth': 7, 'learning_rate': 0.11610164306041397, 'n_estimators': 261}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:59,328]\u001b[0m Trial 6 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 196, 'max_depth': 50, 'learning_rate': 0.017176347163758366, 'n_estimators': 469}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:04,798]\u001b[0m Trial 7 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 178, 'max_depth': 39, 'learning_rate': 0.028848395944330384, 'n_estimators': 1567}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:08,435]\u001b[0m Trial 8 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 201, 'max_depth': 50, 'learning_rate': 0.04929188588622131, 'n_estimators': 1537}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:10,295]\u001b[0m Trial 9 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 244, 'max_depth': 34, 'learning_rate': 0.23785250875386793, 'n_estimators': 1655}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:10,816]\u001b[0m Trial 10 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 48, 'max_depth': 3, 'learning_rate': 0.2606692182172288, 'n_estimators': 806}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:12,588]\u001b[0m Trial 11 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 86, 'max_depth': 20, 'learning_rate': 0.29927270938775724, 'n_estimators': 1152}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:14,014]\u001b[0m Trial 12 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 101, 'max_depth': 14, 'learning_rate': 0.17972893431230677, 'n_estimators': 765}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:16,268]\u001b[0m Trial 13 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 106, 'max_depth': 31, 'learning_rate': 0.1909248503726424, 'n_estimators': 1345}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:16,493]\u001b[0m Trial 14 finished with value: 0.8596837944664032 and parameters: {'num_leaves': 14, 'max_depth': 38, 'learning_rate': 0.011151576350973663, 'n_estimators': 101}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:18,185]\u001b[0m Trial 15 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 165, 'max_depth': 26, 'learning_rate': 0.18428520190639303, 'n_estimators': 845}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:21,228]\u001b[0m Trial 16 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 124, 'max_depth': 26, 'learning_rate': 0.07981219635376566, 'n_estimators': 1931}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:22,405]\u001b[0m Trial 17 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 183, 'max_depth': 11, 'learning_rate': 0.1649109934161007, 'n_estimators': 566}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:26,065]\u001b[0m Trial 18 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 71, 'max_depth': 42, 'learning_rate': 0.2177843846293956, 'n_estimators': 1379}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:26,833]\u001b[0m Trial 19 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 138, 'max_depth': 2, 'learning_rate': 0.1528765919109249, 'n_estimators': 1016}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:28,999]\u001b[0m Trial 20 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 162, 'max_depth': 21, 'learning_rate': 0.0916827811010677, 'n_estimators': 1006}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:30,845]\u001b[0m Trial 21 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 248, 'max_depth': 35, 'learning_rate': 0.23258660458051114, 'n_estimators': 1679}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:32,899]\u001b[0m Trial 22 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 235, 'max_depth': 39, 'learning_rate': 0.25996620955067273, 'n_estimators': 1699}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:34,554]\u001b[0m Trial 23 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 214, 'max_depth': 40, 'learning_rate': 0.2879713253895653, 'n_estimators': 1495}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:36,780]\u001b[0m Trial 24 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 195, 'max_depth': 29, 'learning_rate': 0.2688403703168566, 'n_estimators': 1814}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:39,214]\u001b[0m Trial 25 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 233, 'max_depth': 37, 'learning_rate': 0.20467931940650025, 'n_estimators': 1978}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:41,057]\u001b[0m Trial 26 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 255, 'max_depth': 43, 'learning_rate': 0.25049718776233687, 'n_estimators': 1361}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:42,647]\u001b[0m Trial 27 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 118, 'max_depth': 24, 'learning_rate': 0.27115468360343786, 'n_estimators': 1504}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:43,595]\u001b[0m Trial 28 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 146, 'max_depth': 13, 'learning_rate': 0.2149359254964525, 'n_estimators': 586}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:46,256]\u001b[0m Trial 29 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 162, 'max_depth': 30, 'learning_rate': 0.14930889513764817, 'n_estimators': 1880}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:48,434]\u001b[0m Trial 30 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 210, 'max_depth': 47, 'learning_rate': 0.24517765263825914, 'n_estimators': 1794}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:50,279]\u001b[0m Trial 31 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 234, 'max_depth': 36, 'learning_rate': 0.23746733874665196, 'n_estimators': 1673}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:52,339]\u001b[0m Trial 32 finished with value: 0.883399209486166 and parameters: {'num_leaves': 241, 'max_depth': 40, 'learning_rate': 0.22884699870994835, 'n_estimators': 1595}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:53,837]\u001b[0m Trial 33 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 177, 'max_depth': 33, 'learning_rate': 0.2800015052660114, 'n_estimators': 1281}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:55,717]\u001b[0m Trial 34 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 218, 'max_depth': 33, 'learning_rate': 0.2591883527178805, 'n_estimators': 1785}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:57,841]\u001b[0m Trial 35 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 150, 'max_depth': 42, 'learning_rate': 0.12926030169867445, 'n_estimators': 1168}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:59,559]\u001b[0m Trial 36 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 256, 'max_depth': 39, 'learning_rate': 0.25108674640938256, 'n_estimators': 1618}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:01,274]\u001b[0m Trial 37 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 192, 'max_depth': 47, 'learning_rate': 0.2967170706802925, 'n_estimators': 1428}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:01,848]\u001b[0m Trial 38 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 220, 'max_depth': 7, 'learning_rate': 0.27713932558926335, 'n_estimators': 316}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:04,233]\u001b[0m Trial 39 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 183, 'max_depth': 45, 'learning_rate': 0.2027956334629316, 'n_estimators': 1746}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:05,159]\u001b[0m Trial 40 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 207, 'max_depth': 17, 'learning_rate': 0.03556764463537364, 'n_estimators': 170}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:07,820]\u001b[0m Trial 41 finished with value: 0.883399209486166 and parameters: {'num_leaves': 132, 'max_depth': 8, 'learning_rate': 0.06281506139345308, 'n_estimators': 1587}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:10,368]\u001b[0m Trial 42 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 118, 'max_depth': 18, 'learning_rate': 0.11741527336269154, 'n_estimators': 1708}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:15,930]\u001b[0m Trial 43 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 99, 'max_depth': 10, 'learning_rate': 0.025713628925378033, 'n_estimators': 1879}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:22,667]\u001b[0m Trial 44 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 166, 'max_depth': 15, 'learning_rate': 0.007794669542473598, 'n_estimators': 1224}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:25,065]\u001b[0m Trial 45 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 68, 'max_depth': 21, 'learning_rate': 0.0953190831397989, 'n_estimators': 1427}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:27,234]\u001b[0m Trial 46 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 139, 'max_depth': 28, 'learning_rate': 0.1275709547360263, 'n_estimators': 1107}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:28,344]\u001b[0m Trial 47 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 226, 'max_depth': 35, 'learning_rate': 0.2598028857099704, 'n_estimators': 683}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:29,470]\u001b[0m Trial 48 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 13, 'max_depth': 24, 'learning_rate': 0.054620496398876534, 'n_estimators': 937}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:30,846]\u001b[0m Trial 49 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 107, 'max_depth': 32, 'learning_rate': 0.18333994431971506, 'n_estimators': 390}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:32,579]\u001b[0m Trial 50 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 152, 'max_depth': 50, 'learning_rate': 0.22460433554854317, 'n_estimators': 1524}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:33,933]\u001b[0m Trial 51 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 48, 'max_depth': 43, 'learning_rate': 0.2194520887775453, 'n_estimators': 1398}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:35,264]\u001b[0m Trial 52 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 47, 'max_depth': 5, 'learning_rate': 0.2398371916753913, 'n_estimators': 1273}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:37,410]\u001b[0m Trial 53 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 91, 'max_depth': 45, 'learning_rate': 0.19800991793428394, 'n_estimators': 1605}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:39,213]\u001b[0m Trial 54 finished with value: 0.883399209486166 and parameters: {'num_leaves': 77, 'max_depth': 41, 'learning_rate': 0.21455308094604753, 'n_estimators': 1678}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:41,133]\u001b[0m Trial 55 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 29, 'max_depth': 35, 'learning_rate': 0.1761660911610513, 'n_estimators': 1454}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:43,052]\u001b[0m Trial 56 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 244, 'max_depth': 38, 'learning_rate': 0.2303475142748954, 'n_estimators': 1842}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:45,199]\u001b[0m Trial 57 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 126, 'max_depth': 43, 'learning_rate': 0.24219458565698004, 'n_estimators': 1940}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:47,445]\u001b[0m Trial 58 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 111, 'max_depth': 12, 'learning_rate': 0.26584824261432155, 'n_estimators': 1332}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:49,238]\u001b[0m Trial 59 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 199, 'max_depth': 16, 'learning_rate': 0.2550723303630239, 'n_estimators': 1745}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:51,048]\u001b[0m Trial 60 finished with value: 0.883399209486166 and parameters: {'num_leaves': 63, 'max_depth': 19, 'learning_rate': 0.21030325961747692, 'n_estimators': 1535}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:51,465]\u001b[0m Trial 61 finished with value: 0.883399209486166 and parameters: {'num_leaves': 139, 'max_depth': 2, 'learning_rate': 0.1627478999701727, 'n_estimators': 1017}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:52,683]\u001b[0m Trial 62 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 171, 'max_depth': 4, 'learning_rate': 0.19431248718560248, 'n_estimators': 1642}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:55,133]\u001b[0m Trial 63 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 153, 'max_depth': 23, 'learning_rate': 0.06770019060883609, 'n_estimators': 469}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:56,665]\u001b[0m Trial 64 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 136, 'max_depth': 10, 'learning_rate': 0.13956843538889796, 'n_estimators': 826}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:59,032]\u001b[0m Trial 65 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 157, 'max_depth': 37, 'learning_rate': 0.10967540944446222, 'n_estimators': 883}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:00,630]\u001b[0m Trial 66 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 122, 'max_depth': 6, 'learning_rate': 0.24606917756337318, 'n_estimators': 1755}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:02,500]\u001b[0m Trial 67 finished with value: 0.883399209486166 and parameters: {'num_leaves': 143, 'max_depth': 27, 'learning_rate': 0.22260685005765346, 'n_estimators': 1573}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:04,693]\u001b[0m Trial 68 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 186, 'max_depth': 40, 'learning_rate': 0.09979217202775412, 'n_estimators': 637}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:05,660]\u001b[0m Trial 69 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 235, 'max_depth': 8, 'learning_rate': 0.2333534641349258, 'n_estimators': 768}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:07,952]\u001b[0m Trial 70 finished with value: 0.883399209486166 and parameters: {'num_leaves': 173, 'max_depth': 14, 'learning_rate': 0.18937963008461842, 'n_estimators': 1997}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:08,433]\u001b[0m Trial 71 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 217, 'max_depth': 7, 'learning_rate': 0.27525001357259027, 'n_estimators': 248}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:08,664]\u001b[0m Trial 72 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 228, 'max_depth': 3, 'learning_rate': 0.28652739175909947, 'n_estimators': 295}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:09,140]\u001b[0m Trial 73 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 208, 'max_depth': 10, 'learning_rate': 0.2678625570342841, 'n_estimators': 128}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:09,465]\u001b[0m Trial 74 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 249, 'max_depth': 5, 'learning_rate': 0.24897057471032233, 'n_estimators': 204}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:09,674]\u001b[0m Trial 75 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 224, 'max_depth': 2, 'learning_rate': 0.0818102962354943, 'n_estimators': 389}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:11,506]\u001b[0m Trial 76 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 236, 'max_depth': 38, 'learning_rate': 0.26234909011688423, 'n_estimators': 1840}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:13,729]\u001b[0m Trial 77 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 114, 'max_depth': 48, 'learning_rate': 0.27581366765302884, 'n_estimators': 1704}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:21,718]\u001b[0m Trial 78 finished with value: 0.8754940711462451 and parameters: {'num_leaves': 129, 'max_depth': 41, 'learning_rate': 0.00256175429595807, 'n_estimators': 1495}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:23,212]\u001b[0m Trial 79 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 98, 'max_depth': 9, 'learning_rate': 0.2542820047786321, 'n_estimators': 1113}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:24,044]\u001b[0m Trial 80 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 188, 'max_depth': 30, 'learning_rate': 0.23489379900419766, 'n_estimators': 351}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:27,029]\u001b[0m Trial 81 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 145, 'max_depth': 18, 'learning_rate': 0.11341372566196965, 'n_estimators': 1636}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:29,762]\u001b[0m Trial 82 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 118, 'max_depth': 21, 'learning_rate': 0.11957874106056524, 'n_estimators': 1713}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:32,068]\u001b[0m Trial 83 finished with value: 0.883399209486166 and parameters: {'num_leaves': 160, 'max_depth': 44, 'learning_rate': 0.1348357021323244, 'n_estimators': 1800}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:34,724]\u001b[0m Trial 84 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 252, 'max_depth': 12, 'learning_rate': 0.11723838326543642, 'n_estimators': 1566}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:36,260]\u001b[0m Trial 85 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 82, 'max_depth': 34, 'learning_rate': 0.16553961764058753, 'n_estimators': 524}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:38,381]\u001b[0m Trial 86 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 35, 'max_depth': 15, 'learning_rate': 0.1486873109325388, 'n_estimators': 1674}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:42,083]\u001b[0m Trial 87 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 241, 'max_depth': 39, 'learning_rate': 0.048032507778536515, 'n_estimators': 1385}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:44,728]\u001b[0m Trial 88 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 132, 'max_depth': 36, 'learning_rate': 0.10691405871237478, 'n_estimators': 1477}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:46,807]\u001b[0m Trial 89 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 201, 'max_depth': 7, 'learning_rate': 0.23975699284451585, 'n_estimators': 1916}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:49,329]\u001b[0m Trial 90 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 177, 'max_depth': 42, 'learning_rate': 0.2056087244271001, 'n_estimators': 1722}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:50,997]\u001b[0m Trial 91 finished with value: 0.883399209486166 and parameters: {'num_leaves': 152, 'max_depth': 23, 'learning_rate': 0.06350957588537785, 'n_estimators': 271}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:52,666]\u001b[0m Trial 92 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 167, 'max_depth': 20, 'learning_rate': 0.12210514077919671, 'n_estimators': 466}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:53,747]\u001b[0m Trial 93 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 155, 'max_depth': 24, 'learning_rate': 0.017982910136485564, 'n_estimators': 206}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:54,875]\u001b[0m Trial 94 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 147, 'max_depth': 22, 'learning_rate': 0.2626342678126744, 'n_estimators': 471}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:55,529]\u001b[0m Trial 95 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 121, 'max_depth': 17, 'learning_rate': 0.25114948636434575, 'n_estimators': 113}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:56,002]\u001b[0m Trial 96 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 3, 'max_depth': 13, 'learning_rate': 0.12975932405905505, 'n_estimators': 1312}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:56,772]\u001b[0m Trial 97 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 135, 'max_depth': 25, 'learning_rate': 0.2827124431379691, 'n_estimators': 328}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:59,511]\u001b[0m Trial 98 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 106, 'max_depth': 18, 'learning_rate': 0.08688611497290284, 'n_estimators': 1207}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:01,239]\u001b[0m Trial 99 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 142, 'max_depth': 4, 'learning_rate': 0.07234447291974583, 'n_estimators': 1655}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "index  selected_features_all_best30       XGBClassifier            False   \n",
      "index  selected_features_all_best30      LGBMClassifier            False   \n",
      "index  selected_features_all_best30  LogisticRegression             True   \n",
      "index  selected_features_all_best30                 SVC             True   \n",
      "index  selected_features_all_best30       XGBClassifier             True   \n",
      "index  selected_features_all_best30      LGBMClassifier             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "Evaluating selected_features_all_best50 LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "index  selected_features_all_best30       XGBClassifier            False   \n",
      "index  selected_features_all_best30      LGBMClassifier            False   \n",
      "index  selected_features_all_best30  LogisticRegression             True   \n",
      "index  selected_features_all_best30                 SVC             True   \n",
      "index  selected_features_all_best30       XGBClassifier             True   \n",
      "index  selected_features_all_best30      LGBMClassifier             True   \n",
      "index  selected_features_all_best50  LogisticRegression            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "Evaluating selected_features_all_best50 SVC\n",
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "index  selected_features_all_best30       XGBClassifier            False   \n",
      "index  selected_features_all_best30      LGBMClassifier            False   \n",
      "index  selected_features_all_best30  LogisticRegression             True   \n",
      "index  selected_features_all_best30                 SVC             True   \n",
      "index  selected_features_all_best30       XGBClassifier             True   \n",
      "index  selected_features_all_best30      LGBMClassifier             True   \n",
      "index  selected_features_all_best50  LogisticRegression            False   \n",
      "index  selected_features_all_best50                 SVC            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "Evaluating selected_features_all_best50 XGBClassifier\n",
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "index  selected_features_all_best30       XGBClassifier            False   \n",
      "index  selected_features_all_best30      LGBMClassifier            False   \n",
      "index  selected_features_all_best30  LogisticRegression             True   \n",
      "index  selected_features_all_best30                 SVC             True   \n",
      "index  selected_features_all_best30       XGBClassifier             True   \n",
      "index  selected_features_all_best30      LGBMClassifier             True   \n",
      "index  selected_features_all_best50  LogisticRegression            False   \n",
      "index  selected_features_all_best50                 SVC            False   \n",
      "index  selected_features_all_best50       XGBClassifier            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "index                                               None  0.889811   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "index     0.844898     0.923372   0.911894  0.877119  0.771973   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_no_...  \n",
      "Evaluating selected_features_all_best50 LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:46:12,598]\u001b[0m A new study created in memory with name: no-name-c3ef2b8a-55f4-4ddc-b565-7e3c9cc3467b\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:12,670]\u001b[0m Trial 0 finished with value: 0.8774703557312253 and parameters: {'C': 0.08582067856630485, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 790}. Best is trial 0 with value: 0.8774703557312253.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "index  selected_features_all_best30       XGBClassifier            False   \n",
      "index  selected_features_all_best30      LGBMClassifier            False   \n",
      "index  selected_features_all_best30  LogisticRegression             True   \n",
      "index  selected_features_all_best30                 SVC             True   \n",
      "index  selected_features_all_best30       XGBClassifier             True   \n",
      "index  selected_features_all_best30      LGBMClassifier             True   \n",
      "index  selected_features_all_best50  LogisticRegression            False   \n",
      "index  selected_features_all_best50                 SVC            False   \n",
      "index  selected_features_all_best50       XGBClassifier            False   \n",
      "index  selected_features_all_best50      LGBMClassifier            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.888807   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "index     0.844898     0.923372   0.911894  0.877119  0.771973   \n",
      "index     0.840816     0.923372   0.911504  0.874735  0.768193   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_no_...  \n",
      "index  selected_features_all_best50_LGBMClassifier_no...  \n",
      "Optimizing selected_features_all_best50 LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:46:13,055]\u001b[0m Trial 1 finished with value: 0.8814229249011858 and parameters: {'C': 0.04575595001292701, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 614}. Best is trial 1 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:13,096]\u001b[0m Trial 2 finished with value: 0.8794466403162056 and parameters: {'C': 0.05986810018960859, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 825}. Best is trial 1 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:13,126]\u001b[0m Trial 3 finished with value: 0.8636363636363636 and parameters: {'C': 0.014235066072406884, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 353}. Best is trial 1 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:13,163]\u001b[0m Trial 4 finished with value: 0.8814229249011858 and parameters: {'C': 0.01703248903658563, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 984}. Best is trial 1 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:13,202]\u001b[0m Trial 5 finished with value: 0.883399209486166 and parameters: {'C': 0.04409940316088003, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 231}. Best is trial 5 with value: 0.883399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:13,474]\u001b[0m Trial 6 finished with value: 0.8814229249011858 and parameters: {'C': 0.0305045861308162, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 316}. Best is trial 5 with value: 0.883399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:14,902]\u001b[0m Trial 7 finished with value: 0.8893280632411067 and parameters: {'C': 0.024422805336610946, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 670}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:15,492]\u001b[0m Trial 8 finished with value: 0.883399209486166 and parameters: {'C': 0.01650557576780878, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 572}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:15,536]\u001b[0m Trial 9 finished with value: 0.8774703557312253 and parameters: {'C': 0.07926537686102536, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 414}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:46:15,850]\u001b[0m Trial 10 finished with value: 0.8873517786561265 and parameters: {'C': 0.09808077720532851, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 122}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:46:16,120]\u001b[0m Trial 11 finished with value: 0.8873517786561265 and parameters: {'C': 0.0964859451775026, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 100}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:16,683]\u001b[0m Trial 12 finished with value: 0.8873517786561265 and parameters: {'C': 0.06601531179131047, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 701}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:17,349]\u001b[0m Trial 13 finished with value: 0.8873517786561265 and parameters: {'C': 0.09975983861167052, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 512}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:46:17,734]\u001b[0m Trial 14 finished with value: 0.8774703557312253 and parameters: {'C': 0.07114552958850356, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 173}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:18,125]\u001b[0m Trial 15 finished with value: 0.8853754940711462 and parameters: {'C': 0.05035413019434068, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 463}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:46:19,829]\u001b[0m Trial 16 finished with value: 0.8814229249011858 and parameters: {'C': 0.03457417929038219, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 674}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:20,371]\u001b[0m Trial 17 finished with value: 0.8853754940711462 and parameters: {'C': 0.055817726518791494, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 936}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:46:22,227]\u001b[0m Trial 18 finished with value: 0.8754940711462451 and parameters: {'C': 0.08550976773615715, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 764}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:22,795]\u001b[0m Trial 19 finished with value: 0.8873517786561265 and parameters: {'C': 0.06935632384903487, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 891}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:46:23,448]\u001b[0m Trial 20 finished with value: 0.8794466403162056 and parameters: {'C': 0.03276830994370866, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 269}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:46:23,818]\u001b[0m Trial 21 finished with value: 0.8873517786561265 and parameters: {'C': 0.09663918416806704, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 152}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:46:24,083]\u001b[0m Trial 22 finished with value: 0.8873517786561265 and parameters: {'C': 0.0920346179798913, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 109}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:46:24,548]\u001b[0m Trial 23 finished with value: 0.8873517786561265 and parameters: {'C': 0.07806337781157077, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 219}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:25,204]\u001b[0m Trial 24 finished with value: 0.8873517786561265 and parameters: {'C': 0.09868447267704249, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 369}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:46:25,448]\u001b[0m Trial 25 finished with value: 0.8873517786561265 and parameters: {'C': 0.08919649426820317, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 103}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:26,112]\u001b[0m Trial 26 finished with value: 0.8873517786561265 and parameters: {'C': 0.0925818934117907, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 645}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:26,707]\u001b[0m Trial 27 finished with value: 0.8873517786561265 and parameters: {'C': 0.08105848590879432, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 537}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:46:27,664]\u001b[0m Trial 28 finished with value: 0.8754940711462451 and parameters: {'C': 0.07406697157263506, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 448}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:27,709]\u001b[0m Trial 29 finished with value: 0.8774703557312253 and parameters: {'C': 0.08383148482511989, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 733}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:46:28,276]\u001b[0m Trial 30 finished with value: 0.8873517786561265 and parameters: {'C': 0.09006204730362609, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 294}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:28,761]\u001b[0m Trial 31 finished with value: 0.8873517786561265 and parameters: {'C': 0.06435983030827092, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 706}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:29,367]\u001b[0m Trial 32 finished with value: 0.8873517786561265 and parameters: {'C': 0.08524461629010645, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 804}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:29,894]\u001b[0m Trial 33 finished with value: 0.8873517786561265 and parameters: {'C': 0.06555148564957791, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 599}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:46:30,290]\u001b[0m Trial 34 finished with value: 0.8873517786561265 and parameters: {'C': 0.07759166729764307, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 187}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:30,349]\u001b[0m Trial 35 finished with value: 0.8893280632411067 and parameters: {'C': 0.09583796500662806, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 673}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:30,406]\u001b[0m Trial 36 finished with value: 0.8774703557312253 and parameters: {'C': 0.09307511754664655, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 849}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:30,473]\u001b[0m Trial 37 finished with value: 0.8893280632411067 and parameters: {'C': 0.09685543204990817, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 618}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:30,548]\u001b[0m Trial 38 finished with value: 0.8893280632411067 and parameters: {'C': 0.08768758280428067, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 633}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:30,606]\u001b[0m Trial 39 finished with value: 0.8774703557312253 and parameters: {'C': 0.08454143379882442, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 639}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:30,654]\u001b[0m Trial 40 finished with value: 0.8754940711462451 and parameters: {'C': 0.010221679890305521, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 582}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:30,717]\u001b[0m Trial 41 finished with value: 0.8893280632411067 and parameters: {'C': 0.09984298423084186, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 761}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:30,777]\u001b[0m Trial 42 finished with value: 0.8893280632411067 and parameters: {'C': 0.09451104044885447, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 768}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:30,835]\u001b[0m Trial 43 finished with value: 0.8893280632411067 and parameters: {'C': 0.08975373048797732, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 659}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:30,896]\u001b[0m Trial 44 finished with value: 0.8893280632411067 and parameters: {'C': 0.09961952042194742, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 511}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:30,957]\u001b[0m Trial 45 finished with value: 0.8893280632411067 and parameters: {'C': 0.08930313059308372, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 731}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:31,007]\u001b[0m Trial 46 finished with value: 0.8774703557312253 and parameters: {'C': 0.09503322728098948, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 836}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:31,066]\u001b[0m Trial 47 finished with value: 0.8893280632411067 and parameters: {'C': 0.09971588471774986, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 615}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:31,114]\u001b[0m Trial 48 finished with value: 0.8794466403162056 and parameters: {'C': 0.022031907988338054, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 543}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:31,182]\u001b[0m Trial 49 finished with value: 0.8774703557312253 and parameters: {'C': 0.0955002990444305, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 712}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:31,243]\u001b[0m Trial 50 finished with value: 0.8893280632411067 and parameters: {'C': 0.08808292529875406, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 789}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:31,317]\u001b[0m Trial 51 finished with value: 0.8893280632411067 and parameters: {'C': 0.0946054519979635, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 748}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:31,394]\u001b[0m Trial 52 finished with value: 0.8893280632411067 and parameters: {'C': 0.09309854237702367, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 680}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:31,474]\u001b[0m Trial 53 finished with value: 0.8893280632411067 and parameters: {'C': 0.09564715802670763, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 876}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:31,571]\u001b[0m Trial 54 finished with value: 0.8873517786561265 and parameters: {'C': 0.08639446135222627, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 764}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:31,670]\u001b[0m Trial 55 finished with value: 0.8873517786561265 and parameters: {'C': 0.08288480859170431, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 625}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:31,745]\u001b[0m Trial 56 finished with value: 0.8794466403162056 and parameters: {'C': 0.09988969468973924, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 675}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:31,811]\u001b[0m Trial 57 finished with value: 0.8893280632411067 and parameters: {'C': 0.041420143794679135, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 798}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:31,881]\u001b[0m Trial 58 finished with value: 0.8893280632411067 and parameters: {'C': 0.09102959221544998, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 572}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:31,947]\u001b[0m Trial 59 finished with value: 0.8893280632411067 and parameters: {'C': 0.09649515688973659, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 986}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,014]\u001b[0m Trial 60 finished with value: 0.8774703557312253 and parameters: {'C': 0.08787313494794527, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 929}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,079]\u001b[0m Trial 61 finished with value: 0.8893280632411067 and parameters: {'C': 0.09226643402027108, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 637}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,143]\u001b[0m Trial 62 finished with value: 0.8853754940711462 and parameters: {'C': 0.08119960563875005, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 680}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,203]\u001b[0m Trial 63 finished with value: 0.8893280632411067 and parameters: {'C': 0.08982294892602871, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 668}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,268]\u001b[0m Trial 64 finished with value: 0.8893280632411067 and parameters: {'C': 0.09662565119653509, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 772}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,335]\u001b[0m Trial 65 finished with value: 0.8873517786561265 and parameters: {'C': 0.08637651002134569, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 488}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,399]\u001b[0m Trial 66 finished with value: 0.8893280632411067 and parameters: {'C': 0.09377678565231955, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 594}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,480]\u001b[0m Trial 67 finished with value: 0.8893280632411067 and parameters: {'C': 0.097289217347999, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 652}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,555]\u001b[0m Trial 68 finished with value: 0.8774703557312253 and parameters: {'C': 0.09134077741266249, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 707}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,633]\u001b[0m Trial 69 finished with value: 0.8853754940711462 and parameters: {'C': 0.05361154598795756, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 739}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,695]\u001b[0m Trial 70 finished with value: 0.8853754940711462 and parameters: {'C': 0.0764544704807992, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 570}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,756]\u001b[0m Trial 71 finished with value: 0.8893280632411067 and parameters: {'C': 0.09929700037539269, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 507}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,836]\u001b[0m Trial 72 finished with value: 0.8893280632411067 and parameters: {'C': 0.0978546479106677, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 415}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,901]\u001b[0m Trial 73 finished with value: 0.8893280632411067 and parameters: {'C': 0.0937583023454733, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 540}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,967]\u001b[0m Trial 74 finished with value: 0.8893280632411067 and parameters: {'C': 0.09979574697294216, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 607}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:33,046]\u001b[0m Trial 75 finished with value: 0.8893280632411067 and parameters: {'C': 0.09045153325372077, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 693}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:33,111]\u001b[0m Trial 76 finished with value: 0.8893280632411067 and parameters: {'C': 0.08783488217244072, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 655}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:33,178]\u001b[0m Trial 77 finished with value: 0.8774703557312253 and parameters: {'C': 0.09665901922583311, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 521}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:33,252]\u001b[0m Trial 78 finished with value: 0.8873517786561265 and parameters: {'C': 0.0830362796779517, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 458}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:33,322]\u001b[0m Trial 79 finished with value: 0.8893280632411067 and parameters: {'C': 0.09364793455013652, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 818}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:33,381]\u001b[0m Trial 80 finished with value: 0.8893280632411067 and parameters: {'C': 0.091143371526798, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 714}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:33,443]\u001b[0m Trial 81 finished with value: 0.8893280632411067 and parameters: {'C': 0.08890368116203812, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 730}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:33,507]\u001b[0m Trial 82 finished with value: 0.8893280632411067 and parameters: {'C': 0.09732614356215283, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 617}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:33,570]\u001b[0m Trial 83 finished with value: 0.8893280632411067 and parameters: {'C': 0.09482193263606808, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 758}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:33,635]\u001b[0m Trial 84 finished with value: 0.8873517786561265 and parameters: {'C': 0.08566711067071164, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 727}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:33,697]\u001b[0m Trial 85 finished with value: 0.8794466403162056 and parameters: {'C': 0.09999621375660517, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 561}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:33,759]\u001b[0m Trial 86 finished with value: 0.8893280632411067 and parameters: {'C': 0.08891694538606906, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 861}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:34,421]\u001b[0m Trial 87 finished with value: 0.8873517786561265 and parameters: {'C': 0.09188625950191667, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 786}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:34,492]\u001b[0m Trial 88 finished with value: 0.8893280632411067 and parameters: {'C': 0.09517847261413138, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 662}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:34,550]\u001b[0m Trial 89 finished with value: 0.8774703557312253 and parameters: {'C': 0.0979703026693422, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 697}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:34,615]\u001b[0m Trial 90 finished with value: 0.8853754940711462 and parameters: {'C': 0.08095836931932832, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 630}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:34,680]\u001b[0m Trial 91 finished with value: 0.8893280632411067 and parameters: {'C': 0.09800647325162831, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 591}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:34,744]\u001b[0m Trial 92 finished with value: 0.8893280632411067 and parameters: {'C': 0.09476185579344343, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 616}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:34,827]\u001b[0m Trial 93 finished with value: 0.8893280632411067 and parameters: {'C': 0.09241057472320813, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 648}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:34,915]\u001b[0m Trial 94 finished with value: 0.8893280632411067 and parameters: {'C': 0.09987596885035735, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 821}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:35,651]\u001b[0m Trial 95 finished with value: 0.8873517786561265 and parameters: {'C': 0.0872642787675507, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 687}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:35,728]\u001b[0m Trial 96 finished with value: 0.8893280632411067 and parameters: {'C': 0.09553047005731004, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 777}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:35,805]\u001b[0m Trial 97 finished with value: 0.8893280632411067 and parameters: {'C': 0.08896970489439683, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 479}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:35,883]\u001b[0m Trial 98 finished with value: 0.8893280632411067 and parameters: {'C': 0.09291850541198267, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 720}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:46:37,263]\u001b[0m Trial 99 finished with value: 0.8754940711462451 and parameters: {'C': 0.09711024832893216, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 558}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:37,275]\u001b[0m A new study created in memory with name: no-name-9baff3fb-2474-47e2-a7d5-90e55b59e8b9\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "index  selected_features_all_best30       XGBClassifier            False   \n",
      "index  selected_features_all_best30      LGBMClassifier            False   \n",
      "index  selected_features_all_best30  LogisticRegression             True   \n",
      "index  selected_features_all_best30                 SVC             True   \n",
      "index  selected_features_all_best30       XGBClassifier             True   \n",
      "index  selected_features_all_best30      LGBMClassifier             True   \n",
      "index  selected_features_all_best50  LogisticRegression            False   \n",
      "index  selected_features_all_best50                 SVC            False   \n",
      "index  selected_features_all_best50       XGBClassifier            False   \n",
      "index  selected_features_all_best50      LGBMClassifier            False   \n",
      "index  selected_features_all_best50  LogisticRegression             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.888807   \n",
      "index  {'C': 0.024422805336610946, 'penalty': 'l1', '...  0.889328   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "index     0.844898     0.923372   0.911894  0.877119  0.771973   \n",
      "index     0.840816     0.923372   0.911504  0.874735  0.768193   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_no_...  \n",
      "index  selected_features_all_best50_LGBMClassifier_no...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "Optimizing selected_features_all_best50 SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:46:37,959]\u001b[0m Trial 0 finished with value: 0.5177865612648221 and parameters: {'svc_c': 40.793552289548295, 'svc_gamma': 12.001104843654636}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:38,414]\u001b[0m Trial 1 finished with value: 0.5138339920948617 and parameters: {'svc_c': 58.707983744808175, 'svc_gamma': 99.07600808314264}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:39,087]\u001b[0m Trial 2 finished with value: 0.5177865612648221 and parameters: {'svc_c': 17.864641376687583, 'svc_gamma': 25.242611630690515}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:39,641]\u001b[0m Trial 3 finished with value: 0.5177865612648221 and parameters: {'svc_c': 98.56400962744742, 'svc_gamma': 44.6188513506334}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:40,244]\u001b[0m Trial 4 finished with value: 0.5177865612648221 and parameters: {'svc_c': 45.454149872922336, 'svc_gamma': 21.408257230042246}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:40,765]\u001b[0m Trial 5 finished with value: 0.5158102766798419 and parameters: {'svc_c': 48.673384105051554, 'svc_gamma': 79.3852485300747}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:41,240]\u001b[0m Trial 6 finished with value: 0.5158102766798419 and parameters: {'svc_c': 64.94990696291977, 'svc_gamma': 64.66940457967901}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:41,784]\u001b[0m Trial 7 finished with value: 0.5158102766798419 and parameters: {'svc_c': 88.65463003156906, 'svc_gamma': 64.71666352002408}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:42,330]\u001b[0m Trial 8 finished with value: 0.5158102766798419 and parameters: {'svc_c': 36.688547231224206, 'svc_gamma': 55.09283922029419}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:42,820]\u001b[0m Trial 9 finished with value: 0.5158102766798419 and parameters: {'svc_c': 23.465857420754272, 'svc_gamma': 63.376296078115}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:43,357]\u001b[0m Trial 10 finished with value: 0.5197628458498024 and parameters: {'svc_c': 6.6878321823533255, 'svc_gamma': 2.7813053211138126}. Best is trial 10 with value: 0.5197628458498024.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 11:46:43,820]\u001b[0m Trial 11 finished with value: 0.5158102766798419 and parameters: {'svc_c': 0.24146524987228268, 'svc_gamma': 0.4863051859183143}. Best is trial 10 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:44,429]\u001b[0m Trial 12 finished with value: 0.5177865612648221 and parameters: {'svc_c': 6.673669490772514, 'svc_gamma': 4.758409502037182}. Best is trial 10 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:44,996]\u001b[0m Trial 13 finished with value: 0.5177865612648221 and parameters: {'svc_c': 21.473225606968285, 'svc_gamma': 17.016105362588863}. Best is trial 10 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:45,575]\u001b[0m Trial 14 finished with value: 0.5177865612648221 and parameters: {'svc_c': 35.23962085544444, 'svc_gamma': 36.89404104202824}. Best is trial 10 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:46,170]\u001b[0m Trial 15 finished with value: 0.5177865612648221 and parameters: {'svc_c': 9.476036368977137, 'svc_gamma': 10.891367935294326}. Best is trial 10 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:46,863]\u001b[0m Trial 16 finished with value: 0.5177865612648221 and parameters: {'svc_c': 28.754733713909992, 'svc_gamma': 29.566057239337105}. Best is trial 10 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:47,469]\u001b[0m Trial 17 finished with value: 0.5177865612648221 and parameters: {'svc_c': 13.290388597701643, 'svc_gamma': 11.46496817026582}. Best is trial 10 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:48,094]\u001b[0m Trial 18 finished with value: 0.525691699604743 and parameters: {'svc_c': 2.7920914148728713, 'svc_gamma': 1.6821305039510488}. Best is trial 18 with value: 0.525691699604743.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:48,625]\u001b[0m Trial 19 finished with value: 0.5849802371541502 and parameters: {'svc_c': 1.6255774078512009, 'svc_gamma': 0.8517173189704099}. Best is trial 19 with value: 0.5849802371541502.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:49,152]\u001b[0m Trial 20 finished with value: 0.5177865612648221 and parameters: {'svc_c': 2.4052653458834743, 'svc_gamma': 31.752378788367558}. Best is trial 19 with value: 0.5849802371541502.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 11:46:49,785]\u001b[0m Trial 21 finished with value: 0.5158102766798419 and parameters: {'svc_c': 0.2724049296922506, 'svc_gamma': 1.0210160637711567}. Best is trial 19 with value: 0.5849802371541502.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:50,459]\u001b[0m Trial 22 finished with value: 0.5177865612648221 and parameters: {'svc_c': 12.98686674369452, 'svc_gamma': 17.78382912708701}. Best is trial 19 with value: 0.5849802371541502.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:51,089]\u001b[0m Trial 23 finished with value: 0.5177865612648221 and parameters: {'svc_c': 9.270590824365524, 'svc_gamma': 6.354279705627924}. Best is trial 19 with value: 0.5849802371541502.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:51,722]\u001b[0m Trial 24 finished with value: 0.5177865612648221 and parameters: {'svc_c': 17.504419865850757, 'svc_gamma': 18.59407253287751}. Best is trial 19 with value: 0.5849802371541502.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:52,355]\u001b[0m Trial 25 finished with value: 0.5177865612648221 and parameters: {'svc_c': 26.46466993860618, 'svc_gamma': 7.0698534056025855}. Best is trial 19 with value: 0.5849802371541502.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:52,859]\u001b[0m Trial 26 finished with value: 0.7687747035573123 and parameters: {'svc_c': 6.9473662078437926, 'svc_gamma': 0.3156473166395858}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:53,362]\u001b[0m Trial 27 finished with value: 0.7490118577075099 and parameters: {'svc_c': 15.104327136912802, 'svc_gamma': 0.4108254885984106}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:54,042]\u001b[0m Trial 28 finished with value: 0.5177865612648221 and parameters: {'svc_c': 14.996113958216313, 'svc_gamma': 25.921990330695536}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:54,626]\u001b[0m Trial 29 finished with value: 0.5177865612648221 and parameters: {'svc_c': 27.652440480428478, 'svc_gamma': 13.282010538484386}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:55,276]\u001b[0m Trial 30 finished with value: 0.5177865612648221 and parameters: {'svc_c': 18.38958113720214, 'svc_gamma': 12.22318102854208}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:55,861]\u001b[0m Trial 31 finished with value: 0.5869565217391305 and parameters: {'svc_c': 5.370191582823168, 'svc_gamma': 0.8336222574036899}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:56,429]\u001b[0m Trial 32 finished with value: 0.5177865612648221 and parameters: {'svc_c': 8.90978667782177, 'svc_gamma': 8.899533234218794}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:56,907]\u001b[0m Trial 33 finished with value: 0.6600790513833992 and parameters: {'svc_c': 12.902787950386108, 'svc_gamma': 0.608193023100803}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:57,552]\u001b[0m Trial 34 finished with value: 0.5177865612648221 and parameters: {'svc_c': 14.961965798835456, 'svc_gamma': 9.750093114591015}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:58,268]\u001b[0m Trial 35 finished with value: 0.5177865612648221 and parameters: {'svc_c': 22.6611713639675, 'svc_gamma': 20.55379464547858}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:58,907]\u001b[0m Trial 36 finished with value: 0.5177865612648221 and parameters: {'svc_c': 11.990664625775093, 'svc_gamma': 15.223059439334758}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:59,545]\u001b[0m Trial 37 finished with value: 0.5177865612648221 and parameters: {'svc_c': 18.597850478415115, 'svc_gamma': 6.809491968988338}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:00,119]\u001b[0m Trial 38 finished with value: 0.5177865612648221 and parameters: {'svc_c': 6.146355152984121, 'svc_gamma': 24.032174578234553}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:00,863]\u001b[0m Trial 39 finished with value: 0.5177865612648221 and parameters: {'svc_c': 28.46076291091541, 'svc_gamma': 14.273875561702802}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:01,405]\u001b[0m Trial 40 finished with value: 0.5177865612648221 and parameters: {'svc_c': 33.1213450516107, 'svc_gamma': 5.648670815036355}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:01,869]\u001b[0m Trial 41 finished with value: 0.6857707509881423 and parameters: {'svc_c': 4.83425618594214, 'svc_gamma': 0.5421653085835272}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:02,490]\u001b[0m Trial 42 finished with value: 0.7312252964426877 and parameters: {'svc_c': 5.275448764407853, 'svc_gamma': 0.44542220415956596}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:03,211]\u001b[0m Trial 43 finished with value: 0.5177865612648221 and parameters: {'svc_c': 10.625419330666853, 'svc_gamma': 5.872979252696341}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:03,860]\u001b[0m Trial 44 finished with value: 0.5177865612648221 and parameters: {'svc_c': 19.361438865812822, 'svc_gamma': 9.328873097144859}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:04,533]\u001b[0m Trial 45 finished with value: 0.5177865612648221 and parameters: {'svc_c': 5.270652624171272, 'svc_gamma': 4.722221888692817}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:05,135]\u001b[0m Trial 46 finished with value: 0.650197628458498 and parameters: {'svc_c': 14.398160257740518, 'svc_gamma': 0.635885796514536}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 11:47:05,764]\u001b[0m Trial 47 finished with value: 0.5158102766798419 and parameters: {'svc_c': 0.07006620824162724, 'svc_gamma': 21.841922809160884}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:06,373]\u001b[0m Trial 48 finished with value: 0.5177865612648221 and parameters: {'svc_c': 43.2123619480606, 'svc_gamma': 13.944202511774254}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:06,957]\u001b[0m Trial 49 finished with value: 0.5177865612648221 and parameters: {'svc_c': 22.073689039693324, 'svc_gamma': 17.8770019091505}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:07,801]\u001b[0m Trial 50 finished with value: 0.5177865612648221 and parameters: {'svc_c': 9.003065925712788, 'svc_gamma': 11.156054791482829}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:08,245]\u001b[0m Trial 51 finished with value: 0.8735177865612648 and parameters: {'svc_c': 14.99270459807389, 'svc_gamma': 0.07611819884796}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:08,823]\u001b[0m Trial 52 finished with value: 0.5177865612648221 and parameters: {'svc_c': 5.749966923367242, 'svc_gamma': 3.97824314954979}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:09,461]\u001b[0m Trial 53 finished with value: 0.5177865612648221 and parameters: {'svc_c': 12.402806198972852, 'svc_gamma': 4.844563477621962}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:09,955]\u001b[0m Trial 54 finished with value: 0.8300395256916996 and parameters: {'svc_c': 15.901514650786496, 'svc_gamma': 0.198341206828673}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:10,620]\u001b[0m Trial 55 finished with value: 0.5177865612648221 and parameters: {'svc_c': 16.523176780407073, 'svc_gamma': 8.780622882677788}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:11,127]\u001b[0m Trial 56 finished with value: 0.66600790513834 and parameters: {'svc_c': 4.302351555352635, 'svc_gamma': 0.5880594707504655}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:11,740]\u001b[0m Trial 57 finished with value: 0.5177865612648221 and parameters: {'svc_c': 23.79230338192657, 'svc_gamma': 8.542466774869634}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:12,344]\u001b[0m Trial 58 finished with value: 0.5177865612648221 and parameters: {'svc_c': 8.32565185248351, 'svc_gamma': 4.056093097091449}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:12,957]\u001b[0m Trial 59 finished with value: 0.5177865612648221 and parameters: {'svc_c': 3.0804805385487892, 'svc_gamma': 16.065334259519318}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:13,538]\u001b[0m Trial 60 finished with value: 0.5177865612648221 and parameters: {'svc_c': 20.159424722401535, 'svc_gamma': 3.73993714188555}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:14,053]\u001b[0m Trial 61 finished with value: 0.616600790513834 and parameters: {'svc_c': 3.521593775772068, 'svc_gamma': 0.7193507461868011}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:14,527]\u001b[0m Trial 62 finished with value: 0.841897233201581 and parameters: {'svc_c': 5.828361437854538, 'svc_gamma': 0.1416710643057973}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:15,210]\u001b[0m Trial 63 finished with value: 0.5177865612648221 and parameters: {'svc_c': 11.059098659193797, 'svc_gamma': 7.171084130364333}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:15,856]\u001b[0m Trial 64 finished with value: 0.5177865612648221 and parameters: {'svc_c': 7.490332611291886, 'svc_gamma': 13.419631178127473}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:16,396]\u001b[0m Trial 65 finished with value: 0.5177865612648221 and parameters: {'svc_c': 15.740957355264463, 'svc_gamma': 3.6274196067343283}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:16,977]\u001b[0m Trial 66 finished with value: 0.5177865612648221 and parameters: {'svc_c': 0.7872361792451361, 'svc_gamma': 10.375671343673977}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:17,510]\u001b[0m Trial 67 finished with value: 0.5177865612648221 and parameters: {'svc_c': 10.309361477319772, 'svc_gamma': 3.2982307499019416}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:17,961]\u001b[0m Trial 68 finished with value: 0.8399209486166008 and parameters: {'svc_c': 17.224449027593195, 'svc_gamma': 0.14836396506769145}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:18,493]\u001b[0m Trial 69 finished with value: 0.5177865612648221 and parameters: {'svc_c': 16.5796931137836, 'svc_gamma': 7.292146465060604}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:19,049]\u001b[0m Trial 70 finished with value: 0.5177865612648221 and parameters: {'svc_c': 23.721185198645884, 'svc_gamma': 12.643167708774177}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:19,532]\u001b[0m Trial 71 finished with value: 0.841897233201581 and parameters: {'svc_c': 13.856838678419328, 'svc_gamma': 0.14329151949131858}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:20,073]\u001b[0m Trial 72 finished with value: 0.5197628458498024 and parameters: {'svc_c': 13.213805302059075, 'svc_gamma': 3.1593824355153357}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:20,591]\u001b[0m Trial 73 finished with value: 0.5177865612648221 and parameters: {'svc_c': 19.553748475030783, 'svc_gamma': 5.637606961793944}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:21,192]\u001b[0m Trial 74 finished with value: 0.5177865612648221 and parameters: {'svc_c': 9.073718926510441, 'svc_gamma': 8.76228886069011}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:21,641]\u001b[0m Trial 75 finished with value: 0.7371541501976284 and parameters: {'svc_c': 15.890295183592492, 'svc_gamma': 0.4339976175905842}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:22,207]\u001b[0m Trial 76 finished with value: 0.5177865612648221 and parameters: {'svc_c': 16.999336058554057, 'svc_gamma': 11.066014861580788}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:22,815]\u001b[0m Trial 77 finished with value: 0.5197628458498024 and parameters: {'svc_c': 25.34683271127344, 'svc_gamma': 3.2267959737208303}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:23,408]\u001b[0m Trial 78 finished with value: 0.5177865612648221 and parameters: {'svc_c': 21.397132350192102, 'svc_gamma': 6.752840290806342}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:23,973]\u001b[0m Trial 79 finished with value: 0.5197628458498024 and parameters: {'svc_c': 29.856594369391523, 'svc_gamma': 2.9258731921152323}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:24,414]\u001b[0m Trial 80 finished with value: 0.8300395256916996 and parameters: {'svc_c': 13.247485092654149, 'svc_gamma': 0.20027383501616022}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:24,957]\u001b[0m Trial 81 finished with value: 0.7312252964426877 and parameters: {'svc_c': 13.8427664605395, 'svc_gamma': 0.4470581678103597}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:25,511]\u001b[0m Trial 82 finished with value: 0.5177865612648221 and parameters: {'svc_c': 11.03669501409717, 'svc_gamma': 5.630798953743204}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:25,976]\u001b[0m Trial 83 finished with value: 0.5217391304347826 and parameters: {'svc_c': 15.086643269983696, 'svc_gamma': 2.265673861338271}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:26,332]\u001b[0m Trial 84 finished with value: 0.8656126482213439 and parameters: {'svc_c': 7.403826653294563, 'svc_gamma': 0.08645024885073316}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:26,883]\u001b[0m Trial 85 finished with value: 0.5177865612648221 and parameters: {'svc_c': 7.0374575357005895, 'svc_gamma': 8.148375282246564}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:27,475]\u001b[0m Trial 86 finished with value: 0.5177865612648221 and parameters: {'svc_c': 18.693049209882243, 'svc_gamma': 11.160720357631943}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:27,966]\u001b[0m Trial 87 finished with value: 0.5197628458498024 and parameters: {'svc_c': 2.7309837728442146, 'svc_gamma': 2.8116384140622435}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:28,524]\u001b[0m Trial 88 finished with value: 0.5177865612648221 and parameters: {'svc_c': 11.75765181833263, 'svc_gamma': 5.587373318259302}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:29,055]\u001b[0m Trial 89 finished with value: 0.5177865612648221 and parameters: {'svc_c': 7.424651817628767, 'svc_gamma': 15.613764070336238}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:29,680]\u001b[0m Trial 90 finished with value: 0.5177865612648221 and parameters: {'svc_c': 20.711439332782394, 'svc_gamma': 7.705346386557681}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:30,164]\u001b[0m Trial 91 finished with value: 0.7055335968379447 and parameters: {'svc_c': 14.541976832982478, 'svc_gamma': 0.5120966393964536}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:30,644]\u001b[0m Trial 92 finished with value: 0.5237154150197628 and parameters: {'svc_c': 17.260820220792812, 'svc_gamma': 2.1202174144712016}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:31,102]\u001b[0m Trial 93 finished with value: 0.8003952569169961 and parameters: {'svc_c': 10.344631686213557, 'svc_gamma': 0.25492795420884234}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:31,626]\u001b[0m Trial 94 finished with value: 0.5177865612648221 and parameters: {'svc_c': 9.755812954634592, 'svc_gamma': 4.730878607030429}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:32,205]\u001b[0m Trial 95 finished with value: 0.5177865612648221 and parameters: {'svc_c': 12.843846752113086, 'svc_gamma': 9.460452706975309}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:32,656]\u001b[0m Trial 96 finished with value: 0.5197628458498024 and parameters: {'svc_c': 6.042063874161869, 'svc_gamma': 2.757169133536413}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:33,069]\u001b[0m Trial 97 finished with value: 0.841897233201581 and parameters: {'svc_c': 2.052905630483542, 'svc_gamma': 0.15785048382551736}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:33,490]\u001b[0m Trial 98 finished with value: 0.5217391304347826 and parameters: {'svc_c': 2.1203256667386245, 'svc_gamma': 2.2662573626774627}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:34,053]\u001b[0m Trial 99 finished with value: 0.5177865612648221 and parameters: {'svc_c': 3.749017906045143, 'svc_gamma': 5.882251669510696}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:34,067]\u001b[0m A new study created in memory with name: no-name-de2af5eb-e874-4821-9b4c-a0dfa061e5a0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "index  selected_features_all_best30       XGBClassifier            False   \n",
      "index  selected_features_all_best30      LGBMClassifier            False   \n",
      "index  selected_features_all_best30  LogisticRegression             True   \n",
      "index  selected_features_all_best30                 SVC             True   \n",
      "index  selected_features_all_best30       XGBClassifier             True   \n",
      "index  selected_features_all_best30      LGBMClassifier             True   \n",
      "index  selected_features_all_best50  LogisticRegression            False   \n",
      "index  selected_features_all_best50                 SVC            False   \n",
      "index  selected_features_all_best50       XGBClassifier            False   \n",
      "index  selected_features_all_best50      LGBMClassifier            False   \n",
      "index  selected_features_all_best50  LogisticRegression             True   \n",
      "index  selected_features_all_best50                 SVC             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.888807   \n",
      "index  {'C': 0.024422805336610946, 'penalty': 'l1', '...  0.889328   \n",
      "index  {'svc_c': 14.99270459807389, 'svc_gamma': 0.07...  0.873518   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "index     0.844898     0.923372   0.911894  0.877119  0.771973   \n",
      "index     0.840816     0.923372   0.911504  0.874735  0.768193   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.804082     0.938697   0.924883  0.860262  0.751864   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_no_...  \n",
      "index  selected_features_all_best50_LGBMClassifier_no...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index  selected_features_all_best50_SVC_with_hypertuning  \n",
      "Optimizing selected_features_all_best50 XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:47:35,034]\u001b[0m Trial 0 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.2747358549724469, 'max_depth': 4, 'n_estimators': 206}. Best is trial 0 with value: 0.8873517786561265.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:38,764]\u001b[0m Trial 1 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.049433721318135074, 'max_depth': 3, 'n_estimators': 927}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:40,534]\u001b[0m Trial 2 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.15622721022045377, 'max_depth': 5, 'n_estimators': 190}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:42,826]\u001b[0m Trial 3 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.1511430892067905, 'max_depth': 2, 'n_estimators': 996}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:45,294]\u001b[0m Trial 4 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.13183131438575832, 'max_depth': 4, 'n_estimators': 546}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:46,127]\u001b[0m Trial 5 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.028844342332965123, 'max_depth': 2, 'n_estimators': 336}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:46,876]\u001b[0m Trial 6 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.09958464535305538, 'max_depth': 5, 'n_estimators': 119}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:50,573]\u001b[0m Trial 7 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.20557284491330127, 'max_depth': 6, 'n_estimators': 918}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:51,803]\u001b[0m Trial 8 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.28925390501544057, 'max_depth': 3, 'n_estimators': 321}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:52,225]\u001b[0m Trial 9 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.11893853787929015, 'max_depth': 2, 'n_estimators': 139}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:55,310]\u001b[0m Trial 10 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.02775024627243295, 'max_depth': 3, 'n_estimators': 809}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:58,638]\u001b[0m Trial 11 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.07220529492779568, 'max_depth': 5, 'n_estimators': 656}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:01,194]\u001b[0m Trial 12 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.1983345247108354, 'max_depth': 6, 'n_estimators': 548}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:04,926]\u001b[0m Trial 13 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.07023334496028294, 'max_depth': 5, 'n_estimators': 691}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:06,594]\u001b[0m Trial 14 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.17604241334074694, 'max_depth': 3, 'n_estimators': 415}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:10,014]\u001b[0m Trial 15 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.08671618730991129, 'max_depth': 4, 'n_estimators': 794}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:13,323]\u001b[0m Trial 16 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.018822103759404827, 'max_depth': 5, 'n_estimators': 420}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:15,741]\u001b[0m Trial 17 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.15471191375599358, 'max_depth': 3, 'n_estimators': 683}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:17,799]\u001b[0m Trial 18 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.054885215562698444, 'max_depth': 6, 'n_estimators': 259}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:20,036]\u001b[0m Trial 19 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.11732558717369593, 'max_depth': 4, 'n_estimators': 431}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:23,768]\u001b[0m Trial 20 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.053082326617909806, 'max_depth': 4, 'n_estimators': 843}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:27,644]\u001b[0m Trial 21 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.05301174824756624, 'max_depth': 4, 'n_estimators': 870}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:36,086]\u001b[0m Trial 22 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.013329492295477217, 'max_depth': 5, 'n_estimators': 991}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:39,138]\u001b[0m Trial 23 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.09897726767656737, 'max_depth': 3, 'n_estimators': 782}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:43,187]\u001b[0m Trial 24 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.048709433699719855, 'max_depth': 4, 'n_estimators': 902}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:47,936]\u001b[0m Trial 25 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.03827978209564282, 'max_depth': 4, 'n_estimators': 897}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:51,217]\u001b[0m Trial 26 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.036841662473278414, 'max_depth': 3, 'n_estimators': 855}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:55,986]\u001b[0m Trial 27 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.010442472907658516, 'max_depth': 4, 'n_estimators': 942}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:59,436]\u001b[0m Trial 28 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.07072255812658565, 'max_depth': 3, 'n_estimators': 744}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:02,424]\u001b[0m Trial 29 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.04085753481195363, 'max_depth': 4, 'n_estimators': 615}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:04,703]\u001b[0m Trial 30 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.058574121781619845, 'max_depth': 2, 'n_estimators': 834}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:09,557]\u001b[0m Trial 31 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.04185990685675141, 'max_depth': 4, 'n_estimators': 921}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:13,652]\u001b[0m Trial 32 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.04369772007024786, 'max_depth': 4, 'n_estimators': 895}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:17,683]\u001b[0m Trial 33 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.08049787003610662, 'max_depth': 4, 'n_estimators': 969}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:21,536]\u001b[0m Trial 34 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.05657586179827545, 'max_depth': 4, 'n_estimators': 752}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:24,615]\u001b[0m Trial 35 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.02556920712685201, 'max_depth': 3, 'n_estimators': 867}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:29,121]\u001b[0m Trial 36 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.08984594941141315, 'max_depth': 5, 'n_estimators': 991}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:31,586]\u001b[0m Trial 37 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.024879562707172426, 'max_depth': 2, 'n_estimators': 733}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:35,674]\u001b[0m Trial 38 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.06466918114616128, 'max_depth': 4, 'n_estimators': 910}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:40,464]\u001b[0m Trial 39 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.04336147538445505, 'max_depth': 5, 'n_estimators': 836}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:43,052]\u001b[0m Trial 40 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.10049331991503149, 'max_depth': 3, 'n_estimators': 608}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:46,343]\u001b[0m Trial 41 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.05564717350585232, 'max_depth': 4, 'n_estimators': 742}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:49,944]\u001b[0m Trial 42 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.05742988331647172, 'max_depth': 4, 'n_estimators': 787}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:54,695]\u001b[0m Trial 43 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.0332665109965522, 'max_depth': 4, 'n_estimators': 937}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:59,156]\u001b[0m Trial 44 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.07736834427926068, 'max_depth': 5, 'n_estimators': 892}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:04,082]\u001b[0m Trial 45 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.020726786866582296, 'max_depth': 4, 'n_estimators': 945}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:07,424]\u001b[0m Trial 46 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.069837662723852, 'max_depth': 3, 'n_estimators': 825}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:11,313]\u001b[0m Trial 47 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.030977333752019498, 'max_depth': 4, 'n_estimators': 778}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:14,644]\u001b[0m Trial 48 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.010512088758073163, 'max_depth': 5, 'n_estimators': 512}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:17,591]\u001b[0m Trial 49 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.04948166553335928, 'max_depth': 3, 'n_estimators': 706}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:19,836]\u001b[0m Trial 50 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.06400514386959913, 'max_depth': 2, 'n_estimators': 876}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:21,432]\u001b[0m Trial 51 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.1412013222775527, 'max_depth': 5, 'n_estimators': 299}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:22,155]\u001b[0m Trial 52 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.16856041779317166, 'max_depth': 6, 'n_estimators': 108}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:23,148]\u001b[0m Trial 53 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.11836420537949924, 'max_depth': 4, 'n_estimators': 195}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:26,380]\u001b[0m Trial 54 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.0332669452914449, 'max_depth': 5, 'n_estimators': 462}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:28,353]\u001b[0m Trial 55 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.04933637110833891, 'max_depth': 4, 'n_estimators': 349}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:31,819]\u001b[0m Trial 56 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.08235919490304626, 'max_depth': 5, 'n_estimators': 634}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:36,020]\u001b[0m Trial 57 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.07571303528451738, 'max_depth': 6, 'n_estimators': 649}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:39,217]\u001b[0m Trial 58 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.06534078087773584, 'max_depth': 4, 'n_estimators': 593}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:43,286]\u001b[0m Trial 59 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.05885472795285947, 'max_depth': 4, 'n_estimators': 964}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:45,817]\u001b[0m Trial 60 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.019826044762966313, 'max_depth': 3, 'n_estimators': 565}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:49,201]\u001b[0m Trial 61 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.047396016382337314, 'max_depth': 4, 'n_estimators': 602}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:52,099]\u001b[0m Trial 62 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.0893108598417974, 'max_depth': 4, 'n_estimators': 668}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:54,860]\u001b[0m Trial 63 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.03587165251805628, 'max_depth': 4, 'n_estimators': 507}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:58,651]\u001b[0m Trial 64 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.06777875302163083, 'max_depth': 5, 'n_estimators': 718}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:02,030]\u001b[0m Trial 65 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.08105282803692354, 'max_depth': 4, 'n_estimators': 769}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:05,931]\u001b[0m Trial 66 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.0502667686767308, 'max_depth': 4, 'n_estimators': 809}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:08,152]\u001b[0m Trial 67 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.06460282496122323, 'max_depth': 3, 'n_estimators': 574}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:11,229]\u001b[0m Trial 68 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.04022334669241433, 'max_depth': 4, 'n_estimators': 632}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:17,379]\u001b[0m Trial 69 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.028725566309624865, 'max_depth': 5, 'n_estimators': 847}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:21,576]\u001b[0m Trial 70 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.05930337017737414, 'max_depth': 4, 'n_estimators': 888}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:25,204]\u001b[0m Trial 71 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.048379575531313085, 'max_depth': 4, 'n_estimators': 807}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:29,010]\u001b[0m Trial 72 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.05201139903291287, 'max_depth': 4, 'n_estimators': 762}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:32,990]\u001b[0m Trial 73 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.039617789206286703, 'max_depth': 4, 'n_estimators': 821}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:37,169]\u001b[0m Trial 74 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.07349934650217946, 'max_depth': 4, 'n_estimators': 911}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:41,469]\u001b[0m Trial 75 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.019579483561422292, 'max_depth': 3, 'n_estimators': 692}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:46,848]\u001b[0m Trial 76 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.06200843646859018, 'max_depth': 5, 'n_estimators': 959}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:50,959]\u001b[0m Trial 77 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.046006344920584745, 'max_depth': 4, 'n_estimators': 855}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:55,689]\u001b[0m Trial 78 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.05458465592837063, 'max_depth': 4, 'n_estimators': 932}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:58,365]\u001b[0m Trial 79 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.08144133133112483, 'max_depth': 3, 'n_estimators': 752}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:52:02,287]\u001b[0m Trial 80 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.02810668832364034, 'max_depth': 4, 'n_estimators': 802}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:52:06,539]\u001b[0m Trial 81 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.062048606460242225, 'max_depth': 4, 'n_estimators': 888}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:52:10,757]\u001b[0m Trial 82 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.06940349016974875, 'max_depth': 4, 'n_estimators': 897}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:52:15,590]\u001b[0m Trial 83 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.06983848339959557, 'max_depth': 4, 'n_estimators': 997}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:52:21,505]\u001b[0m Trial 84 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.03955123531819789, 'max_depth': 4, 'n_estimators': 911}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:52:26,498]\u001b[0m Trial 85 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.03651638059998999, 'max_depth': 4, 'n_estimators': 907}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:52:29,087]\u001b[0m Trial 86 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.043119810936547306, 'max_depth': 2, 'n_estimators': 847}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:52:33,157]\u001b[0m Trial 87 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.09569187436724322, 'max_depth': 4, 'n_estimators': 870}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:52:37,648]\u001b[0m Trial 88 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.10685120637008047, 'max_depth': 4, 'n_estimators': 973}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:52:42,930]\u001b[0m Trial 89 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.08534200109075912, 'max_depth': 5, 'n_estimators': 927}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:52:43,817]\u001b[0m Trial 90 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.07400336324259033, 'max_depth': 4, 'n_estimators': 155}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:52:47,668]\u001b[0m Trial 91 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.05252391057319636, 'max_depth': 4, 'n_estimators': 829}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:52:50,691]\u001b[0m Trial 92 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.05587799204005104, 'max_depth': 4, 'n_estimators': 520}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:52:54,853]\u001b[0m Trial 93 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.03698070875672929, 'max_depth': 4, 'n_estimators': 864}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:00,873]\u001b[0m Trial 94 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.06672475876102872, 'max_depth': 4, 'n_estimators': 947}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:06,466]\u001b[0m Trial 95 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.04519461324831292, 'max_depth': 6, 'n_estimators': 900}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:13,498]\u001b[0m Trial 96 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.025139413120095225, 'max_depth': 4, 'n_estimators': 795}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:16,348]\u001b[0m Trial 97 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.030660359112247196, 'max_depth': 3, 'n_estimators': 591}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:20,566]\u001b[0m Trial 98 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.05122601375503418, 'max_depth': 4, 'n_estimators': 880}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:25,133]\u001b[0m Trial 99 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.07417528611284999, 'max_depth': 5, 'n_estimators': 980}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:25,151]\u001b[0m A new study created in memory with name: no-name-123ff715-6b94-462b-8088-6ab77fbd2e00\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "index  selected_features_all_best30       XGBClassifier            False   \n",
      "index  selected_features_all_best30      LGBMClassifier            False   \n",
      "index  selected_features_all_best30  LogisticRegression             True   \n",
      "index  selected_features_all_best30                 SVC             True   \n",
      "index  selected_features_all_best30       XGBClassifier             True   \n",
      "index  selected_features_all_best30      LGBMClassifier             True   \n",
      "index  selected_features_all_best50  LogisticRegression            False   \n",
      "index  selected_features_all_best50                 SVC            False   \n",
      "index  selected_features_all_best50       XGBClassifier            False   \n",
      "index  selected_features_all_best50      LGBMClassifier            False   \n",
      "index  selected_features_all_best50  LogisticRegression             True   \n",
      "index  selected_features_all_best50                 SVC             True   \n",
      "index  selected_features_all_best50       XGBClassifier             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.888807   \n",
      "index  {'C': 0.024422805336610946, 'penalty': 'l1', '...  0.889328   \n",
      "index  {'svc_c': 14.99270459807389, 'svc_gamma': 0.07...  0.873518   \n",
      "index  {'learning_rate': 0.049433721318135074, 'max_d...  0.893281   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "index     0.844898     0.923372   0.911894  0.877119  0.771973   \n",
      "index     0.840816     0.923372   0.911504  0.874735  0.768193   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.804082     0.938697   0.924883  0.860262  0.751864   \n",
      "index     0.844898     0.938697   0.928251  0.884615  0.788768   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_no_...  \n",
      "index  selected_features_all_best50_LGBMClassifier_no...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index  selected_features_all_best50_SVC_with_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_wit...  \n",
      "Optimizing selected_features_all_best50 LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:53:27,429]\u001b[0m Trial 0 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 227, 'max_depth': 43, 'learning_rate': 0.2778019303343961, 'n_estimators': 1461}. Best is trial 0 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:31,940]\u001b[0m Trial 1 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 223, 'max_depth': 16, 'learning_rate': 0.10290531634605304, 'n_estimators': 1215}. Best is trial 1 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:38,623]\u001b[0m Trial 2 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 106, 'max_depth': 27, 'learning_rate': 0.031657949034507527, 'n_estimators': 1008}. Best is trial 1 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:40,454]\u001b[0m Trial 3 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 7, 'max_depth': 40, 'learning_rate': 0.2804540099026719, 'n_estimators': 1662}. Best is trial 1 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:42,778]\u001b[0m Trial 4 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 70, 'max_depth': 50, 'learning_rate': 0.247098647978207, 'n_estimators': 1464}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:47,277]\u001b[0m Trial 5 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 67, 'max_depth': 32, 'learning_rate': 0.02394441746310611, 'n_estimators': 732}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:49,637]\u001b[0m Trial 6 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 79, 'max_depth': 37, 'learning_rate': 0.13727474670710854, 'n_estimators': 823}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:51,724]\u001b[0m Trial 7 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 42, 'max_depth': 11, 'learning_rate': 0.19889917427980472, 'n_estimators': 1341}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:56,999]\u001b[0m Trial 8 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 98, 'max_depth': 19, 'learning_rate': 0.05186328141874624, 'n_estimators': 1552}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:59,881]\u001b[0m Trial 9 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 215, 'max_depth': 16, 'learning_rate': 0.10378634141095336, 'n_estimators': 1492}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:00,211]\u001b[0m Trial 10 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 152, 'max_depth': 4, 'learning_rate': 0.2114960901704434, 'n_estimators': 233}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:03,868]\u001b[0m Trial 11 finished with value: 0.883399209486166 and parameters: {'num_leaves': 154, 'max_depth': 50, 'learning_rate': 0.18008782966111533, 'n_estimators': 1957}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:05,744]\u001b[0m Trial 12 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 62, 'max_depth': 38, 'learning_rate': 0.14316549611035803, 'n_estimators': 657}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:06,431]\u001b[0m Trial 13 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 5, 'max_depth': 50, 'learning_rate': 0.2422179103014768, 'n_estimators': 882}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:08,060]\u001b[0m Trial 14 finished with value: 0.8754940711462451 and parameters: {'num_leaves': 121, 'max_depth': 34, 'learning_rate': 0.15914758221348083, 'n_estimators': 203}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:09,044]\u001b[0m Trial 15 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 79, 'max_depth': 44, 'learning_rate': 0.2360603289563477, 'n_estimators': 491}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:11,208]\u001b[0m Trial 16 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 156, 'max_depth': 45, 'learning_rate': 0.23505470200470757, 'n_estimators': 542}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:12,010]\u001b[0m Trial 17 finished with value: 0.883399209486166 and parameters: {'num_leaves': 42, 'max_depth': 46, 'learning_rate': 0.29150337561485357, 'n_estimators': 451}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:13,600]\u001b[0m Trial 18 finished with value: 0.883399209486166 and parameters: {'num_leaves': 38, 'max_depth': 28, 'learning_rate': 0.24910617566046664, 'n_estimators': 1150}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:16,377]\u001b[0m Trial 19 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 188, 'max_depth': 42, 'learning_rate': 0.2991692323002301, 'n_estimators': 1929}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:20,741]\u001b[0m Trial 20 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 89, 'max_depth': 47, 'learning_rate': 0.21195869318797483, 'n_estimators': 1756}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:22,189]\u001b[0m Trial 21 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 80, 'max_depth': 36, 'learning_rate': 0.2538347761238169, 'n_estimators': 885}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:23,867]\u001b[0m Trial 22 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 122, 'max_depth': 40, 'learning_rate': 0.18239296744604983, 'n_estimators': 398}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:25,179]\u001b[0m Trial 23 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 64, 'max_depth': 31, 'learning_rate': 0.2266623193136236, 'n_estimators': 781}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:26,976]\u001b[0m Trial 24 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 23, 'max_depth': 30, 'learning_rate': 0.23164509250483808, 'n_estimators': 1064}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:27,967]\u001b[0m Trial 25 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 59, 'max_depth': 23, 'learning_rate': 0.2654040279934537, 'n_estimators': 605}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:28,619]\u001b[0m Trial 26 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 102, 'max_depth': 47, 'learning_rate': 0.2629370835182472, 'n_estimators': 106}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:29,357]\u001b[0m Trial 27 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 48, 'max_depth': 23, 'learning_rate': 0.2254818751462364, 'n_estimators': 397}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:31,444]\u001b[0m Trial 28 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 130, 'max_depth': 34, 'learning_rate': 0.26699008061718654, 'n_estimators': 1305}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:33,013]\u001b[0m Trial 29 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 25, 'max_depth': 43, 'learning_rate': 0.2771905683463247, 'n_estimators': 979}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:34,318]\u001b[0m Trial 30 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 76, 'max_depth': 43, 'learning_rate': 0.21901464573451593, 'n_estimators': 737}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:36,534]\u001b[0m Trial 31 finished with value: 0.8754940711462451 and parameters: {'num_leaves': 71, 'max_depth': 50, 'learning_rate': 0.22084549435346562, 'n_estimators': 764}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:37,754]\u001b[0m Trial 32 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 87, 'max_depth': 43, 'learning_rate': 0.2458900823374548, 'n_estimators': 511}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:39,278]\u001b[0m Trial 33 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 57, 'max_depth': 40, 'learning_rate': 0.20019652395429915, 'n_estimators': 717}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:40,964]\u001b[0m Trial 34 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 109, 'max_depth': 45, 'learning_rate': 0.23277641871969687, 'n_estimators': 1128}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:42,619]\u001b[0m Trial 35 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 252, 'max_depth': 31, 'learning_rate': 0.27220556472752194, 'n_estimators': 940}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:44,981]\u001b[0m Trial 36 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 25, 'max_depth': 48, 'learning_rate': 0.250534696238516, 'n_estimators': 1312}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:46,766]\u001b[0m Trial 37 finished with value: 0.883399209486166 and parameters: {'num_leaves': 75, 'max_depth': 41, 'learning_rate': 0.21641226958098628, 'n_estimators': 641}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:48,315]\u001b[0m Trial 38 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 91, 'max_depth': 37, 'learning_rate': 0.19823839644299662, 'n_estimators': 796}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:49,208]\u001b[0m Trial 39 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 141, 'max_depth': 25, 'learning_rate': 0.28404196957343697, 'n_estimators': 318}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:50,213]\u001b[0m Trial 40 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 114, 'max_depth': 11, 'learning_rate': 0.25584860927073494, 'n_estimators': 569}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:51,997]\u001b[0m Trial 41 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 88, 'max_depth': 44, 'learning_rate': 0.24195166425688996, 'n_estimators': 515}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:53,248]\u001b[0m Trial 42 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 73, 'max_depth': 43, 'learning_rate': 0.23635184236694065, 'n_estimators': 704}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:55,186]\u001b[0m Trial 43 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 54, 'max_depth': 38, 'learning_rate': 0.2779919444448549, 'n_estimators': 1638}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:56,239]\u001b[0m Trial 44 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 95, 'max_depth': 48, 'learning_rate': 0.22403502200610062, 'n_estimators': 482}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:57,518]\u001b[0m Trial 45 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 34, 'max_depth': 34, 'learning_rate': 0.25022733249620804, 'n_estimators': 351}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:59,033]\u001b[0m Trial 46 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 65, 'max_depth': 40, 'learning_rate': 0.2114764738882552, 'n_estimators': 855}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:00,049]\u001b[0m Trial 47 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 81, 'max_depth': 49, 'learning_rate': 0.240517040980197, 'n_estimators': 270}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:01,750]\u001b[0m Trial 48 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 99, 'max_depth': 45, 'learning_rate': 0.1906846078698989, 'n_estimators': 663}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:03,579]\u001b[0m Trial 49 finished with value: 0.883399209486166 and parameters: {'num_leaves': 46, 'max_depth': 42, 'learning_rate': 0.26259395623112386, 'n_estimators': 1418}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:04,946]\u001b[0m Trial 50 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 183, 'max_depth': 10, 'learning_rate': 0.2863686902443642, 'n_estimators': 1056}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:07,553]\u001b[0m Trial 51 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 83, 'max_depth': 36, 'learning_rate': 0.16092637097111542, 'n_estimators': 823}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:09,998]\u001b[0m Trial 52 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 64, 'max_depth': 39, 'learning_rate': 0.11200158543017283, 'n_estimators': 903}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:11,412]\u001b[0m Trial 53 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 106, 'max_depth': 29, 'learning_rate': 0.20917965850454817, 'n_estimators': 583}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:13,519]\u001b[0m Trial 54 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 73, 'max_depth': 32, 'learning_rate': 0.2263088748128254, 'n_estimators': 1210}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:15,698]\u001b[0m Trial 55 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 52, 'max_depth': 46, 'learning_rate': 0.17620255827743825, 'n_estimators': 1766}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:16,671]\u001b[0m Trial 56 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 33, 'max_depth': 36, 'learning_rate': 0.2460830495032345, 'n_estimators': 782}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:17,646]\u001b[0m Trial 57 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 118, 'max_depth': 42, 'learning_rate': 0.25764771258309177, 'n_estimators': 424}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:18,826]\u001b[0m Trial 58 finished with value: 0.883399209486166 and parameters: {'num_leaves': 14, 'max_depth': 26, 'learning_rate': 0.2367388840278971, 'n_estimators': 504}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:21,144]\u001b[0m Trial 59 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 135, 'max_depth': 44, 'learning_rate': 0.12920585819356448, 'n_estimators': 696}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:23,095]\u001b[0m Trial 60 finished with value: 0.883399209486166 and parameters: {'num_leaves': 82, 'max_depth': 38, 'learning_rate': 0.27289320072244944, 'n_estimators': 1033}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:25,352]\u001b[0m Trial 61 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 164, 'max_depth': 46, 'learning_rate': 0.23063119133984894, 'n_estimators': 616}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:26,657]\u001b[0m Trial 62 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 166, 'max_depth': 50, 'learning_rate': 0.2217443796478293, 'n_estimators': 544}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:28,547]\u001b[0m Trial 63 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 150, 'max_depth': 48, 'learning_rate': 0.2451958129996075, 'n_estimators': 956}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:29,695]\u001b[0m Trial 64 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 66, 'max_depth': 44, 'learning_rate': 0.29569500264788423, 'n_estimators': 753}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:30,818]\u001b[0m Trial 65 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 190, 'max_depth': 41, 'learning_rate': 0.20608897989418626, 'n_estimators': 454}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:32,219]\u001b[0m Trial 66 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 89, 'max_depth': 47, 'learning_rate': 0.21708913902611165, 'n_estimators': 142}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:33,425]\u001b[0m Trial 67 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 57, 'max_depth': 34, 'learning_rate': 0.2588154847468558, 'n_estimators': 849}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:35,070]\u001b[0m Trial 68 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 100, 'max_depth': 32, 'learning_rate': 0.23124274489912908, 'n_estimators': 317}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:36,779]\u001b[0m Trial 69 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 125, 'max_depth': 45, 'learning_rate': 0.2656658566829736, 'n_estimators': 658}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:37,735]\u001b[0m Trial 70 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 43, 'max_depth': 41, 'learning_rate': 0.20052241856625336, 'n_estimators': 569}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:38,750]\u001b[0m Trial 71 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 77, 'max_depth': 41, 'learning_rate': 0.2037385131573073, 'n_estimators': 538}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:39,665]\u001b[0m Trial 72 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 38, 'max_depth': 39, 'learning_rate': 0.20090980389112456, 'n_estimators': 366}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:40,487]\u001b[0m Trial 73 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 43, 'max_depth': 41, 'learning_rate': 0.2055912090307998, 'n_estimators': 385}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:40,899]\u001b[0m Trial 74 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 18, 'max_depth': 39, 'learning_rate': 0.21650129234185192, 'n_estimators': 202}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:42,521]\u001b[0m Trial 75 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 35, 'max_depth': 42, 'learning_rate': 0.19609747164871863, 'n_estimators': 447}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:43,594]\u001b[0m Trial 76 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 59, 'max_depth': 21, 'learning_rate': 0.19011599673529644, 'n_estimators': 546}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:44,407]\u001b[0m Trial 77 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 50, 'max_depth': 43, 'learning_rate': 0.2231136684142504, 'n_estimators': 248}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:44,666]\u001b[0m Trial 78 finished with value: 0.8754940711462451 and parameters: {'num_leaves': 4, 'max_depth': 37, 'learning_rate': 0.203419068805674, 'n_estimators': 359}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:45,637]\u001b[0m Trial 79 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 68, 'max_depth': 39, 'learning_rate': 0.2506539943914677, 'n_estimators': 601}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:46,351]\u001b[0m Trial 80 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 29, 'max_depth': 35, 'learning_rate': 0.239235697360015, 'n_estimators': 472}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:47,715]\u001b[0m Trial 81 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 78, 'max_depth': 40, 'learning_rate': 0.21426736825920709, 'n_estimators': 720}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:49,257]\u001b[0m Trial 82 finished with value: 0.883399209486166 and parameters: {'num_leaves': 91, 'max_depth': 43, 'learning_rate': 0.22985516730915845, 'n_estimators': 659}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:50,325]\u001b[0m Trial 83 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 41, 'max_depth': 37, 'learning_rate': 0.17558782637909143, 'n_estimators': 510}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:52,716]\u001b[0m Trial 84 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 72, 'max_depth': 41, 'learning_rate': 0.2119365534855873, 'n_estimators': 1534}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:54,103]\u001b[0m Trial 85 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 62, 'max_depth': 33, 'learning_rate': 0.18748867630639557, 'n_estimators': 791}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:55,090]\u001b[0m Trial 86 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 78, 'max_depth': 46, 'learning_rate': 0.24058552755980647, 'n_estimators': 306}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:56,725]\u001b[0m Trial 87 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 86, 'max_depth': 30, 'learning_rate': 0.2008476028993613, 'n_estimators': 573}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:58,292]\u001b[0m Trial 88 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 109, 'max_depth': 38, 'learning_rate': 0.19567139098458408, 'n_estimators': 888}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:00,068]\u001b[0m Trial 89 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 115, 'max_depth': 39, 'learning_rate': 0.22127019784292443, 'n_estimators': 901}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:01,964]\u001b[0m Trial 90 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 94, 'max_depth': 35, 'learning_rate': 0.19531270237723736, 'n_estimators': 997}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:03,874]\u001b[0m Trial 91 finished with value: 0.883399209486166 and parameters: {'num_leaves': 112, 'max_depth': 38, 'learning_rate': 0.22224836458577218, 'n_estimators': 918}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:05,874]\u001b[0m Trial 92 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 117, 'max_depth': 44, 'learning_rate': 0.22828617746453503, 'n_estimators': 1145}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:08,021]\u001b[0m Trial 93 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 103, 'max_depth': 39, 'learning_rate': 0.20722590833959664, 'n_estimators': 1098}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:09,495]\u001b[0m Trial 94 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 109, 'max_depth': 17, 'learning_rate': 0.2186247873293115, 'n_estimators': 857}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:11,293]\u001b[0m Trial 95 finished with value: 0.883399209486166 and parameters: {'num_leaves': 47, 'max_depth': 42, 'learning_rate': 0.23527925074583034, 'n_estimators': 739}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:12,650]\u001b[0m Trial 96 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 96, 'max_depth': 48, 'learning_rate': 0.24319194860797172, 'n_estimators': 621}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:14,389]\u001b[0m Trial 97 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 69, 'max_depth': 40, 'learning_rate': 0.21005038887782726, 'n_estimators': 813}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:15,753]\u001b[0m Trial 98 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 85, 'max_depth': 45, 'learning_rate': 0.2511021730275806, 'n_estimators': 415}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:17,641]\u001b[0m Trial 99 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 77, 'max_depth': 36, 'learning_rate': 0.20187340643402057, 'n_estimators': 891}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "index  selected_features_all_best30       XGBClassifier            False   \n",
      "index  selected_features_all_best30      LGBMClassifier            False   \n",
      "index  selected_features_all_best30  LogisticRegression             True   \n",
      "index  selected_features_all_best30                 SVC             True   \n",
      "index  selected_features_all_best30       XGBClassifier             True   \n",
      "index  selected_features_all_best30      LGBMClassifier             True   \n",
      "index  selected_features_all_best50  LogisticRegression            False   \n",
      "index  selected_features_all_best50                 SVC            False   \n",
      "index  selected_features_all_best50       XGBClassifier            False   \n",
      "index  selected_features_all_best50      LGBMClassifier            False   \n",
      "index  selected_features_all_best50  LogisticRegression             True   \n",
      "index  selected_features_all_best50                 SVC             True   \n",
      "index  selected_features_all_best50       XGBClassifier             True   \n",
      "index  selected_features_all_best50      LGBMClassifier             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.888807   \n",
      "index  {'C': 0.024422805336610946, 'penalty': 'l1', '...  0.889328   \n",
      "index  {'svc_c': 14.99270459807389, 'svc_gamma': 0.07...  0.873518   \n",
      "index  {'learning_rate': 0.049433721318135074, 'max_d...  0.893281   \n",
      "index  {'num_leaves': 77, 'max_depth': 41, 'learning_...  0.895257   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "index     0.844898     0.923372   0.911894  0.877119  0.771973   \n",
      "index     0.840816     0.923372   0.911504  0.874735  0.768193   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.804082     0.938697   0.924883  0.860262  0.751864   \n",
      "index     0.844898     0.938697   0.928251  0.884615  0.788768   \n",
      "index     0.848980     0.938697   0.928571  0.886994  0.792507   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_no_...  \n",
      "index  selected_features_all_best50_LGBMClassifier_no...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index  selected_features_all_best50_SVC_with_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_wit...  \n",
      "index  selected_features_all_best50_LGBMClassifier_wi...  \n",
      "Evaluating selected_features_all_best100 LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        feature_type               model with_hypertuning   \n",
      "index   selected_features_all_best20  LogisticRegression            False  \\\n",
      "index   selected_features_all_best20                 SVC            False   \n",
      "index   selected_features_all_best20       XGBClassifier            False   \n",
      "index   selected_features_all_best20      LGBMClassifier            False   \n",
      "index   selected_features_all_best20  LogisticRegression             True   \n",
      "index   selected_features_all_best20                 SVC             True   \n",
      "index   selected_features_all_best20       XGBClassifier             True   \n",
      "index   selected_features_all_best20      LGBMClassifier             True   \n",
      "index   selected_features_all_best30  LogisticRegression            False   \n",
      "index   selected_features_all_best30                 SVC            False   \n",
      "index   selected_features_all_best30       XGBClassifier            False   \n",
      "index   selected_features_all_best30      LGBMClassifier            False   \n",
      "index   selected_features_all_best30  LogisticRegression             True   \n",
      "index   selected_features_all_best30                 SVC             True   \n",
      "index   selected_features_all_best30       XGBClassifier             True   \n",
      "index   selected_features_all_best30      LGBMClassifier             True   \n",
      "index   selected_features_all_best50  LogisticRegression            False   \n",
      "index   selected_features_all_best50                 SVC            False   \n",
      "index   selected_features_all_best50       XGBClassifier            False   \n",
      "index   selected_features_all_best50      LGBMClassifier            False   \n",
      "index   selected_features_all_best50  LogisticRegression             True   \n",
      "index   selected_features_all_best50                 SVC             True   \n",
      "index   selected_features_all_best50       XGBClassifier             True   \n",
      "index   selected_features_all_best50      LGBMClassifier             True   \n",
      "index  selected_features_all_best100  LogisticRegression            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.888807   \n",
      "index  {'C': 0.024422805336610946, 'penalty': 'l1', '...  0.889328   \n",
      "index  {'svc_c': 14.99270459807389, 'svc_gamma': 0.07...  0.873518   \n",
      "index  {'learning_rate': 0.049433721318135074, 'max_d...  0.893281   \n",
      "index  {'num_leaves': 77, 'max_depth': 41, 'learning_...  0.895257   \n",
      "index                                               None  0.901161   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "index     0.844898     0.923372   0.911894  0.877119  0.771973   \n",
      "index     0.840816     0.923372   0.911504  0.874735  0.768193   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.804082     0.938697   0.924883  0.860262  0.751864   \n",
      "index     0.844898     0.938697   0.928251  0.884615  0.788768   \n",
      "index     0.848980     0.938697   0.928571  0.886994  0.792507   \n",
      "index     0.869388     0.923372   0.914163  0.891213  0.794850   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_no_...  \n",
      "index  selected_features_all_best50_LGBMClassifier_no...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index  selected_features_all_best50_SVC_with_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_wit...  \n",
      "index  selected_features_all_best50_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best100_LogisticRegressi...  \n",
      "Evaluating selected_features_all_best100 SVC\n",
      "                        feature_type               model with_hypertuning   \n",
      "index   selected_features_all_best20  LogisticRegression            False  \\\n",
      "index   selected_features_all_best20                 SVC            False   \n",
      "index   selected_features_all_best20       XGBClassifier            False   \n",
      "index   selected_features_all_best20      LGBMClassifier            False   \n",
      "index   selected_features_all_best20  LogisticRegression             True   \n",
      "index   selected_features_all_best20                 SVC             True   \n",
      "index   selected_features_all_best20       XGBClassifier             True   \n",
      "index   selected_features_all_best20      LGBMClassifier             True   \n",
      "index   selected_features_all_best30  LogisticRegression            False   \n",
      "index   selected_features_all_best30                 SVC            False   \n",
      "index   selected_features_all_best30       XGBClassifier            False   \n",
      "index   selected_features_all_best30      LGBMClassifier            False   \n",
      "index   selected_features_all_best30  LogisticRegression             True   \n",
      "index   selected_features_all_best30                 SVC             True   \n",
      "index   selected_features_all_best30       XGBClassifier             True   \n",
      "index   selected_features_all_best30      LGBMClassifier             True   \n",
      "index   selected_features_all_best50  LogisticRegression            False   \n",
      "index   selected_features_all_best50                 SVC            False   \n",
      "index   selected_features_all_best50       XGBClassifier            False   \n",
      "index   selected_features_all_best50      LGBMClassifier            False   \n",
      "index   selected_features_all_best50  LogisticRegression             True   \n",
      "index   selected_features_all_best50                 SVC             True   \n",
      "index   selected_features_all_best50       XGBClassifier             True   \n",
      "index   selected_features_all_best50      LGBMClassifier             True   \n",
      "index  selected_features_all_best100  LogisticRegression            False   \n",
      "index  selected_features_all_best100                 SVC            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.888807   \n",
      "index  {'C': 0.024422805336610946, 'penalty': 'l1', '...  0.889328   \n",
      "index  {'svc_c': 14.99270459807389, 'svc_gamma': 0.07...  0.873518   \n",
      "index  {'learning_rate': 0.049433721318135074, 'max_d...  0.893281   \n",
      "index  {'num_leaves': 77, 'max_depth': 41, 'learning_...  0.895257   \n",
      "index                                               None  0.901161   \n",
      "index                                               None  0.898695   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "index     0.844898     0.923372   0.911894  0.877119  0.771973   \n",
      "index     0.840816     0.923372   0.911504  0.874735  0.768193   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.804082     0.938697   0.924883  0.860262  0.751864   \n",
      "index     0.844898     0.938697   0.928251  0.884615  0.788768   \n",
      "index     0.848980     0.938697   0.928571  0.886994  0.792507   \n",
      "index     0.869388     0.923372   0.914163  0.891213  0.794850   \n",
      "index     0.853061     0.934866   0.924779  0.887473  0.792056   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_no_...  \n",
      "index  selected_features_all_best50_LGBMClassifier_no...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index  selected_features_all_best50_SVC_with_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_wit...  \n",
      "index  selected_features_all_best50_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best100_LogisticRegressi...  \n",
      "index   selected_features_all_best100_SVC_no_hypertuning  \n",
      "Evaluating selected_features_all_best100 XGBClassifier\n",
      "                        feature_type               model with_hypertuning   \n",
      "index   selected_features_all_best20  LogisticRegression            False  \\\n",
      "index   selected_features_all_best20                 SVC            False   \n",
      "index   selected_features_all_best20       XGBClassifier            False   \n",
      "index   selected_features_all_best20      LGBMClassifier            False   \n",
      "index   selected_features_all_best20  LogisticRegression             True   \n",
      "index   selected_features_all_best20                 SVC             True   \n",
      "index   selected_features_all_best20       XGBClassifier             True   \n",
      "index   selected_features_all_best20      LGBMClassifier             True   \n",
      "index   selected_features_all_best30  LogisticRegression            False   \n",
      "index   selected_features_all_best30                 SVC            False   \n",
      "index   selected_features_all_best30       XGBClassifier            False   \n",
      "index   selected_features_all_best30      LGBMClassifier            False   \n",
      "index   selected_features_all_best30  LogisticRegression             True   \n",
      "index   selected_features_all_best30                 SVC             True   \n",
      "index   selected_features_all_best30       XGBClassifier             True   \n",
      "index   selected_features_all_best30      LGBMClassifier             True   \n",
      "index   selected_features_all_best50  LogisticRegression            False   \n",
      "index   selected_features_all_best50                 SVC            False   \n",
      "index   selected_features_all_best50       XGBClassifier            False   \n",
      "index   selected_features_all_best50      LGBMClassifier            False   \n",
      "index   selected_features_all_best50  LogisticRegression             True   \n",
      "index   selected_features_all_best50                 SVC             True   \n",
      "index   selected_features_all_best50       XGBClassifier             True   \n",
      "index   selected_features_all_best50      LGBMClassifier             True   \n",
      "index  selected_features_all_best100  LogisticRegression            False   \n",
      "index  selected_features_all_best100                 SVC            False   \n",
      "index  selected_features_all_best100       XGBClassifier            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.888807   \n",
      "index  {'C': 0.024422805336610946, 'penalty': 'l1', '...  0.889328   \n",
      "index  {'svc_c': 14.99270459807389, 'svc_gamma': 0.07...  0.873518   \n",
      "index  {'learning_rate': 0.049433721318135074, 'max_d...  0.893281   \n",
      "index  {'num_leaves': 77, 'max_depth': 41, 'learning_...  0.895257   \n",
      "index                                               None  0.901161   \n",
      "index                                               None  0.898695   \n",
      "index                                               None  0.889304   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "index     0.844898     0.923372   0.911894  0.877119  0.771973   \n",
      "index     0.840816     0.923372   0.911504  0.874735  0.768193   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.804082     0.938697   0.924883  0.860262  0.751864   \n",
      "index     0.844898     0.938697   0.928251  0.884615  0.788768   \n",
      "index     0.848980     0.938697   0.928571  0.886994  0.792507   \n",
      "index     0.869388     0.923372   0.914163  0.891213  0.794850   \n",
      "index     0.853061     0.934866   0.924779  0.887473  0.792056   \n",
      "index     0.848980     0.931034   0.920354  0.883227  0.784102   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_no_...  \n",
      "index  selected_features_all_best50_LGBMClassifier_no...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index  selected_features_all_best50_SVC_with_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_wit...  \n",
      "index  selected_features_all_best50_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best100_LogisticRegressi...  \n",
      "index   selected_features_all_best100_SVC_no_hypertuning  \n",
      "index  selected_features_all_best100_XGBClassifier_no...  \n",
      "Evaluating selected_features_all_best100 LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:56:35,852]\u001b[0m A new study created in memory with name: no-name-43b144b1-9ee0-4e09-9aa9-0b9af1db68db\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:35,963]\u001b[0m Trial 0 finished with value: 0.8814229249011858 and parameters: {'C': 0.08534929086077442, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 755}. Best is trial 0 with value: 0.8814229249011858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        feature_type               model with_hypertuning   \n",
      "index   selected_features_all_best20  LogisticRegression            False  \\\n",
      "index   selected_features_all_best20                 SVC            False   \n",
      "index   selected_features_all_best20       XGBClassifier            False   \n",
      "index   selected_features_all_best20      LGBMClassifier            False   \n",
      "index   selected_features_all_best20  LogisticRegression             True   \n",
      "index   selected_features_all_best20                 SVC             True   \n",
      "index   selected_features_all_best20       XGBClassifier             True   \n",
      "index   selected_features_all_best20      LGBMClassifier             True   \n",
      "index   selected_features_all_best30  LogisticRegression            False   \n",
      "index   selected_features_all_best30                 SVC            False   \n",
      "index   selected_features_all_best30       XGBClassifier            False   \n",
      "index   selected_features_all_best30      LGBMClassifier            False   \n",
      "index   selected_features_all_best30  LogisticRegression             True   \n",
      "index   selected_features_all_best30                 SVC             True   \n",
      "index   selected_features_all_best30       XGBClassifier             True   \n",
      "index   selected_features_all_best30      LGBMClassifier             True   \n",
      "index   selected_features_all_best50  LogisticRegression            False   \n",
      "index   selected_features_all_best50                 SVC            False   \n",
      "index   selected_features_all_best50       XGBClassifier            False   \n",
      "index   selected_features_all_best50      LGBMClassifier            False   \n",
      "index   selected_features_all_best50  LogisticRegression             True   \n",
      "index   selected_features_all_best50                 SVC             True   \n",
      "index   selected_features_all_best50       XGBClassifier             True   \n",
      "index   selected_features_all_best50      LGBMClassifier             True   \n",
      "index  selected_features_all_best100  LogisticRegression            False   \n",
      "index  selected_features_all_best100                 SVC            False   \n",
      "index  selected_features_all_best100       XGBClassifier            False   \n",
      "index  selected_features_all_best100      LGBMClassifier            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.888807   \n",
      "index  {'C': 0.024422805336610946, 'penalty': 'l1', '...  0.889328   \n",
      "index  {'svc_c': 14.99270459807389, 'svc_gamma': 0.07...  0.873518   \n",
      "index  {'learning_rate': 0.049433721318135074, 'max_d...  0.893281   \n",
      "index  {'num_leaves': 77, 'max_depth': 41, 'learning_...  0.895257   \n",
      "index                                               None  0.901161   \n",
      "index                                               None  0.898695   \n",
      "index                                               None  0.889304   \n",
      "index                                               None  0.892762   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "index     0.844898     0.923372   0.911894  0.877119  0.771973   \n",
      "index     0.840816     0.923372   0.911504  0.874735  0.768193   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.804082     0.938697   0.924883  0.860262  0.751864   \n",
      "index     0.844898     0.938697   0.928251  0.884615  0.788768   \n",
      "index     0.848980     0.938697   0.928571  0.886994  0.792507   \n",
      "index     0.869388     0.923372   0.914163  0.891213  0.794850   \n",
      "index     0.853061     0.934866   0.924779  0.887473  0.792056   \n",
      "index     0.848980     0.931034   0.920354  0.883227  0.784102   \n",
      "index     0.844898     0.927203   0.915929  0.878981  0.776147   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_no_...  \n",
      "index  selected_features_all_best50_LGBMClassifier_no...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index  selected_features_all_best50_SVC_with_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_wit...  \n",
      "index  selected_features_all_best50_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best100_LogisticRegressi...  \n",
      "index   selected_features_all_best100_SVC_no_hypertuning  \n",
      "index  selected_features_all_best100_XGBClassifier_no...  \n",
      "index  selected_features_all_best100_LGBMClassifier_n...  \n",
      "Optimizing selected_features_all_best100 LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:56:39,417]\u001b[0m Trial 1 finished with value: 0.8853754940711462 and parameters: {'C': 0.06225657591442953, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 788}. Best is trial 1 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:39,514]\u001b[0m Trial 2 finished with value: 0.8932806324110671 and parameters: {'C': 0.08263726939093811, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 623}. Best is trial 2 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:40,858]\u001b[0m Trial 3 finished with value: 0.8952569169960475 and parameters: {'C': 0.08082468014153397, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 497}. Best is trial 3 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:40,941]\u001b[0m Trial 4 finished with value: 0.8932806324110671 and parameters: {'C': 0.07663931196568836, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 320}. Best is trial 3 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:41,018]\u001b[0m Trial 5 finished with value: 0.8893280632411067 and parameters: {'C': 0.04487665451060856, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 483}. Best is trial 3 with value: 0.8952569169960475.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:56:44,214]\u001b[0m Trial 6 finished with value: 0.883399209486166 and parameters: {'C': 0.07603853320921976, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 811}. Best is trial 3 with value: 0.8952569169960475.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:56:44,798]\u001b[0m Trial 7 finished with value: 0.8814229249011858 and parameters: {'C': 0.04416900662939269, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 131}. Best is trial 3 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:44,832]\u001b[0m Trial 8 finished with value: 0.8517786561264822 and parameters: {'C': 0.011024979971963481, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 654}. Best is trial 3 with value: 0.8952569169960475.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:56:47,104]\u001b[0m Trial 9 finished with value: 0.8853754940711462 and parameters: {'C': 0.05850620023177643, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 558}. Best is trial 3 with value: 0.8952569169960475.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:56:48,139]\u001b[0m Trial 10 finished with value: 0.8972332015810277 and parameters: {'C': 0.09995242748229684, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 312}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:56:49,312]\u001b[0m Trial 11 finished with value: 0.8972332015810277 and parameters: {'C': 0.09946477981921274, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 332}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:56:50,186]\u001b[0m Trial 12 finished with value: 0.8972332015810277 and parameters: {'C': 0.09641915840527626, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 266}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:56:51,383]\u001b[0m Trial 13 finished with value: 0.8972332015810277 and parameters: {'C': 0.09810207213385891, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 360}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:52,911]\u001b[0m Trial 14 finished with value: 0.8972332015810277 and parameters: {'C': 0.09963324633394435, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 988}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:56:53,451]\u001b[0m Trial 15 finished with value: 0.8952569169960475 and parameters: {'C': 0.0908514709362179, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 148}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:54,872]\u001b[0m Trial 16 finished with value: 0.8972332015810277 and parameters: {'C': 0.09007993904320592, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 417}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:56:55,780]\u001b[0m Trial 17 finished with value: 0.8913043478260869 and parameters: {'C': 0.07104045126963668, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 275}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:56:56,481]\u001b[0m Trial 18 finished with value: 0.8952569169960475 and parameters: {'C': 0.08794542342531896, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 215}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:56:57,703]\u001b[0m Trial 19 finished with value: 0.8972332015810277 and parameters: {'C': 0.0987949322233307, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 400}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:56:58,267]\u001b[0m Trial 20 finished with value: 0.8932806324110671 and parameters: {'C': 0.07294331626911732, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 176}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:56:59,070]\u001b[0m Trial 21 finished with value: 0.8972332015810277 and parameters: {'C': 0.09994326590053121, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 252}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:00,003]\u001b[0m Trial 22 finished with value: 0.8972332015810277 and parameters: {'C': 0.09165077738873598, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 309}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:01,297]\u001b[0m Trial 23 finished with value: 0.8972332015810277 and parameters: {'C': 0.0931866155054519, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 442}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:01,741]\u001b[0m Trial 24 finished with value: 0.8932806324110671 and parameters: {'C': 0.08507649294830569, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 109}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:02,525]\u001b[0m Trial 25 finished with value: 0.8972332015810277 and parameters: {'C': 0.09211742875384717, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 214}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:03,784]\u001b[0m Trial 26 finished with value: 0.8952569169960475 and parameters: {'C': 0.08184151627671833, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 361}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:03,882]\u001b[0m Trial 27 finished with value: 0.8972332015810277 and parameters: {'C': 0.0998202235416987, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 268}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:05,318]\u001b[0m Trial 28 finished with value: 0.8972332015810277 and parameters: {'C': 0.09398038597593261, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 554}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:05,384]\u001b[0m Trial 29 finished with value: 0.8814229249011858 and parameters: {'C': 0.0850942170211846, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 364}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:05,995]\u001b[0m Trial 30 finished with value: 0.8952569169960475 and parameters: {'C': 0.08593535976096377, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 201}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:07,016]\u001b[0m Trial 31 finished with value: 0.8972332015810277 and parameters: {'C': 0.09690313787811226, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 338}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:08,445]\u001b[0m Trial 32 finished with value: 0.8972332015810277 and parameters: {'C': 0.09554863485260713, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 480}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:09,790]\u001b[0m Trial 33 finished with value: 0.8972332015810277 and parameters: {'C': 0.09422978825940831, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 389}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:10,730]\u001b[0m Trial 34 finished with value: 0.8972332015810277 and parameters: {'C': 0.08805597350604624, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 273}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:12,017]\u001b[0m Trial 35 finished with value: 0.8952569169960475 and parameters: {'C': 0.08079933481280138, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 622}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:12,092]\u001b[0m Trial 36 finished with value: 0.8794466403162056 and parameters: {'C': 0.09496459679836138, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 445}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:13,205]\u001b[0m Trial 37 finished with value: 0.8972332015810277 and parameters: {'C': 0.0893284634950715, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 305}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:13,290]\u001b[0m Trial 38 finished with value: 0.8972332015810277 and parameters: {'C': 0.09984367430541256, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 493}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:14,588]\u001b[0m Trial 39 finished with value: 0.8853754940711462 and parameters: {'C': 0.07824683058264795, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 322}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:15,415]\u001b[0m Trial 40 finished with value: 0.8952569169960475 and parameters: {'C': 0.08303960501136161, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 236}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:16,774]\u001b[0m Trial 41 finished with value: 0.8972332015810277 and parameters: {'C': 0.09652694173655638, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 921}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:18,228]\u001b[0m Trial 42 finished with value: 0.8972332015810277 and parameters: {'C': 0.0998898717576252, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 997}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:19,563]\u001b[0m Trial 43 finished with value: 0.8972332015810277 and parameters: {'C': 0.08974102537475512, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 641}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:20,848]\u001b[0m Trial 44 finished with value: 0.8972332015810277 and parameters: {'C': 0.09453149143338747, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 785}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:22,026]\u001b[0m Trial 45 finished with value: 0.8972332015810277 and parameters: {'C': 0.08764768127533784, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 719}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:22,106]\u001b[0m Trial 46 finished with value: 0.8794466403162056 and parameters: {'C': 0.09601947840529919, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 894}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:23,367]\u001b[0m Trial 47 finished with value: 0.8972332015810277 and parameters: {'C': 0.09163712469329238, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 597}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:24,478]\u001b[0m Trial 48 finished with value: 0.8932806324110671 and parameters: {'C': 0.07863784577539627, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 526}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:24,966]\u001b[0m Trial 49 finished with value: 0.8932806324110671 and parameters: {'C': 0.08531690489668856, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 147}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:27,528]\u001b[0m Trial 50 finished with value: 0.8794466403162056 and parameters: {'C': 0.0969522584222337, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 722}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:28,730]\u001b[0m Trial 51 finished with value: 0.8972332015810277 and parameters: {'C': 0.09174956285001346, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 406}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:29,974]\u001b[0m Trial 52 finished with value: 0.8972332015810277 and parameters: {'C': 0.09082011451020268, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 421}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:31,145]\u001b[0m Trial 53 finished with value: 0.8972332015810277 and parameters: {'C': 0.09713597022541486, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 364}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:32,052]\u001b[0m Trial 54 finished with value: 0.8972332015810277 and parameters: {'C': 0.09964468440362378, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 290}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:33,266]\u001b[0m Trial 55 finished with value: 0.8972332015810277 and parameters: {'C': 0.08905329571234487, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 448}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:33,845]\u001b[0m Trial 56 finished with value: 0.8893280632411067 and parameters: {'C': 0.06600489931869598, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 184}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:34,909]\u001b[0m Trial 57 finished with value: 0.8972332015810277 and parameters: {'C': 0.09391761067885965, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 344}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:35,006]\u001b[0m Trial 58 finished with value: 0.8972332015810277 and parameters: {'C': 0.0971589870346858, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 254}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:36,147]\u001b[0m Trial 59 finished with value: 0.8952569169960475 and parameters: {'C': 0.08359851407152646, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 457}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:37,457]\u001b[0m Trial 60 finished with value: 0.8972332015810277 and parameters: {'C': 0.09221605669960119, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 378}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:38,846]\u001b[0m Trial 61 finished with value: 0.8972332015810277 and parameters: {'C': 0.09837676834221037, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 411}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:40,037]\u001b[0m Trial 62 finished with value: 0.8972332015810277 and parameters: {'C': 0.09367917733994342, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 331}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:40,887]\u001b[0m Trial 63 finished with value: 0.8972332015810277 and parameters: {'C': 0.09977889010833267, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 233}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:42,083]\u001b[0m Trial 64 finished with value: 0.8972332015810277 and parameters: {'C': 0.08679386649953988, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 523}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:43,094]\u001b[0m Trial 65 finished with value: 0.8972332015810277 and parameters: {'C': 0.09618697319560232, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 305}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:44,336]\u001b[0m Trial 66 finished with value: 0.8972332015810277 and parameters: {'C': 0.09017776750387932, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 395}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:45,452]\u001b[0m Trial 67 finished with value: 0.8794466403162056 and parameters: {'C': 0.09292251435564299, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 294}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:45,549]\u001b[0m Trial 68 finished with value: 0.8952569169960475 and parameters: {'C': 0.0872528329169152, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 580}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:46,645]\u001b[0m Trial 69 finished with value: 0.8972332015810277 and parameters: {'C': 0.09719714523432446, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 357}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:48,020]\u001b[0m Trial 70 finished with value: 0.8972332015810277 and parameters: {'C': 0.09508490635356687, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 426}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:48,803]\u001b[0m Trial 71 finished with value: 0.8972332015810277 and parameters: {'C': 0.09937727369966394, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 254}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:49,397]\u001b[0m Trial 72 finished with value: 0.8972332015810277 and parameters: {'C': 0.09991431391114398, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 187}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:50,111]\u001b[0m Trial 73 finished with value: 0.8972332015810277 and parameters: {'C': 0.09426443015511497, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 225}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:51,366]\u001b[0m Trial 74 finished with value: 0.8972332015810277 and parameters: {'C': 0.09763632913487809, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 470}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:52,381]\u001b[0m Trial 75 finished with value: 0.8972332015810277 and parameters: {'C': 0.0906615892083897, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 322}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:53,211]\u001b[0m Trial 76 finished with value: 0.8972332015810277 and parameters: {'C': 0.09293629319881798, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 268}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:54,576]\u001b[0m Trial 77 finished with value: 0.883399209486166 and parameters: {'C': 0.08925726201442123, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 379}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:54,662]\u001b[0m Trial 78 finished with value: 0.8972332015810277 and parameters: {'C': 0.09545999453899931, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 343}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:55,049]\u001b[0m Trial 79 finished with value: 0.8932806324110671 and parameters: {'C': 0.09767873738161978, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 117}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:55,595]\u001b[0m Trial 80 finished with value: 0.8952569169960475 and parameters: {'C': 0.0867365998221825, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 166}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:56,523]\u001b[0m Trial 81 finished with value: 0.8972332015810277 and parameters: {'C': 0.0924379026535291, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 306}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:57,417]\u001b[0m Trial 82 finished with value: 0.8972332015810277 and parameters: {'C': 0.0959536861638325, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 282}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:58,150]\u001b[0m Trial 83 finished with value: 0.8972332015810277 and parameters: {'C': 0.09832676164813023, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 213}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:59,484]\u001b[0m Trial 84 finished with value: 0.8972332015810277 and parameters: {'C': 0.08934703497557002, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 854}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:58:00,415]\u001b[0m Trial 85 finished with value: 0.8972332015810277 and parameters: {'C': 0.0945074796165909, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 258}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:58:01,490]\u001b[0m Trial 86 finished with value: 0.8972332015810277 and parameters: {'C': 0.0913393183573767, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 324}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:58:02,582]\u001b[0m Trial 87 finished with value: 0.8972332015810277 and parameters: {'C': 0.0984220947396474, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 363}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:58:05,051]\u001b[0m Trial 88 finished with value: 0.883399209486166 and parameters: {'C': 0.08263889902051326, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 682}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:06,377]\u001b[0m Trial 89 finished with value: 0.8972332015810277 and parameters: {'C': 0.0957521787741299, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 438}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:06,513]\u001b[0m Trial 90 finished with value: 0.8952569169960475 and parameters: {'C': 0.08478408477214926, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 984}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:58:07,723]\u001b[0m Trial 91 finished with value: 0.8972332015810277 and parameters: {'C': 0.09998802744784008, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 407}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:58:08,883]\u001b[0m Trial 92 finished with value: 0.8972332015810277 and parameters: {'C': 0.09383272315064534, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 386}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:58:10,137]\u001b[0m Trial 93 finished with value: 0.8972332015810277 and parameters: {'C': 0.09700279049065214, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 349}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:11,528]\u001b[0m Trial 94 finished with value: 0.8972332015810277 and parameters: {'C': 0.09166065909413919, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 503}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:58:12,395]\u001b[0m Trial 95 finished with value: 0.8972332015810277 and parameters: {'C': 0.08853281976253288, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 240}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:58:13,443]\u001b[0m Trial 96 finished with value: 0.8972332015810277 and parameters: {'C': 0.09330774141488685, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 300}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:14,923]\u001b[0m Trial 97 finished with value: 0.8972332015810277 and parameters: {'C': 0.09819442096275457, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 424}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:58:15,920]\u001b[0m Trial 98 finished with value: 0.8972332015810277 and parameters: {'C': 0.0955837067673092, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 278}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:17,294]\u001b[0m Trial 99 finished with value: 0.8972332015810277 and parameters: {'C': 0.09152386327755069, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 472}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:17,308]\u001b[0m A new study created in memory with name: no-name-65f9fac0-216c-492e-9d68-0c6efd7f3e94\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        feature_type               model with_hypertuning   \n",
      "index   selected_features_all_best20  LogisticRegression            False  \\\n",
      "index   selected_features_all_best20                 SVC            False   \n",
      "index   selected_features_all_best20       XGBClassifier            False   \n",
      "index   selected_features_all_best20      LGBMClassifier            False   \n",
      "index   selected_features_all_best20  LogisticRegression             True   \n",
      "index   selected_features_all_best20                 SVC             True   \n",
      "index   selected_features_all_best20       XGBClassifier             True   \n",
      "index   selected_features_all_best20      LGBMClassifier             True   \n",
      "index   selected_features_all_best30  LogisticRegression            False   \n",
      "index   selected_features_all_best30                 SVC            False   \n",
      "index   selected_features_all_best30       XGBClassifier            False   \n",
      "index   selected_features_all_best30      LGBMClassifier            False   \n",
      "index   selected_features_all_best30  LogisticRegression             True   \n",
      "index   selected_features_all_best30                 SVC             True   \n",
      "index   selected_features_all_best30       XGBClassifier             True   \n",
      "index   selected_features_all_best30      LGBMClassifier             True   \n",
      "index   selected_features_all_best50  LogisticRegression            False   \n",
      "index   selected_features_all_best50                 SVC            False   \n",
      "index   selected_features_all_best50       XGBClassifier            False   \n",
      "index   selected_features_all_best50      LGBMClassifier            False   \n",
      "index   selected_features_all_best50  LogisticRegression             True   \n",
      "index   selected_features_all_best50                 SVC             True   \n",
      "index   selected_features_all_best50       XGBClassifier             True   \n",
      "index   selected_features_all_best50      LGBMClassifier             True   \n",
      "index  selected_features_all_best100  LogisticRegression            False   \n",
      "index  selected_features_all_best100                 SVC            False   \n",
      "index  selected_features_all_best100       XGBClassifier            False   \n",
      "index  selected_features_all_best100      LGBMClassifier            False   \n",
      "index  selected_features_all_best100  LogisticRegression             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.888807   \n",
      "index  {'C': 0.024422805336610946, 'penalty': 'l1', '...  0.889328   \n",
      "index  {'svc_c': 14.99270459807389, 'svc_gamma': 0.07...  0.873518   \n",
      "index  {'learning_rate': 0.049433721318135074, 'max_d...  0.893281   \n",
      "index  {'num_leaves': 77, 'max_depth': 41, 'learning_...  0.895257   \n",
      "index                                               None  0.901161   \n",
      "index                                               None  0.898695   \n",
      "index                                               None  0.889304   \n",
      "index                                               None  0.892762   \n",
      "index  {'C': 0.09995242748229684, 'penalty': 'l2', 's...  0.897233   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "index     0.844898     0.923372   0.911894  0.877119  0.771973   \n",
      "index     0.840816     0.923372   0.911504  0.874735  0.768193   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.804082     0.938697   0.924883  0.860262  0.751864   \n",
      "index     0.844898     0.938697   0.928251  0.884615  0.788768   \n",
      "index     0.848980     0.938697   0.928571  0.886994  0.792507   \n",
      "index     0.869388     0.923372   0.914163  0.891213  0.794850   \n",
      "index     0.853061     0.934866   0.924779  0.887473  0.792056   \n",
      "index     0.848980     0.931034   0.920354  0.883227  0.784102   \n",
      "index     0.844898     0.927203   0.915929  0.878981  0.776147   \n",
      "index     0.869388     0.923372   0.914163  0.891213  0.794850   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_no_...  \n",
      "index  selected_features_all_best50_LGBMClassifier_no...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index  selected_features_all_best50_SVC_with_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_wit...  \n",
      "index  selected_features_all_best50_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best100_LogisticRegressi...  \n",
      "index   selected_features_all_best100_SVC_no_hypertuning  \n",
      "index  selected_features_all_best100_XGBClassifier_no...  \n",
      "index  selected_features_all_best100_LGBMClassifier_n...  \n",
      "index  selected_features_all_best100_LogisticRegressi...  \n",
      "Optimizing selected_features_all_best100 SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:58:18,108]\u001b[0m Trial 0 finished with value: 0.5177865612648221 and parameters: {'svc_c': 78.12209306408987, 'svc_gamma': 26.10190874864247}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:18,822]\u001b[0m Trial 1 finished with value: 0.5138339920948617 and parameters: {'svc_c': 56.51771659426793, 'svc_gamma': 93.67982138851708}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:19,444]\u001b[0m Trial 2 finished with value: 0.5177865612648221 and parameters: {'svc_c': 70.16516705408472, 'svc_gamma': 19.471233381399788}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:20,054]\u001b[0m Trial 3 finished with value: 0.5177865612648221 and parameters: {'svc_c': 6.87552501441381, 'svc_gamma': 42.74508324946356}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:20,652]\u001b[0m Trial 4 finished with value: 0.5138339920948617 and parameters: {'svc_c': 92.10256990605347, 'svc_gamma': 69.4395315432201}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:21,268]\u001b[0m Trial 5 finished with value: 0.5158102766798419 and parameters: {'svc_c': 87.9380330864905, 'svc_gamma': 54.49797561050639}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:21,848]\u001b[0m Trial 6 finished with value: 0.5138339920948617 and parameters: {'svc_c': 21.030219442710642, 'svc_gamma': 71.45267276654978}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:22,428]\u001b[0m Trial 7 finished with value: 0.5138339920948617 and parameters: {'svc_c': 74.55920066166092, 'svc_gamma': 99.32589946003345}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:23,063]\u001b[0m Trial 8 finished with value: 0.5177865612648221 and parameters: {'svc_c': 87.50991953128603, 'svc_gamma': 27.81719412067129}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:23,677]\u001b[0m Trial 9 finished with value: 0.5138339920948617 and parameters: {'svc_c': 89.09266109326043, 'svc_gamma': 78.49695776261838}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:24,300]\u001b[0m Trial 10 finished with value: 0.5177865612648221 and parameters: {'svc_c': 40.20383811729294, 'svc_gamma': 0.8261899603327763}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:24,953]\u001b[0m Trial 11 finished with value: 0.5177865612648221 and parameters: {'svc_c': 66.79999219438982, 'svc_gamma': 17.833754083919473}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:25,597]\u001b[0m Trial 12 finished with value: 0.5177865612648221 and parameters: {'svc_c': 69.91220050670486, 'svc_gamma': 25.38928724195918}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:26,309]\u001b[0m Trial 13 finished with value: 0.5177865612648221 and parameters: {'svc_c': 48.47693681417393, 'svc_gamma': 12.024390534385377}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:26,924]\u001b[0m Trial 14 finished with value: 0.5177865612648221 and parameters: {'svc_c': 98.87672630102877, 'svc_gamma': 37.502476777123114}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:27,600]\u001b[0m Trial 15 finished with value: 0.5177865612648221 and parameters: {'svc_c': 78.8911593680958, 'svc_gamma': 3.09781757138785}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:28,190]\u001b[0m Trial 16 finished with value: 0.5177865612648221 and parameters: {'svc_c': 62.901285902733086, 'svc_gamma': 34.762533786306065}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:28,848]\u001b[0m Trial 17 finished with value: 0.5177865612648221 and parameters: {'svc_c': 78.14503403953863, 'svc_gamma': 17.228605213815037}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:29,423]\u001b[0m Trial 18 finished with value: 0.5158102766798419 and parameters: {'svc_c': 59.89997779068876, 'svc_gamma': 52.640085836737754}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:30,050]\u001b[0m Trial 19 finished with value: 0.5177865612648221 and parameters: {'svc_c': 44.4004364077908, 'svc_gamma': 29.625521050794347}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:30,769]\u001b[0m Trial 20 finished with value: 0.5177865612648221 and parameters: {'svc_c': 77.86894185390364, 'svc_gamma': 11.758566694767751}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:31,430]\u001b[0m Trial 21 finished with value: 0.5177865612648221 and parameters: {'svc_c': 5.7959328247669895, 'svc_gamma': 41.77040995749499}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:32,095]\u001b[0m Trial 22 finished with value: 0.5177865612648221 and parameters: {'svc_c': 2.200677902693818, 'svc_gamma': 40.69328636989428}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:32,707]\u001b[0m Trial 23 finished with value: 0.5158102766798419 and parameters: {'svc_c': 33.689452201602876, 'svc_gamma': 46.4029457788706}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:33,314]\u001b[0m Trial 24 finished with value: 0.5177865612648221 and parameters: {'svc_c': 52.24518585298658, 'svc_gamma': 22.82846223378123}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:33,897]\u001b[0m Trial 25 finished with value: 0.5177865612648221 and parameters: {'svc_c': 65.46907374261639, 'svc_gamma': 33.09367121886532}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:34,610]\u001b[0m Trial 26 finished with value: 0.5177865612648221 and parameters: {'svc_c': 54.582688212601674, 'svc_gamma': 24.706578201078667}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:35,237]\u001b[0m Trial 27 finished with value: 0.5177865612648221 and parameters: {'svc_c': 27.419741687383453, 'svc_gamma': 32.25365245961089}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:35,870]\u001b[0m Trial 28 finished with value: 0.5158102766798419 and parameters: {'svc_c': 11.533441479676572, 'svc_gamma': 47.45700501094412}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:36,467]\u001b[0m Trial 29 finished with value: 0.5158102766798419 and parameters: {'svc_c': 60.4365018450656, 'svc_gamma': 56.49488338892749}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:37,080]\u001b[0m Trial 30 finished with value: 0.5177865612648221 and parameters: {'svc_c': 15.420250296772725, 'svc_gamma': 39.542115899802326}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:37,705]\u001b[0m Trial 31 finished with value: 0.5177865612648221 and parameters: {'svc_c': 84.16628261484625, 'svc_gamma': 27.230559391629807}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:38,366]\u001b[0m Trial 32 finished with value: 0.5177865612648221 and parameters: {'svc_c': 69.29057296844749, 'svc_gamma': 20.199094563844454}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:38,958]\u001b[0m Trial 33 finished with value: 0.5177865612648221 and parameters: {'svc_c': 93.63579586961617, 'svc_gamma': 32.46852597975328}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:39,662]\u001b[0m Trial 34 finished with value: 0.5177865612648221 and parameters: {'svc_c': 81.168342591493, 'svc_gamma': 11.078204117569328}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:40,238]\u001b[0m Trial 35 finished with value: 0.5177865612648221 and parameters: {'svc_c': 72.649605454717, 'svc_gamma': 29.604716904171745}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:40,818]\u001b[0m Trial 36 finished with value: 0.5177865612648221 and parameters: {'svc_c': 86.1308266113879, 'svc_gamma': 25.988657902022535}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:41,382]\u001b[0m Trial 37 finished with value: 0.5158102766798419 and parameters: {'svc_c': 74.42505335149937, 'svc_gamma': 56.3553582533944}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:42,060]\u001b[0m Trial 38 finished with value: 0.5177865612648221 and parameters: {'svc_c': 90.76340774304016, 'svc_gamma': 18.517763983663865}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:42,702]\u001b[0m Trial 39 finished with value: 0.5177865612648221 and parameters: {'svc_c': 60.027405165024874, 'svc_gamma': 36.08585591915288}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:43,328]\u001b[0m Trial 40 finished with value: 0.5158102766798419 and parameters: {'svc_c': 82.35107448440961, 'svc_gamma': 44.380511127653186}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:43,968]\u001b[0m Trial 41 finished with value: 0.541501976284585 and parameters: {'svc_c': 40.0077579058865, 'svc_gamma': 0.4559815297481933}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:44,679]\u001b[0m Trial 42 finished with value: 0.5177865612648221 and parameters: {'svc_c': 24.710500946402913, 'svc_gamma': 6.99552573524626}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:45,400]\u001b[0m Trial 43 finished with value: 0.5177865612648221 and parameters: {'svc_c': 41.07846518938144, 'svc_gamma': 15.525916351343954}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:46,010]\u001b[0m Trial 44 finished with value: 0.5177865612648221 and parameters: {'svc_c': 70.31288751675747, 'svc_gamma': 0.8041748993406301}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:46,728]\u001b[0m Trial 45 finished with value: 0.5177865612648221 and parameters: {'svc_c': 49.54715824082356, 'svc_gamma': 7.77038606645511}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:47,280]\u001b[0m Trial 46 finished with value: 0.5177865612648221 and parameters: {'svc_c': 34.18956059340391, 'svc_gamma': 19.8778322838498}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:47,908]\u001b[0m Trial 47 finished with value: 0.5177865612648221 and parameters: {'svc_c': 65.23870664686687, 'svc_gamma': 14.835425211423034}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:48,476]\u001b[0m Trial 48 finished with value: 0.5177865612648221 and parameters: {'svc_c': 75.75657438288198, 'svc_gamma': 22.507819760506923}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:49,104]\u001b[0m Trial 49 finished with value: 0.5177865612648221 and parameters: {'svc_c': 86.39540122245106, 'svc_gamma': 12.977993084503687}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:49,669]\u001b[0m Trial 50 finished with value: 0.5177865612648221 and parameters: {'svc_c': 55.649106879939886, 'svc_gamma': 29.71047647083089}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:50,289]\u001b[0m Trial 51 finished with value: 0.5177865612648221 and parameters: {'svc_c': 43.74403917218219, 'svc_gamma': 3.680271092441975}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:50,953]\u001b[0m Trial 52 finished with value: 0.5177865612648221 and parameters: {'svc_c': 95.25043980170712, 'svc_gamma': 6.482270378635739}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:51,578]\u001b[0m Trial 53 finished with value: 0.5177865612648221 and parameters: {'svc_c': 87.5978761466698, 'svc_gamma': 3.374586730935164}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:52,102]\u001b[0m Trial 54 finished with value: 0.5197628458498024 and parameters: {'svc_c': 79.8238833811842, 'svc_gamma': 0.6882095574355136}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:52,751]\u001b[0m Trial 55 finished with value: 0.5177865612648221 and parameters: {'svc_c': 80.74910550366529, 'svc_gamma': 9.237035818337468}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:53,361]\u001b[0m Trial 56 finished with value: 0.5177865612648221 and parameters: {'svc_c': 77.27924807856665, 'svc_gamma': 13.885294039087034}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:53,932]\u001b[0m Trial 57 finished with value: 0.5177865612648221 and parameters: {'svc_c': 90.56617479069408, 'svc_gamma': 1.028271321312662}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:54,488]\u001b[0m Trial 58 finished with value: 0.5177865612648221 and parameters: {'svc_c': 72.14370723250099, 'svc_gamma': 21.65320712112557}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 11:58:55,018]\u001b[0m Trial 59 finished with value: 0.5158102766798419 and parameters: {'svc_c': 0.2241604782472706, 'svc_gamma': 16.82387118129886}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:55,661]\u001b[0m Trial 60 finished with value: 0.5177865612648221 and parameters: {'svc_c': 99.61197814730885, 'svc_gamma': 9.980635335718425}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:56,192]\u001b[0m Trial 61 finished with value: 0.549407114624506 and parameters: {'svc_c': 67.34452739000359, 'svc_gamma': 0.3767760345092279}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:56,788]\u001b[0m Trial 62 finished with value: 0.5177865612648221 and parameters: {'svc_c': 67.91807574320663, 'svc_gamma': 2.134119354637569}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:57,470]\u001b[0m Trial 63 finished with value: 0.5177865612648221 and parameters: {'svc_c': 79.05984313027163, 'svc_gamma': 6.167742284621662}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:58,212]\u001b[0m Trial 64 finished with value: 0.5177865612648221 and parameters: {'svc_c': 63.32810578157674, 'svc_gamma': 5.313682615466945}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:58,911]\u001b[0m Trial 65 finished with value: 0.5177865612648221 and parameters: {'svc_c': 84.02604950784888, 'svc_gamma': 10.759901004671239}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:59,461]\u001b[0m Trial 66 finished with value: 0.5395256916996047 and parameters: {'svc_c': 57.45734990550913, 'svc_gamma': 0.4917907994260844}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:00,108]\u001b[0m Trial 67 finished with value: 0.5177865612648221 and parameters: {'svc_c': 67.09237317635507, 'svc_gamma': 3.4761602079549814}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:00,701]\u001b[0m Trial 68 finished with value: 0.5177865612648221 and parameters: {'svc_c': 54.25199886070488, 'svc_gamma': 0.8883587214380526}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:01,397]\u001b[0m Trial 69 finished with value: 0.5177865612648221 and parameters: {'svc_c': 58.46342898981147, 'svc_gamma': 8.134384269612127}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:02,036]\u001b[0m Trial 70 finished with value: 0.5177865612648221 and parameters: {'svc_c': 63.9384244034017, 'svc_gamma': 12.71448352263352}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:02,710]\u001b[0m Trial 71 finished with value: 0.5177865612648221 and parameters: {'svc_c': 74.41090304104212, 'svc_gamma': 4.392280322535236}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:03,296]\u001b[0m Trial 72 finished with value: 0.5177865612648221 and parameters: {'svc_c': 70.91322675793022, 'svc_gamma': 17.29549618679265}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:03,896]\u001b[0m Trial 73 finished with value: 0.5177865612648221 and parameters: {'svc_c': 57.54754674473161, 'svc_gamma': 24.693386183097967}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:04,453]\u001b[0m Trial 74 finished with value: 0.5177865612648221 and parameters: {'svc_c': 46.91424234826596, 'svc_gamma': 38.065188489516004}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:05,096]\u001b[0m Trial 75 finished with value: 0.5177865612648221 and parameters: {'svc_c': 62.116887888267, 'svc_gamma': 9.51289035137472}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:05,651]\u001b[0m Trial 76 finished with value: 0.5217391304347826 and parameters: {'svc_c': 69.0834459958098, 'svc_gamma': 0.6146482852752728}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:06,203]\u001b[0m Trial 77 finished with value: 0.5395256916996047 and parameters: {'svc_c': 67.65309020408299, 'svc_gamma': 0.4923471900873218}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:06,795]\u001b[0m Trial 78 finished with value: 0.5395256916996047 and parameters: {'svc_c': 67.93724587498527, 'svc_gamma': 0.4657738748022488}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:07,357]\u001b[0m Trial 79 finished with value: 0.5177865612648221 and parameters: {'svc_c': 68.23468194284818, 'svc_gamma': 0.8928780120547333}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:07,905]\u001b[0m Trial 80 finished with value: 0.782608695652174 and parameters: {'svc_c': 65.86290153385131, 'svc_gamma': 0.11904978014531864}. Best is trial 80 with value: 0.782608695652174.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:08,551]\u001b[0m Trial 81 finished with value: 0.5177865612648221 and parameters: {'svc_c': 66.01501499572534, 'svc_gamma': 4.514291135448202}. Best is trial 80 with value: 0.782608695652174.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:09,073]\u001b[0m Trial 82 finished with value: 0.5177865612648221 and parameters: {'svc_c': 71.73489086964884, 'svc_gamma': 1.0286822527761732}. Best is trial 80 with value: 0.782608695652174.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:09,636]\u001b[0m Trial 83 finished with value: 0.5553359683794467 and parameters: {'svc_c': 60.43673293089242, 'svc_gamma': 0.35760934187154875}. Best is trial 80 with value: 0.782608695652174.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:10,172]\u001b[0m Trial 84 finished with value: 0.5513833992094862 and parameters: {'svc_c': 60.350428599391996, 'svc_gamma': 0.3750546089426725}. Best is trial 80 with value: 0.782608695652174.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:10,698]\u001b[0m Trial 85 finished with value: 0.8537549407114624 and parameters: {'svc_c': 61.61503292652254, 'svc_gamma': 0.06504249547943969}. Best is trial 85 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:11,368]\u001b[0m Trial 86 finished with value: 0.5177865612648221 and parameters: {'svc_c': 61.66460851310706, 'svc_gamma': 6.366137664385801}. Best is trial 85 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:12,028]\u001b[0m Trial 87 finished with value: 0.5177865612648221 and parameters: {'svc_c': 58.81707662626825, 'svc_gamma': 4.108345031080367}. Best is trial 85 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:12,689]\u001b[0m Trial 88 finished with value: 0.5177865612648221 and parameters: {'svc_c': 52.21580661780672, 'svc_gamma': 8.124753847543058}. Best is trial 85 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:13,167]\u001b[0m Trial 89 finished with value: 0.857707509881423 and parameters: {'svc_c': 64.25208237539199, 'svc_gamma': 0.060529061603055156}. Best is trial 89 with value: 0.857707509881423.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:13,797]\u001b[0m Trial 90 finished with value: 0.5177865612648221 and parameters: {'svc_c': 60.41790344827232, 'svc_gamma': 3.3227577076389485}. Best is trial 89 with value: 0.857707509881423.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:14,451]\u001b[0m Trial 91 finished with value: 0.5177865612648221 and parameters: {'svc_c': 64.43941660574065, 'svc_gamma': 5.537332978180605}. Best is trial 89 with value: 0.857707509881423.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:15,044]\u001b[0m Trial 92 finished with value: 0.5177865612648221 and parameters: {'svc_c': 57.380402697177374, 'svc_gamma': 2.6312188727709955}. Best is trial 89 with value: 0.857707509881423.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:15,682]\u001b[0m Trial 93 finished with value: 0.5177865612648221 and parameters: {'svc_c': 61.67273429713002, 'svc_gamma': 7.492000218830354}. Best is trial 89 with value: 0.857707509881423.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:16,283]\u001b[0m Trial 94 finished with value: 0.5177865612648221 and parameters: {'svc_c': 64.87633401286764, 'svc_gamma': 3.1106568997932715}. Best is trial 89 with value: 0.857707509881423.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:16,962]\u001b[0m Trial 95 finished with value: 0.5177865612648221 and parameters: {'svc_c': 66.2773608096853, 'svc_gamma': 11.172693320337725}. Best is trial 89 with value: 0.857707509881423.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:17,495]\u001b[0m Trial 96 finished with value: 0.7687747035573123 and parameters: {'svc_c': 55.79377286071175, 'svc_gamma': 0.12960445791754843}. Best is trial 89 with value: 0.857707509881423.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:18,153]\u001b[0m Trial 97 finished with value: 0.5177865612648221 and parameters: {'svc_c': 56.601014102504614, 'svc_gamma': 5.482633144432434}. Best is trial 89 with value: 0.857707509881423.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:18,690]\u001b[0m Trial 98 finished with value: 0.7213438735177866 and parameters: {'svc_c': 53.333521804046036, 'svc_gamma': 0.15325989946300844}. Best is trial 89 with value: 0.857707509881423.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:19,332]\u001b[0m Trial 99 finished with value: 0.5177865612648221 and parameters: {'svc_c': 53.50872440634743, 'svc_gamma': 9.30280088803868}. Best is trial 89 with value: 0.857707509881423.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:19,343]\u001b[0m A new study created in memory with name: no-name-13591680-6693-4878-9fcd-baecec84049d\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        feature_type               model with_hypertuning   \n",
      "index   selected_features_all_best20  LogisticRegression            False  \\\n",
      "index   selected_features_all_best20                 SVC            False   \n",
      "index   selected_features_all_best20       XGBClassifier            False   \n",
      "index   selected_features_all_best20      LGBMClassifier            False   \n",
      "index   selected_features_all_best20  LogisticRegression             True   \n",
      "index   selected_features_all_best20                 SVC             True   \n",
      "index   selected_features_all_best20       XGBClassifier             True   \n",
      "index   selected_features_all_best20      LGBMClassifier             True   \n",
      "index   selected_features_all_best30  LogisticRegression            False   \n",
      "index   selected_features_all_best30                 SVC            False   \n",
      "index   selected_features_all_best30       XGBClassifier            False   \n",
      "index   selected_features_all_best30      LGBMClassifier            False   \n",
      "index   selected_features_all_best30  LogisticRegression             True   \n",
      "index   selected_features_all_best30                 SVC             True   \n",
      "index   selected_features_all_best30       XGBClassifier             True   \n",
      "index   selected_features_all_best30      LGBMClassifier             True   \n",
      "index   selected_features_all_best50  LogisticRegression            False   \n",
      "index   selected_features_all_best50                 SVC            False   \n",
      "index   selected_features_all_best50       XGBClassifier            False   \n",
      "index   selected_features_all_best50      LGBMClassifier            False   \n",
      "index   selected_features_all_best50  LogisticRegression             True   \n",
      "index   selected_features_all_best50                 SVC             True   \n",
      "index   selected_features_all_best50       XGBClassifier             True   \n",
      "index   selected_features_all_best50      LGBMClassifier             True   \n",
      "index  selected_features_all_best100  LogisticRegression            False   \n",
      "index  selected_features_all_best100                 SVC            False   \n",
      "index  selected_features_all_best100       XGBClassifier            False   \n",
      "index  selected_features_all_best100      LGBMClassifier            False   \n",
      "index  selected_features_all_best100  LogisticRegression             True   \n",
      "index  selected_features_all_best100                 SVC             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.888807   \n",
      "index  {'C': 0.024422805336610946, 'penalty': 'l1', '...  0.889328   \n",
      "index  {'svc_c': 14.99270459807389, 'svc_gamma': 0.07...  0.873518   \n",
      "index  {'learning_rate': 0.049433721318135074, 'max_d...  0.893281   \n",
      "index  {'num_leaves': 77, 'max_depth': 41, 'learning_...  0.895257   \n",
      "index                                               None  0.901161   \n",
      "index                                               None  0.898695   \n",
      "index                                               None  0.889304   \n",
      "index                                               None  0.892762   \n",
      "index  {'C': 0.09995242748229684, 'penalty': 'l2', 's...  0.897233   \n",
      "index  {'svc_c': 64.25208237539199, 'svc_gamma': 0.06...  0.857708   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "index     0.844898     0.923372   0.911894  0.877119  0.771973   \n",
      "index     0.840816     0.923372   0.911504  0.874735  0.768193   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.804082     0.938697   0.924883  0.860262  0.751864   \n",
      "index     0.844898     0.938697   0.928251  0.884615  0.788768   \n",
      "index     0.848980     0.938697   0.928571  0.886994  0.792507   \n",
      "index     0.869388     0.923372   0.914163  0.891213  0.794850   \n",
      "index     0.853061     0.934866   0.924779  0.887473  0.792056   \n",
      "index     0.848980     0.931034   0.920354  0.883227  0.784102   \n",
      "index     0.844898     0.927203   0.915929  0.878981  0.776147   \n",
      "index     0.869388     0.923372   0.914163  0.891213  0.794850   \n",
      "index     0.746939     0.961686   0.948187  0.835616  0.729069   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_no_...  \n",
      "index  selected_features_all_best50_LGBMClassifier_no...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index  selected_features_all_best50_SVC_with_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_wit...  \n",
      "index  selected_features_all_best50_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best100_LogisticRegressi...  \n",
      "index   selected_features_all_best100_SVC_no_hypertuning  \n",
      "index  selected_features_all_best100_XGBClassifier_no...  \n",
      "index  selected_features_all_best100_LGBMClassifier_n...  \n",
      "index  selected_features_all_best100_LogisticRegressi...  \n",
      "index  selected_features_all_best100_SVC_with_hypertu...  \n",
      "Optimizing selected_features_all_best100 XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:59:21,611]\u001b[0m Trial 0 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.21246312417174512, 'max_depth': 2, 'n_estimators': 616}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:25,717]\u001b[0m Trial 1 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.05172888818693755, 'max_depth': 5, 'n_estimators': 403}. Best is trial 1 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:30,699]\u001b[0m Trial 2 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.05498622277393403, 'max_depth': 4, 'n_estimators': 496}. Best is trial 1 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:33,145]\u001b[0m Trial 3 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.2611868850156039, 'max_depth': 4, 'n_estimators': 354}. Best is trial 1 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:38,608]\u001b[0m Trial 4 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.1243897891289126, 'max_depth': 4, 'n_estimators': 966}. Best is trial 1 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:46,368]\u001b[0m Trial 5 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.03667566766486474, 'max_depth': 5, 'n_estimators': 979}. Best is trial 1 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:48,653]\u001b[0m Trial 6 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.28880765451505963, 'max_depth': 2, 'n_estimators': 573}. Best is trial 1 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:53,228]\u001b[0m Trial 7 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.032429486033561855, 'max_depth': 5, 'n_estimators': 422}. Best is trial 1 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:56,499]\u001b[0m Trial 8 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.2821243953020519, 'max_depth': 5, 'n_estimators': 347}. Best is trial 1 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:00:02,190]\u001b[0m Trial 9 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.2920560087238877, 'max_depth': 6, 'n_estimators': 768}. Best is trial 9 with value: 0.8992094861660079.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:00:11,263]\u001b[0m Trial 10 finished with value: 0.9011857707509882 and parameters: {'learning_rate': 0.2127264711148268, 'max_depth': 6, 'n_estimators': 764}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:00:21,840]\u001b[0m Trial 11 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.23358501763865008, 'max_depth': 6, 'n_estimators': 760}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:00:27,071]\u001b[0m Trial 12 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.19452557147907185, 'max_depth': 6, 'n_estimators': 752}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:00:32,233]\u001b[0m Trial 13 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.237601434553587, 'max_depth': 6, 'n_estimators': 790}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:00:33,202]\u001b[0m Trial 14 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.29588493745030875, 'max_depth': 3, 'n_estimators': 149}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:00:39,888]\u001b[0m Trial 15 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.17393674473697301, 'max_depth': 6, 'n_estimators': 855}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:00:44,926]\u001b[0m Trial 16 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.25428495693129033, 'max_depth': 6, 'n_estimators': 672}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:00:49,679]\u001b[0m Trial 17 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.13932695065337997, 'max_depth': 3, 'n_estimators': 844}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:00:55,463]\u001b[0m Trial 18 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.21539106043897027, 'max_depth': 5, 'n_estimators': 672}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:01:01,305]\u001b[0m Trial 19 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.2720752302317462, 'max_depth': 6, 'n_estimators': 895}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:01:04,970]\u001b[0m Trial 20 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.25099685066440114, 'max_depth': 3, 'n_estimators': 222}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:01:11,719]\u001b[0m Trial 21 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.16801418941330376, 'max_depth': 6, 'n_estimators': 874}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:01:16,855]\u001b[0m Trial 22 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.185704326710073, 'max_depth': 6, 'n_estimators': 716}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:01:21,816]\u001b[0m Trial 23 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.1606775469160277, 'max_depth': 5, 'n_estimators': 810}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:01:27,117]\u001b[0m Trial 24 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.22645179964734047, 'max_depth': 6, 'n_estimators': 900}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:01:31,129]\u001b[0m Trial 25 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.20109625361938918, 'max_depth': 5, 'n_estimators': 645}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:01:35,725]\u001b[0m Trial 26 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.27000335724073726, 'max_depth': 6, 'n_estimators': 528}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:01:40,412]\u001b[0m Trial 27 finished with value: 0.9051383399209486 and parameters: {'learning_rate': 0.29754822620365323, 'max_depth': 4, 'n_estimators': 926}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:01:45,359]\u001b[0m Trial 28 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.28314310488681954, 'max_depth': 4, 'n_estimators': 1000}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:01:49,970]\u001b[0m Trial 29 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.2951848350145878, 'max_depth': 4, 'n_estimators': 912}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:01:52,524]\u001b[0m Trial 30 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.2985193482664913, 'max_depth': 2, 'n_estimators': 595}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:01:56,854]\u001b[0m Trial 31 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.24756977382343415, 'max_depth': 5, 'n_estimators': 820}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:02:00,624]\u001b[0m Trial 32 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.22560172116797947, 'max_depth': 3, 'n_estimators': 718}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:02:06,024]\u001b[0m Trial 33 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.26747054155262945, 'max_depth': 5, 'n_estimators': 947}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:02:10,904]\u001b[0m Trial 34 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.21176683564733245, 'max_depth': 4, 'n_estimators': 839}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:02:14,845]\u001b[0m Trial 35 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.24606750733735794, 'max_depth': 6, 'n_estimators': 720}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:02:20,047]\u001b[0m Trial 36 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.1772349247013713, 'max_depth': 4, 'n_estimators': 939}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:02:26,586]\u001b[0m Trial 37 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.26328345096574696, 'max_depth': 5, 'n_estimators': 856}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:02:32,173]\u001b[0m Trial 38 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.11105999803649838, 'max_depth': 6, 'n_estimators': 780}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:02:34,941]\u001b[0m Trial 39 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.2760313969090726, 'max_depth': 5, 'n_estimators': 466}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:02:39,351]\u001b[0m Trial 40 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.20757327783901858, 'max_depth': 4, 'n_estimators': 632}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:02:45,081]\u001b[0m Trial 41 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.2811216896533811, 'max_depth': 6, 'n_estimators': 903}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:02:52,796]\u001b[0m Trial 42 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.27118623407852, 'max_depth': 6, 'n_estimators': 954}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:02:58,376]\u001b[0m Trial 43 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.2567371035571457, 'max_depth': 6, 'n_estimators': 871}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:03:02,779]\u001b[0m Trial 44 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.29983822198222354, 'max_depth': 6, 'n_estimators': 769}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:03:10,160]\u001b[0m Trial 45 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.28215829028683154, 'max_depth': 5, 'n_estimators': 1000}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:03:16,379]\u001b[0m Trial 46 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.285667121330633, 'max_depth': 6, 'n_estimators': 907}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:03:21,713]\u001b[0m Trial 47 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.26115019548506374, 'max_depth': 6, 'n_estimators': 815}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:03:26,440]\u001b[0m Trial 48 finished with value: 0.9031620553359684 and parameters: {'learning_rate': 0.22947498993670024, 'max_depth': 6, 'n_estimators': 748}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:03:31,180]\u001b[0m Trial 49 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.19131072271684396, 'max_depth': 5, 'n_estimators': 682}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:03:34,784]\u001b[0m Trial 50 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.23769632288672438, 'max_depth': 3, 'n_estimators': 753}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:03:39,964]\u001b[0m Trial 51 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.22213779845793782, 'max_depth': 6, 'n_estimators': 799}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:03:44,625]\u001b[0m Trial 52 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.23606785411789183, 'max_depth': 6, 'n_estimators': 735}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:03:50,169]\u001b[0m Trial 53 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.27531180485021267, 'max_depth': 6, 'n_estimators': 859}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:03:55,310]\u001b[0m Trial 54 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.2898701633868209, 'max_depth': 6, 'n_estimators': 931}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:00,068]\u001b[0m Trial 55 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.2463879946267618, 'max_depth': 6, 'n_estimators': 687}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:05,462]\u001b[0m Trial 56 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.20170310708388497, 'max_depth': 6, 'n_estimators': 883}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:07,422]\u001b[0m Trial 57 finished with value: 0.9011857707509882 and parameters: {'learning_rate': 0.21609636760199058, 'max_depth': 5, 'n_estimators': 314}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:10,244]\u001b[0m Trial 58 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.18728006541178452, 'max_depth': 5, 'n_estimators': 319}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:13,285]\u001b[0m Trial 59 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.22039410401956758, 'max_depth': 5, 'n_estimators': 560}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:14,344]\u001b[0m Trial 60 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.2135920624676218, 'max_depth': 4, 'n_estimators': 131}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:16,323]\u001b[0m Trial 61 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.26155589040271077, 'max_depth': 6, 'n_estimators': 262}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:18,947]\u001b[0m Trial 62 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.22958743193933065, 'max_depth': 6, 'n_estimators': 416}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:20,198]\u001b[0m Trial 63 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.20163001162972724, 'max_depth': 6, 'n_estimators': 181}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:23,544]\u001b[0m Trial 64 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.28989120471385865, 'max_depth': 4, 'n_estimators': 831}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:28,304]\u001b[0m Trial 65 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.24026042321437613, 'max_depth': 6, 'n_estimators': 968}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:31,387]\u001b[0m Trial 66 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.23032957569567228, 'max_depth': 5, 'n_estimators': 607}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:34,019]\u001b[0m Trial 67 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.2520718667433394, 'max_depth': 6, 'n_estimators': 518}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:36,761]\u001b[0m Trial 68 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.27206514022852896, 'max_depth': 5, 'n_estimators': 461}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:40,802]\u001b[0m Trial 69 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.25596544577256874, 'max_depth': 6, 'n_estimators': 782}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:43,167]\u001b[0m Trial 70 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.17376661131001642, 'max_depth': 4, 'n_estimators': 357}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:46,560]\u001b[0m Trial 71 finished with value: 0.9011857707509882 and parameters: {'learning_rate': 0.18432265152881894, 'max_depth': 6, 'n_estimators': 694}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:50,743]\u001b[0m Trial 72 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.195901637423439, 'max_depth': 6, 'n_estimators': 699}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:54,351]\u001b[0m Trial 73 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.18343393539659553, 'max_depth': 6, 'n_estimators': 755}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:58,555]\u001b[0m Trial 74 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.21129302999224214, 'max_depth': 6, 'n_estimators': 636}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:05:03,143]\u001b[0m Trial 75 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.22006102104221675, 'max_depth': 6, 'n_estimators': 801}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:05:08,056]\u001b[0m Trial 76 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.29306509049472, 'max_depth': 6, 'n_estimators': 736}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:05:13,231]\u001b[0m Trial 77 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.2998113448556124, 'max_depth': 5, 'n_estimators': 843}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:05:18,295]\u001b[0m Trial 78 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.1686072112727568, 'max_depth': 6, 'n_estimators': 878}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:05:21,185]\u001b[0m Trial 79 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.15500441384246894, 'max_depth': 2, 'n_estimators': 659}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:05:25,976]\u001b[0m Trial 80 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.26820882442378985, 'max_depth': 5, 'n_estimators': 925}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:05:29,619]\u001b[0m Trial 81 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.2060601589089161, 'max_depth': 6, 'n_estimators': 715}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:05:34,227]\u001b[0m Trial 82 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.18053848928117078, 'max_depth': 6, 'n_estimators': 783}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:05:39,285]\u001b[0m Trial 83 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.19151591932934708, 'max_depth': 6, 'n_estimators': 814}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:05:43,066]\u001b[0m Trial 84 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.19828926128191002, 'max_depth': 6, 'n_estimators': 586}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:05:47,430]\u001b[0m Trial 85 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.1858645241158682, 'max_depth': 6, 'n_estimators': 733}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:05:50,176]\u001b[0m Trial 86 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.2820310915229983, 'max_depth': 3, 'n_estimators': 664}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:05:54,904]\u001b[0m Trial 87 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.21792641521758266, 'max_depth': 6, 'n_estimators': 709}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:05:58,838]\u001b[0m Trial 88 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.2076964324290555, 'max_depth': 4, 'n_estimators': 888}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:02,960]\u001b[0m Trial 89 finished with value: 0.9011857707509882 and parameters: {'learning_rate': 0.27726762368150704, 'max_depth': 6, 'n_estimators': 852}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:07,053]\u001b[0m Trial 90 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.276199601005673, 'max_depth': 6, 'n_estimators': 850}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:10,075]\u001b[0m Trial 91 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.28971903001550187, 'max_depth': 6, 'n_estimators': 771}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:14,310]\u001b[0m Trial 92 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.2641429984166648, 'max_depth': 6, 'n_estimators': 826}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:19,385]\u001b[0m Trial 93 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.24255571742605672, 'max_depth': 6, 'n_estimators': 912}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:25,090]\u001b[0m Trial 94 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.2275934718489548, 'max_depth': 6, 'n_estimators': 979}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:30,002]\u001b[0m Trial 95 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.28349030806618775, 'max_depth': 6, 'n_estimators': 957}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:34,156]\u001b[0m Trial 96 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.29265708832082366, 'max_depth': 6, 'n_estimators': 759}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:38,620]\u001b[0m Trial 97 finished with value: 0.9011857707509882 and parameters: {'learning_rate': 0.27729980817900696, 'max_depth': 6, 'n_estimators': 864}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:42,961]\u001b[0m Trial 98 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.27510506699826426, 'max_depth': 6, 'n_estimators': 869}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:47,011]\u001b[0m Trial 99 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.2564774984174971, 'max_depth': 4, 'n_estimators': 894}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:47,037]\u001b[0m A new study created in memory with name: no-name-a6efb0b9-d5e1-4c8e-ab73-41f8a2926f70\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        feature_type               model with_hypertuning   \n",
      "index   selected_features_all_best20  LogisticRegression            False  \\\n",
      "index   selected_features_all_best20                 SVC            False   \n",
      "index   selected_features_all_best20       XGBClassifier            False   \n",
      "index   selected_features_all_best20      LGBMClassifier            False   \n",
      "index   selected_features_all_best20  LogisticRegression             True   \n",
      "index   selected_features_all_best20                 SVC             True   \n",
      "index   selected_features_all_best20       XGBClassifier             True   \n",
      "index   selected_features_all_best20      LGBMClassifier             True   \n",
      "index   selected_features_all_best30  LogisticRegression            False   \n",
      "index   selected_features_all_best30                 SVC            False   \n",
      "index   selected_features_all_best30       XGBClassifier            False   \n",
      "index   selected_features_all_best30      LGBMClassifier            False   \n",
      "index   selected_features_all_best30  LogisticRegression             True   \n",
      "index   selected_features_all_best30                 SVC             True   \n",
      "index   selected_features_all_best30       XGBClassifier             True   \n",
      "index   selected_features_all_best30      LGBMClassifier             True   \n",
      "index   selected_features_all_best50  LogisticRegression            False   \n",
      "index   selected_features_all_best50                 SVC            False   \n",
      "index   selected_features_all_best50       XGBClassifier            False   \n",
      "index   selected_features_all_best50      LGBMClassifier            False   \n",
      "index   selected_features_all_best50  LogisticRegression             True   \n",
      "index   selected_features_all_best50                 SVC             True   \n",
      "index   selected_features_all_best50       XGBClassifier             True   \n",
      "index   selected_features_all_best50      LGBMClassifier             True   \n",
      "index  selected_features_all_best100  LogisticRegression            False   \n",
      "index  selected_features_all_best100                 SVC            False   \n",
      "index  selected_features_all_best100       XGBClassifier            False   \n",
      "index  selected_features_all_best100      LGBMClassifier            False   \n",
      "index  selected_features_all_best100  LogisticRegression             True   \n",
      "index  selected_features_all_best100                 SVC             True   \n",
      "index  selected_features_all_best100       XGBClassifier             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.888807   \n",
      "index  {'C': 0.024422805336610946, 'penalty': 'l1', '...  0.889328   \n",
      "index  {'svc_c': 14.99270459807389, 'svc_gamma': 0.07...  0.873518   \n",
      "index  {'learning_rate': 0.049433721318135074, 'max_d...  0.893281   \n",
      "index  {'num_leaves': 77, 'max_depth': 41, 'learning_...  0.895257   \n",
      "index                                               None  0.901161   \n",
      "index                                               None  0.898695   \n",
      "index                                               None  0.889304   \n",
      "index                                               None  0.892762   \n",
      "index  {'C': 0.09995242748229684, 'penalty': 'l2', 's...  0.897233   \n",
      "index  {'svc_c': 64.25208237539199, 'svc_gamma': 0.06...  0.857708   \n",
      "index  {'learning_rate': 0.29754822620365323, 'max_de...  0.905138   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "index     0.844898     0.923372   0.911894  0.877119  0.771973   \n",
      "index     0.840816     0.923372   0.911504  0.874735  0.768193   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.804082     0.938697   0.924883  0.860262  0.751864   \n",
      "index     0.844898     0.938697   0.928251  0.884615  0.788768   \n",
      "index     0.848980     0.938697   0.928571  0.886994  0.792507   \n",
      "index     0.869388     0.923372   0.914163  0.891213  0.794850   \n",
      "index     0.853061     0.934866   0.924779  0.887473  0.792056   \n",
      "index     0.848980     0.931034   0.920354  0.883227  0.784102   \n",
      "index     0.844898     0.927203   0.915929  0.878981  0.776147   \n",
      "index     0.869388     0.923372   0.914163  0.891213  0.794850   \n",
      "index     0.746939     0.961686   0.948187  0.835616  0.729069   \n",
      "index     0.861224     0.946360   0.937778  0.897872  0.812170   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_no_...  \n",
      "index  selected_features_all_best50_LGBMClassifier_no...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index  selected_features_all_best50_SVC_with_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_wit...  \n",
      "index  selected_features_all_best50_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best100_LogisticRegressi...  \n",
      "index   selected_features_all_best100_SVC_no_hypertuning  \n",
      "index  selected_features_all_best100_XGBClassifier_no...  \n",
      "index  selected_features_all_best100_LGBMClassifier_n...  \n",
      "index  selected_features_all_best100_LogisticRegressi...  \n",
      "index  selected_features_all_best100_SVC_with_hypertu...  \n",
      "index  selected_features_all_best100_XGBClassifier_wi...  \n",
      "Optimizing selected_features_all_best100 LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 12:06:48,046]\u001b[0m Trial 0 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 98, 'max_depth': 22, 'learning_rate': 0.26204601918854353, 'n_estimators': 444}. Best is trial 0 with value: 0.8873517786561265.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:49,925]\u001b[0m Trial 1 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 37, 'max_depth': 32, 'learning_rate': 0.0747843128262703, 'n_estimators': 364}. Best is trial 1 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:53,805]\u001b[0m Trial 2 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 177, 'max_depth': 32, 'learning_rate': 0.14651735429553095, 'n_estimators': 1942}. Best is trial 1 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:56,951]\u001b[0m Trial 3 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 120, 'max_depth': 8, 'learning_rate': 0.09491243639916087, 'n_estimators': 1849}. Best is trial 1 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:59,431]\u001b[0m Trial 4 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 127, 'max_depth': 37, 'learning_rate': 0.22604242726241228, 'n_estimators': 550}. Best is trial 1 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:07:21,585]\u001b[0m Trial 5 finished with value: 0.8992094861660079 and parameters: {'num_leaves': 184, 'max_depth': 20, 'learning_rate': 0.006351363152992852, 'n_estimators': 1858}. Best is trial 5 with value: 0.8992094861660079.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:07:33,496]\u001b[0m Trial 6 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 151, 'max_depth': 33, 'learning_rate': 0.016760276542685127, 'n_estimators': 1254}. Best is trial 5 with value: 0.8992094861660079.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:07:36,627]\u001b[0m Trial 7 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 90, 'max_depth': 20, 'learning_rate': 0.0881056672701243, 'n_estimators': 1142}. Best is trial 5 with value: 0.8992094861660079.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:07:38,818]\u001b[0m Trial 8 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 233, 'max_depth': 49, 'learning_rate': 0.27003796452459133, 'n_estimators': 917}. Best is trial 5 with value: 0.8992094861660079.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:07:41,167]\u001b[0m Trial 9 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 58, 'max_depth': 23, 'learning_rate': 0.23814815913655465, 'n_estimators': 567}. Best is trial 5 with value: 0.8992094861660079.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:07:45,103]\u001b[0m Trial 10 finished with value: 0.9011857707509882 and parameters: {'num_leaves': 245, 'max_depth': 5, 'learning_rate': 0.007001654229489285, 'n_estimators': 1599}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:07:47,247]\u001b[0m Trial 11 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 253, 'max_depth': 4, 'learning_rate': 0.003570759959457393, 'n_estimators': 1546}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:07:54,437]\u001b[0m Trial 12 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 189, 'max_depth': 10, 'learning_rate': 0.038302197011485455, 'n_estimators': 1474}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:08:11,289]\u001b[0m Trial 13 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 214, 'max_depth': 14, 'learning_rate': 0.0015362734029856617, 'n_estimators': 1659}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:08:16,599]\u001b[0m Trial 14 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 202, 'max_depth': 15, 'learning_rate': 0.05882176642099174, 'n_estimators': 1751}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:08:17,311]\u001b[0m Trial 15 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 255, 'max_depth': 2, 'learning_rate': 0.04258102289310523, 'n_estimators': 1303}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:08:19,868]\u001b[0m Trial 16 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 161, 'max_depth': 16, 'learning_rate': 0.11208337790521736, 'n_estimators': 880}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:08:26,164]\u001b[0m Trial 17 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 222, 'max_depth': 41, 'learning_rate': 0.04252132567278376, 'n_estimators': 1986}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:08:27,868]\u001b[0m Trial 18 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 4, 'max_depth': 28, 'learning_rate': 0.13068091170039026, 'n_estimators': 1435}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:08:31,335]\u001b[0m Trial 19 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 169, 'max_depth': 8, 'learning_rate': 0.18038715373383296, 'n_estimators': 1676}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:08:34,486]\u001b[0m Trial 20 finished with value: 0.8992094861660079 and parameters: {'num_leaves': 198, 'max_depth': 26, 'learning_rate': 0.060759157177552404, 'n_estimators': 998}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:08:42,540]\u001b[0m Trial 21 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 234, 'max_depth': 26, 'learning_rate': 0.022526386598914386, 'n_estimators': 856}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:08:47,264]\u001b[0m Trial 22 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 203, 'max_depth': 17, 'learning_rate': 0.04377397504878746, 'n_estimators': 1126}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:08:49,205]\u001b[0m Trial 23 finished with value: 0.8992094861660079 and parameters: {'num_leaves': 143, 'max_depth': 27, 'learning_rate': 0.0683948586870417, 'n_estimators': 149}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:08:56,803]\u001b[0m Trial 24 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 185, 'max_depth': 12, 'learning_rate': 0.021397167219452992, 'n_estimators': 1330}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:09:06,437]\u001b[0m Trial 25 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 234, 'max_depth': 41, 'learning_rate': 0.004053217452077262, 'n_estimators': 774}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:09:10,959]\u001b[0m Trial 26 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 195, 'max_depth': 19, 'learning_rate': 0.06902781181039985, 'n_estimators': 1016}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:09:14,464]\u001b[0m Trial 27 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 215, 'max_depth': 5, 'learning_rate': 0.028019472913287317, 'n_estimators': 1822}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:09:22,181]\u001b[0m Trial 28 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 245, 'max_depth': 23, 'learning_rate': 0.050803735009379555, 'n_estimators': 1561}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:09:30,032]\u001b[0m Trial 29 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 108, 'max_depth': 24, 'learning_rate': 0.025584686437228523, 'n_estimators': 688}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:09:34,701]\u001b[0m Trial 30 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 155, 'max_depth': 29, 'learning_rate': 0.0906919070544431, 'n_estimators': 1012}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:09:37,689]\u001b[0m Trial 31 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 147, 'max_depth': 29, 'learning_rate': 0.06303956754824809, 'n_estimators': 143}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:09:40,393]\u001b[0m Trial 32 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 139, 'max_depth': 34, 'learning_rate': 0.07555075326348526, 'n_estimators': 249}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:09:43,883]\u001b[0m Trial 33 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 207, 'max_depth': 20, 'learning_rate': 0.060980942462882964, 'n_estimators': 463}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:09:53,054]\u001b[0m Trial 34 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 173, 'max_depth': 26, 'learning_rate': 0.029332067696794334, 'n_estimators': 1854}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:09:57,326]\u001b[0m Trial 35 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 81, 'max_depth': 38, 'learning_rate': 0.08150916689831518, 'n_estimators': 335}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:10:02,416]\u001b[0m Trial 36 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 131, 'max_depth': 30, 'learning_rate': 0.10617152623330653, 'n_estimators': 1674}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:10:08,811]\u001b[0m Trial 37 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 168, 'max_depth': 34, 'learning_rate': 0.05298431800198406, 'n_estimators': 1886}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:10:09,603]\u001b[0m Trial 38 finished with value: 0.8656126482213439 and parameters: {'num_leaves': 118, 'max_depth': 26, 'learning_rate': 0.010546019916580697, 'n_estimators': 108}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:10:20,044]\u001b[0m Trial 39 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 226, 'max_depth': 50, 'learning_rate': 0.01865268591263491, 'n_estimators': 1199}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:10:23,722]\u001b[0m Trial 40 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 181, 'max_depth': 21, 'learning_rate': 0.07767908779600538, 'n_estimators': 1748}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:10:31,382]\u001b[0m Trial 41 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 187, 'max_depth': 9, 'learning_rate': 0.0345219887442935, 'n_estimators': 1403}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:10:37,227]\u001b[0m Trial 42 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 194, 'max_depth': 13, 'learning_rate': 0.037295007038998455, 'n_estimators': 1458}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:10:46,377]\u001b[0m Trial 43 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 140, 'max_depth': 11, 'learning_rate': 0.0012458664754841572, 'n_estimators': 1540}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:10:49,999]\u001b[0m Trial 44 finished with value: 0.8992094861660079 and parameters: {'num_leaves': 240, 'max_depth': 6, 'learning_rate': 0.05185163935188631, 'n_estimators': 1585}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:10:53,042]\u001b[0m Trial 45 finished with value: 0.8992094861660079 and parameters: {'num_leaves': 245, 'max_depth': 6, 'learning_rate': 0.05562655138659355, 'n_estimators': 1920}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:10:53,713]\u001b[0m Trial 46 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 238, 'max_depth': 2, 'learning_rate': 0.06796150558721119, 'n_estimators': 1599}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:11:05,575]\u001b[0m Trial 47 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 218, 'max_depth': 18, 'learning_rate': 0.015306319865607456, 'n_estimators': 1760}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:11:07,645]\u001b[0m Trial 48 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 255, 'max_depth': 7, 'learning_rate': 0.09580196953839765, 'n_estimators': 598}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:11:15,904]\u001b[0m Trial 49 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 208, 'max_depth': 31, 'learning_rate': 0.047621881547766955, 'n_estimators': 1986}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:11:27,241]\u001b[0m Trial 50 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 158, 'max_depth': 15, 'learning_rate': 0.013892926823980077, 'n_estimators': 1280}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:11:29,873]\u001b[0m Trial 51 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 247, 'max_depth': 5, 'learning_rate': 0.054581154288590485, 'n_estimators': 1911}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:11:33,937]\u001b[0m Trial 52 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 227, 'max_depth': 7, 'learning_rate': 0.03600751854579849, 'n_estimators': 1747}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:11:35,020]\u001b[0m Trial 53 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 241, 'max_depth': 3, 'learning_rate': 0.06172157723410361, 'n_estimators': 1618}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:11:38,591]\u001b[0m Trial 54 finished with value: 0.9011857707509882 and parameters: {'num_leaves': 227, 'max_depth': 6, 'learning_rate': 0.047443865000724665, 'n_estimators': 1796}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:11:44,951]\u001b[0m Trial 55 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 221, 'max_depth': 11, 'learning_rate': 0.031187419233294187, 'n_estimators': 1808}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:11:49,736]\u001b[0m Trial 56 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 196, 'max_depth': 24, 'learning_rate': 0.045201362481111396, 'n_estimators': 1403}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:11:58,865]\u001b[0m Trial 57 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 211, 'max_depth': 45, 'learning_rate': 0.019224175061048423, 'n_estimators': 1658}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:02,704]\u001b[0m Trial 58 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 230, 'max_depth': 27, 'learning_rate': 0.07167093990087557, 'n_estimators': 1497}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:07,983]\u001b[0m Trial 59 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 72, 'max_depth': 9, 'learning_rate': 0.005459453368791896, 'n_estimators': 948}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:09,310]\u001b[0m Trial 60 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 200, 'max_depth': 4, 'learning_rate': 0.04318711429488622, 'n_estimators': 1142}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:12,902]\u001b[0m Trial 61 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 248, 'max_depth': 7, 'learning_rate': 0.05180000849634319, 'n_estimators': 1969}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:17,297]\u001b[0m Trial 62 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 256, 'max_depth': 5, 'learning_rate': 0.026162811094831755, 'n_estimators': 1917}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:20,643]\u001b[0m Trial 63 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 236, 'max_depth': 6, 'learning_rate': 0.08398731565999437, 'n_estimators': 1716}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:21,471]\u001b[0m Trial 64 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 245, 'max_depth': 2, 'learning_rate': 0.059902281256237824, 'n_estimators': 1804}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:29,045]\u001b[0m Trial 65 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 221, 'max_depth': 10, 'learning_rate': 0.03955271301565398, 'n_estimators': 1879}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:31,735]\u001b[0m Trial 66 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 42, 'max_depth': 13, 'learning_rate': 0.07068998335975751, 'n_estimators': 1344}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:43,068]\u001b[0m Trial 67 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 213, 'max_depth': 32, 'learning_rate': 0.016164244274019496, 'n_estimators': 1606}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:47,949]\u001b[0m Trial 68 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 176, 'max_depth': 17, 'learning_rate': 0.027869992277633544, 'n_estimators': 796}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:50,225]\u001b[0m Trial 69 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 99, 'max_depth': 4, 'learning_rate': 0.010131476698485284, 'n_estimators': 1816}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:51,846]\u001b[0m Trial 70 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 229, 'max_depth': 24, 'learning_rate': 0.05292414720522236, 'n_estimators': 207}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:55,650]\u001b[0m Trial 71 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 186, 'max_depth': 9, 'learning_rate': 0.039047870788613645, 'n_estimators': 1529}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:58,641]\u001b[0m Trial 72 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 240, 'max_depth': 6, 'learning_rate': 0.023571042614938732, 'n_estimators': 1210}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:00,321]\u001b[0m Trial 73 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 192, 'max_depth': 8, 'learning_rate': 0.06390378106493454, 'n_estimators': 440}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:05,572]\u001b[0m Trial 74 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 168, 'max_depth': 21, 'learning_rate': 0.034392718861310054, 'n_estimators': 1715}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:08,335]\u001b[0m Trial 75 finished with value: 0.8992094861660079 and parameters: {'num_leaves': 205, 'max_depth': 11, 'learning_rate': 0.07647497467503861, 'n_estimators': 1470}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:11,339]\u001b[0m Trial 76 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 216, 'max_depth': 11, 'learning_rate': 0.08151288092548081, 'n_estimators': 1647}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:12,346]\u001b[0m Trial 77 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 234, 'max_depth': 4, 'learning_rate': 0.09347831224766287, 'n_estimators': 1076}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:15,557]\u001b[0m Trial 78 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 203, 'max_depth': 14, 'learning_rate': 0.07341799421468337, 'n_estimators': 1928}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:19,611]\u001b[0m Trial 79 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 248, 'max_depth': 22, 'learning_rate': 0.05808049150697987, 'n_estimators': 1857}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:23,515]\u001b[0m Trial 80 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 222, 'max_depth': 28, 'learning_rate': 0.04821164959702125, 'n_estimators': 1565}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:27,084]\u001b[0m Trial 81 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 182, 'max_depth': 10, 'learning_rate': 0.043683604814898844, 'n_estimators': 1367}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:31,603]\u001b[0m Trial 82 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 205, 'max_depth': 8, 'learning_rate': 0.023821935926284475, 'n_estimators': 1491}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:34,970]\u001b[0m Trial 83 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 162, 'max_depth': 13, 'learning_rate': 0.0676262195005602, 'n_estimators': 1438}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:36,183]\u001b[0m Trial 84 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 121, 'max_depth': 3, 'learning_rate': 0.03391850499554823, 'n_estimators': 1769}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:40,489]\u001b[0m Trial 85 finished with value: 0.9011857707509882 and parameters: {'num_leaves': 193, 'max_depth': 6, 'learning_rate': 0.008088344143474514, 'n_estimators': 1703}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:41,018]\u001b[0m Trial 86 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 2, 'max_depth': 6, 'learning_rate': 0.004353416198398227, 'n_estimators': 1700}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:45,126]\u001b[0m Trial 87 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 197, 'max_depth': 6, 'learning_rate': 0.018060489273660586, 'n_estimators': 1775}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:52,542]\u001b[0m Trial 88 finished with value: 0.8992094861660079 and parameters: {'num_leaves': 227, 'max_depth': 8, 'learning_rate': 0.010214539967002076, 'n_estimators': 2000}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:53,638]\u001b[0m Trial 89 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 147, 'max_depth': 5, 'learning_rate': 0.052668923023433276, 'n_estimators': 638}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:57,007]\u001b[0m Trial 90 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 210, 'max_depth': 25, 'learning_rate': 0.0874344182144889, 'n_estimators': 1630}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:14:04,724]\u001b[0m Trial 91 finished with value: 0.9011857707509882 and parameters: {'num_leaves': 251, 'max_depth': 8, 'learning_rate': 0.00981288953929796, 'n_estimators': 1997}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:14:05,822]\u001b[0m Trial 92 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 251, 'max_depth': 2, 'learning_rate': 0.004472543623309595, 'n_estimators': 1946}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:14:07,071]\u001b[0m Trial 93 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 239, 'max_depth': 3, 'learning_rate': 0.02965641550963031, 'n_estimators': 1858}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:14:12,863]\u001b[0m Trial 94 finished with value: 0.8992094861660079 and parameters: {'num_leaves': 242, 'max_depth': 7, 'learning_rate': 0.01233494617360778, 'n_estimators': 1895}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:14:19,495]\u001b[0m Trial 95 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 232, 'max_depth': 10, 'learning_rate': 0.018951310307270725, 'n_estimators': 1693}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:14:23,099]\u001b[0m Trial 96 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 251, 'max_depth': 30, 'learning_rate': 0.07750449764405203, 'n_estimators': 1805}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:14:26,026]\u001b[0m Trial 97 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 190, 'max_depth': 9, 'learning_rate': 0.002238077097625175, 'n_estimators': 511}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:14:30,031]\u001b[0m Trial 98 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 217, 'max_depth': 12, 'learning_rate': 0.04577357392705138, 'n_estimators': 1572}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:14:30,686]\u001b[0m Trial 99 finished with value: 0.9031620553359684 and parameters: {'num_leaves': 242, 'max_depth': 5, 'learning_rate': 0.05798877920107935, 'n_estimators': 359}. Best is trial 99 with value: 0.9031620553359684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        feature_type               model with_hypertuning   \n",
      "index   selected_features_all_best20  LogisticRegression            False  \\\n",
      "index   selected_features_all_best20                 SVC            False   \n",
      "index   selected_features_all_best20       XGBClassifier            False   \n",
      "index   selected_features_all_best20      LGBMClassifier            False   \n",
      "index   selected_features_all_best20  LogisticRegression             True   \n",
      "index   selected_features_all_best20                 SVC             True   \n",
      "index   selected_features_all_best20       XGBClassifier             True   \n",
      "index   selected_features_all_best20      LGBMClassifier             True   \n",
      "index   selected_features_all_best30  LogisticRegression            False   \n",
      "index   selected_features_all_best30                 SVC            False   \n",
      "index   selected_features_all_best30       XGBClassifier            False   \n",
      "index   selected_features_all_best30      LGBMClassifier            False   \n",
      "index   selected_features_all_best30  LogisticRegression             True   \n",
      "index   selected_features_all_best30                 SVC             True   \n",
      "index   selected_features_all_best30       XGBClassifier             True   \n",
      "index   selected_features_all_best30      LGBMClassifier             True   \n",
      "index   selected_features_all_best50  LogisticRegression            False   \n",
      "index   selected_features_all_best50                 SVC            False   \n",
      "index   selected_features_all_best50       XGBClassifier            False   \n",
      "index   selected_features_all_best50      LGBMClassifier            False   \n",
      "index   selected_features_all_best50  LogisticRegression             True   \n",
      "index   selected_features_all_best50                 SVC             True   \n",
      "index   selected_features_all_best50       XGBClassifier             True   \n",
      "index   selected_features_all_best50      LGBMClassifier             True   \n",
      "index  selected_features_all_best100  LogisticRegression            False   \n",
      "index  selected_features_all_best100                 SVC            False   \n",
      "index  selected_features_all_best100       XGBClassifier            False   \n",
      "index  selected_features_all_best100      LGBMClassifier            False   \n",
      "index  selected_features_all_best100  LogisticRegression             True   \n",
      "index  selected_features_all_best100                 SVC             True   \n",
      "index  selected_features_all_best100       XGBClassifier             True   \n",
      "index  selected_features_all_best100      LGBMClassifier             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.888807   \n",
      "index  {'C': 0.024422805336610946, 'penalty': 'l1', '...  0.889328   \n",
      "index  {'svc_c': 14.99270459807389, 'svc_gamma': 0.07...  0.873518   \n",
      "index  {'learning_rate': 0.049433721318135074, 'max_d...  0.893281   \n",
      "index  {'num_leaves': 77, 'max_depth': 41, 'learning_...  0.895257   \n",
      "index                                               None  0.901161   \n",
      "index                                               None  0.898695   \n",
      "index                                               None  0.889304   \n",
      "index                                               None  0.892762   \n",
      "index  {'C': 0.09995242748229684, 'penalty': 'l2', 's...  0.897233   \n",
      "index  {'svc_c': 64.25208237539199, 'svc_gamma': 0.06...  0.857708   \n",
      "index  {'learning_rate': 0.29754822620365323, 'max_de...  0.905138   \n",
      "index  {'num_leaves': 242, 'max_depth': 5, 'learning_...  0.903162   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "index     0.844898     0.923372   0.911894  0.877119  0.771973   \n",
      "index     0.840816     0.923372   0.911504  0.874735  0.768193   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.804082     0.938697   0.924883  0.860262  0.751864   \n",
      "index     0.844898     0.938697   0.928251  0.884615  0.788768   \n",
      "index     0.848980     0.938697   0.928571  0.886994  0.792507   \n",
      "index     0.869388     0.923372   0.914163  0.891213  0.794850   \n",
      "index     0.853061     0.934866   0.924779  0.887473  0.792056   \n",
      "index     0.848980     0.931034   0.920354  0.883227  0.784102   \n",
      "index     0.844898     0.927203   0.915929  0.878981  0.776147   \n",
      "index     0.869388     0.923372   0.914163  0.891213  0.794850   \n",
      "index     0.746939     0.961686   0.948187  0.835616  0.729069   \n",
      "index     0.861224     0.946360   0.937778  0.897872  0.812170   \n",
      "index     0.861224     0.942529   0.933628  0.895966  0.807965   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_no_...  \n",
      "index  selected_features_all_best50_LGBMClassifier_no...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index  selected_features_all_best50_SVC_with_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_wit...  \n",
      "index  selected_features_all_best50_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best100_LogisticRegressi...  \n",
      "index   selected_features_all_best100_SVC_no_hypertuning  \n",
      "index  selected_features_all_best100_XGBClassifier_no...  \n",
      "index  selected_features_all_best100_LGBMClassifier_n...  \n",
      "index  selected_features_all_best100_LogisticRegressi...  \n",
      "index  selected_features_all_best100_SVC_with_hypertu...  \n",
      "index  selected_features_all_best100_XGBClassifier_wi...  \n",
      "index  selected_features_all_best100_LGBMClassifier_w...  \n"
     ]
    }
   ],
   "source": [
    "# empty dataframe to store results with the columns feature_type, model, with_hypertuning, accuracy, sensitivity, specificity, precision, f1, mcc\n",
    "results = pd.DataFrame(columns=['feature_type', 'model', 'with_hypertuning', 'best_params', 'accuracy', 'sensitivity', 'specificity', 'precision', 'f1', 'mcc', 'index'])\n",
    "feature_types = ['selected_features_all_best20', 'selected_features_all_best30', 'selected_features_all_best50', 'selected_features_all_best100']\n",
    "for feature_type in feature_types:\n",
    "\n",
    "    # Load the training dataset\n",
    "    data = pd.read_csv(f'{feature_engineered_data_dir}/TR_{feature_type}.csv')\n",
    "\n",
    "    # Separate features and target\n",
    "    X = data.drop(columns=['label', 'id'], axis=1)\n",
    "    y = data['label']\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Evaluate models without hyperparameters tuning\n",
    "    for name, model in models.items():\n",
    "        print(f\"Evaluating {feature_type} {name}\")\n",
    "        results = evaluate_model(name, model, X_train, y_train, X_test, y_test, results, feature_type)\n",
    "        print(results)\n",
    "\n",
    "    # Optimize hyperparameters\n",
    "    for name, model in models_.items():\n",
    "        objective = objectives.get(name)\n",
    "        if objective is not None:\n",
    "            print(f\"Optimizing {feature_type} {name}\")\n",
    "            results = optimize_hyperparameters(name, model, objective, trials=100, results_dataframe=results, feature_type=feature_type, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)\n",
    "            print(results)\n",
    "\n",
    "results.to_csv(f'{feature_engineered_data_dir}/results_20&30&50&100.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model with Full Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Type: AAC done!\n",
      "Feature Type: APAAC done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Type: CTD done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Type: DPC done!\n",
      "Feature Type: PAAC done!\n",
      "Feature Type: selected_features_all_best20 done!\n",
      "Feature Type: selected_features_all_best30 done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Type: selected_features_all_best50 done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Type: selected_features_all_best100 done!\n"
     ]
    }
   ],
   "source": [
    "# Load the results\n",
    "results_without_selected_features = pd.read_csv('results_v2.csv')\n",
    "results_with_selected_features = pd.read_csv(f'{feature_engineered_data_dir}/results_20&30&50&100.csv')\n",
    "\n",
    "feature_types = ['AAC', 'APAAC', 'CTD', 'DPC', 'PAAC']\n",
    "selected_feature_types = ['selected_features_all_best20', 'selected_features_all_best30', 'selected_features_all_best50', 'selected_features_all_best100']\n",
    "\n",
    "# Combine the feature types\n",
    "feature_types.extend(selected_feature_types)\n",
    "\n",
    "test_results = []\n",
    "\n",
    "# iterate through each row of results\n",
    "for feature_type in feature_types:\n",
    "\n",
    "    # Check if the feature type is selected features\n",
    "    if 'selected_features' in feature_type:\n",
    "        # Load the training dataset\n",
    "        train_data = pd.read_csv(f'{feature_engineered_data_dir}/TR_{feature_type}.csv')\n",
    "        test_data = pd.read_csv(f'{feature_engineered_data_dir}/TS_{feature_type}.csv')\n",
    "        results = results_with_selected_features\n",
    "    else:\n",
    "        # Load the training dataset\n",
    "        train_data = pd.read_csv(f'{data_dir}/TR_{feature_type}.csv')\n",
    "        test_data = pd.read_csv(f'{data_dir}/TS_{feature_type}.csv')\n",
    "        results = results_without_selected_features\n",
    "\n",
    "    # Separate features and target\n",
    "    X_train = train_data.drop(columns=['label', 'id'], axis=1)\n",
    "    y_train = train_data['label']\n",
    "\n",
    "    X_test = test_data.drop(columns=['label', 'id'], axis=1)\n",
    "    y_test = test_data['label']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # iterate through each model\n",
    "    for name, model in models.items():\n",
    "        # get the row of the model\n",
    "\n",
    "        \n",
    "        rows = results[(results['feature_type'] == feature_type) & (results['model'] == name)]\n",
    "\n",
    "        # iterate through each row\n",
    "        for index, row in rows.iterrows():\n",
    "\n",
    "            # check whether the model has hyperparameters\n",
    "            if row['with_hypertuning'] == True:\n",
    "                hyperparameters = ast.literal_eval(row['best_params'])\n",
    "                # check the model is SVC\n",
    "                if row['model'] == 'SVC':\n",
    "                    hyperparameters = {k[4:]: v for k, v in hyperparameters.items()}\n",
    "                    # make key 'c' to 'C'\n",
    "                    hyperparameters['C'] = hyperparameters.pop('c')\n",
    "                # set best hyperparameters\n",
    "                model.set_params(**hyperparameters)\n",
    "\n",
    "            # fit model\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # predict\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # evaluate using accuracy, sensitivity, specificity, precision, f1, mcc\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            sensitivity = recall_score(y_test, y_pred)\n",
    "            specificity = recall_score(y_test, y_pred, pos_label=0)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "            # append to test_results\n",
    "            test_results.append({'feature_type': feature_type, 'model': name, 'with_hypertuning': row['with_hypertuning'], 'best_params': row['best_params'], 'accuracy': accuracy, 'sensitivity': sensitivity, 'specificity': specificity, 'precision': precision, 'f1': f1, 'mcc': mcc, 'index': row['index']})\n",
    "    print(f'Feature Type: {feature_type} done!')\n",
    "\n",
    "test_results = pd.DataFrame(test_results)\n",
    "test_results.to_csv('test_results.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Ensembling with Selected Features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "druggable_proteins",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
