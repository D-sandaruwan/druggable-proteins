{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating AAC LogisticRegression\n",
      "      feature_type               model with_hypertuning  accuracy   \n",
      "index          AAC  LogisticRegression            False  0.870562  \\\n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index        0.875     0.924051   0.915888  0.894977  0.800787  \\\n",
      "\n",
      "                                       index  \n",
      "index  AAC_LogisticRegression_no_hypertuning  \n",
      "Evaluating AAC SVC\n",
      "      feature_type               model with_hypertuning  accuracy   \n",
      "index          AAC  LogisticRegression            False  0.870562  \\\n",
      "index          AAC                 SVC            False  0.895351   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.875000     0.924051   0.915888  0.894977  0.800787  \\\n",
      "index     0.825893     0.940928   0.929648  0.874704  0.773776   \n",
      "\n",
      "                                       index  \n",
      "index  AAC_LogisticRegression_no_hypertuning  \n",
      "index                 AAC_SVC_no_hypertuning  \n",
      "Evaluating AAC XGBClassifier\n",
      "      feature_type               model with_hypertuning  accuracy   \n",
      "index          AAC  LogisticRegression            False  0.870562  \\\n",
      "index          AAC                 SVC            False  0.895351   \n",
      "index          AAC       XGBClassifier            False  0.878837   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.875000     0.924051   0.915888  0.894977  0.800787  \\\n",
      "index     0.825893     0.940928   0.929648  0.874704  0.773776   \n",
      "index     0.834821     0.915612   0.903382  0.867749  0.754064   \n",
      "\n",
      "                                       index  \n",
      "index  AAC_LogisticRegression_no_hypertuning  \n",
      "index                 AAC_SVC_no_hypertuning  \n",
      "index       AAC_XGBClassifier_no_hypertuning  \n",
      "Evaluating AAC LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-13 10:59:23,230]\u001b[0m A new study created in memory with name: no-name-83b75a60-d6ee-4e87-9f2b-7d7a37589a72\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning  accuracy   \n",
      "index          AAC  LogisticRegression            False  0.870562  \\\n",
      "index          AAC                 SVC            False  0.895351   \n",
      "index          AAC       XGBClassifier            False  0.878837   \n",
      "index          AAC      LGBMClassifier            False  0.885530   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.875000     0.924051   0.915888  0.894977  0.800787  \\\n",
      "index     0.825893     0.940928   0.929648  0.874704  0.773776   \n",
      "index     0.834821     0.915612   0.903382  0.867749  0.754064   \n",
      "index     0.812500     0.924051   0.910000  0.858491  0.742789   \n",
      "\n",
      "                                       index  \n",
      "index  AAC_LogisticRegression_no_hypertuning  \n",
      "index                 AAC_SVC_no_hypertuning  \n",
      "index       AAC_XGBClassifier_no_hypertuning  \n",
      "index      AAC_LGBMClassifier_no_hypertuning  \n",
      "Optimizing AAC SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-13 10:59:23,766]\u001b[0m Trial 0 finished with value: 0.5509761388286334 and parameters: {'svc_c': 25.24767902464712, 'svc_gamma': 1.5556320756013298}. Best is trial 0 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:24,265]\u001b[0m Trial 1 finished with value: 0.5466377440347071 and parameters: {'svc_c': 70.00109073926264, 'svc_gamma': 57.93728582853489}. Best is trial 0 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:24,743]\u001b[0m Trial 2 finished with value: 0.5466377440347071 and parameters: {'svc_c': 55.41118575902429, 'svc_gamma': 19.56837156908552}. Best is trial 0 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:25,185]\u001b[0m Trial 3 finished with value: 0.5466377440347071 and parameters: {'svc_c': 38.71533986295983, 'svc_gamma': 37.175817923468934}. Best is trial 0 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:25,625]\u001b[0m Trial 4 finished with value: 0.5466377440347071 and parameters: {'svc_c': 91.72450506146482, 'svc_gamma': 30.47001538985282}. Best is trial 0 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:26,082]\u001b[0m Trial 5 finished with value: 0.5466377440347071 and parameters: {'svc_c': 58.398953562742044, 'svc_gamma': 15.644152923648205}. Best is trial 0 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:26,506]\u001b[0m Trial 6 finished with value: 0.5466377440347071 and parameters: {'svc_c': 87.99884796978696, 'svc_gamma': 89.42889270910445}. Best is trial 0 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:26,991]\u001b[0m Trial 7 finished with value: 0.5466377440347071 and parameters: {'svc_c': 84.46131030167679, 'svc_gamma': 22.884756101481155}. Best is trial 0 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:27,591]\u001b[0m Trial 8 finished with value: 0.5509761388286334 and parameters: {'svc_c': 56.13429252108429, 'svc_gamma': 5.766788253296515}. Best is trial 0 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:28,075]\u001b[0m Trial 9 finished with value: 0.5466377440347071 and parameters: {'svc_c': 81.81088755986187, 'svc_gamma': 38.27852680685242}. Best is trial 0 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:28,664]\u001b[0m Trial 10 finished with value: 0.5509761388286334 and parameters: {'svc_c': 6.416563068395998, 'svc_gamma': 5.3431226771662}. Best is trial 0 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:29,132]\u001b[0m Trial 11 finished with value: 0.5509761388286334 and parameters: {'svc_c': 38.04214186999653, 'svc_gamma': 1.3800429353530146}. Best is trial 0 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:29,559]\u001b[0m Trial 12 finished with value: 0.5509761388286334 and parameters: {'svc_c': 20.922375857702754, 'svc_gamma': 0.8495194577175798}. Best is trial 0 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:30,075]\u001b[0m Trial 13 finished with value: 0.5488069414316703 and parameters: {'svc_c': 33.994854542756144, 'svc_gamma': 11.7063892609419}. Best is trial 0 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:30,470]\u001b[0m Trial 14 finished with value: 0.7635574837310195 and parameters: {'svc_c': 21.276477817977057, 'svc_gamma': 0.08552708983873103}. Best is trial 14 with value: 0.7635574837310195.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:30,941]\u001b[0m Trial 15 finished with value: 0.5466377440347071 and parameters: {'svc_c': 6.006081861916234, 'svc_gamma': 20.798011318128033}. Best is trial 14 with value: 0.7635574837310195.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:31,432]\u001b[0m Trial 16 finished with value: 0.5466377440347071 and parameters: {'svc_c': 20.709239719890626, 'svc_gamma': 49.01417379244383}. Best is trial 14 with value: 0.7635574837310195.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:31,851]\u001b[0m Trial 17 finished with value: 0.5184381778741866 and parameters: {'svc_c': 0.43127577548688123, 'svc_gamma': 0.8435627125298897}. Best is trial 14 with value: 0.7635574837310195.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:32,376]\u001b[0m Trial 18 finished with value: 0.5488069414316703 and parameters: {'svc_c': 21.790027806620955, 'svc_gamma': 11.88917957598453}. Best is trial 14 with value: 0.7635574837310195.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:32,846]\u001b[0m Trial 19 finished with value: 0.5466377440347071 and parameters: {'svc_c': 45.71999054675545, 'svc_gamma': 25.820331595890906}. Best is trial 14 with value: 0.7635574837310195.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:33,353]\u001b[0m Trial 20 finished with value: 0.5488069414316703 and parameters: {'svc_c': 26.275008010108, 'svc_gamma': 10.893935783382922}. Best is trial 14 with value: 0.7635574837310195.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:33,867]\u001b[0m Trial 21 finished with value: 0.5488069414316703 and parameters: {'svc_c': 47.775980440819225, 'svc_gamma': 9.527697727576893}. Best is trial 14 with value: 0.7635574837310195.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:34,329]\u001b[0m Trial 22 finished with value: 0.5509761388286334 and parameters: {'svc_c': 61.15826979941499, 'svc_gamma': 1.6698911230287767}. Best is trial 14 with value: 0.7635574837310195.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:34,825]\u001b[0m Trial 23 finished with value: 0.5466377440347071 and parameters: {'svc_c': 28.774965939608446, 'svc_gamma': 14.682212185186465}. Best is trial 14 with value: 0.7635574837310195.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:35,467]\u001b[0m Trial 24 finished with value: 0.5509761388286334 and parameters: {'svc_c': 13.583525752749878, 'svc_gamma': 6.584104635805292}. Best is trial 14 with value: 0.7635574837310195.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:35,982]\u001b[0m Trial 25 finished with value: 0.5466377440347071 and parameters: {'svc_c': 42.69275026348068, 'svc_gamma': 17.48014971891876}. Best is trial 14 with value: 0.7635574837310195.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:36,508]\u001b[0m Trial 26 finished with value: 0.5509761388286334 and parameters: {'svc_c': 33.540232946876976, 'svc_gamma': 8.461550639052593}. Best is trial 14 with value: 0.7635574837310195.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:36,886]\u001b[0m Trial 27 finished with value: 0.7982646420824295 and parameters: {'svc_c': 14.17864848563184, 'svc_gamma': 0.060955365765849506}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:37,300]\u001b[0m Trial 28 finished with value: 0.5770065075921909 and parameters: {'svc_c': 14.472308541765912, 'svc_gamma': 0.3741174412949554}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:37,751]\u001b[0m Trial 29 finished with value: 0.5466377440347071 and parameters: {'svc_c': 14.472893942303974, 'svc_gamma': 26.019183667125102}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:38,234]\u001b[0m Trial 30 finished with value: 0.5509761388286334 and parameters: {'svc_c': 14.557100108445187, 'svc_gamma': 1.3136802813981625}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:38,739]\u001b[0m Trial 31 finished with value: 0.5466377440347071 and parameters: {'svc_c': 27.150097724759455, 'svc_gamma': 14.967861104987893}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:39,319]\u001b[0m Trial 32 finished with value: 0.5509761388286334 and parameters: {'svc_c': 9.646233229697751, 'svc_gamma': 7.006715688203113}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-13 10:59:39,782]\u001b[0m Trial 33 finished with value: 0.5140997830802603 and parameters: {'svc_c': 0.20661800332521096, 'svc_gamma': 19.79996497976604}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:40,271]\u001b[0m Trial 34 finished with value: 0.5488069414316703 and parameters: {'svc_c': 17.137742120527626, 'svc_gamma': 12.727492779988015}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:40,724]\u001b[0m Trial 35 finished with value: 0.5531453362255966 and parameters: {'svc_c': 10.559784128450602, 'svc_gamma': 0.6029187707334285}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:41,278]\u001b[0m Trial 36 finished with value: 0.5509761388286334 and parameters: {'svc_c': 10.450190927322147, 'svc_gamma': 6.747279779120884}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:41,736]\u001b[0m Trial 37 finished with value: 0.5466377440347071 and parameters: {'svc_c': 18.414365463376864, 'svc_gamma': 17.470862929575198}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:42,177]\u001b[0m Trial 38 finished with value: 0.5466377440347071 and parameters: {'svc_c': 22.727011126594405, 'svc_gamma': 33.627963356476116}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:42,601]\u001b[0m Trial 39 finished with value: 0.5509761388286334 and parameters: {'svc_c': 6.125610013201392, 'svc_gamma': 0.7245981664459318}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:43,063]\u001b[0m Trial 40 finished with value: 0.5466377440347071 and parameters: {'svc_c': 29.846892337659483, 'svc_gamma': 25.45429096807593}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:43,634]\u001b[0m Trial 41 finished with value: 0.5509761388286334 and parameters: {'svc_c': 24.350307401221237, 'svc_gamma': 6.006455548489178}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:44,191]\u001b[0m Trial 42 finished with value: 0.5509761388286334 and parameters: {'svc_c': 17.584401311864077, 'svc_gamma': 4.930598586681992}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:44,676]\u001b[0m Trial 43 finished with value: 0.5488069414316703 and parameters: {'svc_c': 10.966912025725323, 'svc_gamma': 11.098802747788074}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:45,142]\u001b[0m Trial 44 finished with value: 0.5466377440347071 and parameters: {'svc_c': 18.02400622882454, 'svc_gamma': 15.644496384745764}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:45,763]\u001b[0m Trial 45 finished with value: 0.5509761388286334 and parameters: {'svc_c': 33.387135287404945, 'svc_gamma': 4.683748655923747}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:46,250]\u001b[0m Trial 46 finished with value: 0.5466377440347071 and parameters: {'svc_c': 23.982891835735558, 'svc_gamma': 22.494384106544395}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:46,696]\u001b[0m Trial 47 finished with value: 0.5509761388286334 and parameters: {'svc_c': 3.814062531549663, 'svc_gamma': 1.0960753083731523}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:47,229]\u001b[0m Trial 48 finished with value: 0.5488069414316703 and parameters: {'svc_c': 8.523801898933193, 'svc_gamma': 9.189368378973455}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:47,789]\u001b[0m Trial 49 finished with value: 0.5509761388286334 and parameters: {'svc_c': 14.005321795495966, 'svc_gamma': 4.560728745019669}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:48,182]\u001b[0m Trial 50 finished with value: 0.6681127982646421 and parameters: {'svc_c': 3.817927501034907, 'svc_gamma': 0.15738527507358457}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:48,584]\u001b[0m Trial 51 finished with value: 0.7180043383947939 and parameters: {'svc_c': 3.7081614827580704, 'svc_gamma': 0.11897558255845797}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:49,052]\u001b[0m Trial 52 finished with value: 0.5683297180043384 and parameters: {'svc_c': 3.7191016995620085, 'svc_gamma': 0.4145059903551018}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:49,575]\u001b[0m Trial 53 finished with value: 0.5488069414316703 and parameters: {'svc_c': 3.0100671288023264, 'svc_gamma': 11.971120838877521}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:49,975]\u001b[0m Trial 54 finished with value: 0.7093275488069414 and parameters: {'svc_c': 3.3409580370068013, 'svc_gamma': 0.12346325925125773}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:50,543]\u001b[0m Trial 55 finished with value: 0.5509761388286334 and parameters: {'svc_c': 7.366197294089741, 'svc_gamma': 4.486498379139695}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:51,026]\u001b[0m Trial 56 finished with value: 0.5466377440347071 and parameters: {'svc_c': 0.5564140705182048, 'svc_gamma': 8.991909169062023}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:51,491]\u001b[0m Trial 57 finished with value: 0.5466377440347071 and parameters: {'svc_c': 5.869806578176334, 'svc_gamma': 14.423137326853054}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:52,071]\u001b[0m Trial 58 finished with value: 0.5509761388286334 and parameters: {'svc_c': 11.982940824419968, 'svc_gamma': 3.7266733700334784}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:52,597]\u001b[0m Trial 59 finished with value: 0.5509761388286334 and parameters: {'svc_c': 8.424247836545954, 'svc_gamma': 7.8604410533111215}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:53,045]\u001b[0m Trial 60 finished with value: 0.5466377440347071 and parameters: {'svc_c': 3.650667445214224, 'svc_gamma': 17.91531107359318}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:53,445]\u001b[0m Trial 61 finished with value: 0.7418655097613883 and parameters: {'svc_c': 4.771449843466669, 'svc_gamma': 0.10026152349921094}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:54,011]\u001b[0m Trial 62 finished with value: 0.5509761388286334 and parameters: {'svc_c': 13.112722306743784, 'svc_gamma': 3.897066013580452}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-13 10:59:54,389]\u001b[0m Trial 63 finished with value: 0.5140997830802603 and parameters: {'svc_c': 0.24049318711552026, 'svc_gamma': 0.273473232556843}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:54,915]\u001b[0m Trial 64 finished with value: 0.5488069414316703 and parameters: {'svc_c': 7.401780179025749, 'svc_gamma': 9.280897131531027}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:55,465]\u001b[0m Trial 65 finished with value: 0.5509761388286334 and parameters: {'svc_c': 20.854462366510795, 'svc_gamma': 3.1410124685777663}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:55,959]\u001b[0m Trial 66 finished with value: 0.5488069414316703 and parameters: {'svc_c': 15.546008339680345, 'svc_gamma': 12.277303974479073}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:56,491]\u001b[0m Trial 67 finished with value: 0.5509761388286334 and parameters: {'svc_c': 10.578432623509874, 'svc_gamma': 7.23288707072886}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:57,016]\u001b[0m Trial 68 finished with value: 0.5509761388286334 and parameters: {'svc_c': 12.309687352621209, 'svc_gamma': 3.0560967360671025}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:57,574]\u001b[0m Trial 69 finished with value: 0.5488069414316703 and parameters: {'svc_c': 5.079282558150411, 'svc_gamma': 9.654110194207638}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:58,249]\u001b[0m Trial 70 finished with value: 0.5509761388286334 and parameters: {'svc_c': 20.012275798300994, 'svc_gamma': 6.261103419148949}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:58,689]\u001b[0m Trial 71 finished with value: 0.5639913232104121 and parameters: {'svc_c': 3.6699600660813427, 'svc_gamma': 0.43955962735612997}. Best is trial 27 with value: 0.7982646420824295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:59,062]\u001b[0m Trial 72 finished with value: 0.8308026030368764 and parameters: {'svc_c': 2.6177275021843887, 'svc_gamma': 0.04985010197853701}. Best is trial 72 with value: 0.8308026030368764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:59,614]\u001b[0m Trial 73 finished with value: 0.5509761388286334 and parameters: {'svc_c': 7.759977270346241, 'svc_gamma': 4.059241776974439}. Best is trial 72 with value: 0.8308026030368764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 10:59:59,974]\u001b[0m Trial 74 finished with value: 0.7874186550976139 and parameters: {'svc_c': 15.792252548342105, 'svc_gamma': 0.07072419575363309}. Best is trial 72 with value: 0.8308026030368764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:00,507]\u001b[0m Trial 75 finished with value: 0.5509761388286334 and parameters: {'svc_c': 1.9124539429095426, 'svc_gamma': 7.0650484164843865}. Best is trial 72 with value: 0.8308026030368764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:01,041]\u001b[0m Trial 76 finished with value: 0.5509761388286334 and parameters: {'svc_c': 5.907575201558476, 'svc_gamma': 3.0883868677284494}. Best is trial 72 with value: 0.8308026030368764.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-13 11:00:01,449]\u001b[0m Trial 77 finished with value: 0.5140997830802603 and parameters: {'svc_c': 0.076400252200024, 'svc_gamma': 13.22223081311268}. Best is trial 72 with value: 0.8308026030368764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:01,986]\u001b[0m Trial 78 finished with value: 0.5488069414316703 and parameters: {'svc_c': 16.38730987484977, 'svc_gamma': 10.805048483469891}. Best is trial 72 with value: 0.8308026030368764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:02,489]\u001b[0m Trial 79 finished with value: 0.5509761388286334 and parameters: {'svc_c': 11.19926590160653, 'svc_gamma': 2.581776098576106}. Best is trial 72 with value: 0.8308026030368764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:03,056]\u001b[0m Trial 80 finished with value: 0.5509761388286334 and parameters: {'svc_c': 7.712501638156651, 'svc_gamma': 6.461674271802232}. Best is trial 72 with value: 0.8308026030368764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:03,447]\u001b[0m Trial 81 finished with value: 0.5531453362255966 and parameters: {'svc_c': 16.03960576179146, 'svc_gamma': 0.6369795024733194}. Best is trial 72 with value: 0.8308026030368764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:03,967]\u001b[0m Trial 82 finished with value: 0.5509761388286334 and parameters: {'svc_c': 9.23860196753277, 'svc_gamma': 3.020285230914502}. Best is trial 72 with value: 0.8308026030368764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:04,518]\u001b[0m Trial 83 finished with value: 0.5509761388286334 and parameters: {'svc_c': 3.3815267650342027, 'svc_gamma': 5.7180423506164715}. Best is trial 72 with value: 0.8308026030368764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:05,044]\u001b[0m Trial 84 finished with value: 0.5509761388286334 and parameters: {'svc_c': 14.783258452598941, 'svc_gamma': 8.689836224303855}. Best is trial 72 with value: 0.8308026030368764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:05,544]\u001b[0m Trial 85 finished with value: 0.5509761388286334 and parameters: {'svc_c': 19.367695204120952, 'svc_gamma': 2.6011048009744773}. Best is trial 72 with value: 0.8308026030368764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:05,896]\u001b[0m Trial 86 finished with value: 0.8177874186550976 and parameters: {'svc_c': 12.38867516512896, 'svc_gamma': 0.055774839446143476}. Best is trial 72 with value: 0.8308026030368764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:06,454]\u001b[0m Trial 87 finished with value: 0.5509761388286334 and parameters: {'svc_c': 2.3013959971698457, 'svc_gamma': 5.406029908960844}. Best is trial 72 with value: 0.8308026030368764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:06,680]\u001b[0m Trial 88 finished with value: 0.8676789587852495 and parameters: {'svc_c': 12.177171527291012, 'svc_gamma': 0.01711656067428087}. Best is trial 88 with value: 0.8676789587852495.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:07,211]\u001b[0m Trial 89 finished with value: 0.5488069414316703 and parameters: {'svc_c': 22.257966831019154, 'svc_gamma': 11.46090198596643}. Best is trial 88 with value: 0.8676789587852495.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:07,793]\u001b[0m Trial 90 finished with value: 0.5509761388286334 and parameters: {'svc_c': 12.100097630109808, 'svc_gamma': 8.178959030559572}. Best is trial 88 with value: 0.8676789587852495.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:08,201]\u001b[0m Trial 91 finished with value: 0.5531453362255966 and parameters: {'svc_c': 5.168883722302589, 'svc_gamma': 0.5533499492655254}. Best is trial 88 with value: 0.8676789587852495.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:08,717]\u001b[0m Trial 92 finished with value: 0.5509761388286334 and parameters: {'svc_c': 9.570794213865083, 'svc_gamma': 2.735439262454399}. Best is trial 88 with value: 0.8676789587852495.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:09,282]\u001b[0m Trial 93 finished with value: 0.5509761388286334 and parameters: {'svc_c': 18.33941581530747, 'svc_gamma': 5.152605942980347}. Best is trial 88 with value: 0.8676789587852495.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:09,697]\u001b[0m Trial 94 finished with value: 0.7049891540130152 and parameters: {'svc_c': 5.574430378967042, 'svc_gamma': 0.12579207158889644}. Best is trial 88 with value: 0.8676789587852495.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:10,252]\u001b[0m Trial 95 finished with value: 0.5509761388286334 and parameters: {'svc_c': 13.109958026778429, 'svc_gamma': 2.544242150062962}. Best is trial 88 with value: 0.8676789587852495.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:10,864]\u001b[0m Trial 96 finished with value: 0.5509761388286334 and parameters: {'svc_c': 6.359130069379866, 'svc_gamma': 7.274077737388248}. Best is trial 88 with value: 0.8676789587852495.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:11,486]\u001b[0m Trial 97 finished with value: 0.5509761388286334 and parameters: {'svc_c': 9.200007589240622, 'svc_gamma': 4.801598504475505}. Best is trial 88 with value: 0.8676789587852495.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:11,917]\u001b[0m Trial 98 finished with value: 0.6464208242950108 and parameters: {'svc_c': 16.158760037020013, 'svc_gamma': 0.19657441776244622}. Best is trial 88 with value: 0.8676789587852495.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:12,420]\u001b[0m Trial 99 finished with value: 0.5488069414316703 and parameters: {'svc_c': 1.4678804557142828, 'svc_gamma': 10.081184396761298}. Best is trial 88 with value: 0.8676789587852495.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:12,425]\u001b[0m A new study created in memory with name: no-name-25c1e6a7-21cf-4fca-b743-acb742b0caee\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning  accuracy   \n",
      "index          AAC  LogisticRegression            False  0.870562  \\\n",
      "index          AAC                 SVC            False  0.895351   \n",
      "index          AAC       XGBClassifier            False  0.878837   \n",
      "index          AAC      LGBMClassifier            False  0.885530   \n",
      "index          AAC                 SVC             True  0.867679   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.875000     0.924051   0.915888  0.894977  0.800787  \\\n",
      "index     0.825893     0.940928   0.929648  0.874704  0.773776   \n",
      "index     0.834821     0.915612   0.903382  0.867749  0.754064   \n",
      "index     0.812500     0.924051   0.910000  0.858491  0.742789   \n",
      "index     0.803571     0.928270   0.913706  0.855107  0.739401   \n",
      "\n",
      "                                       index  \n",
      "index  AAC_LogisticRegression_no_hypertuning  \n",
      "index                 AAC_SVC_no_hypertuning  \n",
      "index       AAC_XGBClassifier_no_hypertuning  \n",
      "index      AAC_LGBMClassifier_no_hypertuning  \n",
      "index               AAC_SVC_with_hypertuning  \n",
      "Optimizing AAC XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-13 11:00:13,383]\u001b[0m Trial 0 finished with value: 0.8741865509761388 and parameters: {'learning_rate': 0.29893335591271175, 'max_depth': 5, 'n_estimators': 449}. Best is trial 0 with value: 0.8741865509761388.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:15,037]\u001b[0m Trial 1 finished with value: 0.8741865509761388 and parameters: {'learning_rate': 0.03798015091166178, 'max_depth': 3, 'n_estimators': 901}. Best is trial 0 with value: 0.8741865509761388.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:16,697]\u001b[0m Trial 2 finished with value: 0.8676789587852495 and parameters: {'learning_rate': 0.12347931663748123, 'max_depth': 3, 'n_estimators': 904}. Best is trial 0 with value: 0.8741865509761388.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:18,316]\u001b[0m Trial 3 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.11054573809731578, 'max_depth': 4, 'n_estimators': 728}. Best is trial 3 with value: 0.8763557483731019.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:19,221]\u001b[0m Trial 4 finished with value: 0.8698481561822126 and parameters: {'learning_rate': 0.25217124312186645, 'max_depth': 3, 'n_estimators': 534}. Best is trial 3 with value: 0.8763557483731019.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:21,372]\u001b[0m Trial 5 finished with value: 0.8720173535791758 and parameters: {'learning_rate': 0.24643511122977343, 'max_depth': 5, 'n_estimators': 941}. Best is trial 3 with value: 0.8763557483731019.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:22,689]\u001b[0m Trial 6 finished with value: 0.8741865509761388 and parameters: {'learning_rate': 0.18086971094534737, 'max_depth': 5, 'n_estimators': 493}. Best is trial 3 with value: 0.8763557483731019.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:24,015]\u001b[0m Trial 7 finished with value: 0.8676789587852495 and parameters: {'learning_rate': 0.17687589871694256, 'max_depth': 3, 'n_estimators': 714}. Best is trial 3 with value: 0.8763557483731019.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:25,829]\u001b[0m Trial 8 finished with value: 0.8720173535791758 and parameters: {'learning_rate': 0.23260979674650942, 'max_depth': 6, 'n_estimators': 696}. Best is trial 3 with value: 0.8763557483731019.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:28,205]\u001b[0m Trial 9 finished with value: 0.8806941431670282 and parameters: {'learning_rate': 0.07405982070252194, 'max_depth': 5, 'n_estimators': 826}. Best is trial 9 with value: 0.8806941431670282.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:28,910]\u001b[0m Trial 10 finished with value: 0.8741865509761388 and parameters: {'learning_rate': 0.021193027748731393, 'max_depth': 6, 'n_estimators': 154}. Best is trial 9 with value: 0.8806941431670282.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:30,631]\u001b[0m Trial 11 finished with value: 0.8741865509761388 and parameters: {'learning_rate': 0.08791639965884346, 'max_depth': 4, 'n_estimators': 712}. Best is trial 9 with value: 0.8806941431670282.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:32,605]\u001b[0m Trial 12 finished with value: 0.8785249457700651 and parameters: {'learning_rate': 0.09114144698841413, 'max_depth': 4, 'n_estimators': 778}. Best is trial 9 with value: 0.8806941431670282.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:33,774]\u001b[0m Trial 13 finished with value: 0.8655097613882863 and parameters: {'learning_rate': 0.07364555175737153, 'max_depth': 2, 'n_estimators': 834}. Best is trial 9 with value: 0.8806941431670282.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:34,897]\u001b[0m Trial 14 finished with value: 0.8828633405639913 and parameters: {'learning_rate': 0.05436721903658459, 'max_depth': 5, 'n_estimators': 327}. Best is trial 14 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:35,887]\u001b[0m Trial 15 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.05143212366742629, 'max_depth': 5, 'n_estimators': 308}. Best is trial 14 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:37,576]\u001b[0m Trial 16 finished with value: 0.8720173535791758 and parameters: {'learning_rate': 0.016198283365714217, 'max_depth': 6, 'n_estimators': 348}. Best is trial 14 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:38,199]\u001b[0m Trial 17 finished with value: 0.8806941431670282 and parameters: {'learning_rate': 0.060509775842782804, 'max_depth': 5, 'n_estimators': 162}. Best is trial 14 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:40,014]\u001b[0m Trial 18 finished with value: 0.8676789587852495 and parameters: {'learning_rate': 0.12396859185196343, 'max_depth': 6, 'n_estimators': 605}. Best is trial 14 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:41,103]\u001b[0m Trial 19 finished with value: 0.8785249457700651 and parameters: {'learning_rate': 0.047159720904818354, 'max_depth': 5, 'n_estimators': 290}. Best is trial 14 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:42,314]\u001b[0m Trial 20 finished with value: 0.8872017353579176 and parameters: {'learning_rate': 0.015379821830581342, 'max_depth': 4, 'n_estimators': 393}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:43,431]\u001b[0m Trial 21 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.026254098210345467, 'max_depth': 4, 'n_estimators': 407}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:44,130]\u001b[0m Trial 22 finished with value: 0.8850325379609545 and parameters: {'learning_rate': 0.016872801437967544, 'max_depth': 4, 'n_estimators': 229}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:44,790]\u001b[0m Trial 23 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.014327991256242692, 'max_depth': 4, 'n_estimators': 228}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:45,180]\u001b[0m Trial 24 finished with value: 0.8546637744034707 and parameters: {'learning_rate': 0.010407498486626716, 'max_depth': 2, 'n_estimators': 244}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:46,248]\u001b[0m Trial 25 finished with value: 0.8720173535791758 and parameters: {'learning_rate': 0.04234284666129892, 'max_depth': 4, 'n_estimators': 401}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:46,704]\u001b[0m Trial 26 finished with value: 0.8785249457700651 and parameters: {'learning_rate': 0.035240395823541534, 'max_depth': 4, 'n_estimators': 107}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:47,922]\u001b[0m Trial 27 finished with value: 0.8698481561822126 and parameters: {'learning_rate': 0.057822392467866246, 'max_depth': 3, 'n_estimators': 584}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:49,206]\u001b[0m Trial 28 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.03834886007372397, 'max_depth': 4, 'n_estimators': 362}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:50,897]\u001b[0m Trial 29 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.011730270892966884, 'max_depth': 5, 'n_estimators': 470}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:51,768]\u001b[0m Trial 30 finished with value: 0.8741865509761388 and parameters: {'learning_rate': 0.06673717391088334, 'max_depth': 4, 'n_estimators': 284}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:52,515]\u001b[0m Trial 31 finished with value: 0.8741865509761388 and parameters: {'learning_rate': 0.07224497757160167, 'max_depth': 5, 'n_estimators': 211}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:53,921]\u001b[0m Trial 32 finished with value: 0.8828633405639913 and parameters: {'learning_rate': 0.03613100034113508, 'max_depth': 5, 'n_estimators': 425}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:55,103]\u001b[0m Trial 33 finished with value: 0.8806941431670282 and parameters: {'learning_rate': 0.04697550963881397, 'max_depth': 5, 'n_estimators': 351}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:56,046]\u001b[0m Trial 34 finished with value: 0.8676789587852495 and parameters: {'learning_rate': 0.03914146088061209, 'max_depth': 3, 'n_estimators': 427}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:57,729]\u001b[0m Trial 35 finished with value: 0.8806941431670282 and parameters: {'learning_rate': 0.02388721000938146, 'max_depth': 5, 'n_estimators': 467}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:00:59,300]\u001b[0m Trial 36 finished with value: 0.8741865509761388 and parameters: {'learning_rate': 0.02727494585138328, 'max_depth': 4, 'n_estimators': 526}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:00,239]\u001b[0m Trial 37 finished with value: 0.8676789587852495 and parameters: {'learning_rate': 0.034900286398177285, 'max_depth': 3, 'n_estimators': 377}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:01,394]\u001b[0m Trial 38 finished with value: 0.8806941431670282 and parameters: {'learning_rate': 0.09466539042803812, 'max_depth': 6, 'n_estimators': 311}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:03,520]\u001b[0m Trial 39 finished with value: 0.8785249457700651 and parameters: {'learning_rate': 0.05666628047807907, 'max_depth': 5, 'n_estimators': 621}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:03,954]\u001b[0m Trial 40 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.02962941832732779, 'max_depth': 3, 'n_estimators': 175}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:07,054]\u001b[0m Trial 41 finished with value: 0.8806941431670282 and parameters: {'learning_rate': 0.052766106882979294, 'max_depth': 5, 'n_estimators': 985}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:08,812]\u001b[0m Trial 42 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.07635480197802755, 'max_depth': 4, 'n_estimators': 647}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:10,690]\u001b[0m Trial 43 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.06311211042015742, 'max_depth': 5, 'n_estimators': 496}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:13,659]\u001b[0m Trial 44 finished with value: 0.8785249457700651 and parameters: {'learning_rate': 0.02763246151712006, 'max_depth': 5, 'n_estimators': 871}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:14,677]\u001b[0m Trial 45 finished with value: 0.8720173535791758 and parameters: {'learning_rate': 0.08226809063238821, 'max_depth': 6, 'n_estimators': 259}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:16,213]\u001b[0m Trial 46 finished with value: 0.8741865509761388 and parameters: {'learning_rate': 0.10390690130251795, 'max_depth': 4, 'n_estimators': 551}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:17,677]\u001b[0m Trial 47 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.04513835526207314, 'max_depth': 4, 'n_estimators': 445}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:18,769]\u001b[0m Trial 48 finished with value: 0.8741865509761388 and parameters: {'learning_rate': 0.06932410008860045, 'max_depth': 5, 'n_estimators': 312}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:19,663]\u001b[0m Trial 49 finished with value: 0.8720173535791758 and parameters: {'learning_rate': 0.010477252401541935, 'max_depth': 6, 'n_estimators': 195}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:21,849]\u001b[0m Trial 50 finished with value: 0.8698481561822126 and parameters: {'learning_rate': 0.12280705381545626, 'max_depth': 5, 'n_estimators': 771}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:22,475]\u001b[0m Trial 51 finished with value: 0.8785249457700651 and parameters: {'learning_rate': 0.060483835000788, 'max_depth': 5, 'n_estimators': 119}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:23,079]\u001b[0m Trial 52 finished with value: 0.8850325379609545 and parameters: {'learning_rate': 0.023463655560567124, 'max_depth': 5, 'n_estimators': 160}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:23,844]\u001b[0m Trial 53 finished with value: 0.8828633405639913 and parameters: {'learning_rate': 0.026081985497369346, 'max_depth': 4, 'n_estimators': 264}. Best is trial 20 with value: 0.8872017353579176.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:24,573]\u001b[0m Trial 54 finished with value: 0.8893709327548807 and parameters: {'learning_rate': 0.022560943024356607, 'max_depth': 4, 'n_estimators': 254}. Best is trial 54 with value: 0.8893709327548807.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:24,970]\u001b[0m Trial 55 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.02007454513085486, 'max_depth': 4, 'n_estimators': 129}. Best is trial 54 with value: 0.8893709327548807.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:25,534]\u001b[0m Trial 56 finished with value: 0.8850325379609545 and parameters: {'learning_rate': 0.03593567759857709, 'max_depth': 4, 'n_estimators': 198}. Best is trial 54 with value: 0.8893709327548807.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:26,115]\u001b[0m Trial 57 finished with value: 0.8828633405639913 and parameters: {'learning_rate': 0.021392373724985952, 'max_depth': 4, 'n_estimators': 194}. Best is trial 54 with value: 0.8893709327548807.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:26,472]\u001b[0m Trial 58 finished with value: 0.8741865509761388 and parameters: {'learning_rate': 0.04933839571124434, 'max_depth': 3, 'n_estimators': 152}. Best is trial 54 with value: 0.8893709327548807.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:27,152]\u001b[0m Trial 59 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.010070901051138594, 'max_depth': 4, 'n_estimators': 230}. Best is trial 54 with value: 0.8893709327548807.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:28,051]\u001b[0m Trial 60 finished with value: 0.8806941431670282 and parameters: {'learning_rate': 0.03950422629137065, 'max_depth': 4, 'n_estimators': 325}. Best is trial 54 with value: 0.8893709327548807.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:28,799]\u001b[0m Trial 61 finished with value: 0.8741865509761388 and parameters: {'learning_rate': 0.033977073023425036, 'max_depth': 4, 'n_estimators': 266}. Best is trial 54 with value: 0.8893709327548807.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:29,874]\u001b[0m Trial 62 finished with value: 0.8806941431670282 and parameters: {'learning_rate': 0.02023937874820394, 'max_depth': 4, 'n_estimators': 388}. Best is trial 54 with value: 0.8893709327548807.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:30,886]\u001b[0m Trial 63 finished with value: 0.8806941431670282 and parameters: {'learning_rate': 0.03330517659696414, 'max_depth': 4, 'n_estimators': 337}. Best is trial 54 with value: 0.8893709327548807.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:31,876]\u001b[0m Trial 64 finished with value: 0.8785249457700651 and parameters: {'learning_rate': 0.045498915483398975, 'max_depth': 5, 'n_estimators': 223}. Best is trial 54 with value: 0.8893709327548807.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:32,998]\u001b[0m Trial 65 finished with value: 0.8806941431670282 and parameters: {'learning_rate': 0.018067563889821673, 'max_depth': 5, 'n_estimators': 288}. Best is trial 54 with value: 0.8893709327548807.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:33,518]\u001b[0m Trial 66 finished with value: 0.8720173535791758 and parameters: {'learning_rate': 0.03794401541190198, 'max_depth': 3, 'n_estimators': 178}. Best is trial 54 with value: 0.8893709327548807.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:33,941]\u001b[0m Trial 67 finished with value: 0.8785249457700651 and parameters: {'learning_rate': 0.05941345119950961, 'max_depth': 4, 'n_estimators': 141}. Best is trial 54 with value: 0.8893709327548807.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:35,137]\u001b[0m Trial 68 finished with value: 0.8741865509761388 and parameters: {'learning_rate': 0.05278193004453771, 'max_depth': 4, 'n_estimators': 424}. Best is trial 54 with value: 0.8893709327548807.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:36,624]\u001b[0m Trial 69 finished with value: 0.8785249457700651 and parameters: {'learning_rate': 0.017612807626483342, 'max_depth': 5, 'n_estimators': 368}. Best is trial 54 with value: 0.8893709327548807.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:37,746]\u001b[0m Trial 70 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.03103556863693893, 'max_depth': 6, 'n_estimators': 244}. Best is trial 54 with value: 0.8893709327548807.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:38,739]\u001b[0m Trial 71 finished with value: 0.8915401301518439 and parameters: {'learning_rate': 0.025916494798371634, 'max_depth': 4, 'n_estimators': 260}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:39,351]\u001b[0m Trial 72 finished with value: 0.8720173535791758 and parameters: {'learning_rate': 0.04270872043975922, 'max_depth': 4, 'n_estimators': 208}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:40,220]\u001b[0m Trial 73 finished with value: 0.8872017353579176 and parameters: {'learning_rate': 0.02352426794484065, 'max_depth': 4, 'n_estimators': 284}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:41,065]\u001b[0m Trial 74 finished with value: 0.8893709327548807 and parameters: {'learning_rate': 0.02292506678884482, 'max_depth': 4, 'n_estimators': 277}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:42,050]\u001b[0m Trial 75 finished with value: 0.8741865509761388 and parameters: {'learning_rate': 0.01035789195262523, 'max_depth': 4, 'n_estimators': 288}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:42,391]\u001b[0m Trial 76 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.022765140124831922, 'max_depth': 4, 'n_estimators': 102}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:42,792]\u001b[0m Trial 77 finished with value: 0.8720173535791758 and parameters: {'learning_rate': 0.028418211189743324, 'max_depth': 3, 'n_estimators': 168}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:43,528]\u001b[0m Trial 78 finished with value: 0.8828633405639913 and parameters: {'learning_rate': 0.017599800803532597, 'max_depth': 4, 'n_estimators': 246}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:44,117]\u001b[0m Trial 79 finished with value: 0.8915401301518439 and parameters: {'learning_rate': 0.02850085074166986, 'max_depth': 4, 'n_estimators': 195}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:45,018]\u001b[0m Trial 80 finished with value: 0.8828633405639913 and parameters: {'learning_rate': 0.026181149459347762, 'max_depth': 4, 'n_estimators': 293}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:45,706]\u001b[0m Trial 81 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.01657220002902706, 'max_depth': 4, 'n_estimators': 191}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:46,427]\u001b[0m Trial 82 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.04279329949163777, 'max_depth': 4, 'n_estimators': 229}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:47,257]\u001b[0m Trial 83 finished with value: 0.8828633405639913 and parameters: {'learning_rate': 0.03334694116510376, 'max_depth': 4, 'n_estimators': 270}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:47,728]\u001b[0m Trial 84 finished with value: 0.8872017353579176 and parameters: {'learning_rate': 0.027798844473372674, 'max_depth': 4, 'n_estimators': 147}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:48,207]\u001b[0m Trial 85 finished with value: 0.8828633405639913 and parameters: {'learning_rate': 0.0278923636215244, 'max_depth': 4, 'n_estimators': 146}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:48,803]\u001b[0m Trial 86 finished with value: 0.8785249457700651 and parameters: {'learning_rate': 0.048621588649402164, 'max_depth': 4, 'n_estimators': 164}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:49,437]\u001b[0m Trial 87 finished with value: 0.8806941431670282 and parameters: {'learning_rate': 0.016685564116677883, 'max_depth': 4, 'n_estimators': 214}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:49,854]\u001b[0m Trial 88 finished with value: 0.8676789587852495 and parameters: {'learning_rate': 0.010411021244634309, 'max_depth': 4, 'n_estimators': 127}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:50,574]\u001b[0m Trial 89 finished with value: 0.8720173535791758 and parameters: {'learning_rate': 0.023714056829466118, 'max_depth': 3, 'n_estimators': 320}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:51,126]\u001b[0m Trial 90 finished with value: 0.8676789587852495 and parameters: {'learning_rate': 0.040895432421847434, 'max_depth': 3, 'n_estimators': 246}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:51,711]\u001b[0m Trial 91 finished with value: 0.8850325379609545 and parameters: {'learning_rate': 0.03350888043051011, 'max_depth': 4, 'n_estimators': 186}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:52,398]\u001b[0m Trial 92 finished with value: 0.8698481561822126 and parameters: {'learning_rate': 0.05308401961448769, 'max_depth': 4, 'n_estimators': 203}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:53,505]\u001b[0m Trial 93 finished with value: 0.8828633405639913 and parameters: {'learning_rate': 0.025764544777954174, 'max_depth': 4, 'n_estimators': 300}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:54,553]\u001b[0m Trial 94 finished with value: 0.8741865509761388 and parameters: {'learning_rate': 0.03816330743409452, 'max_depth': 4, 'n_estimators': 342}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:55,545]\u001b[0m Trial 95 finished with value: 0.8915401301518439 and parameters: {'learning_rate': 0.016984892761443198, 'max_depth': 4, 'n_estimators': 277}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:56,365]\u001b[0m Trial 96 finished with value: 0.8893709327548807 and parameters: {'learning_rate': 0.01730189834524584, 'max_depth': 4, 'n_estimators': 266}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:57,212]\u001b[0m Trial 97 finished with value: 0.8893709327548807 and parameters: {'learning_rate': 0.018391828551422074, 'max_depth': 4, 'n_estimators': 272}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:58,137]\u001b[0m Trial 98 finished with value: 0.8872017353579176 and parameters: {'learning_rate': 0.015941439488996, 'max_depth': 4, 'n_estimators': 280}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:58,923]\u001b[0m Trial 99 finished with value: 0.8850325379609545 and parameters: {'learning_rate': 0.015674050964891748, 'max_depth': 4, 'n_estimators': 256}. Best is trial 71 with value: 0.8915401301518439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:01:58,932]\u001b[0m A new study created in memory with name: no-name-c57d0ae4-93f2-45a0-b2c1-7798b57ae069\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning  accuracy   \n",
      "index          AAC  LogisticRegression            False  0.870562  \\\n",
      "index          AAC                 SVC            False  0.895351   \n",
      "index          AAC       XGBClassifier            False  0.878837   \n",
      "index          AAC      LGBMClassifier            False  0.885530   \n",
      "index          AAC                 SVC             True  0.867679   \n",
      "index          AAC       XGBClassifier             True  0.891540   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.875000     0.924051   0.915888  0.894977  0.800787  \\\n",
      "index     0.825893     0.940928   0.929648  0.874704  0.773776   \n",
      "index     0.834821     0.915612   0.903382  0.867749  0.754064   \n",
      "index     0.812500     0.924051   0.910000  0.858491  0.742789   \n",
      "index     0.803571     0.928270   0.913706  0.855107  0.739401   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "\n",
      "                                       index  \n",
      "index  AAC_LogisticRegression_no_hypertuning  \n",
      "index                 AAC_SVC_no_hypertuning  \n",
      "index       AAC_XGBClassifier_no_hypertuning  \n",
      "index      AAC_LGBMClassifier_no_hypertuning  \n",
      "index               AAC_SVC_with_hypertuning  \n",
      "index     AAC_XGBClassifier_with_hypertuning  \n",
      "Optimizing AAC LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-13 11:02:00,874]\u001b[0m Trial 0 finished with value: 0.8850325379609545 and parameters: {'num_leaves': 130, 'max_depth': 33, 'learning_rate': 0.10135424501871838, 'n_estimators': 1697}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:01,276]\u001b[0m Trial 1 finished with value: 0.8741865509761388 and parameters: {'num_leaves': 57, 'max_depth': 12, 'learning_rate': 0.2922692539644473, 'n_estimators': 306}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:02,539]\u001b[0m Trial 2 finished with value: 0.8850325379609545 and parameters: {'num_leaves': 63, 'max_depth': 29, 'learning_rate': 0.13672012886264004, 'n_estimators': 1318}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:03,865]\u001b[0m Trial 3 finished with value: 0.8806941431670282 and parameters: {'num_leaves': 166, 'max_depth': 49, 'learning_rate': 0.27587478397394594, 'n_estimators': 1552}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:04,250]\u001b[0m Trial 4 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 65, 'max_depth': 45, 'learning_rate': 0.2841452966612469, 'n_estimators': 263}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:06,959]\u001b[0m Trial 5 finished with value: 0.8698481561822126 and parameters: {'num_leaves': 99, 'max_depth': 21, 'learning_rate': 0.013220771678401605, 'n_estimators': 745}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:08,623]\u001b[0m Trial 6 finished with value: 0.8720173535791758 and parameters: {'num_leaves': 210, 'max_depth': 23, 'learning_rate': 0.17065272403375914, 'n_estimators': 1859}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:08,827]\u001b[0m Trial 7 finished with value: 0.8698481561822126 and parameters: {'num_leaves': 8, 'max_depth': 17, 'learning_rate': 0.038354007769438814, 'n_estimators': 375}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:11,083]\u001b[0m Trial 8 finished with value: 0.8806941431670282 and parameters: {'num_leaves': 211, 'max_depth': 20, 'learning_rate': 0.06971452350401594, 'n_estimators': 1870}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:11,926]\u001b[0m Trial 9 finished with value: 0.8828633405639913 and parameters: {'num_leaves': 230, 'max_depth': 32, 'learning_rate': 0.20407421124989972, 'n_estimators': 510}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:13,604]\u001b[0m Trial 10 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 154, 'max_depth': 38, 'learning_rate': 0.09338743426187268, 'n_estimators': 1170}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:13,982]\u001b[0m Trial 11 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 105, 'max_depth': 2, 'learning_rate': 0.12312075544144342, 'n_estimators': 1292}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:14,445]\u001b[0m Trial 12 finished with value: 0.8720173535791758 and parameters: {'num_leaves': 5, 'max_depth': 32, 'learning_rate': 0.13924437459027486, 'n_estimators': 1532}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:15,511]\u001b[0m Trial 13 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 62, 'max_depth': 32, 'learning_rate': 0.09353244990087536, 'n_estimators': 877}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:17,107]\u001b[0m Trial 14 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 128, 'max_depth': 40, 'learning_rate': 0.1707379784805828, 'n_estimators': 1488}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:19,544]\u001b[0m Trial 15 finished with value: 0.8806941431670282 and parameters: {'num_leaves': 171, 'max_depth': 29, 'learning_rate': 0.059321198965991515, 'n_estimators': 1698}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:23,586]\u001b[0m Trial 16 finished with value: 0.8741865509761388 and parameters: {'num_leaves': 93, 'max_depth': 40, 'learning_rate': 0.0018153026084191393, 'n_estimators': 1309}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:25,506]\u001b[0m Trial 17 finished with value: 0.8741865509761388 and parameters: {'num_leaves': 138, 'max_depth': 14, 'learning_rate': 0.11475096532436625, 'n_estimators': 1973}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:26,451]\u001b[0m Trial 18 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 39, 'max_depth': 27, 'learning_rate': 0.15147446729754416, 'n_estimators': 993}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:27,720]\u001b[0m Trial 19 finished with value: 0.8741865509761388 and parameters: {'num_leaves': 35, 'max_depth': 8, 'learning_rate': 0.20787552748995966, 'n_estimators': 1704}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:29,659]\u001b[0m Trial 20 finished with value: 0.8828633405639913 and parameters: {'num_leaves': 121, 'max_depth': 36, 'learning_rate': 0.08227604375687626, 'n_estimators': 1354}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:30,497]\u001b[0m Trial 21 finished with value: 0.8741865509761388 and parameters: {'num_leaves': 237, 'max_depth': 32, 'learning_rate': 0.20741546520797777, 'n_estimators': 600}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:31,621]\u001b[0m Trial 22 finished with value: 0.8828633405639913 and parameters: {'num_leaves': 247, 'max_depth': 25, 'learning_rate': 0.10965282968121302, 'n_estimators': 624}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:32,168]\u001b[0m Trial 23 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 199, 'max_depth': 35, 'learning_rate': 0.20132077144061547, 'n_estimators': 135}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:33,584]\u001b[0m Trial 24 finished with value: 0.8806941431670282 and parameters: {'num_leaves': 189, 'max_depth': 45, 'learning_rate': 0.12311079067013865, 'n_estimators': 1101}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:34,234]\u001b[0m Trial 25 finished with value: 0.8741865509761388 and parameters: {'num_leaves': 85, 'max_depth': 29, 'learning_rate': 0.23925741426130123, 'n_estimators': 517}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:35,347]\u001b[0m Trial 26 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 226, 'max_depth': 26, 'learning_rate': 0.14425158919524386, 'n_estimators': 860}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:36,825]\u001b[0m Trial 27 finished with value: 0.8806941431670282 and parameters: {'num_leaves': 145, 'max_depth': 34, 'learning_rate': 0.17879915869782392, 'n_estimators': 1690}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:38,535]\u001b[0m Trial 28 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 180, 'max_depth': 45, 'learning_rate': 0.1545341576688227, 'n_estimators': 1224}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:39,952]\u001b[0m Trial 29 finished with value: 0.8806941431670282 and parameters: {'num_leaves': 78, 'max_depth': 41, 'learning_rate': 0.13361054874480924, 'n_estimators': 1437}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:41,003]\u001b[0m Trial 30 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 34, 'max_depth': 18, 'learning_rate': 0.0958118675504186, 'n_estimators': 998}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:43,152]\u001b[0m Trial 31 finished with value: 0.8828633405639913 and parameters: {'num_leaves': 132, 'max_depth': 36, 'learning_rate': 0.07140130954446139, 'n_estimators': 1362}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:45,040]\u001b[0m Trial 32 finished with value: 0.8741865509761388 and parameters: {'num_leaves': 120, 'max_depth': 29, 'learning_rate': 0.10227646329347143, 'n_estimators': 1617}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:47,089]\u001b[0m Trial 33 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 116, 'max_depth': 36, 'learning_rate': 0.0818175264608414, 'n_estimators': 1407}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:49,541]\u001b[0m Trial 34 finished with value: 0.8741865509761388 and parameters: {'num_leaves': 153, 'max_depth': 49, 'learning_rate': 0.056006917272042905, 'n_estimators': 1115}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:50,873]\u001b[0m Trial 35 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 109, 'max_depth': 23, 'learning_rate': 0.29944817430793813, 'n_estimators': 1580}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:52,551]\u001b[0m Trial 36 finished with value: 0.8741865509761388 and parameters: {'num_leaves': 51, 'max_depth': 43, 'learning_rate': 0.12648599142475445, 'n_estimators': 1827}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:53,892]\u001b[0m Trial 37 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 74, 'max_depth': 31, 'learning_rate': 0.04107113860407795, 'n_estimators': 391}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:55,303]\u001b[0m Trial 38 finished with value: 0.8806941431670282 and parameters: {'num_leaves': 256, 'max_depth': 38, 'learning_rate': 0.08820579304656341, 'n_estimators': 708}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:56,319]\u001b[0m Trial 39 finished with value: 0.8806941431670282 and parameters: {'num_leaves': 24, 'max_depth': 24, 'learning_rate': 0.10756647719306942, 'n_estimators': 1192}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:57,788]\u001b[0m Trial 40 finished with value: 0.8806941431670282 and parameters: {'num_leaves': 216, 'max_depth': 34, 'learning_rate': 0.2773303749192695, 'n_estimators': 1786}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:58,944]\u001b[0m Trial 41 finished with value: 0.8828633405639913 and parameters: {'num_leaves': 248, 'max_depth': 26, 'learning_rate': 0.11254992225830868, 'n_estimators': 517}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:02:59,846]\u001b[0m Trial 42 finished with value: 0.8828633405639913 and parameters: {'num_leaves': 226, 'max_depth': 20, 'learning_rate': 0.10781275964905765, 'n_estimators': 335}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:01,579]\u001b[0m Trial 43 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 200, 'max_depth': 29, 'learning_rate': 0.08313637857620364, 'n_estimators': 744}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:02,319]\u001b[0m Trial 44 finished with value: 0.8850325379609545 and parameters: {'num_leaves': 240, 'max_depth': 38, 'learning_rate': 0.13370147959672476, 'n_estimators': 213}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:03,146]\u001b[0m Trial 45 finished with value: 0.8828633405639913 and parameters: {'num_leaves': 167, 'max_depth': 38, 'learning_rate': 0.13141085098030827, 'n_estimators': 253}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:03,486]\u001b[0m Trial 46 finished with value: 0.8806941431670282 and parameters: {'num_leaves': 53, 'max_depth': 32, 'learning_rate': 0.16062753929876836, 'n_estimators': 146}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:04,612]\u001b[0m Trial 47 finished with value: 0.8828633405639913 and parameters: {'num_leaves': 97, 'max_depth': 37, 'learning_rate': 0.14216532372345145, 'n_estimators': 883}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:06,268]\u001b[0m Trial 48 finished with value: 0.8828633405639913 and parameters: {'num_leaves': 153, 'max_depth': 42, 'learning_rate': 0.1325526939181805, 'n_estimators': 1271}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:07,092]\u001b[0m Trial 49 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 233, 'max_depth': 47, 'learning_rate': 0.1200705212545954, 'n_estimators': 235}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:08,471]\u001b[0m Trial 50 finished with value: 0.8655097613882863 and parameters: {'num_leaves': 17, 'max_depth': 39, 'learning_rate': 0.16206282136273295, 'n_estimators': 1931}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:09,634]\u001b[0m Trial 51 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 253, 'max_depth': 27, 'learning_rate': 0.10182447449932225, 'n_estimators': 470}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:10,879]\u001b[0m Trial 52 finished with value: 0.8828633405639913 and parameters: {'num_leaves': 213, 'max_depth': 31, 'learning_rate': 0.11483300401842798, 'n_estimators': 673}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:11,938]\u001b[0m Trial 53 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 244, 'max_depth': 33, 'learning_rate': 0.14602816826266907, 'n_estimators': 409}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:13,318]\u001b[0m Trial 54 finished with value: 0.8806941431670282 and parameters: {'num_leaves': 242, 'max_depth': 24, 'learning_rate': 0.0943435064862776, 'n_estimators': 563}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:14,466]\u001b[0m Trial 55 finished with value: 0.8741865509761388 and parameters: {'num_leaves': 228, 'max_depth': 30, 'learning_rate': 0.12650304480292074, 'n_estimators': 630}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:16,131]\u001b[0m Trial 56 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 220, 'max_depth': 22, 'learning_rate': 0.07801896814181454, 'n_estimators': 838}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:17,838]\u001b[0m Trial 57 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 197, 'max_depth': 27, 'learning_rate': 0.13895911958330315, 'n_estimators': 1534}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:18,299]\u001b[0m Trial 58 finished with value: 0.8698481561822126 and parameters: {'num_leaves': 206, 'max_depth': 35, 'learning_rate': 0.09943716419223977, 'n_estimators': 104}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:19,746]\u001b[0m Trial 59 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 238, 'max_depth': 25, 'learning_rate': 0.11917647259199309, 'n_estimators': 940}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:21,108]\u001b[0m Trial 60 finished with value: 0.8828633405639913 and parameters: {'num_leaves': 179, 'max_depth': 8, 'learning_rate': 0.17368969478951568, 'n_estimators': 1342}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:23,121]\u001b[0m Trial 61 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 142, 'max_depth': 36, 'learning_rate': 0.07206763247059422, 'n_estimators': 1354}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:25,565]\u001b[0m Trial 62 finished with value: 0.8806941431670282 and parameters: {'num_leaves': 120, 'max_depth': 34, 'learning_rate': 0.06615934551589464, 'n_estimators': 1481}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:27,200]\u001b[0m Trial 63 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 106, 'max_depth': 36, 'learning_rate': 0.09214234465216165, 'n_estimators': 1126}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:29,457]\u001b[0m Trial 64 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 85, 'max_depth': 40, 'learning_rate': 0.07456070017998147, 'n_estimators': 1634}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:31,219]\u001b[0m Trial 65 finished with value: 0.8741865509761388 and parameters: {'num_leaves': 159, 'max_depth': 28, 'learning_rate': 0.10895153867203447, 'n_estimators': 1264}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:32,887]\u001b[0m Trial 66 finished with value: 0.8850325379609545 and parameters: {'num_leaves': 128, 'max_depth': 33, 'learning_rate': 0.085642443610942, 'n_estimators': 1056}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:34,365]\u001b[0m Trial 67 finished with value: 0.8828633405639913 and parameters: {'num_leaves': 69, 'max_depth': 31, 'learning_rate': 0.0874611685744083, 'n_estimators': 1016}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:35,744]\u001b[0m Trial 68 finished with value: 0.8741865509761388 and parameters: {'num_leaves': 130, 'max_depth': 33, 'learning_rate': 0.11639307515198338, 'n_estimators': 947}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:37,078]\u001b[0m Trial 69 finished with value: 0.8806941431670282 and parameters: {'num_leaves': 89, 'max_depth': 17, 'learning_rate': 0.15262119861796108, 'n_estimators': 794}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:38,648]\u001b[0m Trial 70 finished with value: 0.8828633405639913 and parameters: {'num_leaves': 112, 'max_depth': 43, 'learning_rate': 0.1368023421876648, 'n_estimators': 1167}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:40,523]\u001b[0m Trial 71 finished with value: 0.8828633405639913 and parameters: {'num_leaves': 131, 'max_depth': 37, 'learning_rate': 0.08300998132922772, 'n_estimators': 1074}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:42,913]\u001b[0m Trial 72 finished with value: 0.8741865509761388 and parameters: {'num_leaves': 124, 'max_depth': 33, 'learning_rate': 0.06334120782744666, 'n_estimators': 1403}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:45,000]\u001b[0m Trial 73 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 139, 'max_depth': 30, 'learning_rate': 0.09758134395720797, 'n_estimators': 1768}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:47,301]\u001b[0m Trial 74 finished with value: 0.8806941431670282 and parameters: {'num_leaves': 100, 'max_depth': 39, 'learning_rate': 0.05839862132618487, 'n_estimators': 1491}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:48,063]\u001b[0m Trial 75 finished with value: 0.8676789587852495 and parameters: {'num_leaves': 148, 'max_depth': 28, 'learning_rate': 0.05031856150809222, 'n_estimators': 183}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:50,210]\u001b[0m Trial 76 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 60, 'max_depth': 35, 'learning_rate': 0.07434115525278892, 'n_estimators': 1232}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:50,889]\u001b[0m Trial 77 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 45, 'max_depth': 37, 'learning_rate': 0.08585868031265283, 'n_estimators': 312}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:51,872]\u001b[0m Trial 78 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 160, 'max_depth': 30, 'learning_rate': 0.10636337648524687, 'n_estimators': 438}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:53,462]\u001b[0m Trial 79 finished with value: 0.8828633405639913 and parameters: {'num_leaves': 176, 'max_depth': 41, 'learning_rate': 0.12591389159303162, 'n_estimators': 1354}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:55,968]\u001b[0m Trial 80 finished with value: 0.8720173535791758 and parameters: {'num_leaves': 247, 'max_depth': 32, 'learning_rate': 0.06726765947542247, 'n_estimators': 1435}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:57,144]\u001b[0m Trial 81 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 254, 'max_depth': 26, 'learning_rate': 0.11196121499673865, 'n_estimators': 485}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:58,136]\u001b[0m Trial 82 finished with value: 0.8806941431670282 and parameters: {'num_leaves': 223, 'max_depth': 34, 'learning_rate': 0.10171849606585134, 'n_estimators': 345}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:03:59,179]\u001b[0m Trial 83 finished with value: 0.8850325379609545 and parameters: {'num_leaves': 233, 'max_depth': 22, 'learning_rate': 0.1146446598888249, 'n_estimators': 523}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:00,775]\u001b[0m Trial 84 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 233, 'max_depth': 21, 'learning_rate': 0.09141672187969761, 'n_estimators': 593}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:02,024]\u001b[0m Trial 85 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 239, 'max_depth': 18, 'learning_rate': 0.13391255084931175, 'n_estimators': 668}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:02,986]\u001b[0m Trial 86 finished with value: 0.8741865509761388 and parameters: {'num_leaves': 192, 'max_depth': 14, 'learning_rate': 0.1227942812866375, 'n_estimators': 561}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:03,782]\u001b[0m Trial 87 finished with value: 0.8806941431670282 and parameters: {'num_leaves': 136, 'max_depth': 23, 'learning_rate': 0.08099014870252458, 'n_estimators': 209}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:05,707]\u001b[0m Trial 88 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 208, 'max_depth': 25, 'learning_rate': 0.10636360110693148, 'n_estimators': 1583}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:06,546]\u001b[0m Trial 89 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 219, 'max_depth': 28, 'learning_rate': 0.1176341323076136, 'n_estimators': 281}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:06,776]\u001b[0m Trial 90 finished with value: 0.8720173535791758 and parameters: {'num_leaves': 115, 'max_depth': 2, 'learning_rate': 0.1459793859895068, 'n_estimators': 744}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:08,245]\u001b[0m Trial 91 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 248, 'max_depth': 20, 'learning_rate': 0.11220111468196232, 'n_estimators': 515}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:09,371]\u001b[0m Trial 92 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 233, 'max_depth': 26, 'learning_rate': 0.09821396800999077, 'n_estimators': 423}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:10,653]\u001b[0m Trial 93 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 251, 'max_depth': 24, 'learning_rate': 0.09366950175488664, 'n_estimators': 371}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:11,699]\u001b[0m Trial 94 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 242, 'max_depth': 32, 'learning_rate': 0.12942408315147438, 'n_estimators': 525}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:13,128]\u001b[0m Trial 95 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 231, 'max_depth': 35, 'learning_rate': 0.12169284223038102, 'n_estimators': 919}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:13,373]\u001b[0m Trial 96 finished with value: 0.8676789587852495 and parameters: {'num_leaves': 3, 'max_depth': 31, 'learning_rate': 0.10413626702930923, 'n_estimators': 794}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:15,125]\u001b[0m Trial 97 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 124, 'max_depth': 38, 'learning_rate': 0.11257902604792144, 'n_estimators': 1298}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:16,244]\u001b[0m Trial 98 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 256, 'max_depth': 36, 'learning_rate': 0.14023495153492666, 'n_estimators': 649}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:17,903]\u001b[0m Trial 99 finished with value: 0.8828633405639913 and parameters: {'num_leaves': 226, 'max_depth': 39, 'learning_rate': 0.1282021365741449, 'n_estimators': 1160}. Best is trial 0 with value: 0.8850325379609545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning  accuracy   \n",
      "index          AAC  LogisticRegression            False  0.870562  \\\n",
      "index          AAC                 SVC            False  0.895351   \n",
      "index          AAC       XGBClassifier            False  0.878837   \n",
      "index          AAC      LGBMClassifier            False  0.885530   \n",
      "index          AAC                 SVC             True  0.867679   \n",
      "index          AAC       XGBClassifier             True  0.891540   \n",
      "index          AAC      LGBMClassifier             True  0.885033   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.875000     0.924051   0.915888  0.894977  0.800787  \\\n",
      "index     0.825893     0.940928   0.929648  0.874704  0.773776   \n",
      "index     0.834821     0.915612   0.903382  0.867749  0.754064   \n",
      "index     0.812500     0.924051   0.910000  0.858491  0.742789   \n",
      "index     0.803571     0.928270   0.913706  0.855107  0.739401   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.830357     0.936709   0.925373  0.875294  0.773119   \n",
      "\n",
      "                                       index  \n",
      "index  AAC_LogisticRegression_no_hypertuning  \n",
      "index                 AAC_SVC_no_hypertuning  \n",
      "index       AAC_XGBClassifier_no_hypertuning  \n",
      "index      AAC_LGBMClassifier_no_hypertuning  \n",
      "index               AAC_SVC_with_hypertuning  \n",
      "index     AAC_XGBClassifier_with_hypertuning  \n",
      "index    AAC_LGBMClassifier_with_hypertuning  \n",
      "Evaluating APAAC LogisticRegression\n",
      "      feature_type               model with_hypertuning  accuracy   \n",
      "index          AAC  LogisticRegression            False  0.870562  \\\n",
      "index          AAC                 SVC            False  0.895351   \n",
      "index          AAC       XGBClassifier            False  0.878837   \n",
      "index          AAC      LGBMClassifier            False  0.885530   \n",
      "index          AAC                 SVC             True  0.867679   \n",
      "index          AAC       XGBClassifier             True  0.891540   \n",
      "index          AAC      LGBMClassifier             True  0.885033   \n",
      "index        APAAC  LogisticRegression            False  0.874261   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.875000     0.924051   0.915888  0.894977  0.800787  \\\n",
      "index     0.825893     0.940928   0.929648  0.874704  0.773776   \n",
      "index     0.834821     0.915612   0.903382  0.867749  0.754064   \n",
      "index     0.812500     0.924051   0.910000  0.858491  0.742789   \n",
      "index     0.803571     0.928270   0.913706  0.855107  0.739401   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.830357     0.936709   0.925373  0.875294  0.773119   \n",
      "index     0.870536     0.928270   0.919811  0.894495  0.801072   \n",
      "\n",
      "                                         index  \n",
      "index    AAC_LogisticRegression_no_hypertuning  \n",
      "index                   AAC_SVC_no_hypertuning  \n",
      "index         AAC_XGBClassifier_no_hypertuning  \n",
      "index        AAC_LGBMClassifier_no_hypertuning  \n",
      "index                 AAC_SVC_with_hypertuning  \n",
      "index       AAC_XGBClassifier_with_hypertuning  \n",
      "index      AAC_LGBMClassifier_with_hypertuning  \n",
      "index  APAAC_LogisticRegression_no_hypertuning  \n",
      "Evaluating APAAC SVC\n",
      "      feature_type               model with_hypertuning  accuracy   \n",
      "index          AAC  LogisticRegression            False  0.870562  \\\n",
      "index          AAC                 SVC            False  0.895351   \n",
      "index          AAC       XGBClassifier            False  0.878837   \n",
      "index          AAC      LGBMClassifier            False  0.885530   \n",
      "index          AAC                 SVC             True  0.867679   \n",
      "index          AAC       XGBClassifier             True  0.891540   \n",
      "index          AAC      LGBMClassifier             True  0.885033   \n",
      "index        APAAC  LogisticRegression            False  0.874261   \n",
      "index        APAAC                 SVC            False  0.870301   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.875000     0.924051   0.915888  0.894977  0.800787  \\\n",
      "index     0.825893     0.940928   0.929648  0.874704  0.773776   \n",
      "index     0.834821     0.915612   0.903382  0.867749  0.754064   \n",
      "index     0.812500     0.924051   0.910000  0.858491  0.742789   \n",
      "index     0.803571     0.928270   0.913706  0.855107  0.739401   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.830357     0.936709   0.925373  0.875294  0.773119   \n",
      "index     0.870536     0.928270   0.919811  0.894495  0.801072   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "\n",
      "                                         index  \n",
      "index    AAC_LogisticRegression_no_hypertuning  \n",
      "index                   AAC_SVC_no_hypertuning  \n",
      "index         AAC_XGBClassifier_no_hypertuning  \n",
      "index        AAC_LGBMClassifier_no_hypertuning  \n",
      "index                 AAC_SVC_with_hypertuning  \n",
      "index       AAC_XGBClassifier_with_hypertuning  \n",
      "index      AAC_LGBMClassifier_with_hypertuning  \n",
      "index  APAAC_LogisticRegression_no_hypertuning  \n",
      "index                 APAAC_SVC_no_hypertuning  \n",
      "Evaluating APAAC XGBClassifier\n",
      "      feature_type               model with_hypertuning  accuracy   \n",
      "index          AAC  LogisticRegression            False  0.870562  \\\n",
      "index          AAC                 SVC            False  0.895351   \n",
      "index          AAC       XGBClassifier            False  0.878837   \n",
      "index          AAC      LGBMClassifier            False  0.885530   \n",
      "index          AAC                 SVC             True  0.867679   \n",
      "index          AAC       XGBClassifier             True  0.891540   \n",
      "index          AAC      LGBMClassifier             True  0.885033   \n",
      "index        APAAC  LogisticRegression            False  0.874261   \n",
      "index        APAAC                 SVC            False  0.870301   \n",
      "index        APAAC       XGBClassifier            False  0.880982   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.875000     0.924051   0.915888  0.894977  0.800787  \\\n",
      "index     0.825893     0.940928   0.929648  0.874704  0.773776   \n",
      "index     0.834821     0.915612   0.903382  0.867749  0.754064   \n",
      "index     0.812500     0.924051   0.910000  0.858491  0.742789   \n",
      "index     0.803571     0.928270   0.913706  0.855107  0.739401   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.830357     0.936709   0.925373  0.875294  0.773119   \n",
      "index     0.870536     0.928270   0.919811  0.894495  0.801072   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.825893     0.928270   0.915842  0.868545  0.759692   \n",
      "\n",
      "                                         index  \n",
      "index    AAC_LogisticRegression_no_hypertuning  \n",
      "index                   AAC_SVC_no_hypertuning  \n",
      "index         AAC_XGBClassifier_no_hypertuning  \n",
      "index        AAC_LGBMClassifier_no_hypertuning  \n",
      "index                 AAC_SVC_with_hypertuning  \n",
      "index       AAC_XGBClassifier_with_hypertuning  \n",
      "index      AAC_LGBMClassifier_with_hypertuning  \n",
      "index  APAAC_LogisticRegression_no_hypertuning  \n",
      "index                 APAAC_SVC_no_hypertuning  \n",
      "index       APAAC_XGBClassifier_no_hypertuning  \n",
      "Evaluating APAAC LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-13 11:04:27,382]\u001b[0m A new study created in memory with name: no-name-14a75d22-9642-447c-8592-1170012fbea0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning  accuracy   \n",
      "index          AAC  LogisticRegression            False  0.870562  \\\n",
      "index          AAC                 SVC            False  0.895351   \n",
      "index          AAC       XGBClassifier            False  0.878837   \n",
      "index          AAC      LGBMClassifier            False  0.885530   \n",
      "index          AAC                 SVC             True  0.867679   \n",
      "index          AAC       XGBClassifier             True  0.891540   \n",
      "index          AAC      LGBMClassifier             True  0.885033   \n",
      "index        APAAC  LogisticRegression            False  0.874261   \n",
      "index        APAAC                 SVC            False  0.870301   \n",
      "index        APAAC       XGBClassifier            False  0.880982   \n",
      "index        APAAC      LGBMClassifier            False  0.885727   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.875000     0.924051   0.915888  0.894977  0.800787  \\\n",
      "index     0.825893     0.940928   0.929648  0.874704  0.773776   \n",
      "index     0.834821     0.915612   0.903382  0.867749  0.754064   \n",
      "index     0.812500     0.924051   0.910000  0.858491  0.742789   \n",
      "index     0.803571     0.928270   0.913706  0.855107  0.739401   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.830357     0.936709   0.925373  0.875294  0.773119   \n",
      "index     0.870536     0.928270   0.919811  0.894495  0.801072   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.825893     0.928270   0.915842  0.868545  0.759692   \n",
      "index     0.821429     0.924051   0.910891  0.863850  0.750945   \n",
      "\n",
      "                                         index  \n",
      "index    AAC_LogisticRegression_no_hypertuning  \n",
      "index                   AAC_SVC_no_hypertuning  \n",
      "index         AAC_XGBClassifier_no_hypertuning  \n",
      "index        AAC_LGBMClassifier_no_hypertuning  \n",
      "index                 AAC_SVC_with_hypertuning  \n",
      "index       AAC_XGBClassifier_with_hypertuning  \n",
      "index      AAC_LGBMClassifier_with_hypertuning  \n",
      "index  APAAC_LogisticRegression_no_hypertuning  \n",
      "index                 APAAC_SVC_no_hypertuning  \n",
      "index       APAAC_XGBClassifier_no_hypertuning  \n",
      "index      APAAC_LGBMClassifier_no_hypertuning  \n",
      "Optimizing APAAC SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-13 11:04:28,063]\u001b[0m Trial 0 finished with value: 0.5466377440347071 and parameters: {'svc_c': 62.126480845441336, 'svc_gamma': 77.85274306421229}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:28,665]\u001b[0m Trial 1 finished with value: 0.5466377440347071 and parameters: {'svc_c': 99.51840390649261, 'svc_gamma': 39.10028262018109}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:29,268]\u001b[0m Trial 2 finished with value: 0.5466377440347071 and parameters: {'svc_c': 8.959661984273525, 'svc_gamma': 36.96900556859915}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:29,926]\u001b[0m Trial 3 finished with value: 0.5466377440347071 and parameters: {'svc_c': 90.78535750279524, 'svc_gamma': 78.92468530973966}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:30,531]\u001b[0m Trial 4 finished with value: 0.5466377440347071 and parameters: {'svc_c': 4.043359815308452, 'svc_gamma': 86.14893323808171}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:31,111]\u001b[0m Trial 5 finished with value: 0.5466377440347071 and parameters: {'svc_c': 85.24395020046832, 'svc_gamma': 68.63826139026122}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:31,729]\u001b[0m Trial 6 finished with value: 0.5466377440347071 and parameters: {'svc_c': 92.65531162886583, 'svc_gamma': 54.1153274262258}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:32,339]\u001b[0m Trial 7 finished with value: 0.5466377440347071 and parameters: {'svc_c': 93.81437133993123, 'svc_gamma': 29.524325463398842}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:32,889]\u001b[0m Trial 8 finished with value: 0.5466377440347071 and parameters: {'svc_c': 0.5896481811706407, 'svc_gamma': 9.587350050666272}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:33,470]\u001b[0m Trial 9 finished with value: 0.5466377440347071 and parameters: {'svc_c': 76.24239023222131, 'svc_gamma': 61.82912983658625}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:34,065]\u001b[0m Trial 10 finished with value: 0.5466377440347071 and parameters: {'svc_c': 58.3326842859279, 'svc_gamma': 96.968088141238}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:34,639]\u001b[0m Trial 11 finished with value: 0.5466377440347071 and parameters: {'svc_c': 62.9525097930338, 'svc_gamma': 44.552399798937714}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:35,212]\u001b[0m Trial 12 finished with value: 0.5466377440347071 and parameters: {'svc_c': 45.86140140128914, 'svc_gamma': 67.90248587500416}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:35,796]\u001b[0m Trial 13 finished with value: 0.5466377440347071 and parameters: {'svc_c': 99.96612239325074, 'svc_gamma': 50.62443386065189}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:36,361]\u001b[0m Trial 14 finished with value: 0.5466377440347071 and parameters: {'svc_c': 74.01006760229471, 'svc_gamma': 26.752387947323438}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:36,931]\u001b[0m Trial 15 finished with value: 0.5466377440347071 and parameters: {'svc_c': 40.54248341569729, 'svc_gamma': 79.23428243144373}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:37,499]\u001b[0m Trial 16 finished with value: 0.5466377440347071 and parameters: {'svc_c': 78.79513093001988, 'svc_gamma': 98.5963661589239}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:38,107]\u001b[0m Trial 17 finished with value: 0.5466377440347071 and parameters: {'svc_c': 63.27167507204774, 'svc_gamma': 58.636060622301244}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:38,669]\u001b[0m Trial 18 finished with value: 0.5466377440347071 and parameters: {'svc_c': 80.45416845316043, 'svc_gamma': 43.095864343396094}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:39,229]\u001b[0m Trial 19 finished with value: 0.5466377440347071 and parameters: {'svc_c': 98.81515558745173, 'svc_gamma': 13.220805017557232}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:39,831]\u001b[0m Trial 20 finished with value: 0.5466377440347071 and parameters: {'svc_c': 35.29056948923447, 'svc_gamma': 23.3212942181174}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:40,439]\u001b[0m Trial 21 finished with value: 0.5466377440347071 and parameters: {'svc_c': 29.24113816253601, 'svc_gamma': 38.82961612998184}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:41,021]\u001b[0m Trial 22 finished with value: 0.5466377440347071 and parameters: {'svc_c': 22.49264608597, 'svc_gamma': 37.683049516117435}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:41,548]\u001b[0m Trial 23 finished with value: 0.5466377440347071 and parameters: {'svc_c': 53.03344374320475, 'svc_gamma': 35.24412552340257}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:42,101]\u001b[0m Trial 24 finished with value: 0.5466377440347071 and parameters: {'svc_c': 69.31957255507051, 'svc_gamma': 48.392811903509724}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:42,631]\u001b[0m Trial 25 finished with value: 0.5466377440347071 and parameters: {'svc_c': 49.83930781097523, 'svc_gamma': 19.587852085367626}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:43,293]\u001b[0m Trial 26 finished with value: 0.5466377440347071 and parameters: {'svc_c': 84.6808747636151, 'svc_gamma': 2.1418708167931513}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:43,813]\u001b[0m Trial 27 finished with value: 0.5466377440347071 and parameters: {'svc_c': 69.40418772373862, 'svc_gamma': 34.040244919238226}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:44,343]\u001b[0m Trial 28 finished with value: 0.5466377440347071 and parameters: {'svc_c': 19.674194150057737, 'svc_gamma': 44.001704749132784}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:44,874]\u001b[0m Trial 29 finished with value: 0.5466377440347071 and parameters: {'svc_c': 88.74212556398341, 'svc_gamma': 54.12337883026698}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:45,435]\u001b[0m Trial 30 finished with value: 0.5466377440347071 and parameters: {'svc_c': 54.776417512790346, 'svc_gamma': 64.79862784424844}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:45,972]\u001b[0m Trial 31 finished with value: 0.5466377440347071 and parameters: {'svc_c': 91.96623749215843, 'svc_gamma': 74.39737156721985}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:46,510]\u001b[0m Trial 32 finished with value: 0.5466377440347071 and parameters: {'svc_c': 7.640226262080512, 'svc_gamma': 87.61165098646995}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:47,071]\u001b[0m Trial 33 finished with value: 0.5466377440347071 and parameters: {'svc_c': 86.23703673037625, 'svc_gamma': 73.10582699839419}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:47,638]\u001b[0m Trial 34 finished with value: 0.5466377440347071 and parameters: {'svc_c': 96.42178174474547, 'svc_gamma': 58.703906117106484}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:48,190]\u001b[0m Trial 35 finished with value: 0.5466377440347071 and parameters: {'svc_c': 92.86296256987961, 'svc_gamma': 84.9162598641042}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:48,743]\u001b[0m Trial 36 finished with value: 0.5466377440347071 and parameters: {'svc_c': 83.23314524450402, 'svc_gamma': 30.073933434273393}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:49,290]\u001b[0m Trial 37 finished with value: 0.5466377440347071 and parameters: {'svc_c': 89.19310954470436, 'svc_gamma': 66.69540727088115}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:49,845]\u001b[0m Trial 38 finished with value: 0.5466377440347071 and parameters: {'svc_c': 95.32907947354585, 'svc_gamma': 52.99959035561472}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:50,396]\u001b[0m Trial 39 finished with value: 0.5466377440347071 and parameters: {'svc_c': 73.68923111155331, 'svc_gamma': 92.29665125046813}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:50,975]\u001b[0m Trial 40 finished with value: 0.5466377440347071 and parameters: {'svc_c': 81.34786332097123, 'svc_gamma': 79.71850431586249}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:51,567]\u001b[0m Trial 41 finished with value: 0.5466377440347071 and parameters: {'svc_c': 6.884902438363964, 'svc_gamma': 90.96352980640735}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:52,117]\u001b[0m Trial 42 finished with value: 0.5466377440347071 and parameters: {'svc_c': 44.07753807503646, 'svc_gamma': 83.3297862241631}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:52,643]\u001b[0m Trial 43 finished with value: 0.5466377440347071 and parameters: {'svc_c': 0.8617428285875635, 'svc_gamma': 74.12998737557204}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:53,182]\u001b[0m Trial 44 finished with value: 0.5466377440347071 and parameters: {'svc_c': 99.01924345799819, 'svc_gamma': 98.82794409394148}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:53,729]\u001b[0m Trial 45 finished with value: 0.5466377440347071 and parameters: {'svc_c': 77.39957105740476, 'svc_gamma': 92.84038344176473}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:54,270]\u001b[0m Trial 46 finished with value: 0.5466377440347071 and parameters: {'svc_c': 60.70541417644464, 'svc_gamma': 80.68951607304349}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:54,806]\u001b[0m Trial 47 finished with value: 0.5466377440347071 and parameters: {'svc_c': 89.54052036896071, 'svc_gamma': 71.58437060743972}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:55,378]\u001b[0m Trial 48 finished with value: 0.5466377440347071 and parameters: {'svc_c': 57.61166123966448, 'svc_gamma': 78.41777677502047}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:55,944]\u001b[0m Trial 49 finished with value: 0.5466377440347071 and parameters: {'svc_c': 93.70030794866803, 'svc_gamma': 86.23613935972702}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:56,462]\u001b[0m Trial 50 finished with value: 0.5466377440347071 and parameters: {'svc_c': 66.9102619276328, 'svc_gamma': 61.133257573948995}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:56,932]\u001b[0m Trial 51 finished with value: 0.5466377440347071 and parameters: {'svc_c': 84.59786176841887, 'svc_gamma': 69.38281745249311}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:57,398]\u001b[0m Trial 52 finished with value: 0.5466377440347071 and parameters: {'svc_c': 75.31833493894852, 'svc_gamma': 76.19827945050058}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:57,863]\u001b[0m Trial 53 finished with value: 0.5466377440347071 and parameters: {'svc_c': 80.45245328874863, 'svc_gamma': 82.83368050447245}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:58,360]\u001b[0m Trial 54 finished with value: 0.5466377440347071 and parameters: {'svc_c': 97.07218545556826, 'svc_gamma': 69.8989923791749}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:58,869]\u001b[0m Trial 55 finished with value: 0.5466377440347071 and parameters: {'svc_c': 99.28780914390568, 'svc_gamma': 64.23831874661948}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:59,355]\u001b[0m Trial 56 finished with value: 0.5466377440347071 and parameters: {'svc_c': 91.17739718736593, 'svc_gamma': 78.18497510667312}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:04:59,824]\u001b[0m Trial 57 finished with value: 0.5466377440347071 and parameters: {'svc_c': 48.804639900623634, 'svc_gamma': 41.148622554722564}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:00,297]\u001b[0m Trial 58 finished with value: 0.5466377440347071 and parameters: {'svc_c': 86.20407679752523, 'svc_gamma': 46.43048529438204}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:00,790]\u001b[0m Trial 59 finished with value: 0.5466377440347071 and parameters: {'svc_c': 40.90981766440282, 'svc_gamma': 88.4218945783445}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:01,316]\u001b[0m Trial 60 finished with value: 0.5466377440347071 and parameters: {'svc_c': 63.668327537871065, 'svc_gamma': 95.21066008395162}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:01,855]\u001b[0m Trial 61 finished with value: 0.5466377440347071 and parameters: {'svc_c': 95.49822542774373, 'svc_gamma': 48.9014214613172}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:02,382]\u001b[0m Trial 62 finished with value: 0.5466377440347071 and parameters: {'svc_c': 92.54314963261656, 'svc_gamma': 55.95994251075025}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:02,861]\u001b[0m Trial 63 finished with value: 0.5466377440347071 and parameters: {'svc_c': 88.00128272425138, 'svc_gamma': 40.87683444432264}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:03,382]\u001b[0m Trial 64 finished with value: 0.5466377440347071 and parameters: {'svc_c': 83.31734429120222, 'svc_gamma': 45.94297235506739}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:03,882]\u001b[0m Trial 65 finished with value: 0.5466377440347071 and parameters: {'svc_c': 78.14936143889068, 'svc_gamma': 67.78422106996221}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:04,359]\u001b[0m Trial 66 finished with value: 0.5466377440347071 and parameters: {'svc_c': 90.67973170280364, 'svc_gamma': 34.73329341728534}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:04,842]\u001b[0m Trial 67 finished with value: 0.5466377440347071 and parameters: {'svc_c': 95.64751884224493, 'svc_gamma': 71.96415495768943}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:05,315]\u001b[0m Trial 68 finished with value: 0.5466377440347071 and parameters: {'svc_c': 99.61592607374422, 'svc_gamma': 75.95584437042815}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:05,790]\u001b[0m Trial 69 finished with value: 0.5466377440347071 and parameters: {'svc_c': 86.25820816843084, 'svc_gamma': 82.92996924667622}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:06,273]\u001b[0m Trial 70 finished with value: 0.5466377440347071 and parameters: {'svc_c': 74.0345130671797, 'svc_gamma': 52.58244555948947}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:06,781]\u001b[0m Trial 71 finished with value: 0.5466377440347071 and parameters: {'svc_c': 93.67052242506574, 'svc_gamma': 30.044579689840567}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:07,290]\u001b[0m Trial 72 finished with value: 0.5466377440347071 and parameters: {'svc_c': 89.70060226673905, 'svc_gamma': 37.547861779530805}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:07,765]\u001b[0m Trial 73 finished with value: 0.5466377440347071 and parameters: {'svc_c': 96.58394829000042, 'svc_gamma': 44.36302977491586}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:08,265]\u001b[0m Trial 74 finished with value: 0.5466377440347071 and parameters: {'svc_c': 81.51965785106657, 'svc_gamma': 30.672818011582436}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:08,747]\u001b[0m Trial 75 finished with value: 0.5466377440347071 and parameters: {'svc_c': 31.71821035245801, 'svc_gamma': 26.280560874851002}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:09,227]\u001b[0m Trial 76 finished with value: 0.5466377440347071 and parameters: {'svc_c': 92.78583438247864, 'svc_gamma': 49.18627802820017}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:09,752]\u001b[0m Trial 77 finished with value: 0.5466377440347071 and parameters: {'svc_c': 86.9047325473336, 'svc_gamma': 38.85472891812303}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:10,262]\u001b[0m Trial 78 finished with value: 0.5466377440347071 and parameters: {'svc_c': 88.04955983565466, 'svc_gamma': 57.967181644834454}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:10,763]\u001b[0m Trial 79 finished with value: 0.5466377440347071 and parameters: {'svc_c': 71.21101170172348, 'svc_gamma': 63.14459151286013}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:11,287]\u001b[0m Trial 80 finished with value: 0.5466377440347071 and parameters: {'svc_c': 77.09163305028662, 'svc_gamma': 66.79373406004828}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:11,732]\u001b[0m Trial 81 finished with value: 0.5466377440347071 and parameters: {'svc_c': 0.9087540301290389, 'svc_gamma': 18.3999500462266}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:12,218]\u001b[0m Trial 82 finished with value: 0.5466377440347071 and parameters: {'svc_c': 11.246369882161229, 'svc_gamma': 8.57910213169098}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:12,716]\u001b[0m Trial 83 finished with value: 0.5466377440347071 and parameters: {'svc_c': 99.883269552501, 'svc_gamma': 41.810514968560355}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:13,197]\u001b[0m Trial 84 finished with value: 0.5466377440347071 and parameters: {'svc_c': 12.349932737725123, 'svc_gamma': 32.83369034705482}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:13,675]\u001b[0m Trial 85 finished with value: 0.5466377440347071 and parameters: {'svc_c': 4.775295145800435, 'svc_gamma': 36.71672521977522}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:14,176]\u001b[0m Trial 86 finished with value: 0.5466377440347071 and parameters: {'svc_c': 54.66213953881025, 'svc_gamma': 21.23990091873685}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:14,696]\u001b[0m Trial 87 finished with value: 0.5509761388286334 and parameters: {'svc_c': 96.74176487155613, 'svc_gamma': 0.21236644029303875}. Best is trial 87 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:15,217]\u001b[0m Trial 88 finished with value: 0.5466377440347071 and parameters: {'svc_c': 97.31283637592875, 'svc_gamma': 51.079373028467394}. Best is trial 87 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:15,748]\u001b[0m Trial 89 finished with value: 0.5466377440347071 and parameters: {'svc_c': 91.6919109899996, 'svc_gamma': 25.446454705977978}. Best is trial 87 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:16,324]\u001b[0m Trial 90 finished with value: 0.5466377440347071 and parameters: {'svc_c': 93.62347031892891, 'svc_gamma': 4.308658439180476}. Best is trial 87 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:16,972]\u001b[0m Trial 91 finished with value: 0.5466377440347071 and parameters: {'svc_c': 95.29397062984913, 'svc_gamma': 1.989459963635901}. Best is trial 87 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:17,537]\u001b[0m Trial 92 finished with value: 0.5466377440347071 and parameters: {'svc_c': 84.17442782058802, 'svc_gamma': 15.04993757998297}. Best is trial 87 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:18,097]\u001b[0m Trial 93 finished with value: 0.5466377440347071 and parameters: {'svc_c': 90.39401913917787, 'svc_gamma': 9.055861926863404}. Best is trial 87 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:18,693]\u001b[0m Trial 94 finished with value: 0.5509761388286334 and parameters: {'svc_c': 97.63417521825616, 'svc_gamma': 0.4766777976971213}. Best is trial 87 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:19,274]\u001b[0m Trial 95 finished with value: 0.5466377440347071 and parameters: {'svc_c': 94.80040137011814, 'svc_gamma': 11.6609508783814}. Best is trial 87 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:19,951]\u001b[0m Trial 96 finished with value: 0.5488069414316703 and parameters: {'svc_c': 98.26294998628515, 'svc_gamma': 0.9811056272685301}. Best is trial 87 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:20,482]\u001b[0m Trial 97 finished with value: 0.5704989154013015 and parameters: {'svc_c': 97.78063377955574, 'svc_gamma': 0.08981503015351167}. Best is trial 97 with value: 0.5704989154013015.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:21,103]\u001b[0m Trial 98 finished with value: 0.5466377440347071 and parameters: {'svc_c': 99.64735390509595, 'svc_gamma': 4.623421131557212}. Best is trial 97 with value: 0.5704989154013015.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:21,662]\u001b[0m Trial 99 finished with value: 0.5553145336225597 and parameters: {'svc_c': 95.83194911286101, 'svc_gamma': 0.16786491364723213}. Best is trial 97 with value: 0.5704989154013015.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:21,669]\u001b[0m A new study created in memory with name: no-name-da62fc77-6db5-4d44-8b1b-4366ff3ae747\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning  accuracy   \n",
      "index          AAC  LogisticRegression            False  0.870562  \\\n",
      "index          AAC                 SVC            False  0.895351   \n",
      "index          AAC       XGBClassifier            False  0.878837   \n",
      "index          AAC      LGBMClassifier            False  0.885530   \n",
      "index          AAC                 SVC             True  0.867679   \n",
      "index          AAC       XGBClassifier             True  0.891540   \n",
      "index          AAC      LGBMClassifier             True  0.885033   \n",
      "index        APAAC  LogisticRegression            False  0.874261   \n",
      "index        APAAC                 SVC            False  0.870301   \n",
      "index        APAAC       XGBClassifier            False  0.880982   \n",
      "index        APAAC      LGBMClassifier            False  0.885727   \n",
      "index        APAAC                 SVC             True  0.570499   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.875000     0.924051   0.915888  0.894977  0.800787  \\\n",
      "index     0.825893     0.940928   0.929648  0.874704  0.773776   \n",
      "index     0.834821     0.915612   0.903382  0.867749  0.754064   \n",
      "index     0.812500     0.924051   0.910000  0.858491  0.742789   \n",
      "index     0.803571     0.928270   0.913706  0.855107  0.739401   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.830357     0.936709   0.925373  0.875294  0.773119   \n",
      "index     0.870536     0.928270   0.919811  0.894495  0.801072   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.825893     0.928270   0.915842  0.868545  0.759692   \n",
      "index     0.821429     0.924051   0.910891  0.863850  0.750945   \n",
      "index     0.129464     0.987342   0.906250  0.226562  0.229699   \n",
      "\n",
      "                                         index  \n",
      "index    AAC_LogisticRegression_no_hypertuning  \n",
      "index                   AAC_SVC_no_hypertuning  \n",
      "index         AAC_XGBClassifier_no_hypertuning  \n",
      "index        AAC_LGBMClassifier_no_hypertuning  \n",
      "index                 AAC_SVC_with_hypertuning  \n",
      "index       AAC_XGBClassifier_with_hypertuning  \n",
      "index      AAC_LGBMClassifier_with_hypertuning  \n",
      "index  APAAC_LogisticRegression_no_hypertuning  \n",
      "index                 APAAC_SVC_no_hypertuning  \n",
      "index       APAAC_XGBClassifier_no_hypertuning  \n",
      "index      APAAC_LGBMClassifier_no_hypertuning  \n",
      "index               APAAC_SVC_with_hypertuning  \n",
      "Optimizing APAAC XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-13 11:05:23,506]\u001b[0m Trial 0 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.046694373956595425, 'max_depth': 6, 'n_estimators': 262}. Best is trial 0 with value: 0.8763557483731019.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:24,698]\u001b[0m Trial 1 finished with value: 0.8698481561822126 and parameters: {'learning_rate': 0.10653835517519342, 'max_depth': 4, 'n_estimators': 211}. Best is trial 0 with value: 0.8763557483731019.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:25,122]\u001b[0m Trial 2 finished with value: 0.8785249457700651 and parameters: {'learning_rate': 0.17261775078176933, 'max_depth': 3, 'n_estimators': 103}. Best is trial 2 with value: 0.8785249457700651.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:27,386]\u001b[0m Trial 3 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.056803447518480495, 'max_depth': 3, 'n_estimators': 626}. Best is trial 2 with value: 0.8785249457700651.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:30,301]\u001b[0m Trial 4 finished with value: 0.8741865509761388 and parameters: {'learning_rate': 0.26524169454158764, 'max_depth': 5, 'n_estimators': 647}. Best is trial 2 with value: 0.8785249457700651.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:32,445]\u001b[0m Trial 5 finished with value: 0.8676789587852495 and parameters: {'learning_rate': 0.18369880195131738, 'max_depth': 4, 'n_estimators': 473}. Best is trial 2 with value: 0.8785249457700651.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:34,871]\u001b[0m Trial 6 finished with value: 0.8850325379609545 and parameters: {'learning_rate': 0.07240750708065184, 'max_depth': 3, 'n_estimators': 586}. Best is trial 6 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:39,150]\u001b[0m Trial 7 finished with value: 0.8698481561822126 and parameters: {'learning_rate': 0.02615020183328689, 'max_depth': 4, 'n_estimators': 887}. Best is trial 6 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:42,307]\u001b[0m Trial 8 finished with value: 0.8676789587852495 and parameters: {'learning_rate': 0.26389485865592754, 'max_depth': 3, 'n_estimators': 871}. Best is trial 6 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:44,523]\u001b[0m Trial 9 finished with value: 0.8806941431670282 and parameters: {'learning_rate': 0.10752021383766873, 'max_depth': 6, 'n_estimators': 320}. Best is trial 6 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:46,751]\u001b[0m Trial 10 finished with value: 0.8806941431670282 and parameters: {'learning_rate': 0.1089279334102973, 'max_depth': 2, 'n_estimators': 758}. Best is trial 6 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:49,473]\u001b[0m Trial 11 finished with value: 0.8785249457700651 and parameters: {'learning_rate': 0.0924444674712338, 'max_depth': 6, 'n_estimators': 416}. Best is trial 6 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:52,027]\u001b[0m Trial 12 finished with value: 0.8698481561822126 and parameters: {'learning_rate': 0.010755265874354082, 'max_depth': 5, 'n_estimators': 365}. Best is trial 6 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:53,780]\u001b[0m Trial 13 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.13774856298418833, 'max_depth': 2, 'n_estimators': 536}. Best is trial 6 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:05:59,248]\u001b[0m Trial 14 finished with value: 0.8741865509761388 and parameters: {'learning_rate': 0.06827305806774994, 'max_depth': 5, 'n_estimators': 1000}. Best is trial 6 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:06:01,485]\u001b[0m Trial 15 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.14723887717132247, 'max_depth': 6, 'n_estimators': 335}. Best is trial 6 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:06:04,143]\u001b[0m Trial 16 finished with value: 0.8828633405639913 and parameters: {'learning_rate': 0.07743110557005846, 'max_depth': 3, 'n_estimators': 627}. Best is trial 6 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:06:06,883]\u001b[0m Trial 17 finished with value: 0.8806941431670282 and parameters: {'learning_rate': 0.0714341853838779, 'max_depth': 3, 'n_estimators': 662}. Best is trial 6 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:06:09,150]\u001b[0m Trial 18 finished with value: 0.8937093275488069 and parameters: {'learning_rate': 0.0326375531277094, 'max_depth': 2, 'n_estimators': 730}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:06:11,493]\u001b[0m Trial 19 finished with value: 0.8893709327548807 and parameters: {'learning_rate': 0.032904001321947186, 'max_depth': 2, 'n_estimators': 740}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:06:13,862]\u001b[0m Trial 20 finished with value: 0.8915401301518439 and parameters: {'learning_rate': 0.03299450704579458, 'max_depth': 2, 'n_estimators': 738}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:06:16,109]\u001b[0m Trial 21 finished with value: 0.8893709327548807 and parameters: {'learning_rate': 0.032089643581550274, 'max_depth': 2, 'n_estimators': 772}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:06:18,357]\u001b[0m Trial 22 finished with value: 0.8828633405639913 and parameters: {'learning_rate': 0.010236007243962501, 'max_depth': 2, 'n_estimators': 753}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:06:20,754]\u001b[0m Trial 23 finished with value: 0.8828633405639913 and parameters: {'learning_rate': 0.04650010541432183, 'max_depth': 2, 'n_estimators': 850}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:06:22,939]\u001b[0m Trial 24 finished with value: 0.8893709327548807 and parameters: {'learning_rate': 0.039426024249244976, 'max_depth': 2, 'n_estimators': 726}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:06:25,211]\u001b[0m Trial 25 finished with value: 0.8937093275488069 and parameters: {'learning_rate': 0.027531179171006677, 'max_depth': 2, 'n_estimators': 813}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:06:27,922]\u001b[0m Trial 26 finished with value: 0.8893709327548807 and parameters: {'learning_rate': 0.01162814023846891, 'max_depth': 2, 'n_estimators': 844}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:06:31,607]\u001b[0m Trial 27 finished with value: 0.8741865509761388 and parameters: {'learning_rate': 0.05943009082362777, 'max_depth': 3, 'n_estimators': 933}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:06:33,362]\u001b[0m Trial 28 finished with value: 0.8872017353579176 and parameters: {'learning_rate': 0.04664667430936145, 'max_depth': 2, 'n_estimators': 536}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:06:36,613]\u001b[0m Trial 29 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.048464311712007116, 'max_depth': 3, 'n_estimators': 807}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:06:39,337]\u001b[0m Trial 30 finished with value: 0.8893709327548807 and parameters: {'learning_rate': 0.02710527209890625, 'max_depth': 2, 'n_estimators': 946}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:06:41,397]\u001b[0m Trial 31 finished with value: 0.8872017353579176 and parameters: {'learning_rate': 0.030545771713343106, 'max_depth': 2, 'n_estimators': 706}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:06:43,585]\u001b[0m Trial 32 finished with value: 0.8872017353579176 and parameters: {'learning_rate': 0.03461828275837621, 'max_depth': 2, 'n_estimators': 713}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:06:46,045]\u001b[0m Trial 33 finished with value: 0.8741865509761388 and parameters: {'learning_rate': 0.08890625374721649, 'max_depth': 2, 'n_estimators': 808}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:06:49,281]\u001b[0m Trial 34 finished with value: 0.8785249457700651 and parameters: {'learning_rate': 0.05805191783273338, 'max_depth': 3, 'n_estimators': 686}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:06:51,585]\u001b[0m Trial 35 finished with value: 0.8806941431670282 and parameters: {'learning_rate': 0.04971594504131449, 'max_depth': 2, 'n_estimators': 807}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:06:54,192]\u001b[0m Trial 36 finished with value: 0.8828633405639913 and parameters: {'learning_rate': 0.024218949047756344, 'max_depth': 3, 'n_estimators': 588}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:06:56,777]\u001b[0m Trial 37 finished with value: 0.8741865509761388 and parameters: {'learning_rate': 0.05819869391718796, 'max_depth': 4, 'n_estimators': 486}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:07:00,593]\u001b[0m Trial 38 finished with value: 0.8893709327548807 and parameters: {'learning_rate': 0.01885345841622916, 'max_depth': 3, 'n_estimators': 914}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:07:04,159]\u001b[0m Trial 39 finished with value: 0.8676789587852495 and parameters: {'learning_rate': 0.03839935926444414, 'max_depth': 4, 'n_estimators': 611}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:07:04,642]\u001b[0m Trial 40 finished with value: 0.8655097613882863 and parameters: {'learning_rate': 0.024715245215455543, 'max_depth': 2, 'n_estimators': 139}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:07:06,796]\u001b[0m Trial 41 finished with value: 0.8872017353579176 and parameters: {'learning_rate': 0.04020841167220281, 'max_depth': 2, 'n_estimators': 777}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:07:09,015]\u001b[0m Trial 42 finished with value: 0.8872017353579176 and parameters: {'learning_rate': 0.03112391817989608, 'max_depth': 2, 'n_estimators': 668}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:07:11,189]\u001b[0m Trial 43 finished with value: 0.8806941431670282 and parameters: {'learning_rate': 0.06496438687045591, 'max_depth': 2, 'n_estimators': 760}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:07:13,717]\u001b[0m Trial 44 finished with value: 0.8850325379609545 and parameters: {'learning_rate': 0.017678991974390944, 'max_depth': 2, 'n_estimators': 832}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:07:17,296]\u001b[0m Trial 45 finished with value: 0.8741865509761388 and parameters: {'learning_rate': 0.08318798357419006, 'max_depth': 3, 'n_estimators': 882}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:07:19,622]\u001b[0m Trial 46 finished with value: 0.8850325379609545 and parameters: {'learning_rate': 0.09490610605493363, 'max_depth': 2, 'n_estimators': 729}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:07:22,890]\u001b[0m Trial 47 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.05269942672484227, 'max_depth': 3, 'n_estimators': 794}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:07:27,704]\u001b[0m Trial 48 finished with value: 0.8720173535791758 and parameters: {'learning_rate': 0.0682011891425287, 'max_depth': 4, 'n_estimators': 981}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:07:29,909]\u001b[0m Trial 49 finished with value: 0.8893709327548807 and parameters: {'learning_rate': 0.034905530021303116, 'max_depth': 2, 'n_estimators': 639}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:07:33,601]\u001b[0m Trial 50 finished with value: 0.8850325379609545 and parameters: {'learning_rate': 0.01039877723673397, 'max_depth': 3, 'n_estimators': 899}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:07:35,824]\u001b[0m Trial 51 finished with value: 0.8893709327548807 and parameters: {'learning_rate': 0.03869500091250038, 'max_depth': 2, 'n_estimators': 731}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:07:37,892]\u001b[0m Trial 52 finished with value: 0.8872017353579176 and parameters: {'learning_rate': 0.022721409467149793, 'max_depth': 2, 'n_estimators': 682}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:07:40,140]\u001b[0m Trial 53 finished with value: 0.8872017353579176 and parameters: {'learning_rate': 0.04418528952618886, 'max_depth': 2, 'n_estimators': 740}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:07:42,537]\u001b[0m Trial 54 finished with value: 0.8785249457700651 and parameters: {'learning_rate': 0.07878855530084325, 'max_depth': 2, 'n_estimators': 847}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:07:45,104]\u001b[0m Trial 55 finished with value: 0.8850325379609545 and parameters: {'learning_rate': 0.058531239034490055, 'max_depth': 2, 'n_estimators': 772}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:07:47,188]\u001b[0m Trial 56 finished with value: 0.8893709327548807 and parameters: {'learning_rate': 0.0695248166258072, 'max_depth': 2, 'n_estimators': 715}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:07:49,967]\u001b[0m Trial 57 finished with value: 0.8893709327548807 and parameters: {'learning_rate': 0.01848562659911032, 'max_depth': 3, 'n_estimators': 654}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:07:51,617]\u001b[0m Trial 58 finished with value: 0.8872017353579176 and parameters: {'learning_rate': 0.04438136104103066, 'max_depth': 2, 'n_estimators': 566}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:07:54,036]\u001b[0m Trial 59 finished with value: 0.8915401301518439 and parameters: {'learning_rate': 0.030199827630486575, 'max_depth': 2, 'n_estimators': 832}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:07:56,690]\u001b[0m Trial 60 finished with value: 0.8872017353579176 and parameters: {'learning_rate': 0.030433055175494, 'max_depth': 2, 'n_estimators': 869}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:07:59,110]\u001b[0m Trial 61 finished with value: 0.8872017353579176 and parameters: {'learning_rate': 0.03805685307707316, 'max_depth': 2, 'n_estimators': 789}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:08:04,194]\u001b[0m Trial 62 finished with value: 0.8785249457700651 and parameters: {'learning_rate': 0.05177367007401207, 'max_depth': 5, 'n_estimators': 837}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:08:06,457]\u001b[0m Trial 63 finished with value: 0.8850325379609545 and parameters: {'learning_rate': 0.011054882956020293, 'max_depth': 2, 'n_estimators': 695}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:08:08,626]\u001b[0m Trial 64 finished with value: 0.8915401301518439 and parameters: {'learning_rate': 0.026659380728665576, 'max_depth': 2, 'n_estimators': 750}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:08:11,147]\u001b[0m Trial 65 finished with value: 0.8915401301518439 and parameters: {'learning_rate': 0.026868475923553806, 'max_depth': 2, 'n_estimators': 820}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:08:14,185]\u001b[0m Trial 66 finished with value: 0.8893709327548807 and parameters: {'learning_rate': 0.022161732462925667, 'max_depth': 2, 'n_estimators': 937}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:08:16,747]\u001b[0m Trial 67 finished with value: 0.8785249457700651 and parameters: {'learning_rate': 0.061361708114010254, 'max_depth': 2, 'n_estimators': 823}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:08:20,995]\u001b[0m Trial 68 finished with value: 0.8828633405639913 and parameters: {'learning_rate': 0.0308591390314661, 'max_depth': 3, 'n_estimators': 863}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:08:23,477]\u001b[0m Trial 69 finished with value: 0.8806941431670282 and parameters: {'learning_rate': 0.047761136350790157, 'max_depth': 2, 'n_estimators': 752}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:08:31,005]\u001b[0m Trial 70 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.017834222542534063, 'max_depth': 6, 'n_estimators': 967}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:08:33,351]\u001b[0m Trial 71 finished with value: 0.8893709327548807 and parameters: {'learning_rate': 0.027639984135069278, 'max_depth': 2, 'n_estimators': 779}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:08:35,739]\u001b[0m Trial 72 finished with value: 0.8872017353579176 and parameters: {'learning_rate': 0.043762011122741834, 'max_depth': 2, 'n_estimators': 814}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:08:38,452]\u001b[0m Trial 73 finished with value: 0.8872017353579176 and parameters: {'learning_rate': 0.052560596260353434, 'max_depth': 2, 'n_estimators': 895}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:08:40,674]\u001b[0m Trial 74 finished with value: 0.8850325379609545 and parameters: {'learning_rate': 0.033375733437561186, 'max_depth': 2, 'n_estimators': 754}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:08:42,961]\u001b[0m Trial 75 finished with value: 0.8850325379609545 and parameters: {'learning_rate': 0.02127249884779757, 'max_depth': 2, 'n_estimators': 706}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:08:44,861]\u001b[0m Trial 76 finished with value: 0.8915401301518439 and parameters: {'learning_rate': 0.03646194348752527, 'max_depth': 2, 'n_estimators': 611}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:08:46,510]\u001b[0m Trial 77 finished with value: 0.8850325379609545 and parameters: {'learning_rate': 0.03816836487034612, 'max_depth': 2, 'n_estimators': 489}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:08:49,125]\u001b[0m Trial 78 finished with value: 0.8741865509761388 and parameters: {'learning_rate': 0.06277700772629315, 'max_depth': 3, 'n_estimators': 615}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:08:51,182]\u001b[0m Trial 79 finished with value: 0.8915401301518439 and parameters: {'learning_rate': 0.01640989875910879, 'max_depth': 2, 'n_estimators': 671}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:08:55,066]\u001b[0m Trial 80 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.014042344825652062, 'max_depth': 5, 'n_estimators': 525}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:08:57,058]\u001b[0m Trial 81 finished with value: 0.8872017353579176 and parameters: {'learning_rate': 0.029462603488384104, 'max_depth': 2, 'n_estimators': 585}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:08:59,079]\u001b[0m Trial 82 finished with value: 0.8850325379609545 and parameters: {'learning_rate': 0.02396825133930193, 'max_depth': 2, 'n_estimators': 674}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:01,197]\u001b[0m Trial 83 finished with value: 0.8850325379609545 and parameters: {'learning_rate': 0.016535762313595177, 'max_depth': 2, 'n_estimators': 629}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:03,281]\u001b[0m Trial 84 finished with value: 0.8893709327548807 and parameters: {'learning_rate': 0.042103475725963076, 'max_depth': 2, 'n_estimators': 655}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:05,576]\u001b[0m Trial 85 finished with value: 0.8850325379609545 and parameters: {'learning_rate': 0.05510800204837328, 'max_depth': 2, 'n_estimators': 795}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:06,323]\u001b[0m Trial 86 finished with value: 0.8741865509761388 and parameters: {'learning_rate': 0.025137074068802515, 'max_depth': 2, 'n_estimators': 240}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:08,999]\u001b[0m Trial 87 finished with value: 0.8828633405639913 and parameters: {'learning_rate': 0.01124261688604535, 'max_depth': 2, 'n_estimators': 740}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:10,264]\u001b[0m Trial 88 finished with value: 0.8828633405639913 and parameters: {'learning_rate': 0.03305208557642973, 'max_depth': 2, 'n_estimators': 419}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:13,325]\u001b[0m Trial 89 finished with value: 0.8785249457700651 and parameters: {'learning_rate': 0.04984365821932592, 'max_depth': 3, 'n_estimators': 704}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:16,002]\u001b[0m Trial 90 finished with value: 0.8850325379609545 and parameters: {'learning_rate': 0.018170076442064313, 'max_depth': 2, 'n_estimators': 917}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:18,322]\u001b[0m Trial 91 finished with value: 0.8893709327548807 and parameters: {'learning_rate': 0.03527887979066552, 'max_depth': 2, 'n_estimators': 724}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:20,578]\u001b[0m Trial 92 finished with value: 0.8893709327548807 and parameters: {'learning_rate': 0.04159324071060512, 'max_depth': 2, 'n_estimators': 764}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:23,186]\u001b[0m Trial 93 finished with value: 0.8872017353579176 and parameters: {'learning_rate': 0.027205679857197733, 'max_depth': 2, 'n_estimators': 822}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:25,498]\u001b[0m Trial 94 finished with value: 0.8850325379609545 and parameters: {'learning_rate': 0.04731131826347106, 'max_depth': 2, 'n_estimators': 681}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:29,044]\u001b[0m Trial 95 finished with value: 0.8872017353579176 and parameters: {'learning_rate': 0.022269346997319285, 'max_depth': 2, 'n_estimators': 854}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:31,386]\u001b[0m Trial 96 finished with value: 0.8893709327548807 and parameters: {'learning_rate': 0.036697324724528434, 'max_depth': 2, 'n_estimators': 776}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:33,932]\u001b[0m Trial 97 finished with value: 0.8893709327548807 and parameters: {'learning_rate': 0.033080013959182135, 'max_depth': 2, 'n_estimators': 801}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:36,139]\u001b[0m Trial 98 finished with value: 0.8806941431670282 and parameters: {'learning_rate': 0.05490732061861887, 'max_depth': 2, 'n_estimators': 732}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:38,073]\u001b[0m Trial 99 finished with value: 0.8893709327548807 and parameters: {'learning_rate': 0.01805157666768826, 'max_depth': 2, 'n_estimators': 607}. Best is trial 18 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:38,084]\u001b[0m A new study created in memory with name: no-name-87f9dcb2-4310-425a-9a49-3c028344b94c\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning  accuracy   \n",
      "index          AAC  LogisticRegression            False  0.870562  \\\n",
      "index          AAC                 SVC            False  0.895351   \n",
      "index          AAC       XGBClassifier            False  0.878837   \n",
      "index          AAC      LGBMClassifier            False  0.885530   \n",
      "index          AAC                 SVC             True  0.867679   \n",
      "index          AAC       XGBClassifier             True  0.891540   \n",
      "index          AAC      LGBMClassifier             True  0.885033   \n",
      "index        APAAC  LogisticRegression            False  0.874261   \n",
      "index        APAAC                 SVC            False  0.870301   \n",
      "index        APAAC       XGBClassifier            False  0.880982   \n",
      "index        APAAC      LGBMClassifier            False  0.885727   \n",
      "index        APAAC                 SVC             True  0.570499   \n",
      "index        APAAC       XGBClassifier             True  0.893709   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.875000     0.924051   0.915888  0.894977  0.800787  \\\n",
      "index     0.825893     0.940928   0.929648  0.874704  0.773776   \n",
      "index     0.834821     0.915612   0.903382  0.867749  0.754064   \n",
      "index     0.812500     0.924051   0.910000  0.858491  0.742789   \n",
      "index     0.803571     0.928270   0.913706  0.855107  0.739401   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.830357     0.936709   0.925373  0.875294  0.773119   \n",
      "index     0.870536     0.928270   0.919811  0.894495  0.801072   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.825893     0.928270   0.915842  0.868545  0.759692   \n",
      "index     0.821429     0.924051   0.910891  0.863850  0.750945   \n",
      "index     0.129464     0.987342   0.906250  0.226562  0.229699   \n",
      "index     0.857143     0.928270   0.918660  0.886836  0.788538   \n",
      "\n",
      "                                         index  \n",
      "index    AAC_LogisticRegression_no_hypertuning  \n",
      "index                   AAC_SVC_no_hypertuning  \n",
      "index         AAC_XGBClassifier_no_hypertuning  \n",
      "index        AAC_LGBMClassifier_no_hypertuning  \n",
      "index                 AAC_SVC_with_hypertuning  \n",
      "index       AAC_XGBClassifier_with_hypertuning  \n",
      "index      AAC_LGBMClassifier_with_hypertuning  \n",
      "index  APAAC_LogisticRegression_no_hypertuning  \n",
      "index                 APAAC_SVC_no_hypertuning  \n",
      "index       APAAC_XGBClassifier_no_hypertuning  \n",
      "index      APAAC_LGBMClassifier_no_hypertuning  \n",
      "index               APAAC_SVC_with_hypertuning  \n",
      "index     APAAC_XGBClassifier_with_hypertuning  \n",
      "Optimizing APAAC LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-13 11:09:39,570]\u001b[0m Trial 0 finished with value: 0.8676789587852495 and parameters: {'num_leaves': 192, 'max_depth': 8, 'learning_rate': 0.2142124381930116, 'n_estimators': 1119}. Best is trial 0 with value: 0.8676789587852495.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:41,280]\u001b[0m Trial 1 finished with value: 0.8655097613882863 and parameters: {'num_leaves': 244, 'max_depth': 15, 'learning_rate': 0.10481171658053184, 'n_estimators': 362}. Best is trial 0 with value: 0.8676789587852495.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:41,736]\u001b[0m Trial 2 finished with value: 0.8806941431670282 and parameters: {'num_leaves': 21, 'max_depth': 26, 'learning_rate': 0.061794221084381214, 'n_estimators': 159}. Best is trial 2 with value: 0.8806941431670282.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:42,891]\u001b[0m Trial 3 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 173, 'max_depth': 38, 'learning_rate': 0.12355060105920429, 'n_estimators': 193}. Best is trial 2 with value: 0.8806941431670282.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:43,869]\u001b[0m Trial 4 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 42, 'max_depth': 44, 'learning_rate': 0.010515372166059658, 'n_estimators': 315}. Best is trial 2 with value: 0.8806941431670282.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:45,499]\u001b[0m Trial 5 finished with value: 0.8828633405639913 and parameters: {'num_leaves': 20, 'max_depth': 24, 'learning_rate': 0.10487037533501994, 'n_estimators': 1223}. Best is trial 5 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:46,856]\u001b[0m Trial 6 finished with value: 0.8741865509761388 and parameters: {'num_leaves': 170, 'max_depth': 35, 'learning_rate': 0.2697865347124278, 'n_estimators': 631}. Best is trial 5 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:49,042]\u001b[0m Trial 7 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 103, 'max_depth': 20, 'learning_rate': 0.20223066287361474, 'n_estimators': 1474}. Best is trial 5 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:50,336]\u001b[0m Trial 8 finished with value: 0.8698481561822126 and parameters: {'num_leaves': 10, 'max_depth': 13, 'learning_rate': 0.03875525095289915, 'n_estimators': 1411}. Best is trial 5 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:51,095]\u001b[0m Trial 9 finished with value: 0.8698481561822126 and parameters: {'num_leaves': 194, 'max_depth': 34, 'learning_rate': 0.28772659682558993, 'n_estimators': 170}. Best is trial 5 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:52,187]\u001b[0m Trial 10 finished with value: 0.8720173535791758 and parameters: {'num_leaves': 83, 'max_depth': 4, 'learning_rate': 0.16049606355240986, 'n_estimators': 1702}. Best is trial 5 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:54,442]\u001b[0m Trial 11 finished with value: 0.8806941431670282 and parameters: {'num_leaves': 46, 'max_depth': 26, 'learning_rate': 0.07063336860940352, 'n_estimators': 823}. Best is trial 5 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:55,383]\u001b[0m Trial 12 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 8, 'max_depth': 26, 'learning_rate': 0.0626150073031563, 'n_estimators': 1146}. Best is trial 5 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:09:58,274]\u001b[0m Trial 13 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 59, 'max_depth': 21, 'learning_rate': 0.09026363071876486, 'n_estimators': 1940}. Best is trial 5 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:02,855]\u001b[0m Trial 14 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 129, 'max_depth': 30, 'learning_rate': 0.008127587069705414, 'n_estimators': 743}. Best is trial 5 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:03,677]\u001b[0m Trial 15 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 7, 'max_depth': 46, 'learning_rate': 0.14174673176174826, 'n_estimators': 937}. Best is trial 5 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:06,062]\u001b[0m Trial 16 finished with value: 0.8741865509761388 and parameters: {'num_leaves': 75, 'max_depth': 20, 'learning_rate': 0.04912917299414615, 'n_estimators': 523}. Best is trial 5 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:08,975]\u001b[0m Trial 17 finished with value: 0.8806941431670282 and parameters: {'num_leaves': 114, 'max_depth': 39, 'learning_rate': 0.09380419994232797, 'n_estimators': 1318}. Best is trial 5 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:11,502]\u001b[0m Trial 18 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 33, 'max_depth': 30, 'learning_rate': 0.1204705503130876, 'n_estimators': 1780}. Best is trial 5 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:14,070]\u001b[0m Trial 19 finished with value: 0.8806941431670282 and parameters: {'num_leaves': 84, 'max_depth': 50, 'learning_rate': 0.07507605978259449, 'n_estimators': 1018}. Best is trial 5 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:18,833]\u001b[0m Trial 20 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 142, 'max_depth': 13, 'learning_rate': 0.036233572118775065, 'n_estimators': 1556}. Best is trial 5 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:20,884]\u001b[0m Trial 21 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 38, 'max_depth': 26, 'learning_rate': 0.06795424579891596, 'n_estimators': 830}. Best is trial 5 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:23,204]\u001b[0m Trial 22 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 55, 'max_depth': 23, 'learning_rate': 0.078123219218792, 'n_estimators': 1189}. Best is trial 5 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:24,118]\u001b[0m Trial 23 finished with value: 0.8850325379609545 and parameters: {'num_leaves': 24, 'max_depth': 30, 'learning_rate': 0.10354397616075156, 'n_estimators': 497}. Best is trial 23 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:24,925]\u001b[0m Trial 24 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 25, 'max_depth': 32, 'learning_rate': 0.10925938863682154, 'n_estimators': 444}. Best is trial 23 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:26,291]\u001b[0m Trial 25 finished with value: 0.8741865509761388 and parameters: {'num_leaves': 63, 'max_depth': 29, 'learning_rate': 0.15303227861348195, 'n_estimators': 583}. Best is trial 23 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:26,686]\u001b[0m Trial 26 finished with value: 0.8806941431670282 and parameters: {'num_leaves': 26, 'max_depth': 16, 'learning_rate': 0.10293646297723213, 'n_estimators': 145}. Best is trial 23 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:26,858]\u001b[0m Trial 27 finished with value: 0.8937093275488069 and parameters: {'num_leaves': 2, 'max_depth': 37, 'learning_rate': 0.13058250969412558, 'n_estimators': 302}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:28,820]\u001b[0m Trial 28 finished with value: 0.8720173535791758 and parameters: {'num_leaves': 249, 'max_depth': 39, 'learning_rate': 0.13395025764364304, 'n_estimators': 675}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:29,030]\u001b[0m Trial 29 finished with value: 0.8698481561822126 and parameters: {'num_leaves': 3, 'max_depth': 44, 'learning_rate': 0.16910364598377, 'n_estimators': 394}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:31,172]\u001b[0m Trial 30 finished with value: 0.8633405639913232 and parameters: {'num_leaves': 68, 'max_depth': 36, 'learning_rate': 0.17668284233919418, 'n_estimators': 1275}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:31,591]\u001b[0m Trial 31 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 21, 'max_depth': 24, 'learning_rate': 0.11946394772862336, 'n_estimators': 205}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:32,100]\u001b[0m Trial 32 finished with value: 0.8828633405639913 and parameters: {'num_leaves': 20, 'max_depth': 29, 'learning_rate': 0.09345555414377421, 'n_estimators': 309}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:34,029]\u001b[0m Trial 33 finished with value: 0.8720173535791758 and parameters: {'num_leaves': 228, 'max_depth': 32, 'learning_rate': 0.09458128944583295, 'n_estimators': 293}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:35,247]\u001b[0m Trial 34 finished with value: 0.8828633405639913 and parameters: {'num_leaves': 46, 'max_depth': 41, 'learning_rate': 0.13584242902180904, 'n_estimators': 517}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:35,825]\u001b[0m Trial 35 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 18, 'max_depth': 28, 'learning_rate': 0.10912090970763069, 'n_estimators': 279}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:37,246]\u001b[0m Trial 36 finished with value: 0.8720173535791758 and parameters: {'num_leaves': 97, 'max_depth': 17, 'learning_rate': 0.12888590597692082, 'n_estimators': 441}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:37,521]\u001b[0m Trial 37 finished with value: 0.8872017353579176 and parameters: {'num_leaves': 2, 'max_depth': 33, 'learning_rate': 0.1474105195009274, 'n_estimators': 997}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:37,877]\u001b[0m Trial 38 finished with value: 0.8720173535791758 and parameters: {'num_leaves': 3, 'max_depth': 36, 'learning_rate': 0.1860246835242071, 'n_estimators': 1016}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:39,495]\u001b[0m Trial 39 finished with value: 0.8698481561822126 and parameters: {'num_leaves': 46, 'max_depth': 32, 'learning_rate': 0.14736714865247785, 'n_estimators': 935}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:41,320]\u001b[0m Trial 40 finished with value: 0.8828633405639913 and parameters: {'num_leaves': 34, 'max_depth': 42, 'learning_rate': 0.15873036870264665, 'n_estimators': 1257}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:41,644]\u001b[0m Trial 41 finished with value: 0.8828633405639913 and parameters: {'num_leaves': 18, 'max_depth': 35, 'learning_rate': 0.10955591821703146, 'n_estimators': 107}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:42,167]\u001b[0m Trial 42 finished with value: 0.8806941431670282 and parameters: {'num_leaves': 19, 'max_depth': 28, 'learning_rate': 0.12403583367870635, 'n_estimators': 351}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:42,492]\u001b[0m Trial 43 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 2, 'max_depth': 23, 'learning_rate': 0.14179300263785782, 'n_estimators': 1429}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:43,304]\u001b[0m Trial 44 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 31, 'max_depth': 34, 'learning_rate': 0.08635321215828451, 'n_estimators': 273}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:44,780]\u001b[0m Trial 45 finished with value: 0.8698481561822126 and parameters: {'num_leaves': 50, 'max_depth': 38, 'learning_rate': 0.09854654023955234, 'n_estimators': 651}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:46,427]\u001b[0m Trial 46 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 11, 'max_depth': 33, 'learning_rate': 0.11890548551728651, 'n_estimators': 1532}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:48,468]\u001b[0m Trial 47 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 183, 'max_depth': 18, 'learning_rate': 0.08491577645820209, 'n_estimators': 517}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:49,902]\u001b[0m Trial 48 finished with value: 0.8720173535791758 and parameters: {'num_leaves': 36, 'max_depth': 9, 'learning_rate': 0.2228956798962033, 'n_estimators': 1089}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:53,236]\u001b[0m Trial 49 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 213, 'max_depth': 30, 'learning_rate': 0.05478867771754913, 'n_estimators': 808}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:53,643]\u001b[0m Trial 50 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 15, 'max_depth': 26, 'learning_rate': 0.14759602156469293, 'n_estimators': 237}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:54,808]\u001b[0m Trial 51 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 47, 'max_depth': 41, 'learning_rate': 0.13343893539067264, 'n_estimators': 531}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:55,771]\u001b[0m Trial 52 finished with value: 0.8828633405639913 and parameters: {'num_leaves': 29, 'max_depth': 37, 'learning_rate': 0.13109115519972092, 'n_estimators': 450}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:56,645]\u001b[0m Trial 53 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 12, 'max_depth': 41, 'learning_rate': 0.11333238916433426, 'n_estimators': 745}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:57,789]\u001b[0m Trial 54 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 42, 'max_depth': 46, 'learning_rate': 0.09949550731397062, 'n_estimators': 366}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:10:59,604]\u001b[0m Trial 55 finished with value: 0.8828633405639913 and parameters: {'num_leaves': 71, 'max_depth': 31, 'learning_rate': 0.08047604547714646, 'n_estimators': 585}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:01,863]\u001b[0m Trial 56 finished with value: 0.8655097613882863 and parameters: {'num_leaves': 146, 'max_depth': 24, 'learning_rate': 0.138138289179815, 'n_estimators': 899}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:03,862]\u001b[0m Trial 57 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 57, 'max_depth': 44, 'learning_rate': 0.12405930350112636, 'n_estimators': 1185}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:06,436]\u001b[0m Trial 58 finished with value: 0.8676789587852495 and parameters: {'num_leaves': 84, 'max_depth': 28, 'learning_rate': 0.10471034768669173, 'n_estimators': 1361}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:07,889]\u001b[0m Trial 59 finished with value: 0.8850325379609545 and parameters: {'num_leaves': 26, 'max_depth': 21, 'learning_rate': 0.09185034786261304, 'n_estimators': 713}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:09,349]\u001b[0m Trial 60 finished with value: 0.8741865509761388 and parameters: {'num_leaves': 27, 'max_depth': 19, 'learning_rate': 0.07419582196270796, 'n_estimators': 704}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:10,069]\u001b[0m Trial 61 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 14, 'max_depth': 21, 'learning_rate': 0.09072594302015932, 'n_estimators': 591}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:11,175]\u001b[0m Trial 62 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 37, 'max_depth': 22, 'learning_rate': 0.11599347099106733, 'n_estimators': 505}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:11,811]\u001b[0m Trial 63 finished with value: 0.8720173535791758 and parameters: {'num_leaves': 9, 'max_depth': 14, 'learning_rate': 0.06758740721985063, 'n_estimators': 384}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:13,138]\u001b[0m Trial 64 finished with value: 0.8872017353579176 and parameters: {'num_leaves': 25, 'max_depth': 25, 'learning_rate': 0.1038635054791558, 'n_estimators': 770}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:14,781]\u001b[0m Trial 65 finished with value: 0.8850325379609545 and parameters: {'num_leaves': 23, 'max_depth': 25, 'learning_rate': 0.09765317507419057, 'n_estimators': 972}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:16,363]\u001b[0m Trial 66 finished with value: 0.8850325379609545 and parameters: {'num_leaves': 26, 'max_depth': 25, 'learning_rate': 0.10042399707291873, 'n_estimators': 994}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:18,231]\u001b[0m Trial 67 finished with value: 0.8872017353579176 and parameters: {'num_leaves': 28, 'max_depth': 26, 'learning_rate': 0.10335891560950611, 'n_estimators': 986}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:18,906]\u001b[0m Trial 68 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 8, 'max_depth': 27, 'learning_rate': 0.08093300034258004, 'n_estimators': 870}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:20,684]\u001b[0m Trial 69 finished with value: 0.8872017353579176 and parameters: {'num_leaves': 38, 'max_depth': 22, 'learning_rate': 0.11287830679828242, 'n_estimators': 1111}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:22,747]\u001b[0m Trial 70 finished with value: 0.8698481561822126 and parameters: {'num_leaves': 62, 'max_depth': 20, 'learning_rate': 0.12421364590802692, 'n_estimators': 1084}. Best is trial 27 with value: 0.8937093275488069.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:22,993]\u001b[0m Trial 71 finished with value: 0.89587852494577 and parameters: {'num_leaves': 2, 'max_depth': 25, 'learning_rate': 0.11115904161599455, 'n_estimators': 781}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:23,400]\u001b[0m Trial 72 finished with value: 0.8698481561822126 and parameters: {'num_leaves': 4, 'max_depth': 22, 'learning_rate': 0.11395618939289866, 'n_estimators': 785}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:25,443]\u001b[0m Trial 73 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 52, 'max_depth': 27, 'learning_rate': 0.10560442058576743, 'n_estimators': 884}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:27,445]\u001b[0m Trial 74 finished with value: 0.8828633405639913 and parameters: {'num_leaves': 41, 'max_depth': 23, 'learning_rate': 0.0910371142004016, 'n_estimators': 1053}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:29,217]\u001b[0m Trial 75 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 32, 'max_depth': 31, 'learning_rate': 0.11165732476127792, 'n_estimators': 1161}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:30,053]\u001b[0m Trial 76 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 15, 'max_depth': 34, 'learning_rate': 0.12468740925867675, 'n_estimators': 719}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:30,849]\u001b[0m Trial 77 finished with value: 0.8806941431670282 and parameters: {'num_leaves': 9, 'max_depth': 16, 'learning_rate': 0.14085763000768198, 'n_estimators': 955}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:31,111]\u001b[0m Trial 78 finished with value: 0.8915401301518439 and parameters: {'num_leaves': 2, 'max_depth': 25, 'learning_rate': 0.08617150552930926, 'n_estimators': 833}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:31,422]\u001b[0m Trial 79 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 3, 'max_depth': 29, 'learning_rate': 0.11822233943939232, 'n_estimators': 773}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:33,176]\u001b[0m Trial 80 finished with value: 0.8850325379609545 and parameters: {'num_leaves': 19, 'max_depth': 25, 'learning_rate': 0.10301146239622855, 'n_estimators': 1129}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:34,651]\u001b[0m Trial 81 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 25, 'max_depth': 21, 'learning_rate': 0.08501315632494699, 'n_estimators': 831}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:35,620]\u001b[0m Trial 82 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 13, 'max_depth': 27, 'learning_rate': 0.07444746080708198, 'n_estimators': 917}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:37,486]\u001b[0m Trial 83 finished with value: 0.8741865509761388 and parameters: {'num_leaves': 40, 'max_depth': 19, 'learning_rate': 0.0899598928877982, 'n_estimators': 849}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:39,132]\u001b[0m Trial 84 finished with value: 0.8720173535791758 and parameters: {'num_leaves': 31, 'max_depth': 22, 'learning_rate': 0.1322701116212749, 'n_estimators': 1041}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:39,392]\u001b[0m Trial 85 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 3, 'max_depth': 2, 'learning_rate': 0.11016744124171021, 'n_estimators': 627}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:40,524]\u001b[0m Trial 86 finished with value: 0.8785249457700651 and parameters: {'num_leaves': 22, 'max_depth': 31, 'learning_rate': 0.09444828905059338, 'n_estimators': 683}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:43,446]\u001b[0m Trial 87 finished with value: 0.8741865509761388 and parameters: {'num_leaves': 108, 'max_depth': 24, 'learning_rate': 0.10572370398084624, 'n_estimators': 1220}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:46,362]\u001b[0m Trial 88 finished with value: 0.8720173535791758 and parameters: {'num_leaves': 163, 'max_depth': 33, 'learning_rate': 0.06700113369831673, 'n_estimators': 780}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:47,310]\u001b[0m Trial 89 finished with value: 0.8806941431670282 and parameters: {'num_leaves': 10, 'max_depth': 29, 'learning_rate': 0.08354998553363743, 'n_estimators': 987}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:49,176]\u001b[0m Trial 90 finished with value: 0.8741865509761388 and parameters: {'num_leaves': 125, 'max_depth': 25, 'learning_rate': 0.12817295055801212, 'n_estimators': 643}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:50,698]\u001b[0m Trial 91 finished with value: 0.8850325379609545 and parameters: {'num_leaves': 22, 'max_depth': 25, 'learning_rate': 0.09813830802588078, 'n_estimators': 950}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:52,059]\u001b[0m Trial 92 finished with value: 0.8763557483731019 and parameters: {'num_leaves': 16, 'max_depth': 26, 'learning_rate': 0.10047859613930467, 'n_estimators': 1080}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:54,048]\u001b[0m Trial 93 finished with value: 0.8676789587852495 and parameters: {'num_leaves': 33, 'max_depth': 23, 'learning_rate': 0.11670789001231724, 'n_estimators': 984}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:55,877]\u001b[0m Trial 94 finished with value: 0.8720173535791758 and parameters: {'num_leaves': 24, 'max_depth': 18, 'learning_rate': 0.09373737911616684, 'n_estimators': 864}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:56,832]\u001b[0m Trial 95 finished with value: 0.8698481561822126 and parameters: {'num_leaves': 8, 'max_depth': 28, 'learning_rate': 0.07783330845815761, 'n_estimators': 919}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:57,054]\u001b[0m Trial 96 finished with value: 0.89587852494577 and parameters: {'num_leaves': 2, 'max_depth': 24, 'learning_rate': 0.10951186800647117, 'n_estimators': 740}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:58,140]\u001b[0m Trial 97 finished with value: 0.8720173535791758 and parameters: {'num_leaves': 15, 'max_depth': 21, 'learning_rate': 0.12106783435171713, 'n_estimators': 756}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:58,400]\u001b[0m Trial 98 finished with value: 0.89587852494577 and parameters: {'num_leaves': 2, 'max_depth': 35, 'learning_rate': 0.10958811299218826, 'n_estimators': 814}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:11:58,643]\u001b[0m Trial 99 finished with value: 0.8915401301518439 and parameters: {'num_leaves': 2, 'max_depth': 39, 'learning_rate': 0.1450175133205706, 'n_estimators': 824}. Best is trial 71 with value: 0.89587852494577.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning  accuracy   \n",
      "index          AAC  LogisticRegression            False  0.870562  \\\n",
      "index          AAC                 SVC            False  0.895351   \n",
      "index          AAC       XGBClassifier            False  0.878837   \n",
      "index          AAC      LGBMClassifier            False  0.885530   \n",
      "index          AAC                 SVC             True  0.867679   \n",
      "index          AAC       XGBClassifier             True  0.891540   \n",
      "index          AAC      LGBMClassifier             True  0.885033   \n",
      "index        APAAC  LogisticRegression            False  0.874261   \n",
      "index        APAAC                 SVC            False  0.870301   \n",
      "index        APAAC       XGBClassifier            False  0.880982   \n",
      "index        APAAC      LGBMClassifier            False  0.885727   \n",
      "index        APAAC                 SVC             True  0.570499   \n",
      "index        APAAC       XGBClassifier             True  0.893709   \n",
      "index        APAAC      LGBMClassifier             True  0.895879   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.875000     0.924051   0.915888  0.894977  0.800787  \\\n",
      "index     0.825893     0.940928   0.929648  0.874704  0.773776   \n",
      "index     0.834821     0.915612   0.903382  0.867749  0.754064   \n",
      "index     0.812500     0.924051   0.910000  0.858491  0.742789   \n",
      "index     0.803571     0.928270   0.913706  0.855107  0.739401   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.830357     0.936709   0.925373  0.875294  0.773119   \n",
      "index     0.870536     0.928270   0.919811  0.894495  0.801072   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.825893     0.928270   0.915842  0.868545  0.759692   \n",
      "index     0.821429     0.924051   0.910891  0.863850  0.750945   \n",
      "index     0.129464     0.987342   0.906250  0.226562  0.229699   \n",
      "index     0.857143     0.928270   0.918660  0.886836  0.788538   \n",
      "index     0.852679     0.936709   0.927184  0.888372  0.793569   \n",
      "\n",
      "                                         index  \n",
      "index    AAC_LogisticRegression_no_hypertuning  \n",
      "index                   AAC_SVC_no_hypertuning  \n",
      "index         AAC_XGBClassifier_no_hypertuning  \n",
      "index        AAC_LGBMClassifier_no_hypertuning  \n",
      "index                 AAC_SVC_with_hypertuning  \n",
      "index       AAC_XGBClassifier_with_hypertuning  \n",
      "index      AAC_LGBMClassifier_with_hypertuning  \n",
      "index  APAAC_LogisticRegression_no_hypertuning  \n",
      "index                 APAAC_SVC_no_hypertuning  \n",
      "index       APAAC_XGBClassifier_no_hypertuning  \n",
      "index      APAAC_LGBMClassifier_no_hypertuning  \n",
      "index               APAAC_SVC_with_hypertuning  \n",
      "index     APAAC_XGBClassifier_with_hypertuning  \n",
      "index    APAAC_LGBMClassifier_with_hypertuning  \n",
      "Evaluating CTD LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning  accuracy   \n",
      "index          AAC  LogisticRegression            False  0.870562  \\\n",
      "index          AAC                 SVC            False  0.895351   \n",
      "index          AAC       XGBClassifier            False  0.878837   \n",
      "index          AAC      LGBMClassifier            False  0.885530   \n",
      "index          AAC                 SVC             True  0.867679   \n",
      "index          AAC       XGBClassifier             True  0.891540   \n",
      "index          AAC      LGBMClassifier             True  0.885033   \n",
      "index        APAAC  LogisticRegression            False  0.874261   \n",
      "index        APAAC                 SVC            False  0.870301   \n",
      "index        APAAC       XGBClassifier            False  0.880982   \n",
      "index        APAAC      LGBMClassifier            False  0.885727   \n",
      "index        APAAC                 SVC             True  0.570499   \n",
      "index        APAAC       XGBClassifier             True  0.893709   \n",
      "index        APAAC      LGBMClassifier             True  0.895879   \n",
      "index          CTD  LogisticRegression            False  0.702615   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.875000     0.924051   0.915888  0.894977  0.800787  \\\n",
      "index     0.825893     0.940928   0.929648  0.874704  0.773776   \n",
      "index     0.834821     0.915612   0.903382  0.867749  0.754064   \n",
      "index     0.812500     0.924051   0.910000  0.858491  0.742789   \n",
      "index     0.803571     0.928270   0.913706  0.855107  0.739401   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.830357     0.936709   0.925373  0.875294  0.773119   \n",
      "index     0.870536     0.928270   0.919811  0.894495  0.801072   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.825893     0.928270   0.915842  0.868545  0.759692   \n",
      "index     0.821429     0.924051   0.910891  0.863850  0.750945   \n",
      "index     0.129464     0.987342   0.906250  0.226562  0.229699   \n",
      "index     0.857143     0.928270   0.918660  0.886836  0.788538   \n",
      "index     0.852679     0.936709   0.927184  0.888372  0.793569   \n",
      "index     0.678571     0.548523   0.586873  0.629400  0.228760   \n",
      "\n",
      "                                         index  \n",
      "index    AAC_LogisticRegression_no_hypertuning  \n",
      "index                   AAC_SVC_no_hypertuning  \n",
      "index         AAC_XGBClassifier_no_hypertuning  \n",
      "index        AAC_LGBMClassifier_no_hypertuning  \n",
      "index                 AAC_SVC_with_hypertuning  \n",
      "index       AAC_XGBClassifier_with_hypertuning  \n",
      "index      AAC_LGBMClassifier_with_hypertuning  \n",
      "index  APAAC_LogisticRegression_no_hypertuning  \n",
      "index                 APAAC_SVC_no_hypertuning  \n",
      "index       APAAC_XGBClassifier_no_hypertuning  \n",
      "index      APAAC_LGBMClassifier_no_hypertuning  \n",
      "index               APAAC_SVC_with_hypertuning  \n",
      "index     APAAC_XGBClassifier_with_hypertuning  \n",
      "index    APAAC_LGBMClassifier_with_hypertuning  \n",
      "index    CTD_LogisticRegression_no_hypertuning  \n",
      "Evaluating CTD SVC\n",
      "      feature_type               model with_hypertuning  accuracy   \n",
      "index          AAC  LogisticRegression            False  0.870562  \\\n",
      "index          AAC                 SVC            False  0.895351   \n",
      "index          AAC       XGBClassifier            False  0.878837   \n",
      "index          AAC      LGBMClassifier            False  0.885530   \n",
      "index          AAC                 SVC             True  0.867679   \n",
      "index          AAC       XGBClassifier             True  0.891540   \n",
      "index          AAC      LGBMClassifier             True  0.885033   \n",
      "index        APAAC  LogisticRegression            False  0.874261   \n",
      "index        APAAC                 SVC            False  0.870301   \n",
      "index        APAAC       XGBClassifier            False  0.880982   \n",
      "index        APAAC      LGBMClassifier            False  0.885727   \n",
      "index        APAAC                 SVC             True  0.570499   \n",
      "index        APAAC       XGBClassifier             True  0.893709   \n",
      "index        APAAC      LGBMClassifier             True  0.895879   \n",
      "index          CTD  LogisticRegression            False  0.702615   \n",
      "index          CTD                 SVC            False  0.675452   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.875000     0.924051   0.915888  0.894977  0.800787  \\\n",
      "index     0.825893     0.940928   0.929648  0.874704  0.773776   \n",
      "index     0.834821     0.915612   0.903382  0.867749  0.754064   \n",
      "index     0.812500     0.924051   0.910000  0.858491  0.742789   \n",
      "index     0.803571     0.928270   0.913706  0.855107  0.739401   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.830357     0.936709   0.925373  0.875294  0.773119   \n",
      "index     0.870536     0.928270   0.919811  0.894495  0.801072   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.825893     0.928270   0.915842  0.868545  0.759692   \n",
      "index     0.821429     0.924051   0.910891  0.863850  0.750945   \n",
      "index     0.129464     0.987342   0.906250  0.226562  0.229699   \n",
      "index     0.857143     0.928270   0.918660  0.886836  0.788538   \n",
      "index     0.852679     0.936709   0.927184  0.888372  0.793569   \n",
      "index     0.678571     0.548523   0.586873  0.629400  0.228760   \n",
      "index     0.866071     0.248945   0.521505  0.651007  0.145644   \n",
      "\n",
      "                                         index  \n",
      "index    AAC_LogisticRegression_no_hypertuning  \n",
      "index                   AAC_SVC_no_hypertuning  \n",
      "index         AAC_XGBClassifier_no_hypertuning  \n",
      "index        AAC_LGBMClassifier_no_hypertuning  \n",
      "index                 AAC_SVC_with_hypertuning  \n",
      "index       AAC_XGBClassifier_with_hypertuning  \n",
      "index      AAC_LGBMClassifier_with_hypertuning  \n",
      "index  APAAC_LogisticRegression_no_hypertuning  \n",
      "index                 APAAC_SVC_no_hypertuning  \n",
      "index       APAAC_XGBClassifier_no_hypertuning  \n",
      "index      APAAC_LGBMClassifier_no_hypertuning  \n",
      "index               APAAC_SVC_with_hypertuning  \n",
      "index     APAAC_XGBClassifier_with_hypertuning  \n",
      "index    APAAC_LGBMClassifier_with_hypertuning  \n",
      "index    CTD_LogisticRegression_no_hypertuning  \n",
      "index                   CTD_SVC_no_hypertuning  \n",
      "Evaluating CTD XGBClassifier\n",
      "      feature_type               model with_hypertuning  accuracy   \n",
      "index          AAC  LogisticRegression            False  0.870562  \\\n",
      "index          AAC                 SVC            False  0.895351   \n",
      "index          AAC       XGBClassifier            False  0.878837   \n",
      "index          AAC      LGBMClassifier            False  0.885530   \n",
      "index          AAC                 SVC             True  0.867679   \n",
      "index          AAC       XGBClassifier             True  0.891540   \n",
      "index          AAC      LGBMClassifier             True  0.885033   \n",
      "index        APAAC  LogisticRegression            False  0.874261   \n",
      "index        APAAC                 SVC            False  0.870301   \n",
      "index        APAAC       XGBClassifier            False  0.880982   \n",
      "index        APAAC      LGBMClassifier            False  0.885727   \n",
      "index        APAAC                 SVC             True  0.570499   \n",
      "index        APAAC       XGBClassifier             True  0.893709   \n",
      "index        APAAC      LGBMClassifier             True  0.895879   \n",
      "index          CTD  LogisticRegression            False  0.702615   \n",
      "index          CTD                 SVC            False  0.675452   \n",
      "index          CTD       XGBClassifier            False  0.854839   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.875000     0.924051   0.915888  0.894977  0.800787  \\\n",
      "index     0.825893     0.940928   0.929648  0.874704  0.773776   \n",
      "index     0.834821     0.915612   0.903382  0.867749  0.754064   \n",
      "index     0.812500     0.924051   0.910000  0.858491  0.742789   \n",
      "index     0.803571     0.928270   0.913706  0.855107  0.739401   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.830357     0.936709   0.925373  0.875294  0.773119   \n",
      "index     0.870536     0.928270   0.919811  0.894495  0.801072   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.825893     0.928270   0.915842  0.868545  0.759692   \n",
      "index     0.821429     0.924051   0.910891  0.863850  0.750945   \n",
      "index     0.129464     0.987342   0.906250  0.226562  0.229699   \n",
      "index     0.857143     0.928270   0.918660  0.886836  0.788538   \n",
      "index     0.852679     0.936709   0.927184  0.888372  0.793569   \n",
      "index     0.678571     0.548523   0.586873  0.629400  0.228760   \n",
      "index     0.866071     0.248945   0.521505  0.651007  0.145644   \n",
      "index     0.808036     0.869198   0.853774  0.830275  0.679156   \n",
      "\n",
      "                                         index  \n",
      "index    AAC_LogisticRegression_no_hypertuning  \n",
      "index                   AAC_SVC_no_hypertuning  \n",
      "index         AAC_XGBClassifier_no_hypertuning  \n",
      "index        AAC_LGBMClassifier_no_hypertuning  \n",
      "index                 AAC_SVC_with_hypertuning  \n",
      "index       AAC_XGBClassifier_with_hypertuning  \n",
      "index      AAC_LGBMClassifier_with_hypertuning  \n",
      "index  APAAC_LogisticRegression_no_hypertuning  \n",
      "index                 APAAC_SVC_no_hypertuning  \n",
      "index       APAAC_XGBClassifier_no_hypertuning  \n",
      "index      APAAC_LGBMClassifier_no_hypertuning  \n",
      "index               APAAC_SVC_with_hypertuning  \n",
      "index     APAAC_XGBClassifier_with_hypertuning  \n",
      "index    APAAC_LGBMClassifier_with_hypertuning  \n",
      "index    CTD_LogisticRegression_no_hypertuning  \n",
      "index                   CTD_SVC_no_hypertuning  \n",
      "index         CTD_XGBClassifier_no_hypertuning  \n",
      "Evaluating CTD LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-13 11:12:30,324]\u001b[0m A new study created in memory with name: no-name-ae8d0cc6-ab56-4036-ba56-0340795f9543\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning  accuracy   \n",
      "index          AAC  LogisticRegression            False  0.870562  \\\n",
      "index          AAC                 SVC            False  0.895351   \n",
      "index          AAC       XGBClassifier            False  0.878837   \n",
      "index          AAC      LGBMClassifier            False  0.885530   \n",
      "index          AAC                 SVC             True  0.867679   \n",
      "index          AAC       XGBClassifier             True  0.891540   \n",
      "index          AAC      LGBMClassifier             True  0.885033   \n",
      "index        APAAC  LogisticRegression            False  0.874261   \n",
      "index        APAAC                 SVC            False  0.870301   \n",
      "index        APAAC       XGBClassifier            False  0.880982   \n",
      "index        APAAC      LGBMClassifier            False  0.885727   \n",
      "index        APAAC                 SVC             True  0.570499   \n",
      "index        APAAC       XGBClassifier             True  0.893709   \n",
      "index        APAAC      LGBMClassifier             True  0.895879   \n",
      "index          CTD  LogisticRegression            False  0.702615   \n",
      "index          CTD                 SVC            False  0.675452   \n",
      "index          CTD       XGBClassifier            False  0.854839   \n",
      "index          CTD      LGBMClassifier            False  0.858768   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.875000     0.924051   0.915888  0.894977  0.800787  \\\n",
      "index     0.825893     0.940928   0.929648  0.874704  0.773776   \n",
      "index     0.834821     0.915612   0.903382  0.867749  0.754064   \n",
      "index     0.812500     0.924051   0.910000  0.858491  0.742789   \n",
      "index     0.803571     0.928270   0.913706  0.855107  0.739401   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.830357     0.936709   0.925373  0.875294  0.773119   \n",
      "index     0.870536     0.928270   0.919811  0.894495  0.801072   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.825893     0.928270   0.915842  0.868545  0.759692   \n",
      "index     0.821429     0.924051   0.910891  0.863850  0.750945   \n",
      "index     0.129464     0.987342   0.906250  0.226562  0.229699   \n",
      "index     0.857143     0.928270   0.918660  0.886836  0.788538   \n",
      "index     0.852679     0.936709   0.927184  0.888372  0.793569   \n",
      "index     0.678571     0.548523   0.586873  0.629400  0.228760   \n",
      "index     0.866071     0.248945   0.521505  0.651007  0.145644   \n",
      "index     0.808036     0.869198   0.853774  0.830275  0.679156   \n",
      "index     0.767857     0.902954   0.882051  0.821002  0.678641   \n",
      "\n",
      "                                         index  \n",
      "index    AAC_LogisticRegression_no_hypertuning  \n",
      "index                   AAC_SVC_no_hypertuning  \n",
      "index         AAC_XGBClassifier_no_hypertuning  \n",
      "index        AAC_LGBMClassifier_no_hypertuning  \n",
      "index                 AAC_SVC_with_hypertuning  \n",
      "index       AAC_XGBClassifier_with_hypertuning  \n",
      "index      AAC_LGBMClassifier_with_hypertuning  \n",
      "index  APAAC_LogisticRegression_no_hypertuning  \n",
      "index                 APAAC_SVC_no_hypertuning  \n",
      "index       APAAC_XGBClassifier_no_hypertuning  \n",
      "index      APAAC_LGBMClassifier_no_hypertuning  \n",
      "index               APAAC_SVC_with_hypertuning  \n",
      "index     APAAC_XGBClassifier_with_hypertuning  \n",
      "index    APAAC_LGBMClassifier_with_hypertuning  \n",
      "index    CTD_LogisticRegression_no_hypertuning  \n",
      "index                   CTD_SVC_no_hypertuning  \n",
      "index         CTD_XGBClassifier_no_hypertuning  \n",
      "index        CTD_LGBMClassifier_no_hypertuning  \n",
      "Optimizing CTD SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-13 11:12:31,434]\u001b[0m Trial 0 finished with value: 0.5466377440347071 and parameters: {'svc_c': 58.40112713348541, 'svc_gamma': 11.436293064492174}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:12:32,517]\u001b[0m Trial 1 finished with value: 0.5466377440347071 and parameters: {'svc_c': 54.348854772156635, 'svc_gamma': 94.89106644294307}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:12:33,552]\u001b[0m Trial 2 finished with value: 0.5466377440347071 and parameters: {'svc_c': 27.887568390646106, 'svc_gamma': 23.62349761202505}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:12:34,662]\u001b[0m Trial 3 finished with value: 0.5466377440347071 and parameters: {'svc_c': 95.03997765472904, 'svc_gamma': 87.64022817575669}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:12:35,718]\u001b[0m Trial 4 finished with value: 0.5466377440347071 and parameters: {'svc_c': 81.83747770926693, 'svc_gamma': 85.27720038817691}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:12:36,785]\u001b[0m Trial 5 finished with value: 0.5466377440347071 and parameters: {'svc_c': 87.35446300145462, 'svc_gamma': 73.64200097001445}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:12:37,886]\u001b[0m Trial 6 finished with value: 0.5466377440347071 and parameters: {'svc_c': 6.3019086214883435, 'svc_gamma': 52.92655143762244}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:12:39,048]\u001b[0m Trial 7 finished with value: 0.5466377440347071 and parameters: {'svc_c': 87.24749590591536, 'svc_gamma': 68.53372618916494}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:12:40,149]\u001b[0m Trial 8 finished with value: 0.5466377440347071 and parameters: {'svc_c': 84.41142842248436, 'svc_gamma': 2.435995517315819}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:12:41,244]\u001b[0m Trial 9 finished with value: 0.5466377440347071 and parameters: {'svc_c': 48.377817899495895, 'svc_gamma': 68.36969933585296}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:12:42,342]\u001b[0m Trial 10 finished with value: 0.5466377440347071 and parameters: {'svc_c': 63.28834149370432, 'svc_gamma': 29.433510145392532}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:12:43,484]\u001b[0m Trial 11 finished with value: 0.5466377440347071 and parameters: {'svc_c': 56.924949503104045, 'svc_gamma': 97.44792907258504}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:12:44,629]\u001b[0m Trial 12 finished with value: 0.5466377440347071 and parameters: {'svc_c': 46.06747210305639, 'svc_gamma': 46.996146712937794}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:12:45,719]\u001b[0m Trial 13 finished with value: 0.5466377440347071 and parameters: {'svc_c': 69.1599540646709, 'svc_gamma': 96.6267619598588}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:12:46,818]\u001b[0m Trial 14 finished with value: 0.5466377440347071 and parameters: {'svc_c': 39.453631314419695, 'svc_gamma': 1.9615240919044226}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:12:47,973]\u001b[0m Trial 15 finished with value: 0.5466377440347071 and parameters: {'svc_c': 69.90272293974093, 'svc_gamma': 52.715428039318525}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:12:49,084]\u001b[0m Trial 16 finished with value: 0.5466377440347071 and parameters: {'svc_c': 35.801823739083645, 'svc_gamma': 20.507618503173255}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:12:50,187]\u001b[0m Trial 17 finished with value: 0.5466377440347071 and parameters: {'svc_c': 57.884440447553374, 'svc_gamma': 37.345111491469524}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:12:51,282]\u001b[0m Trial 18 finished with value: 0.5466377440347071 and parameters: {'svc_c': 71.44496796230675, 'svc_gamma': 14.794456488295296}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:12:52,404]\u001b[0m Trial 19 finished with value: 0.5466377440347071 and parameters: {'svc_c': 52.77250264374832, 'svc_gamma': 40.55719300366718}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:12:53,517]\u001b[0m Trial 20 finished with value: 0.5466377440347071 and parameters: {'svc_c': 24.068045355429962, 'svc_gamma': 64.9398454337929}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:12:54,623]\u001b[0m Trial 21 finished with value: 0.5466377440347071 and parameters: {'svc_c': 30.838548016411448, 'svc_gamma': 19.09964823865286}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:12:55,705]\u001b[0m Trial 22 finished with value: 0.5466377440347071 and parameters: {'svc_c': 23.284646986167783, 'svc_gamma': 29.01392008881792}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:12:56,800]\u001b[0m Trial 23 finished with value: 0.5466377440347071 and parameters: {'svc_c': 43.669400452109834, 'svc_gamma': 10.00154954299457}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:12:57,869]\u001b[0m Trial 24 finished with value: 0.5466377440347071 and parameters: {'svc_c': 52.46658315685939, 'svc_gamma': 26.22286087304505}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:12:58,944]\u001b[0m Trial 25 finished with value: 0.5466377440347071 and parameters: {'svc_c': 60.71730977416822, 'svc_gamma': 11.087132370851798}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:00,104]\u001b[0m Trial 26 finished with value: 0.5466377440347071 and parameters: {'svc_c': 42.705397333689554, 'svc_gamma': 36.20186175488587}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:01,167]\u001b[0m Trial 27 finished with value: 0.5466377440347071 and parameters: {'svc_c': 51.21051822120962, 'svc_gamma': 21.74962016321488}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:02,326]\u001b[0m Trial 28 finished with value: 0.5466377440347071 and parameters: {'svc_c': 32.64023993673317, 'svc_gamma': 8.332312922785013}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:03,487]\u001b[0m Trial 29 finished with value: 0.5466377440347071 and parameters: {'svc_c': 65.6105887154431, 'svc_gamma': 85.30785207081719}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:04,638]\u001b[0m Trial 30 finished with value: 0.5466377440347071 and parameters: {'svc_c': 94.5658147899874, 'svc_gamma': 13.94543471521986}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:05,741]\u001b[0m Trial 31 finished with value: 0.5466377440347071 and parameters: {'svc_c': 77.42781723319479, 'svc_gamma': 83.48104027270543}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:06,892]\u001b[0m Trial 32 finished with value: 0.5466377440347071 and parameters: {'svc_c': 97.48791149554556, 'svc_gamma': 98.82286096422258}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:07,964]\u001b[0m Trial 33 finished with value: 0.5466377440347071 and parameters: {'svc_c': 79.34837031267888, 'svc_gamma': 87.06400790225115}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:09,108]\u001b[0m Trial 34 finished with value: 0.5466377440347071 and parameters: {'svc_c': 99.9355297911797, 'svc_gamma': 61.247473257953885}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:10,189]\u001b[0m Trial 35 finished with value: 0.5466377440347071 and parameters: {'svc_c': 76.68022247581087, 'svc_gamma': 74.73306174961198}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:11,354]\u001b[0m Trial 36 finished with value: 0.5466377440347071 and parameters: {'svc_c': 90.44926967750594, 'svc_gamma': 92.49857413243839}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:12,501]\u001b[0m Trial 37 finished with value: 0.5466377440347071 and parameters: {'svc_c': 87.03636973140445, 'svc_gamma': 78.10094085264811}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:13,557]\u001b[0m Trial 38 finished with value: 0.5466377440347071 and parameters: {'svc_c': 57.10007324398313, 'svc_gamma': 79.91112826510246}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:14,714]\u001b[0m Trial 39 finished with value: 0.5466377440347071 and parameters: {'svc_c': 83.26079880210452, 'svc_gamma': 92.71884322990778}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:15,727]\u001b[0m Trial 40 finished with value: 0.5466377440347071 and parameters: {'svc_c': 65.21310838657088, 'svc_gamma': 74.2244996525733}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:16,734]\u001b[0m Trial 41 finished with value: 0.5466377440347071 and parameters: {'svc_c': 93.88316333607139, 'svc_gamma': 88.5724171253618}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:17,737]\u001b[0m Trial 42 finished with value: 0.5466377440347071 and parameters: {'svc_c': 90.46507214524642, 'svc_gamma': 90.95680671337652}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:18,734]\u001b[0m Trial 43 finished with value: 0.5466377440347071 and parameters: {'svc_c': 47.30652679875122, 'svc_gamma': 99.95941882822682}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:19,747]\u001b[0m Trial 44 finished with value: 0.5466377440347071 and parameters: {'svc_c': 71.90754900963245, 'svc_gamma': 81.61553221966696}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:20,711]\u001b[0m Trial 45 finished with value: 0.5466377440347071 and parameters: {'svc_c': 87.0703688729934, 'svc_gamma': 94.59830146192607}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:21,693]\u001b[0m Trial 46 finished with value: 0.5466377440347071 and parameters: {'svc_c': 60.09068345827562, 'svc_gamma': 85.8627156259608}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:22,654]\u001b[0m Trial 47 finished with value: 0.5466377440347071 and parameters: {'svc_c': 6.479756970173199, 'svc_gamma': 70.69001470921731}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:23,618]\u001b[0m Trial 48 finished with value: 0.5466377440347071 and parameters: {'svc_c': 82.62127598175803, 'svc_gamma': 57.85144986864326}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:24,570]\u001b[0m Trial 49 finished with value: 0.5466377440347071 and parameters: {'svc_c': 55.954100018010976, 'svc_gamma': 49.16212732341482}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:25,526]\u001b[0m Trial 50 finished with value: 0.5466377440347071 and parameters: {'svc_c': 68.45571757487846, 'svc_gamma': 2.2752221586629915}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:26,479]\u001b[0m Trial 51 finished with value: 0.5466377440347071 and parameters: {'svc_c': 73.06236259948025, 'svc_gamma': 89.8334861866428}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:27,441]\u001b[0m Trial 52 finished with value: 0.5466377440347071 and parameters: {'svc_c': 81.74860112475183, 'svc_gamma': 82.30666855170473}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:28,395]\u001b[0m Trial 53 finished with value: 0.5466377440347071 and parameters: {'svc_c': 91.8581883365424, 'svc_gamma': 95.055511879583}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:29,347]\u001b[0m Trial 54 finished with value: 0.5466377440347071 and parameters: {'svc_c': 88.82251660076213, 'svc_gamma': 88.74470392480146}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:30,322]\u001b[0m Trial 55 finished with value: 0.5466377440347071 and parameters: {'svc_c': 62.35621895454403, 'svc_gamma': 5.409051992097446}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:31,338]\u001b[0m Trial 56 finished with value: 0.5466377440347071 and parameters: {'svc_c': 86.05774988286116, 'svc_gamma': 96.86210956728478}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:32,380]\u001b[0m Trial 57 finished with value: 0.5466377440347071 and parameters: {'svc_c': 74.85599620264146, 'svc_gamma': 77.47857380494813}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:33,410]\u001b[0m Trial 58 finished with value: 0.5466377440347071 and parameters: {'svc_c': 80.0380249321947, 'svc_gamma': 84.82667074093487}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:34,522]\u001b[0m Trial 59 finished with value: 0.5466377440347071 and parameters: {'svc_c': 68.33273915389483, 'svc_gamma': 66.95960881515792}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:35,610]\u001b[0m Trial 60 finished with value: 0.5466377440347071 and parameters: {'svc_c': 48.95384043604094, 'svc_gamma': 43.43997853833367}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:36,681]\u001b[0m Trial 61 finished with value: 0.5466377440347071 and parameters: {'svc_c': 38.74654901227531, 'svc_gamma': 51.41975264681113}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:37,767]\u001b[0m Trial 62 finished with value: 0.5466377440347071 and parameters: {'svc_c': 45.37319446607433, 'svc_gamma': 34.80710146481863}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:38,900]\u001b[0m Trial 63 finished with value: 0.5466377440347071 and parameters: {'svc_c': 51.011477229283166, 'svc_gamma': 54.74961543548807}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:40,015]\u001b[0m Trial 64 finished with value: 0.5466377440347071 and parameters: {'svc_c': 95.90782265309612, 'svc_gamma': 17.914483107313426}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:41,120]\u001b[0m Trial 65 finished with value: 0.5466377440347071 and parameters: {'svc_c': 54.77820815373713, 'svc_gamma': 25.4213499418331}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:42,222]\u001b[0m Trial 66 finished with value: 0.5466377440347071 and parameters: {'svc_c': 99.657844434595, 'svc_gamma': 63.765603896678684}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:43,383]\u001b[0m Trial 67 finished with value: 0.5466377440347071 and parameters: {'svc_c': 85.34790474603896, 'svc_gamma': 69.91046477344224}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:44,579]\u001b[0m Trial 68 finished with value: 0.5466377440347071 and parameters: {'svc_c': 12.4146613224156, 'svc_gamma': 86.4073339732552}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:45,765]\u001b[0m Trial 69 finished with value: 0.5466377440347071 and parameters: {'svc_c': 26.708942235065482, 'svc_gamma': 93.73012061370774}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:46,896]\u001b[0m Trial 70 finished with value: 0.5466377440347071 and parameters: {'svc_c': 53.55629903039693, 'svc_gamma': 14.715768358253259}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:48,089]\u001b[0m Trial 71 finished with value: 0.5466377440347071 and parameters: {'svc_c': 93.32246886340917, 'svc_gamma': 73.2078339036671}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:49,195]\u001b[0m Trial 72 finished with value: 0.5466377440347071 and parameters: {'svc_c': 88.90693914545986, 'svc_gamma': 77.70833126193772}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:50,302]\u001b[0m Trial 73 finished with value: 0.5466377440347071 and parameters: {'svc_c': 41.33436313723597, 'svc_gamma': 81.8492034773788}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:51,398]\u001b[0m Trial 74 finished with value: 0.5466377440347071 and parameters: {'svc_c': 76.79081628990816, 'svc_gamma': 60.83585836671284}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:52,486]\u001b[0m Trial 75 finished with value: 0.5466377440347071 and parameters: {'svc_c': 84.42372895101042, 'svc_gamma': 67.96194922705403}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:53,650]\u001b[0m Trial 76 finished with value: 0.5466377440347071 and parameters: {'svc_c': 95.67526900246752, 'svc_gamma': 5.462037717420589}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:54,695]\u001b[0m Trial 77 finished with value: 0.5466377440347071 and parameters: {'svc_c': 18.19483110599912, 'svc_gamma': 90.41807661406982}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:55,709]\u001b[0m Trial 78 finished with value: 0.5466377440347071 and parameters: {'svc_c': 0.6835338615282716, 'svc_gamma': 79.58490406440578}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:56,688]\u001b[0m Trial 79 finished with value: 0.5466377440347071 and parameters: {'svc_c': 58.81537376380374, 'svc_gamma': 45.009653686675506}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:57,629]\u001b[0m Trial 80 finished with value: 0.5466377440347071 and parameters: {'svc_c': 91.49218309717936, 'svc_gamma': 97.57673128495435}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:58,632]\u001b[0m Trial 81 finished with value: 0.5466377440347071 and parameters: {'svc_c': 79.30841405336082, 'svc_gamma': 9.020979611665936}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:13:59,581]\u001b[0m Trial 82 finished with value: 0.5466377440347071 and parameters: {'svc_c': 88.57281439265002, 'svc_gamma': 13.261957942227717}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:14:00,534]\u001b[0m Trial 83 finished with value: 0.5488069414316703 and parameters: {'svc_c': 82.8031841881174, 'svc_gamma': 0.9220457742628141}. Best is trial 83 with value: 0.5488069414316703.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:14:01,508]\u001b[0m Trial 84 finished with value: 0.5466377440347071 and parameters: {'svc_c': 33.222202797513276, 'svc_gamma': 1.0960287396674016}. Best is trial 83 with value: 0.5488069414316703.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:14:02,465]\u001b[0m Trial 85 finished with value: 0.5466377440347071 and parameters: {'svc_c': 84.81493889801222, 'svc_gamma': 5.686775057766839}. Best is trial 83 with value: 0.5488069414316703.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:14:03,462]\u001b[0m Trial 86 finished with value: 0.5466377440347071 and parameters: {'svc_c': 49.180798467322354, 'svc_gamma': 83.76951686456103}. Best is trial 83 with value: 0.5488069414316703.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:14:04,461]\u001b[0m Trial 87 finished with value: 0.5466377440347071 and parameters: {'svc_c': 73.21746850506129, 'svc_gamma': 87.63471129041952}. Best is trial 83 with value: 0.5488069414316703.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:14:05,666]\u001b[0m Trial 88 finished with value: 0.5488069414316703 and parameters: {'svc_c': 82.47389125057343, 'svc_gamma': 0.16661641860724563}. Best is trial 83 with value: 0.5488069414316703.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:14:06,702]\u001b[0m Trial 89 finished with value: 0.5466377440347071 and parameters: {'svc_c': 81.62469907074305, 'svc_gamma': 1.7423464671116822}. Best is trial 83 with value: 0.5488069414316703.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:14:07,868]\u001b[0m Trial 90 finished with value: 0.5488069414316703 and parameters: {'svc_c': 64.73033111986935, 'svc_gamma': 0.4208342174607388}. Best is trial 83 with value: 0.5488069414316703.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:14:09,089]\u001b[0m Trial 91 finished with value: 0.5553145336225597 and parameters: {'svc_c': 62.83440524942616, 'svc_gamma': 0.029656759333250293}. Best is trial 91 with value: 0.5553145336225597.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:14:10,166]\u001b[0m Trial 92 finished with value: 0.5488069414316703 and parameters: {'svc_c': 61.20941527507715, 'svc_gamma': 0.7277173960550373}. Best is trial 91 with value: 0.5553145336225597.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:14:11,217]\u001b[0m Trial 93 finished with value: 0.5466377440347071 and parameters: {'svc_c': 62.19595799328542, 'svc_gamma': 3.419304551840641}. Best is trial 91 with value: 0.5553145336225597.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:14:12,357]\u001b[0m Trial 94 finished with value: 0.5488069414316703 and parameters: {'svc_c': 58.23493461663113, 'svc_gamma': 0.45190089574605913}. Best is trial 91 with value: 0.5553145336225597.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:14:13,398]\u001b[0m Trial 95 finished with value: 0.5466377440347071 and parameters: {'svc_c': 63.760856327774476, 'svc_gamma': 7.538158848173975}. Best is trial 91 with value: 0.5553145336225597.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:14:14,623]\u001b[0m Trial 96 finished with value: 0.5488069414316703 and parameters: {'svc_c': 58.928314239459866, 'svc_gamma': 0.17522674647885372}. Best is trial 91 with value: 0.5553145336225597.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:14:15,852]\u001b[0m Trial 97 finished with value: 0.5488069414316703 and parameters: {'svc_c': 58.08641076490547, 'svc_gamma': 0.2867311157166527}. Best is trial 91 with value: 0.5553145336225597.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:14:16,941]\u001b[0m Trial 98 finished with value: 0.5488069414316703 and parameters: {'svc_c': 57.91655364201843, 'svc_gamma': 0.4158502862756466}. Best is trial 91 with value: 0.5553145336225597.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:14:17,920]\u001b[0m Trial 99 finished with value: 0.5466377440347071 and parameters: {'svc_c': 59.12212897535169, 'svc_gamma': 3.487410973549591}. Best is trial 91 with value: 0.5553145336225597.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:14:17,927]\u001b[0m A new study created in memory with name: no-name-064c3812-aaf2-45a8-b576-2efd8d1d3d97\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning  accuracy   \n",
      "index          AAC  LogisticRegression            False  0.870562  \\\n",
      "index          AAC                 SVC            False  0.895351   \n",
      "index          AAC       XGBClassifier            False  0.878837   \n",
      "index          AAC      LGBMClassifier            False  0.885530   \n",
      "index          AAC                 SVC             True  0.867679   \n",
      "index          AAC       XGBClassifier             True  0.891540   \n",
      "index          AAC      LGBMClassifier             True  0.885033   \n",
      "index        APAAC  LogisticRegression            False  0.874261   \n",
      "index        APAAC                 SVC            False  0.870301   \n",
      "index        APAAC       XGBClassifier            False  0.880982   \n",
      "index        APAAC      LGBMClassifier            False  0.885727   \n",
      "index        APAAC                 SVC             True  0.570499   \n",
      "index        APAAC       XGBClassifier             True  0.893709   \n",
      "index        APAAC      LGBMClassifier             True  0.895879   \n",
      "index          CTD  LogisticRegression            False  0.702615   \n",
      "index          CTD                 SVC            False  0.675452   \n",
      "index          CTD       XGBClassifier            False  0.854839   \n",
      "index          CTD      LGBMClassifier            False  0.858768   \n",
      "index          CTD                 SVC             True  0.555315   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.875000     0.924051   0.915888  0.894977  0.800787  \\\n",
      "index     0.825893     0.940928   0.929648  0.874704  0.773776   \n",
      "index     0.834821     0.915612   0.903382  0.867749  0.754064   \n",
      "index     0.812500     0.924051   0.910000  0.858491  0.742789   \n",
      "index     0.803571     0.928270   0.913706  0.855107  0.739401   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.830357     0.936709   0.925373  0.875294  0.773119   \n",
      "index     0.870536     0.928270   0.919811  0.894495  0.801072   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.825893     0.928270   0.915842  0.868545  0.759692   \n",
      "index     0.821429     0.924051   0.910891  0.863850  0.750945   \n",
      "index     0.129464     0.987342   0.906250  0.226562  0.229699   \n",
      "index     0.857143     0.928270   0.918660  0.886836  0.788538   \n",
      "index     0.852679     0.936709   0.927184  0.888372  0.793569   \n",
      "index     0.678571     0.548523   0.586873  0.629400  0.228760   \n",
      "index     0.866071     0.248945   0.521505  0.651007  0.145644   \n",
      "index     0.808036     0.869198   0.853774  0.830275  0.679156   \n",
      "index     0.767857     0.902954   0.882051  0.821002  0.678641   \n",
      "index     0.084821     1.000000   1.000000  0.156379  0.213263   \n",
      "\n",
      "                                         index  \n",
      "index    AAC_LogisticRegression_no_hypertuning  \n",
      "index                   AAC_SVC_no_hypertuning  \n",
      "index         AAC_XGBClassifier_no_hypertuning  \n",
      "index        AAC_LGBMClassifier_no_hypertuning  \n",
      "index                 AAC_SVC_with_hypertuning  \n",
      "index       AAC_XGBClassifier_with_hypertuning  \n",
      "index      AAC_LGBMClassifier_with_hypertuning  \n",
      "index  APAAC_LogisticRegression_no_hypertuning  \n",
      "index                 APAAC_SVC_no_hypertuning  \n",
      "index       APAAC_XGBClassifier_no_hypertuning  \n",
      "index      APAAC_LGBMClassifier_no_hypertuning  \n",
      "index               APAAC_SVC_with_hypertuning  \n",
      "index     APAAC_XGBClassifier_with_hypertuning  \n",
      "index    APAAC_LGBMClassifier_with_hypertuning  \n",
      "index    CTD_LogisticRegression_no_hypertuning  \n",
      "index                   CTD_SVC_no_hypertuning  \n",
      "index         CTD_XGBClassifier_no_hypertuning  \n",
      "index        CTD_LGBMClassifier_no_hypertuning  \n",
      "index                 CTD_SVC_with_hypertuning  \n",
      "Optimizing CTD XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-13 11:14:25,633]\u001b[0m Trial 0 finished with value: 0.8329718004338394 and parameters: {'learning_rate': 0.062281730777814216, 'max_depth': 6, 'n_estimators': 513}. Best is trial 0 with value: 0.8329718004338394.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:14:27,206]\u001b[0m Trial 1 finished with value: 0.8459869848156182 and parameters: {'learning_rate': 0.267452862441178, 'max_depth': 2, 'n_estimators': 226}. Best is trial 1 with value: 0.8459869848156182.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:14:34,063]\u001b[0m Trial 2 finished with value: 0.8459869848156182 and parameters: {'learning_rate': 0.1710964498774929, 'max_depth': 3, 'n_estimators': 793}. Best is trial 1 with value: 0.8459869848156182.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:14:40,788]\u001b[0m Trial 3 finished with value: 0.841648590021692 and parameters: {'learning_rate': 0.1087075284019735, 'max_depth': 3, 'n_estimators': 698}. Best is trial 1 with value: 0.8459869848156182.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:14:43,462]\u001b[0m Trial 4 finished with value: 0.7939262472885033 and parameters: {'learning_rate': 0.019800957961656616, 'max_depth': 2, 'n_estimators': 385}. Best is trial 1 with value: 0.8459869848156182.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:14:51,789]\u001b[0m Trial 5 finished with value: 0.8351409978308026 and parameters: {'learning_rate': 0.01900637436663328, 'max_depth': 3, 'n_estimators': 839}. Best is trial 1 with value: 0.8459869848156182.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:14:57,014]\u001b[0m Trial 6 finished with value: 0.8546637744034707 and parameters: {'learning_rate': 0.27213181515006024, 'max_depth': 2, 'n_estimators': 714}. Best is trial 6 with value: 0.8546637744034707.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:15:00,703]\u001b[0m Trial 7 finished with value: 0.8394793926247288 and parameters: {'learning_rate': 0.276878103658395, 'max_depth': 4, 'n_estimators': 297}. Best is trial 6 with value: 0.8546637744034707.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:15:08,283]\u001b[0m Trial 8 finished with value: 0.8351409978308026 and parameters: {'learning_rate': 0.023153110468571172, 'max_depth': 5, 'n_estimators': 451}. Best is trial 6 with value: 0.8546637744034707.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:15:14,168]\u001b[0m Trial 9 finished with value: 0.8394793926247288 and parameters: {'learning_rate': 0.10709456678662774, 'max_depth': 2, 'n_estimators': 854}. Best is trial 6 with value: 0.8546637744034707.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:15:23,970]\u001b[0m Trial 10 finished with value: 0.8438177874186551 and parameters: {'learning_rate': 0.21858139913622954, 'max_depth': 4, 'n_estimators': 982}. Best is trial 6 with value: 0.8546637744034707.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:15:25,418]\u001b[0m Trial 11 finished with value: 0.8264642082429501 and parameters: {'learning_rate': 0.2748306105124164, 'max_depth': 2, 'n_estimators': 190}. Best is trial 6 with value: 0.8546637744034707.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:15:29,736]\u001b[0m Trial 12 finished with value: 0.8459869848156182 and parameters: {'learning_rate': 0.2874585320538009, 'max_depth': 2, 'n_estimators': 631}. Best is trial 6 with value: 0.8546637744034707.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:15:31,177]\u001b[0m Trial 13 finished with value: 0.8373101952277657 and parameters: {'learning_rate': 0.22585424680684774, 'max_depth': 3, 'n_estimators': 110}. Best is trial 6 with value: 0.8546637744034707.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:15:38,700]\u001b[0m Trial 14 finished with value: 0.8481561822125814 and parameters: {'learning_rate': 0.24333118244619084, 'max_depth': 5, 'n_estimators': 643}. Best is trial 6 with value: 0.8546637744034707.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:15:46,275]\u001b[0m Trial 15 finished with value: 0.8503253796095445 and parameters: {'learning_rate': 0.23027694283450148, 'max_depth': 5, 'n_estimators': 626}. Best is trial 6 with value: 0.8546637744034707.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:15:53,473]\u001b[0m Trial 16 finished with value: 0.8177874186550976 and parameters: {'learning_rate': 0.19883961619473156, 'max_depth': 6, 'n_estimators': 535}. Best is trial 6 with value: 0.8546637744034707.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:16:04,920]\u001b[0m Trial 17 finished with value: 0.8438177874186551 and parameters: {'learning_rate': 0.2989693825783998, 'max_depth': 5, 'n_estimators': 992}. Best is trial 6 with value: 0.8546637744034707.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:16:13,690]\u001b[0m Trial 18 finished with value: 0.841648590021692 and parameters: {'learning_rate': 0.2456076907802645, 'max_depth': 5, 'n_estimators': 720}. Best is trial 6 with value: 0.8546637744034707.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:16:20,553]\u001b[0m Trial 19 finished with value: 0.8438177874186551 and parameters: {'learning_rate': 0.19106043436407918, 'max_depth': 4, 'n_estimators': 601}. Best is trial 6 with value: 0.8546637744034707.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:16:25,404]\u001b[0m Trial 20 finished with value: 0.841648590021692 and parameters: {'learning_rate': 0.25111985694924854, 'max_depth': 4, 'n_estimators': 409}. Best is trial 6 with value: 0.8546637744034707.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:16:33,379]\u001b[0m Trial 21 finished with value: 0.8438177874186551 and parameters: {'learning_rate': 0.23595899860244246, 'max_depth': 5, 'n_estimators': 686}. Best is trial 6 with value: 0.8546637744034707.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:16:42,472]\u001b[0m Trial 22 finished with value: 0.8568329718004338 and parameters: {'learning_rate': 0.25468463485479376, 'max_depth': 6, 'n_estimators': 767}. Best is trial 22 with value: 0.8568329718004338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:16:52,195]\u001b[0m Trial 23 finished with value: 0.8351409978308026 and parameters: {'learning_rate': 0.26462450475186805, 'max_depth': 6, 'n_estimators': 778}. Best is trial 22 with value: 0.8568329718004338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:17:02,308]\u001b[0m Trial 24 finished with value: 0.8351409978308026 and parameters: {'learning_rate': 0.29773425829784816, 'max_depth': 6, 'n_estimators': 882}. Best is trial 22 with value: 0.8568329718004338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:17:11,634]\u001b[0m Trial 25 finished with value: 0.8308026030368764 and parameters: {'learning_rate': 0.2197550900927936, 'max_depth': 6, 'n_estimators': 745}. Best is trial 22 with value: 0.8568329718004338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:17:21,822]\u001b[0m Trial 26 finished with value: 0.8438177874186551 and parameters: {'learning_rate': 0.2582939532530153, 'max_depth': 5, 'n_estimators': 914}. Best is trial 22 with value: 0.8568329718004338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:17:31,241]\u001b[0m Trial 27 finished with value: 0.8394793926247288 and parameters: {'learning_rate': 0.20326493592414496, 'max_depth': 6, 'n_estimators': 584}. Best is trial 22 with value: 0.8568329718004338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:17:36,785]\u001b[0m Trial 28 finished with value: 0.8394793926247288 and parameters: {'learning_rate': 0.27607461355187884, 'max_depth': 4, 'n_estimators': 473}. Best is trial 22 with value: 0.8568329718004338.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:17:44,265]\u001b[0m Trial 29 finished with value: 0.8611713665943601 and parameters: {'learning_rate': 0.23612178866811623, 'max_depth': 6, 'n_estimators': 554}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:17:51,159]\u001b[0m Trial 30 finished with value: 0.8459869848156182 and parameters: {'learning_rate': 0.2549646377594923, 'max_depth': 6, 'n_estimators': 514}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:17:59,526]\u001b[0m Trial 31 finished with value: 0.8438177874186551 and parameters: {'learning_rate': 0.2315657276380358, 'max_depth': 6, 'n_estimators': 668}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:18:06,993]\u001b[0m Trial 32 finished with value: 0.8524945770065075 and parameters: {'learning_rate': 0.25745589597354684, 'max_depth': 5, 'n_estimators': 584}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:18:14,225]\u001b[0m Trial 33 finished with value: 0.841648590021692 and parameters: {'learning_rate': 0.26352892354751095, 'max_depth': 6, 'n_estimators': 569}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:18:23,231]\u001b[0m Trial 34 finished with value: 0.8459869848156182 and parameters: {'learning_rate': 0.2766014994145758, 'max_depth': 5, 'n_estimators': 776}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:18:28,858]\u001b[0m Trial 35 finished with value: 0.841648590021692 and parameters: {'learning_rate': 0.1619420630803568, 'max_depth': 6, 'n_estimators': 342}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:18:33,512]\u001b[0m Trial 36 finished with value: 0.8503253796095445 and parameters: {'learning_rate': 0.24792031454808822, 'max_depth': 3, 'n_estimators': 466}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:18:43,380]\u001b[0m Trial 37 finished with value: 0.8503253796095445 and parameters: {'learning_rate': 0.18369095466667812, 'max_depth': 5, 'n_estimators': 810}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:18:52,630]\u001b[0m Trial 38 finished with value: 0.8524945770065075 and parameters: {'learning_rate': 0.2104190467751822, 'max_depth': 6, 'n_estimators': 706}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:18:58,355]\u001b[0m Trial 39 finished with value: 0.8481561822125814 and parameters: {'learning_rate': 0.2865168167391694, 'max_depth': 3, 'n_estimators': 563}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:19:06,738]\u001b[0m Trial 40 finished with value: 0.8394793926247288 and parameters: {'learning_rate': 0.17767040279723478, 'max_depth': 4, 'n_estimators': 736}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:19:16,170]\u001b[0m Trial 41 finished with value: 0.8459869848156182 and parameters: {'learning_rate': 0.20673142094111452, 'max_depth': 6, 'n_estimators': 694}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:19:24,912]\u001b[0m Trial 42 finished with value: 0.8459869848156182 and parameters: {'learning_rate': 0.21163929874140464, 'max_depth': 6, 'n_estimators': 663}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:19:34,892]\u001b[0m Trial 43 finished with value: 0.8503253796095445 and parameters: {'learning_rate': 0.24051351510733174, 'max_depth': 6, 'n_estimators': 835}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:19:45,360]\u001b[0m Trial 44 finished with value: 0.8438177874186551 and parameters: {'learning_rate': 0.2197943449418563, 'max_depth': 5, 'n_estimators': 903}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:19:50,755]\u001b[0m Trial 45 finished with value: 0.8351409978308026 and parameters: {'learning_rate': 0.26491206197475836, 'max_depth': 2, 'n_estimators': 749}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:19:58,854]\u001b[0m Trial 46 finished with value: 0.8438177874186551 and parameters: {'learning_rate': 0.25624108389369193, 'max_depth': 6, 'n_estimators': 614}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:20:05,335]\u001b[0m Trial 47 finished with value: 0.8373101952277657 and parameters: {'learning_rate': 0.23380111745472562, 'max_depth': 5, 'n_estimators': 510}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:20:13,986]\u001b[0m Trial 48 finished with value: 0.8351409978308026 and parameters: {'learning_rate': 0.2842356039880141, 'max_depth': 6, 'n_estimators': 701}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:20:22,513]\u001b[0m Trial 49 finished with value: 0.8373101952277657 and parameters: {'learning_rate': 0.2702982627607037, 'max_depth': 4, 'n_estimators': 796}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:20:25,894]\u001b[0m Trial 50 finished with value: 0.8438177874186551 and parameters: {'learning_rate': 0.21616458758116827, 'max_depth': 2, 'n_estimators': 430}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:20:33,855]\u001b[0m Trial 51 finished with value: 0.8503253796095445 and parameters: {'learning_rate': 0.22842808467321207, 'max_depth': 5, 'n_estimators': 636}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:20:40,529]\u001b[0m Trial 52 finished with value: 0.8568329718004338 and parameters: {'learning_rate': 0.24272014528661104, 'max_depth': 5, 'n_estimators': 539}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:20:47,843]\u001b[0m Trial 53 finished with value: 0.8524945770065075 and parameters: {'learning_rate': 0.24744544917457856, 'max_depth': 6, 'n_estimators': 541}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:20:54,269]\u001b[0m Trial 54 finished with value: 0.841648590021692 and parameters: {'learning_rate': 0.23980787177485413, 'max_depth': 5, 'n_estimators': 503}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:20:59,044]\u001b[0m Trial 55 finished with value: 0.8459869848156182 and parameters: {'learning_rate': 0.19791289467133794, 'max_depth': 4, 'n_estimators': 361}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:21:07,326]\u001b[0m Trial 56 finished with value: 0.841648590021692 and parameters: {'learning_rate': 0.2558083976597755, 'max_depth': 3, 'n_estimators': 662}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:21:14,905]\u001b[0m Trial 57 finished with value: 0.8459869848156182 and parameters: {'learning_rate': 0.2691704150737365, 'max_depth': 6, 'n_estimators': 598}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:21:18,904]\u001b[0m Trial 58 finished with value: 0.8308026030368764 and parameters: {'learning_rate': 0.24049133152015562, 'max_depth': 5, 'n_estimators': 247}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:21:28,231]\u001b[0m Trial 59 finished with value: 0.8394793926247288 and parameters: {'learning_rate': 0.22415764327636742, 'max_depth': 6, 'n_estimators': 760}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:21:38,431]\u001b[0m Trial 60 finished with value: 0.8568329718004338 and parameters: {'learning_rate': 0.2113951338778352, 'max_depth': 5, 'n_estimators': 837}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:21:49,078]\u001b[0m Trial 61 finished with value: 0.841648590021692 and parameters: {'learning_rate': 0.22739033200216888, 'max_depth': 5, 'n_estimators': 936}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:21:59,013]\u001b[0m Trial 62 finished with value: 0.8503253796095445 and parameters: {'learning_rate': 0.20933180904186624, 'max_depth': 5, 'n_estimators': 843}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:22:11,844]\u001b[0m Trial 63 finished with value: 0.8524945770065075 and parameters: {'learning_rate': 0.2491500335019627, 'max_depth': 5, 'n_estimators': 875}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:22:23,404]\u001b[0m Trial 64 finished with value: 0.8568329718004338 and parameters: {'learning_rate': 0.19019156236118634, 'max_depth': 4, 'n_estimators': 815}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:22:35,933]\u001b[0m Trial 65 finished with value: 0.8524945770065075 and parameters: {'learning_rate': 0.26064839991709093, 'max_depth': 4, 'n_estimators': 943}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:22:44,841]\u001b[0m Trial 66 finished with value: 0.8611713665943601 and parameters: {'learning_rate': 0.19562994225404676, 'max_depth': 3, 'n_estimators': 832}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:22:53,260]\u001b[0m Trial 67 finished with value: 0.8503253796095445 and parameters: {'learning_rate': 0.19110076467430714, 'max_depth': 3, 'n_estimators': 800}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:22:59,469]\u001b[0m Trial 68 finished with value: 0.8459869848156182 and parameters: {'learning_rate': 0.2003124600320721, 'max_depth': 2, 'n_estimators': 822}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:23:08,046]\u001b[0m Trial 69 finished with value: 0.8568329718004338 and parameters: {'learning_rate': 0.16511451201780517, 'max_depth': 3, 'n_estimators': 862}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:23:17,453]\u001b[0m Trial 70 finished with value: 0.8546637744034707 and parameters: {'learning_rate': 0.1680514536412813, 'max_depth': 3, 'n_estimators': 882}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:23:26,358]\u001b[0m Trial 71 finished with value: 0.841648590021692 and parameters: {'learning_rate': 0.14214918772476148, 'max_depth': 3, 'n_estimators': 858}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:23:35,452]\u001b[0m Trial 72 finished with value: 0.8438177874186551 and parameters: {'learning_rate': 0.1879070816820146, 'max_depth': 4, 'n_estimators': 775}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:23:40,941]\u001b[0m Trial 73 finished with value: 0.8459869848156182 and parameters: {'learning_rate': 0.2183503347682999, 'max_depth': 2, 'n_estimators': 726}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:23:50,198]\u001b[0m Trial 74 finished with value: 0.8546637744034707 and parameters: {'learning_rate': 0.23471862038267224, 'max_depth': 3, 'n_estimators': 960}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:23:57,636]\u001b[0m Trial 75 finished with value: 0.8438177874186551 and parameters: {'learning_rate': 0.17800905352854957, 'max_depth': 2, 'n_estimators': 867}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:24:10,618]\u001b[0m Trial 76 finished with value: 0.8503253796095445 and parameters: {'learning_rate': 0.19553631330666074, 'max_depth': 4, 'n_estimators': 916}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:24:19,763]\u001b[0m Trial 77 finished with value: 0.8524945770065075 and parameters: {'learning_rate': 0.21110713234942224, 'max_depth': 3, 'n_estimators': 819}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:24:30,382]\u001b[0m Trial 78 finished with value: 0.841648590021692 and parameters: {'learning_rate': 0.15233613980827942, 'max_depth': 4, 'n_estimators': 896}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:24:38,231]\u001b[0m Trial 79 finished with value: 0.8590021691973969 and parameters: {'learning_rate': 0.20231442026661076, 'max_depth': 3, 'n_estimators': 788}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:24:46,668]\u001b[0m Trial 80 finished with value: 0.8481561822125814 and parameters: {'learning_rate': 0.2035912153478039, 'max_depth': 3, 'n_estimators': 773}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:24:55,746]\u001b[0m Trial 81 finished with value: 0.8503253796095445 and parameters: {'learning_rate': 0.1823125490700774, 'max_depth': 3, 'n_estimators': 835}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:25:02,367]\u001b[0m Trial 82 finished with value: 0.8394793926247288 and parameters: {'learning_rate': 0.2231808609264525, 'max_depth': 2, 'n_estimators': 806}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:25:09,711]\u001b[0m Trial 83 finished with value: 0.8481561822125814 and parameters: {'learning_rate': 0.18927089505409744, 'max_depth': 3, 'n_estimators': 730}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:25:18,400]\u001b[0m Trial 84 finished with value: 0.8503253796095445 and parameters: {'learning_rate': 0.2439107901182722, 'max_depth': 3, 'n_estimators': 856}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:25:28,281]\u001b[0m Trial 85 finished with value: 0.8438177874186551 and parameters: {'learning_rate': 0.20664523236092794, 'max_depth': 3, 'n_estimators': 790}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:25:41,041]\u001b[0m Trial 86 finished with value: 0.8524945770065075 and parameters: {'learning_rate': 0.23422091887506827, 'max_depth': 4, 'n_estimators': 756}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:25:50,827]\u001b[0m Trial 87 finished with value: 0.8524945770065075 and parameters: {'learning_rate': 0.21552737994884957, 'max_depth': 2, 'n_estimators': 833}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:25:53,246]\u001b[0m Trial 88 finished with value: 0.8481561822125814 and parameters: {'learning_rate': 0.19675006899529768, 'max_depth': 4, 'n_estimators': 113}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:26:03,478]\u001b[0m Trial 89 finished with value: 0.8524945770065075 and parameters: {'learning_rate': 0.25051495365718807, 'max_depth': 3, 'n_estimators': 683}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:26:16,247]\u001b[0m Trial 90 finished with value: 0.8524945770065075 and parameters: {'learning_rate': 0.17444883654403562, 'max_depth': 4, 'n_estimators': 976}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:26:25,879]\u001b[0m Trial 91 finished with value: 0.8503253796095445 and parameters: {'learning_rate': 0.16083636252538322, 'max_depth': 3, 'n_estimators': 905}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:26:31,097]\u001b[0m Trial 92 finished with value: 0.8373101952277657 and parameters: {'learning_rate': 0.16662101826741182, 'max_depth': 3, 'n_estimators': 485}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:26:39,743]\u001b[0m Trial 93 finished with value: 0.8546637744034707 and parameters: {'learning_rate': 0.18413271695672176, 'max_depth': 3, 'n_estimators': 884}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:26:51,004]\u001b[0m Trial 94 finished with value: 0.8524945770065075 and parameters: {'learning_rate': 0.17118183558703484, 'max_depth': 3, 'n_estimators': 935}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:26:57,675]\u001b[0m Trial 95 finished with value: 0.8481561822125814 and parameters: {'learning_rate': 0.20431798244376326, 'max_depth': 2, 'n_estimators': 877}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:27:06,040]\u001b[0m Trial 96 finished with value: 0.8503253796095445 and parameters: {'learning_rate': 0.22984560382490804, 'max_depth': 3, 'n_estimators': 852}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:27:17,091]\u001b[0m Trial 97 finished with value: 0.8503253796095445 and parameters: {'learning_rate': 0.19401019440773656, 'max_depth': 6, 'n_estimators': 816}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:27:26,555]\u001b[0m Trial 98 finished with value: 0.8351409978308026 and parameters: {'learning_rate': 0.27184796479892087, 'max_depth': 6, 'n_estimators': 749}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:27:38,156]\u001b[0m Trial 99 finished with value: 0.8524945770065075 and parameters: {'learning_rate': 0.26125587182556315, 'max_depth': 5, 'n_estimators': 999}. Best is trial 29 with value: 0.8611713665943601.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:27:38,169]\u001b[0m A new study created in memory with name: no-name-520000dd-6c4b-4215-8864-281583a290a5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning  accuracy   \n",
      "index          AAC  LogisticRegression            False  0.870562  \\\n",
      "index          AAC                 SVC            False  0.895351   \n",
      "index          AAC       XGBClassifier            False  0.878837   \n",
      "index          AAC      LGBMClassifier            False  0.885530   \n",
      "index          AAC                 SVC             True  0.867679   \n",
      "index          AAC       XGBClassifier             True  0.891540   \n",
      "index          AAC      LGBMClassifier             True  0.885033   \n",
      "index        APAAC  LogisticRegression            False  0.874261   \n",
      "index        APAAC                 SVC            False  0.870301   \n",
      "index        APAAC       XGBClassifier            False  0.880982   \n",
      "index        APAAC      LGBMClassifier            False  0.885727   \n",
      "index        APAAC                 SVC             True  0.570499   \n",
      "index        APAAC       XGBClassifier             True  0.893709   \n",
      "index        APAAC      LGBMClassifier             True  0.895879   \n",
      "index          CTD  LogisticRegression            False  0.702615   \n",
      "index          CTD                 SVC            False  0.675452   \n",
      "index          CTD       XGBClassifier            False  0.854839   \n",
      "index          CTD      LGBMClassifier            False  0.858768   \n",
      "index          CTD                 SVC             True  0.555315   \n",
      "index          CTD       XGBClassifier             True  0.861171   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.875000     0.924051   0.915888  0.894977  0.800787  \\\n",
      "index     0.825893     0.940928   0.929648  0.874704  0.773776   \n",
      "index     0.834821     0.915612   0.903382  0.867749  0.754064   \n",
      "index     0.812500     0.924051   0.910000  0.858491  0.742789   \n",
      "index     0.803571     0.928270   0.913706  0.855107  0.739401   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.830357     0.936709   0.925373  0.875294  0.773119   \n",
      "index     0.870536     0.928270   0.919811  0.894495  0.801072   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.825893     0.928270   0.915842  0.868545  0.759692   \n",
      "index     0.821429     0.924051   0.910891  0.863850  0.750945   \n",
      "index     0.129464     0.987342   0.906250  0.226562  0.229699   \n",
      "index     0.857143     0.928270   0.918660  0.886836  0.788538   \n",
      "index     0.852679     0.936709   0.927184  0.888372  0.793569   \n",
      "index     0.678571     0.548523   0.586873  0.629400  0.228760   \n",
      "index     0.866071     0.248945   0.521505  0.651007  0.145644   \n",
      "index     0.808036     0.869198   0.853774  0.830275  0.679156   \n",
      "index     0.767857     0.902954   0.882051  0.821002  0.678641   \n",
      "index     0.084821     1.000000   1.000000  0.156379  0.213263   \n",
      "index     0.803571     0.915612   0.900000  0.849057  0.725275   \n",
      "\n",
      "                                         index  \n",
      "index    AAC_LogisticRegression_no_hypertuning  \n",
      "index                   AAC_SVC_no_hypertuning  \n",
      "index         AAC_XGBClassifier_no_hypertuning  \n",
      "index        AAC_LGBMClassifier_no_hypertuning  \n",
      "index                 AAC_SVC_with_hypertuning  \n",
      "index       AAC_XGBClassifier_with_hypertuning  \n",
      "index      AAC_LGBMClassifier_with_hypertuning  \n",
      "index  APAAC_LogisticRegression_no_hypertuning  \n",
      "index                 APAAC_SVC_no_hypertuning  \n",
      "index       APAAC_XGBClassifier_no_hypertuning  \n",
      "index      APAAC_LGBMClassifier_no_hypertuning  \n",
      "index               APAAC_SVC_with_hypertuning  \n",
      "index     APAAC_XGBClassifier_with_hypertuning  \n",
      "index    APAAC_LGBMClassifier_with_hypertuning  \n",
      "index    CTD_LogisticRegression_no_hypertuning  \n",
      "index                   CTD_SVC_no_hypertuning  \n",
      "index         CTD_XGBClassifier_no_hypertuning  \n",
      "index        CTD_LGBMClassifier_no_hypertuning  \n",
      "index                 CTD_SVC_with_hypertuning  \n",
      "index       CTD_XGBClassifier_with_hypertuning  \n",
      "Optimizing CTD LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-13 11:28:00,533]\u001b[0m Trial 0 finished with value: 0.8264642082429501 and parameters: {'num_leaves': 251, 'max_depth': 48, 'learning_rate': 0.012852525252637567, 'n_estimators': 1156}. Best is trial 0 with value: 0.8264642082429501.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:28:06,757]\u001b[0m Trial 1 finished with value: 0.8264642082429501 and parameters: {'num_leaves': 172, 'max_depth': 22, 'learning_rate': 0.1969690937387182, 'n_estimators': 1491}. Best is trial 0 with value: 0.8264642082429501.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:28:09,647]\u001b[0m Trial 2 finished with value: 0.824295010845987 and parameters: {'num_leaves': 255, 'max_depth': 4, 'learning_rate': 0.15819382476339455, 'n_estimators': 1419}. Best is trial 0 with value: 0.8264642082429501.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:28:13,818]\u001b[0m Trial 3 finished with value: 0.8308026030368764 and parameters: {'num_leaves': 86, 'max_depth': 45, 'learning_rate': 0.21692028948699024, 'n_estimators': 1038}. Best is trial 3 with value: 0.8308026030368764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:28:27,375]\u001b[0m Trial 4 finished with value: 0.8329718004338394 and parameters: {'num_leaves': 252, 'max_depth': 21, 'learning_rate': 0.05220462679173467, 'n_estimators': 1782}. Best is trial 4 with value: 0.8329718004338394.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:28:31,984]\u001b[0m Trial 5 finished with value: 0.824295010845987 and parameters: {'num_leaves': 182, 'max_depth': 20, 'learning_rate': 0.1376979908212915, 'n_estimators': 743}. Best is trial 4 with value: 0.8329718004338394.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:28:37,725]\u001b[0m Trial 6 finished with value: 0.8438177874186551 and parameters: {'num_leaves': 249, 'max_depth': 7, 'learning_rate': 0.1327673333103016, 'n_estimators': 1646}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:28:42,253]\u001b[0m Trial 7 finished with value: 0.8286334056399133 and parameters: {'num_leaves': 178, 'max_depth': 36, 'learning_rate': 0.25153642485385874, 'n_estimators': 1265}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:28:43,814]\u001b[0m Trial 8 finished with value: 0.8329718004338394 and parameters: {'num_leaves': 139, 'max_depth': 2, 'learning_rate': 0.045827637930169446, 'n_estimators': 1521}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:28:48,645]\u001b[0m Trial 9 finished with value: 0.8373101952277657 and parameters: {'num_leaves': 208, 'max_depth': 34, 'learning_rate': 0.21834599973661006, 'n_estimators': 1211}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:28:49,862]\u001b[0m Trial 10 finished with value: 0.8329718004338394 and parameters: {'num_leaves': 12, 'max_depth': 12, 'learning_rate': 0.2857279382786318, 'n_estimators': 376}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:28:59,199]\u001b[0m Trial 11 finished with value: 0.8199566160520607 and parameters: {'num_leaves': 208, 'max_depth': 34, 'learning_rate': 0.12535640208273446, 'n_estimators': 1902}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:29:03,350]\u001b[0m Trial 12 finished with value: 0.8264642082429501 and parameters: {'num_leaves': 215, 'max_depth': 32, 'learning_rate': 0.18887368507343477, 'n_estimators': 820}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:29:11,707]\u001b[0m Trial 13 finished with value: 0.8286334056399133 and parameters: {'num_leaves': 106, 'max_depth': 12, 'learning_rate': 0.09757682337966542, 'n_estimators': 1682}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:29:13,581]\u001b[0m Trial 14 finished with value: 0.8199566160520607 and parameters: {'num_leaves': 215, 'max_depth': 42, 'learning_rate': 0.24728912885196921, 'n_estimators': 126}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:29:20,028]\u001b[0m Trial 15 finished with value: 0.8177874186550976 and parameters: {'num_leaves': 136, 'max_depth': 28, 'learning_rate': 0.160158866624725, 'n_estimators': 881}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:29:25,519]\u001b[0m Trial 16 finished with value: 0.8286334056399133 and parameters: {'num_leaves': 53, 'max_depth': 13, 'learning_rate': 0.10473643786528086, 'n_estimators': 1282}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:29:32,432]\u001b[0m Trial 17 finished with value: 0.8329718004338394 and parameters: {'num_leaves': 220, 'max_depth': 39, 'learning_rate': 0.19572491098923633, 'n_estimators': 1957}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:29:38,027]\u001b[0m Trial 18 finished with value: 0.8373101952277657 and parameters: {'num_leaves': 164, 'max_depth': 29, 'learning_rate': 0.29813090464600156, 'n_estimators': 1652}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:29:41,125]\u001b[0m Trial 19 finished with value: 0.8177874186550976 and parameters: {'num_leaves': 231, 'max_depth': 7, 'learning_rate': 0.17325046149989437, 'n_estimators': 673}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:29:45,172]\u001b[0m Trial 20 finished with value: 0.8199566160520607 and parameters: {'num_leaves': 197, 'max_depth': 17, 'learning_rate': 0.22409899705987074, 'n_estimators': 1021}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:29:51,242]\u001b[0m Trial 21 finished with value: 0.8264642082429501 and parameters: {'num_leaves': 156, 'max_depth': 27, 'learning_rate': 0.2913896984789176, 'n_estimators': 1627}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:29:57,782]\u001b[0m Trial 22 finished with value: 0.8373101952277657 and parameters: {'num_leaves': 156, 'max_depth': 29, 'learning_rate': 0.295536968613527, 'n_estimators': 1781}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:30:02,937]\u001b[0m Trial 23 finished with value: 0.8308026030368764 and parameters: {'num_leaves': 231, 'max_depth': 38, 'learning_rate': 0.25886335086748513, 'n_estimators': 1338}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:30:09,549]\u001b[0m Trial 24 finished with value: 0.8286334056399133 and parameters: {'num_leaves': 195, 'max_depth': 24, 'learning_rate': 0.2257899178947817, 'n_estimators': 1580}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:30:15,490]\u001b[0m Trial 25 finished with value: 0.8329718004338394 and parameters: {'num_leaves': 111, 'max_depth': 32, 'learning_rate': 0.26056404779695175, 'n_estimators': 1720}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:30:19,848]\u001b[0m Trial 26 finished with value: 0.8308026030368764 and parameters: {'num_leaves': 236, 'max_depth': 16, 'learning_rate': 0.2726723901949342, 'n_estimators': 1184}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:30:32,741]\u001b[0m Trial 27 finished with value: 0.824295010845987 and parameters: {'num_leaves': 153, 'max_depth': 42, 'learning_rate': 0.23563874276786917, 'n_estimators': 1996}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:30:39,977]\u001b[0m Trial 28 finished with value: 0.8177874186550976 and parameters: {'num_leaves': 196, 'max_depth': 7, 'learning_rate': 0.29896892374915196, 'n_estimators': 1413}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:30:45,054]\u001b[0m Trial 29 finished with value: 0.8221258134490239 and parameters: {'num_leaves': 176, 'max_depth': 50, 'learning_rate': 0.2095545990714494, 'n_estimators': 1136}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:30:48,087]\u001b[0m Trial 30 finished with value: 0.8199566160520607 and parameters: {'num_leaves': 230, 'max_depth': 31, 'learning_rate': 0.2704180061818503, 'n_estimators': 559}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:30:53,629]\u001b[0m Trial 31 finished with value: 0.8264642082429501 and parameters: {'num_leaves': 160, 'max_depth': 29, 'learning_rate': 0.2793871401351735, 'n_estimators': 1800}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:30:59,309]\u001b[0m Trial 32 finished with value: 0.8286334056399133 and parameters: {'num_leaves': 128, 'max_depth': 24, 'learning_rate': 0.2987863503755797, 'n_estimators': 1828}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:31:04,508]\u001b[0m Trial 33 finished with value: 0.8177874186550976 and parameters: {'num_leaves': 241, 'max_depth': 25, 'learning_rate': 0.24275550132702056, 'n_estimators': 1493}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:31:10,187]\u001b[0m Trial 34 finished with value: 0.8286334056399133 and parameters: {'num_leaves': 165, 'max_depth': 35, 'learning_rate': 0.2636286077124154, 'n_estimators': 1632}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:31:15,239]\u001b[0m Trial 35 finished with value: 0.8264642082429501 and parameters: {'num_leaves': 254, 'max_depth': 30, 'learning_rate': 0.2764066450255982, 'n_estimators': 1426}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:31:21,526]\u001b[0m Trial 36 finished with value: 0.8286334056399133 and parameters: {'num_leaves': 74, 'max_depth': 19, 'learning_rate': 0.23699680351787714, 'n_estimators': 1861}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:31:27,500]\u001b[0m Trial 37 finished with value: 0.8394793926247288 and parameters: {'num_leaves': 190, 'max_depth': 46, 'learning_rate': 0.2073487054413447, 'n_estimators': 1759}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:31:32,889]\u001b[0m Trial 38 finished with value: 0.8329718004338394 and parameters: {'num_leaves': 187, 'max_depth': 45, 'learning_rate': 0.20277086445255893, 'n_estimators': 1567}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:31:37,361]\u001b[0m Trial 39 finished with value: 0.8329718004338394 and parameters: {'num_leaves': 205, 'max_depth': 47, 'learning_rate': 0.18675690171391093, 'n_estimators': 947}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:31:42,638]\u001b[0m Trial 40 finished with value: 0.8177874186550976 and parameters: {'num_leaves': 185, 'max_depth': 39, 'learning_rate': 0.21201035227097315, 'n_estimators': 1388}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:31:48,348]\u001b[0m Trial 41 finished with value: 0.824295010845987 and parameters: {'num_leaves': 147, 'max_depth': 42, 'learning_rate': 0.25196392037672294, 'n_estimators': 1739}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:31:54,576]\u001b[0m Trial 42 finished with value: 0.8373101952277657 and parameters: {'num_leaves': 172, 'max_depth': 34, 'learning_rate': 0.29001293381971427, 'n_estimators': 1881}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:32:00,035]\u001b[0m Trial 43 finished with value: 0.8308026030368764 and parameters: {'num_leaves': 120, 'max_depth': 23, 'learning_rate': 0.22947207370237238, 'n_estimators': 1686}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:32:06,214]\u001b[0m Trial 44 finished with value: 0.8373101952277657 and parameters: {'num_leaves': 243, 'max_depth': 21, 'learning_rate': 0.14922456060518804, 'n_estimators': 1484}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:32:10,322]\u001b[0m Trial 45 finished with value: 0.8329718004338394 and parameters: {'num_leaves': 144, 'max_depth': 27, 'learning_rate': 0.2828797709336628, 'n_estimators': 1157}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:32:16,197]\u001b[0m Trial 46 finished with value: 0.8221258134490239 and parameters: {'num_leaves': 170, 'max_depth': 37, 'learning_rate': 0.21753803865497348, 'n_estimators': 1798}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:32:22,487]\u001b[0m Trial 47 finished with value: 0.8264642082429501 and parameters: {'num_leaves': 213, 'max_depth': 33, 'learning_rate': 0.18163553780475802, 'n_estimators': 1638}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:32:28,623]\u001b[0m Trial 48 finished with value: 0.8351409978308026 and parameters: {'num_leaves': 204, 'max_depth': 45, 'learning_rate': 0.25371249271648205, 'n_estimators': 1922}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:32:33,834]\u001b[0m Trial 49 finished with value: 0.8264642082429501 and parameters: {'num_leaves': 225, 'max_depth': 41, 'learning_rate': 0.1685715267033473, 'n_estimators': 1242}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:32:39,602]\u001b[0m Trial 50 finished with value: 0.8221258134490239 and parameters: {'num_leaves': 186, 'max_depth': 36, 'learning_rate': 0.1989271106250915, 'n_estimators': 1559}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:32:45,224]\u001b[0m Trial 51 finished with value: 0.8308026030368764 and parameters: {'num_leaves': 171, 'max_depth': 30, 'learning_rate': 0.29304868610998663, 'n_estimators': 1895}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:32:50,889]\u001b[0m Trial 52 finished with value: 0.8329718004338394 and parameters: {'num_leaves': 160, 'max_depth': 34, 'learning_rate': 0.28318892218644737, 'n_estimators': 1740}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:32:56,311]\u001b[0m Trial 53 finished with value: 0.8373101952277657 and parameters: {'num_leaves': 133, 'max_depth': 27, 'learning_rate': 0.2993381112478043, 'n_estimators': 1863}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:33:02,027]\u001b[0m Trial 54 finished with value: 0.8394793926247288 and parameters: {'num_leaves': 15, 'max_depth': 32, 'learning_rate': 0.2683751726366957, 'n_estimators': 1991}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:33:07,137]\u001b[0m Trial 55 finished with value: 0.841648590021692 and parameters: {'num_leaves': 21, 'max_depth': 29, 'learning_rate': 0.2705276317369508, 'n_estimators': 1954}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:33:09,078]\u001b[0m Trial 56 finished with value: 0.8394793926247288 and parameters: {'num_leaves': 6, 'max_depth': 2, 'learning_rate': 0.2613174866414057, 'n_estimators': 1998}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:33:10,842]\u001b[0m Trial 57 finished with value: 0.841648590021692 and parameters: {'num_leaves': 3, 'max_depth': 2, 'learning_rate': 0.24859309210847974, 'n_estimators': 1989}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:33:13,256]\u001b[0m Trial 58 finished with value: 0.8373101952277657 and parameters: {'num_leaves': 10, 'max_depth': 3, 'learning_rate': 0.2447787655703546, 'n_estimators': 1986}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:33:17,181]\u001b[0m Trial 59 finished with value: 0.8329718004338394 and parameters: {'num_leaves': 34, 'max_depth': 5, 'learning_rate': 0.26468436941006424, 'n_estimators': 1940}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:33:18,275]\u001b[0m Trial 60 finished with value: 0.8351409978308026 and parameters: {'num_leaves': 2, 'max_depth': 8, 'learning_rate': 0.25081168810485766, 'n_estimators': 1990}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:33:20,185]\u001b[0m Trial 61 finished with value: 0.8438177874186551 and parameters: {'num_leaves': 27, 'max_depth': 2, 'learning_rate': 0.23251352448500248, 'n_estimators': 1949}. Best is trial 6 with value: 0.8438177874186551.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:33:21,853]\u001b[0m Trial 62 finished with value: 0.8503253796095445 and parameters: {'num_leaves': 29, 'max_depth': 2, 'learning_rate': 0.2405487018939399, 'n_estimators': 1923}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:33:25,714]\u001b[0m Trial 63 finished with value: 0.824295010845987 and parameters: {'num_leaves': 22, 'max_depth': 5, 'learning_rate': 0.23602777308285994, 'n_estimators': 1917}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:33:31,008]\u001b[0m Trial 64 finished with value: 0.8329718004338394 and parameters: {'num_leaves': 41, 'max_depth': 10, 'learning_rate': 0.2292894811764291, 'n_estimators': 1821}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:33:33,905]\u001b[0m Trial 65 finished with value: 0.8329718004338394 and parameters: {'num_leaves': 61, 'max_depth': 4, 'learning_rate': 0.2713970030052947, 'n_estimators': 1749}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:33:39,569]\u001b[0m Trial 66 finished with value: 0.8394793926247288 and parameters: {'num_leaves': 18, 'max_depth': 10, 'learning_rate': 0.2205085899355752, 'n_estimators': 1929}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:33:41,718]\u001b[0m Trial 67 finished with value: 0.8503253796095445 and parameters: {'num_leaves': 28, 'max_depth': 2, 'learning_rate': 0.24329974985142352, 'n_estimators': 1838}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:33:43,188]\u001b[0m Trial 68 finished with value: 0.8373101952277657 and parameters: {'num_leaves': 29, 'max_depth': 2, 'learning_rate': 0.2448120625954328, 'n_estimators': 1696}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:33:47,318]\u001b[0m Trial 69 finished with value: 0.8329718004338394 and parameters: {'num_leaves': 48, 'max_depth': 5, 'learning_rate': 0.23548632793011365, 'n_estimators': 1851}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:33:48,188]\u001b[0m Trial 70 finished with value: 0.8394793926247288 and parameters: {'num_leaves': 26, 'max_depth': 7, 'learning_rate': 0.20687795908661752, 'n_estimators': 166}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:33:51,138]\u001b[0m Trial 71 finished with value: 0.8286334056399133 and parameters: {'num_leaves': 16, 'max_depth': 4, 'learning_rate': 0.25884675715779154, 'n_estimators': 1789}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:33:52,835]\u001b[0m Trial 72 finished with value: 0.8459869848156182 and parameters: {'num_leaves': 43, 'max_depth': 2, 'learning_rate': 0.26985900332970536, 'n_estimators': 1942}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:33:54,590]\u001b[0m Trial 73 finished with value: 0.8481561822125814 and parameters: {'num_leaves': 38, 'max_depth': 2, 'learning_rate': 0.22334568589016252, 'n_estimators': 1881}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:33:56,228]\u001b[0m Trial 74 finished with value: 0.8351409978308026 and parameters: {'num_leaves': 62, 'max_depth': 2, 'learning_rate': 0.27663245214557175, 'n_estimators': 1874}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:34:00,767]\u001b[0m Trial 75 finished with value: 0.8394793926247288 and parameters: {'num_leaves': 38, 'max_depth': 6, 'learning_rate': 0.25080188458211494, 'n_estimators': 1928}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:34:05,991]\u001b[0m Trial 76 finished with value: 0.824295010845987 and parameters: {'num_leaves': 86, 'max_depth': 9, 'learning_rate': 0.22549506531280095, 'n_estimators': 1829}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:34:08,770]\u001b[0m Trial 77 finished with value: 0.841648590021692 and parameters: {'num_leaves': 45, 'max_depth': 3, 'learning_rate': 0.21536089675300235, 'n_estimators': 1937}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:34:14,836]\u001b[0m Trial 78 finished with value: 0.8373101952277657 and parameters: {'num_leaves': 55, 'max_depth': 13, 'learning_rate': 0.2418098601866475, 'n_estimators': 1889}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:34:22,427]\u001b[0m Trial 79 finished with value: 0.8329718004338394 and parameters: {'num_leaves': 31, 'max_depth': 6, 'learning_rate': 0.25896881795550136, 'n_estimators': 1689}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:34:25,642]\u001b[0m Trial 80 finished with value: 0.8286334056399133 and parameters: {'num_leaves': 22, 'max_depth': 4, 'learning_rate': 0.26978300266279964, 'n_estimators': 1786}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:34:27,971]\u001b[0m Trial 81 finished with value: 0.8351409978308026 and parameters: {'num_leaves': 44, 'max_depth': 3, 'learning_rate': 0.23223806859974852, 'n_estimators': 1965}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:34:30,392]\u001b[0m Trial 82 finished with value: 0.8481561822125814 and parameters: {'num_leaves': 49, 'max_depth': 3, 'learning_rate': 0.2161490607647033, 'n_estimators': 1836}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:34:32,276]\u001b[0m Trial 83 finished with value: 0.8459869848156182 and parameters: {'num_leaves': 36, 'max_depth': 2, 'learning_rate': 0.24100940571726323, 'n_estimators': 1832}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:34:36,346]\u001b[0m Trial 84 finished with value: 0.8351409978308026 and parameters: {'num_leaves': 73, 'max_depth': 6, 'learning_rate': 0.23906484995188473, 'n_estimators': 1828}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:34:40,926]\u001b[0m Trial 85 finished with value: 0.8438177874186551 and parameters: {'num_leaves': 37, 'max_depth': 8, 'learning_rate': 0.21997959753194568, 'n_estimators': 1713}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:34:43,550]\u001b[0m Trial 86 finished with value: 0.8394793926247288 and parameters: {'num_leaves': 37, 'max_depth': 4, 'learning_rate': 0.2250403464471854, 'n_estimators': 1609}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:34:48,408]\u001b[0m Trial 87 finished with value: 0.841648590021692 and parameters: {'num_leaves': 54, 'max_depth': 8, 'learning_rate': 0.2170087601464702, 'n_estimators': 1720}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:34:53,534]\u001b[0m Trial 88 finished with value: 0.8438177874186551 and parameters: {'num_leaves': 68, 'max_depth': 10, 'learning_rate': 0.19693638238793998, 'n_estimators': 1664}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:34:58,880]\u001b[0m Trial 89 finished with value: 0.8481561822125814 and parameters: {'num_leaves': 95, 'max_depth': 8, 'learning_rate': 0.21261513093002618, 'n_estimators': 1764}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:35:01,280]\u001b[0m Trial 90 finished with value: 0.8394793926247288 and parameters: {'num_leaves': 85, 'max_depth': 3, 'learning_rate': 0.20972509950605236, 'n_estimators': 1769}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:35:06,310]\u001b[0m Trial 91 finished with value: 0.8199566160520607 and parameters: {'num_leaves': 51, 'max_depth': 8, 'learning_rate': 0.22471776294368312, 'n_estimators': 1852}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:35:10,261]\u001b[0m Trial 92 finished with value: 0.8394793926247288 and parameters: {'num_leaves': 26, 'max_depth': 6, 'learning_rate': 0.21947054961957393, 'n_estimators': 1727}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:35:16,410]\u001b[0m Trial 93 finished with value: 0.8221258134490239 and parameters: {'num_leaves': 59, 'max_depth': 15, 'learning_rate': 0.23305444345049792, 'n_estimators': 1889}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:35:22,480]\u001b[0m Trial 94 finished with value: 0.8308026030368764 and parameters: {'num_leaves': 92, 'max_depth': 12, 'learning_rate': 0.19286130984797847, 'n_estimators': 1799}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:35:24,246]\u001b[0m Trial 95 finished with value: 0.8351409978308026 and parameters: {'num_leaves': 34, 'max_depth': 5, 'learning_rate': 0.2421289393888162, 'n_estimators': 651}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:35:26,179]\u001b[0m Trial 96 finished with value: 0.8329718004338394 and parameters: {'num_leaves': 11, 'max_depth': 3, 'learning_rate': 0.20126239628687145, 'n_estimators': 1536}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:35:30,233]\u001b[0m Trial 97 finished with value: 0.8286334056399133 and parameters: {'num_leaves': 103, 'max_depth': 7, 'learning_rate': 0.22910226599501876, 'n_estimators': 1610}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:35:32,152]\u001b[0m Trial 98 finished with value: 0.8308026030368764 and parameters: {'num_leaves': 42, 'max_depth': 2, 'learning_rate': 0.2142231113920758, 'n_estimators': 1831}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:35:35,375]\u001b[0m Trial 99 finished with value: 0.8286334056399133 and parameters: {'num_leaves': 48, 'max_depth': 5, 'learning_rate': 0.2547221682083827, 'n_estimators': 1753}. Best is trial 62 with value: 0.8503253796095445.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning  accuracy   \n",
      "index          AAC  LogisticRegression            False  0.870562  \\\n",
      "index          AAC                 SVC            False  0.895351   \n",
      "index          AAC       XGBClassifier            False  0.878837   \n",
      "index          AAC      LGBMClassifier            False  0.885530   \n",
      "index          AAC                 SVC             True  0.867679   \n",
      "index          AAC       XGBClassifier             True  0.891540   \n",
      "index          AAC      LGBMClassifier             True  0.885033   \n",
      "index        APAAC  LogisticRegression            False  0.874261   \n",
      "index        APAAC                 SVC            False  0.870301   \n",
      "index        APAAC       XGBClassifier            False  0.880982   \n",
      "index        APAAC      LGBMClassifier            False  0.885727   \n",
      "index        APAAC                 SVC             True  0.570499   \n",
      "index        APAAC       XGBClassifier             True  0.893709   \n",
      "index        APAAC      LGBMClassifier             True  0.895879   \n",
      "index          CTD  LogisticRegression            False  0.702615   \n",
      "index          CTD                 SVC            False  0.675452   \n",
      "index          CTD       XGBClassifier            False  0.854839   \n",
      "index          CTD      LGBMClassifier            False  0.858768   \n",
      "index          CTD                 SVC             True  0.555315   \n",
      "index          CTD       XGBClassifier             True  0.861171   \n",
      "index          CTD      LGBMClassifier             True  0.850325   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.875000     0.924051   0.915888  0.894977  0.800787  \\\n",
      "index     0.825893     0.940928   0.929648  0.874704  0.773776   \n",
      "index     0.834821     0.915612   0.903382  0.867749  0.754064   \n",
      "index     0.812500     0.924051   0.910000  0.858491  0.742789   \n",
      "index     0.803571     0.928270   0.913706  0.855107  0.739401   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.830357     0.936709   0.925373  0.875294  0.773119   \n",
      "index     0.870536     0.928270   0.919811  0.894495  0.801072   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.825893     0.928270   0.915842  0.868545  0.759692   \n",
      "index     0.821429     0.924051   0.910891  0.863850  0.750945   \n",
      "index     0.129464     0.987342   0.906250  0.226562  0.229699   \n",
      "index     0.857143     0.928270   0.918660  0.886836  0.788538   \n",
      "index     0.852679     0.936709   0.927184  0.888372  0.793569   \n",
      "index     0.678571     0.548523   0.586873  0.629400  0.228760   \n",
      "index     0.866071     0.248945   0.521505  0.651007  0.145644   \n",
      "index     0.808036     0.869198   0.853774  0.830275  0.679156   \n",
      "index     0.767857     0.902954   0.882051  0.821002  0.678641   \n",
      "index     0.084821     1.000000   1.000000  0.156379  0.213263   \n",
      "index     0.803571     0.915612   0.900000  0.849057  0.725275   \n",
      "index     0.767857     0.928270   0.910053  0.832930  0.707410   \n",
      "\n",
      "                                         index  \n",
      "index    AAC_LogisticRegression_no_hypertuning  \n",
      "index                   AAC_SVC_no_hypertuning  \n",
      "index         AAC_XGBClassifier_no_hypertuning  \n",
      "index        AAC_LGBMClassifier_no_hypertuning  \n",
      "index                 AAC_SVC_with_hypertuning  \n",
      "index       AAC_XGBClassifier_with_hypertuning  \n",
      "index      AAC_LGBMClassifier_with_hypertuning  \n",
      "index  APAAC_LogisticRegression_no_hypertuning  \n",
      "index                 APAAC_SVC_no_hypertuning  \n",
      "index       APAAC_XGBClassifier_no_hypertuning  \n",
      "index      APAAC_LGBMClassifier_no_hypertuning  \n",
      "index               APAAC_SVC_with_hypertuning  \n",
      "index     APAAC_XGBClassifier_with_hypertuning  \n",
      "index    APAAC_LGBMClassifier_with_hypertuning  \n",
      "index    CTD_LogisticRegression_no_hypertuning  \n",
      "index                   CTD_SVC_no_hypertuning  \n",
      "index         CTD_XGBClassifier_no_hypertuning  \n",
      "index        CTD_LGBMClassifier_no_hypertuning  \n",
      "index                 CTD_SVC_with_hypertuning  \n",
      "index       CTD_XGBClassifier_with_hypertuning  \n",
      "index      CTD_LGBMClassifier_with_hypertuning  \n",
      "Evaluating DPC LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning  accuracy   \n",
      "index          AAC  LogisticRegression            False  0.870562  \\\n",
      "index          AAC                 SVC            False  0.895351   \n",
      "index          AAC       XGBClassifier            False  0.878837   \n",
      "index          AAC      LGBMClassifier            False  0.885530   \n",
      "index          AAC                 SVC             True  0.867679   \n",
      "index          AAC       XGBClassifier             True  0.891540   \n",
      "index          AAC      LGBMClassifier             True  0.885033   \n",
      "index        APAAC  LogisticRegression            False  0.874261   \n",
      "index        APAAC                 SVC            False  0.870301   \n",
      "index        APAAC       XGBClassifier            False  0.880982   \n",
      "index        APAAC      LGBMClassifier            False  0.885727   \n",
      "index        APAAC                 SVC             True  0.570499   \n",
      "index        APAAC       XGBClassifier             True  0.893709   \n",
      "index        APAAC      LGBMClassifier             True  0.895879   \n",
      "index          CTD  LogisticRegression            False  0.702615   \n",
      "index          CTD                 SVC            False  0.675452   \n",
      "index          CTD       XGBClassifier            False  0.854839   \n",
      "index          CTD      LGBMClassifier            False  0.858768   \n",
      "index          CTD                 SVC             True  0.555315   \n",
      "index          CTD       XGBClassifier             True  0.861171   \n",
      "index          CTD      LGBMClassifier             True  0.850325   \n",
      "index          DPC  LogisticRegression            False  0.862727   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.875000     0.924051   0.915888  0.894977  0.800787  \\\n",
      "index     0.825893     0.940928   0.929648  0.874704  0.773776   \n",
      "index     0.834821     0.915612   0.903382  0.867749  0.754064   \n",
      "index     0.812500     0.924051   0.910000  0.858491  0.742789   \n",
      "index     0.803571     0.928270   0.913706  0.855107  0.739401   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.830357     0.936709   0.925373  0.875294  0.773119   \n",
      "index     0.870536     0.928270   0.919811  0.894495  0.801072   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.825893     0.928270   0.915842  0.868545  0.759692   \n",
      "index     0.821429     0.924051   0.910891  0.863850  0.750945   \n",
      "index     0.129464     0.987342   0.906250  0.226562  0.229699   \n",
      "index     0.857143     0.928270   0.918660  0.886836  0.788538   \n",
      "index     0.852679     0.936709   0.927184  0.888372  0.793569   \n",
      "index     0.678571     0.548523   0.586873  0.629400  0.228760   \n",
      "index     0.866071     0.248945   0.521505  0.651007  0.145644   \n",
      "index     0.808036     0.869198   0.853774  0.830275  0.679156   \n",
      "index     0.767857     0.902954   0.882051  0.821002  0.678641   \n",
      "index     0.084821     1.000000   1.000000  0.156379  0.213263   \n",
      "index     0.803571     0.915612   0.900000  0.849057  0.725275   \n",
      "index     0.767857     0.928270   0.910053  0.832930  0.707410   \n",
      "index     0.852679     0.886076   0.876147  0.864253  0.739549   \n",
      "\n",
      "                                         index  \n",
      "index    AAC_LogisticRegression_no_hypertuning  \n",
      "index                   AAC_SVC_no_hypertuning  \n",
      "index         AAC_XGBClassifier_no_hypertuning  \n",
      "index        AAC_LGBMClassifier_no_hypertuning  \n",
      "index                 AAC_SVC_with_hypertuning  \n",
      "index       AAC_XGBClassifier_with_hypertuning  \n",
      "index      AAC_LGBMClassifier_with_hypertuning  \n",
      "index  APAAC_LogisticRegression_no_hypertuning  \n",
      "index                 APAAC_SVC_no_hypertuning  \n",
      "index       APAAC_XGBClassifier_no_hypertuning  \n",
      "index      APAAC_LGBMClassifier_no_hypertuning  \n",
      "index               APAAC_SVC_with_hypertuning  \n",
      "index     APAAC_XGBClassifier_with_hypertuning  \n",
      "index    APAAC_LGBMClassifier_with_hypertuning  \n",
      "index    CTD_LogisticRegression_no_hypertuning  \n",
      "index                   CTD_SVC_no_hypertuning  \n",
      "index         CTD_XGBClassifier_no_hypertuning  \n",
      "index        CTD_LGBMClassifier_no_hypertuning  \n",
      "index                 CTD_SVC_with_hypertuning  \n",
      "index       CTD_XGBClassifier_with_hypertuning  \n",
      "index      CTD_LGBMClassifier_with_hypertuning  \n",
      "index    DPC_LogisticRegression_no_hypertuning  \n",
      "Evaluating DPC SVC\n",
      "      feature_type               model with_hypertuning  accuracy   \n",
      "index          AAC  LogisticRegression            False  0.870562  \\\n",
      "index          AAC                 SVC            False  0.895351   \n",
      "index          AAC       XGBClassifier            False  0.878837   \n",
      "index          AAC      LGBMClassifier            False  0.885530   \n",
      "index          AAC                 SVC             True  0.867679   \n",
      "index          AAC       XGBClassifier             True  0.891540   \n",
      "index          AAC      LGBMClassifier             True  0.885033   \n",
      "index        APAAC  LogisticRegression            False  0.874261   \n",
      "index        APAAC                 SVC            False  0.870301   \n",
      "index        APAAC       XGBClassifier            False  0.880982   \n",
      "index        APAAC      LGBMClassifier            False  0.885727   \n",
      "index        APAAC                 SVC             True  0.570499   \n",
      "index        APAAC       XGBClassifier             True  0.893709   \n",
      "index        APAAC      LGBMClassifier             True  0.895879   \n",
      "index          CTD  LogisticRegression            False  0.702615   \n",
      "index          CTD                 SVC            False  0.675452   \n",
      "index          CTD       XGBClassifier            False  0.854839   \n",
      "index          CTD      LGBMClassifier            False  0.858768   \n",
      "index          CTD                 SVC             True  0.555315   \n",
      "index          CTD       XGBClassifier             True  0.861171   \n",
      "index          CTD      LGBMClassifier             True  0.850325   \n",
      "index          DPC  LogisticRegression            False  0.862727   \n",
      "index          DPC                 SVC            False  0.893407   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.875000     0.924051   0.915888  0.894977  0.800787  \\\n",
      "index     0.825893     0.940928   0.929648  0.874704  0.773776   \n",
      "index     0.834821     0.915612   0.903382  0.867749  0.754064   \n",
      "index     0.812500     0.924051   0.910000  0.858491  0.742789   \n",
      "index     0.803571     0.928270   0.913706  0.855107  0.739401   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.830357     0.936709   0.925373  0.875294  0.773119   \n",
      "index     0.870536     0.928270   0.919811  0.894495  0.801072   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.825893     0.928270   0.915842  0.868545  0.759692   \n",
      "index     0.821429     0.924051   0.910891  0.863850  0.750945   \n",
      "index     0.129464     0.987342   0.906250  0.226562  0.229699   \n",
      "index     0.857143     0.928270   0.918660  0.886836  0.788538   \n",
      "index     0.852679     0.936709   0.927184  0.888372  0.793569   \n",
      "index     0.678571     0.548523   0.586873  0.629400  0.228760   \n",
      "index     0.866071     0.248945   0.521505  0.651007  0.145644   \n",
      "index     0.808036     0.869198   0.853774  0.830275  0.679156   \n",
      "index     0.767857     0.902954   0.882051  0.821002  0.678641   \n",
      "index     0.084821     1.000000   1.000000  0.156379  0.213263   \n",
      "index     0.803571     0.915612   0.900000  0.849057  0.725275   \n",
      "index     0.767857     0.928270   0.910053  0.832930  0.707410   \n",
      "index     0.852679     0.886076   0.876147  0.864253  0.739549   \n",
      "index     0.794643     0.945148   0.931937  0.857831  0.750600   \n",
      "\n",
      "                                         index  \n",
      "index    AAC_LogisticRegression_no_hypertuning  \n",
      "index                   AAC_SVC_no_hypertuning  \n",
      "index         AAC_XGBClassifier_no_hypertuning  \n",
      "index        AAC_LGBMClassifier_no_hypertuning  \n",
      "index                 AAC_SVC_with_hypertuning  \n",
      "index       AAC_XGBClassifier_with_hypertuning  \n",
      "index      AAC_LGBMClassifier_with_hypertuning  \n",
      "index  APAAC_LogisticRegression_no_hypertuning  \n",
      "index                 APAAC_SVC_no_hypertuning  \n",
      "index       APAAC_XGBClassifier_no_hypertuning  \n",
      "index      APAAC_LGBMClassifier_no_hypertuning  \n",
      "index               APAAC_SVC_with_hypertuning  \n",
      "index     APAAC_XGBClassifier_with_hypertuning  \n",
      "index    APAAC_LGBMClassifier_with_hypertuning  \n",
      "index    CTD_LogisticRegression_no_hypertuning  \n",
      "index                   CTD_SVC_no_hypertuning  \n",
      "index         CTD_XGBClassifier_no_hypertuning  \n",
      "index        CTD_LGBMClassifier_no_hypertuning  \n",
      "index                 CTD_SVC_with_hypertuning  \n",
      "index       CTD_XGBClassifier_with_hypertuning  \n",
      "index      CTD_LGBMClassifier_with_hypertuning  \n",
      "index    DPC_LogisticRegression_no_hypertuning  \n",
      "index                   DPC_SVC_no_hypertuning  \n",
      "Evaluating DPC XGBClassifier\n",
      "      feature_type               model with_hypertuning  accuracy   \n",
      "index          AAC  LogisticRegression            False  0.870562  \\\n",
      "index          AAC                 SVC            False  0.895351   \n",
      "index          AAC       XGBClassifier            False  0.878837   \n",
      "index          AAC      LGBMClassifier            False  0.885530   \n",
      "index          AAC                 SVC             True  0.867679   \n",
      "index          AAC       XGBClassifier             True  0.891540   \n",
      "index          AAC      LGBMClassifier             True  0.885033   \n",
      "index        APAAC  LogisticRegression            False  0.874261   \n",
      "index        APAAC                 SVC            False  0.870301   \n",
      "index        APAAC       XGBClassifier            False  0.880982   \n",
      "index        APAAC      LGBMClassifier            False  0.885727   \n",
      "index        APAAC                 SVC             True  0.570499   \n",
      "index        APAAC       XGBClassifier             True  0.893709   \n",
      "index        APAAC      LGBMClassifier             True  0.895879   \n",
      "index          CTD  LogisticRegression            False  0.702615   \n",
      "index          CTD                 SVC            False  0.675452   \n",
      "index          CTD       XGBClassifier            False  0.854839   \n",
      "index          CTD      LGBMClassifier            False  0.858768   \n",
      "index          CTD                 SVC             True  0.555315   \n",
      "index          CTD       XGBClassifier             True  0.861171   \n",
      "index          CTD      LGBMClassifier             True  0.850325   \n",
      "index          DPC  LogisticRegression            False  0.862727   \n",
      "index          DPC                 SVC            False  0.893407   \n",
      "index          DPC       XGBClassifier            False  0.877664   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.875000     0.924051   0.915888  0.894977  0.800787  \\\n",
      "index     0.825893     0.940928   0.929648  0.874704  0.773776   \n",
      "index     0.834821     0.915612   0.903382  0.867749  0.754064   \n",
      "index     0.812500     0.924051   0.910000  0.858491  0.742789   \n",
      "index     0.803571     0.928270   0.913706  0.855107  0.739401   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.830357     0.936709   0.925373  0.875294  0.773119   \n",
      "index     0.870536     0.928270   0.919811  0.894495  0.801072   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.825893     0.928270   0.915842  0.868545  0.759692   \n",
      "index     0.821429     0.924051   0.910891  0.863850  0.750945   \n",
      "index     0.129464     0.987342   0.906250  0.226562  0.229699   \n",
      "index     0.857143     0.928270   0.918660  0.886836  0.788538   \n",
      "index     0.852679     0.936709   0.927184  0.888372  0.793569   \n",
      "index     0.678571     0.548523   0.586873  0.629400  0.228760   \n",
      "index     0.866071     0.248945   0.521505  0.651007  0.145644   \n",
      "index     0.808036     0.869198   0.853774  0.830275  0.679156   \n",
      "index     0.767857     0.902954   0.882051  0.821002  0.678641   \n",
      "index     0.084821     1.000000   1.000000  0.156379  0.213263   \n",
      "index     0.803571     0.915612   0.900000  0.849057  0.725275   \n",
      "index     0.767857     0.928270   0.910053  0.832930  0.707410   \n",
      "index     0.852679     0.886076   0.876147  0.864253  0.739549   \n",
      "index     0.794643     0.945148   0.931937  0.857831  0.750600   \n",
      "index     0.812500     0.949367   0.938144  0.870813  0.771296   \n",
      "\n",
      "                                         index  \n",
      "index    AAC_LogisticRegression_no_hypertuning  \n",
      "index                   AAC_SVC_no_hypertuning  \n",
      "index         AAC_XGBClassifier_no_hypertuning  \n",
      "index        AAC_LGBMClassifier_no_hypertuning  \n",
      "index                 AAC_SVC_with_hypertuning  \n",
      "index       AAC_XGBClassifier_with_hypertuning  \n",
      "index      AAC_LGBMClassifier_with_hypertuning  \n",
      "index  APAAC_LogisticRegression_no_hypertuning  \n",
      "index                 APAAC_SVC_no_hypertuning  \n",
      "index       APAAC_XGBClassifier_no_hypertuning  \n",
      "index      APAAC_LGBMClassifier_no_hypertuning  \n",
      "index               APAAC_SVC_with_hypertuning  \n",
      "index     APAAC_XGBClassifier_with_hypertuning  \n",
      "index    APAAC_LGBMClassifier_with_hypertuning  \n",
      "index    CTD_LogisticRegression_no_hypertuning  \n",
      "index                   CTD_SVC_no_hypertuning  \n",
      "index         CTD_XGBClassifier_no_hypertuning  \n",
      "index        CTD_LGBMClassifier_no_hypertuning  \n",
      "index                 CTD_SVC_with_hypertuning  \n",
      "index       CTD_XGBClassifier_with_hypertuning  \n",
      "index      CTD_LGBMClassifier_with_hypertuning  \n",
      "index    DPC_LogisticRegression_no_hypertuning  \n",
      "index                   DPC_SVC_no_hypertuning  \n",
      "index         DPC_XGBClassifier_no_hypertuning  \n",
      "Evaluating DPC LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-13 11:36:18,291]\u001b[0m A new study created in memory with name: no-name-d4eab9ad-317c-410e-90bc-38548688c6b5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning  accuracy   \n",
      "index          AAC  LogisticRegression            False  0.870562  \\\n",
      "index          AAC                 SVC            False  0.895351   \n",
      "index          AAC       XGBClassifier            False  0.878837   \n",
      "index          AAC      LGBMClassifier            False  0.885530   \n",
      "index          AAC                 SVC             True  0.867679   \n",
      "index          AAC       XGBClassifier             True  0.891540   \n",
      "index          AAC      LGBMClassifier             True  0.885033   \n",
      "index        APAAC  LogisticRegression            False  0.874261   \n",
      "index        APAAC                 SVC            False  0.870301   \n",
      "index        APAAC       XGBClassifier            False  0.880982   \n",
      "index        APAAC      LGBMClassifier            False  0.885727   \n",
      "index        APAAC                 SVC             True  0.570499   \n",
      "index        APAAC       XGBClassifier             True  0.893709   \n",
      "index        APAAC      LGBMClassifier             True  0.895879   \n",
      "index          CTD  LogisticRegression            False  0.702615   \n",
      "index          CTD                 SVC            False  0.675452   \n",
      "index          CTD       XGBClassifier            False  0.854839   \n",
      "index          CTD      LGBMClassifier            False  0.858768   \n",
      "index          CTD                 SVC             True  0.555315   \n",
      "index          CTD       XGBClassifier             True  0.861171   \n",
      "index          CTD      LGBMClassifier             True  0.850325   \n",
      "index          DPC  LogisticRegression            False  0.862727   \n",
      "index          DPC                 SVC            False  0.893407   \n",
      "index          DPC       XGBClassifier            False  0.877664   \n",
      "index          DPC      LGBMClassifier            False  0.878062   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.875000     0.924051   0.915888  0.894977  0.800787  \\\n",
      "index     0.825893     0.940928   0.929648  0.874704  0.773776   \n",
      "index     0.834821     0.915612   0.903382  0.867749  0.754064   \n",
      "index     0.812500     0.924051   0.910000  0.858491  0.742789   \n",
      "index     0.803571     0.928270   0.913706  0.855107  0.739401   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.830357     0.936709   0.925373  0.875294  0.773119   \n",
      "index     0.870536     0.928270   0.919811  0.894495  0.801072   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.825893     0.928270   0.915842  0.868545  0.759692   \n",
      "index     0.821429     0.924051   0.910891  0.863850  0.750945   \n",
      "index     0.129464     0.987342   0.906250  0.226562  0.229699   \n",
      "index     0.857143     0.928270   0.918660  0.886836  0.788538   \n",
      "index     0.852679     0.936709   0.927184  0.888372  0.793569   \n",
      "index     0.678571     0.548523   0.586873  0.629400  0.228760   \n",
      "index     0.866071     0.248945   0.521505  0.651007  0.145644   \n",
      "index     0.808036     0.869198   0.853774  0.830275  0.679156   \n",
      "index     0.767857     0.902954   0.882051  0.821002  0.678641   \n",
      "index     0.084821     1.000000   1.000000  0.156379  0.213263   \n",
      "index     0.803571     0.915612   0.900000  0.849057  0.725275   \n",
      "index     0.767857     0.928270   0.910053  0.832930  0.707410   \n",
      "index     0.852679     0.886076   0.876147  0.864253  0.739549   \n",
      "index     0.794643     0.945148   0.931937  0.857831  0.750600   \n",
      "index     0.812500     0.949367   0.938144  0.870813  0.771296   \n",
      "index     0.812500     0.915612   0.900990  0.854460  0.733450   \n",
      "\n",
      "                                         index  \n",
      "index    AAC_LogisticRegression_no_hypertuning  \n",
      "index                   AAC_SVC_no_hypertuning  \n",
      "index         AAC_XGBClassifier_no_hypertuning  \n",
      "index        AAC_LGBMClassifier_no_hypertuning  \n",
      "index                 AAC_SVC_with_hypertuning  \n",
      "index       AAC_XGBClassifier_with_hypertuning  \n",
      "index      AAC_LGBMClassifier_with_hypertuning  \n",
      "index  APAAC_LogisticRegression_no_hypertuning  \n",
      "index                 APAAC_SVC_no_hypertuning  \n",
      "index       APAAC_XGBClassifier_no_hypertuning  \n",
      "index      APAAC_LGBMClassifier_no_hypertuning  \n",
      "index               APAAC_SVC_with_hypertuning  \n",
      "index     APAAC_XGBClassifier_with_hypertuning  \n",
      "index    APAAC_LGBMClassifier_with_hypertuning  \n",
      "index    CTD_LogisticRegression_no_hypertuning  \n",
      "index                   CTD_SVC_no_hypertuning  \n",
      "index         CTD_XGBClassifier_no_hypertuning  \n",
      "index        CTD_LGBMClassifier_no_hypertuning  \n",
      "index                 CTD_SVC_with_hypertuning  \n",
      "index       CTD_XGBClassifier_with_hypertuning  \n",
      "index      CTD_LGBMClassifier_with_hypertuning  \n",
      "index    DPC_LogisticRegression_no_hypertuning  \n",
      "index                   DPC_SVC_no_hypertuning  \n",
      "index         DPC_XGBClassifier_no_hypertuning  \n",
      "index        DPC_LGBMClassifier_no_hypertuning  \n",
      "Optimizing DPC SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-13 11:36:21,388]\u001b[0m Trial 0 finished with value: 0.5466377440347071 and parameters: {'svc_c': 96.31857904584875, 'svc_gamma': 99.13841856406363}. Best is trial 0 with value: 0.5466377440347071.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:36:24,569]\u001b[0m Trial 1 finished with value: 0.5488069414316703 and parameters: {'svc_c': 67.93430152588688, 'svc_gamma': 6.055161297419746}. Best is trial 1 with value: 0.5488069414316703.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:36:27,649]\u001b[0m Trial 2 finished with value: 0.5466377440347071 and parameters: {'svc_c': 70.75422077826076, 'svc_gamma': 65.33240490696714}. Best is trial 1 with value: 0.5488069414316703.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:36:30,819]\u001b[0m Trial 3 finished with value: 0.5466377440347071 and parameters: {'svc_c': 15.751894888513169, 'svc_gamma': 42.24731039157137}. Best is trial 1 with value: 0.5488069414316703.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:36:34,207]\u001b[0m Trial 4 finished with value: 0.5466377440347071 and parameters: {'svc_c': 61.741736887374515, 'svc_gamma': 29.303569983714517}. Best is trial 1 with value: 0.5488069414316703.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:36:37,502]\u001b[0m Trial 5 finished with value: 0.5466377440347071 and parameters: {'svc_c': 47.15043902734042, 'svc_gamma': 88.56965618490128}. Best is trial 1 with value: 0.5488069414316703.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:36:40,793]\u001b[0m Trial 6 finished with value: 0.5466377440347071 and parameters: {'svc_c': 98.57309485576245, 'svc_gamma': 57.12877154697767}. Best is trial 1 with value: 0.5488069414316703.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-13 11:36:44,129]\u001b[0m Trial 7 finished with value: 0.5140997830802603 and parameters: {'svc_c': 0.41045448294505904, 'svc_gamma': 42.48104080446621}. Best is trial 1 with value: 0.5488069414316703.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:36:47,454]\u001b[0m Trial 8 finished with value: 0.5466377440347071 and parameters: {'svc_c': 47.856887260962814, 'svc_gamma': 25.369133399808813}. Best is trial 1 with value: 0.5488069414316703.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:36:50,716]\u001b[0m Trial 9 finished with value: 0.5466377440347071 and parameters: {'svc_c': 80.73431386654624, 'svc_gamma': 52.88971170447927}. Best is trial 1 with value: 0.5488069414316703.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:36:54,069]\u001b[0m Trial 10 finished with value: 0.5509761388286334 and parameters: {'svc_c': 38.473312305590774, 'svc_gamma': 1.4940617255466533}. Best is trial 10 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:36:57,352]\u001b[0m Trial 11 finished with value: 0.5509761388286334 and parameters: {'svc_c': 34.609232595740615, 'svc_gamma': 0.6628932080542572}. Best is trial 10 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:37:00,646]\u001b[0m Trial 12 finished with value: 0.5509761388286334 and parameters: {'svc_c': 37.355167387514484, 'svc_gamma': 0.8483997798269769}. Best is trial 10 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:37:04,172]\u001b[0m Trial 13 finished with value: 0.5466377440347071 and parameters: {'svc_c': 33.78755427033461, 'svc_gamma': 12.913695161016292}. Best is trial 10 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:37:07,486]\u001b[0m Trial 14 finished with value: 0.5466377440347071 and parameters: {'svc_c': 28.73106538254971, 'svc_gamma': 14.900694925002275}. Best is trial 10 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:37:10,645]\u001b[0m Trial 15 finished with value: 0.5488069414316703 and parameters: {'svc_c': 23.182512872292296, 'svc_gamma': 5.8461083907848845}. Best is trial 10 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:37:13,835]\u001b[0m Trial 16 finished with value: 0.5466377440347071 and parameters: {'svc_c': 45.521991214961645, 'svc_gamma': 20.88243564415953}. Best is trial 10 with value: 0.5509761388286334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:37:16,897]\u001b[0m Trial 17 finished with value: 0.6030368763557483 and parameters: {'svc_c': 56.010241970836276, 'svc_gamma': 0.2853561798535836}. Best is trial 17 with value: 0.6030368763557483.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:37:20,174]\u001b[0m Trial 18 finished with value: 0.5466377440347071 and parameters: {'svc_c': 57.61400759228482, 'svc_gamma': 30.68543495571162}. Best is trial 17 with value: 0.6030368763557483.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:37:23,505]\u001b[0m Trial 19 finished with value: 0.5466377440347071 and parameters: {'svc_c': 55.36040587522157, 'svc_gamma': 11.363961372690213}. Best is trial 17 with value: 0.6030368763557483.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:37:26,768]\u001b[0m Trial 20 finished with value: 0.5466377440347071 and parameters: {'svc_c': 42.046319557319755, 'svc_gamma': 17.936667479518853}. Best is trial 17 with value: 0.6030368763557483.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:37:29,893]\u001b[0m Trial 21 finished with value: 0.5509761388286334 and parameters: {'svc_c': 34.92721483226763, 'svc_gamma': 0.8828229063634794}. Best is trial 17 with value: 0.6030368763557483.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:37:32,860]\u001b[0m Trial 22 finished with value: 0.5813449023861171 and parameters: {'svc_c': 52.10812817677691, 'svc_gamma': 0.34594057715517423}. Best is trial 17 with value: 0.6030368763557483.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:37:36,081]\u001b[0m Trial 23 finished with value: 0.5466377440347071 and parameters: {'svc_c': 50.97650820327225, 'svc_gamma': 10.456442292062977}. Best is trial 17 with value: 0.6030368763557483.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:37:39,313]\u001b[0m Trial 24 finished with value: 0.5466377440347071 and parameters: {'svc_c': 56.81962674721176, 'svc_gamma': 20.00530001498506}. Best is trial 17 with value: 0.6030368763557483.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:37:42,544]\u001b[0m Trial 25 finished with value: 0.5466377440347071 and parameters: {'svc_c': 41.82796179206529, 'svc_gamma': 10.69181571652065}. Best is trial 17 with value: 0.6030368763557483.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:37:45,625]\u001b[0m Trial 26 finished with value: 0.5509761388286334 and parameters: {'svc_c': 65.62718503096931, 'svc_gamma': 1.1307614561205939}. Best is trial 17 with value: 0.6030368763557483.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:37:48,776]\u001b[0m Trial 27 finished with value: 0.5466377440347071 and parameters: {'svc_c': 53.38054494217096, 'svc_gamma': 22.671492159805418}. Best is trial 17 with value: 0.6030368763557483.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:37:51,945]\u001b[0m Trial 28 finished with value: 0.5466377440347071 and parameters: {'svc_c': 72.57436885942968, 'svc_gamma': 10.225869794882003}. Best is trial 17 with value: 0.6030368763557483.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:37:55,061]\u001b[0m Trial 29 finished with value: 0.5466377440347071 and parameters: {'svc_c': 90.43234536989442, 'svc_gamma': 31.84952922039984}. Best is trial 17 with value: 0.6030368763557483.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:37:58,261]\u001b[0m Trial 30 finished with value: 0.5466377440347071 and parameters: {'svc_c': 60.96447150665037, 'svc_gamma': 15.946653407845302}. Best is trial 17 with value: 0.6030368763557483.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:38:01,332]\u001b[0m Trial 31 finished with value: 0.5488069414316703 and parameters: {'svc_c': 50.62003107467281, 'svc_gamma': 4.888729803190787}. Best is trial 17 with value: 0.6030368763557483.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:38:04,312]\u001b[0m Trial 32 finished with value: 0.5509761388286334 and parameters: {'svc_c': 41.29363433752461, 'svc_gamma': 0.5839445642618029}. Best is trial 17 with value: 0.6030368763557483.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:38:07,431]\u001b[0m Trial 33 finished with value: 0.5488069414316703 and parameters: {'svc_c': 27.826455032190385, 'svc_gamma': 7.123818658465101}. Best is trial 17 with value: 0.6030368763557483.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:38:10,565]\u001b[0m Trial 34 finished with value: 0.5488069414316703 and parameters: {'svc_c': 45.37637732744539, 'svc_gamma': 7.296444412564885}. Best is trial 17 with value: 0.6030368763557483.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:38:13,802]\u001b[0m Trial 35 finished with value: 0.5466377440347071 and parameters: {'svc_c': 38.37002867376766, 'svc_gamma': 15.863173827308577}. Best is trial 17 with value: 0.6030368763557483.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:38:16,852]\u001b[0m Trial 36 finished with value: 0.6355748373101953 and parameters: {'svc_c': 64.9709303982404, 'svc_gamma': 0.20902236270792013}. Best is trial 36 with value: 0.6355748373101953.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:38:20,123]\u001b[0m Trial 37 finished with value: 0.5488069414316703 and parameters: {'svc_c': 65.275763310249, 'svc_gamma': 7.133722840317974}. Best is trial 36 with value: 0.6355748373101953.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:38:23,153]\u001b[0m Trial 38 finished with value: 0.5466377440347071 and parameters: {'svc_c': 70.18578870074315, 'svc_gamma': 24.792159412872138}. Best is trial 36 with value: 0.6355748373101953.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:38:26,381]\u001b[0m Trial 39 finished with value: 0.5466377440347071 and parameters: {'svc_c': 60.35265045309063, 'svc_gamma': 14.625636602864041}. Best is trial 36 with value: 0.6355748373101953.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:38:29,344]\u001b[0m Trial 40 finished with value: 0.5466377440347071 and parameters: {'svc_c': 76.46402988419894, 'svc_gamma': 34.90685994720476}. Best is trial 36 with value: 0.6355748373101953.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:38:30,459]\u001b[0m Trial 41 finished with value: 0.8655097613882863 and parameters: {'svc_c': 50.313435041323025, 'svc_gamma': 0.011760511494206316}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:38:33,631]\u001b[0m Trial 42 finished with value: 0.5488069414316703 and parameters: {'svc_c': 51.96553211264847, 'svc_gamma': 4.901231928892922}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:38:36,666]\u001b[0m Trial 43 finished with value: 0.5488069414316703 and parameters: {'svc_c': 59.94314628725003, 'svc_gamma': 4.091705401764784}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:38:39,575]\u001b[0m Trial 44 finished with value: 0.5856832971800434 and parameters: {'svc_c': 64.85731996441281, 'svc_gamma': 0.31501908103226367}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:38:42,630]\u001b[0m Trial 45 finished with value: 0.5466377440347071 and parameters: {'svc_c': 68.1200177110169, 'svc_gamma': 8.613196123020847}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:38:45,841]\u001b[0m Trial 46 finished with value: 0.5466377440347071 and parameters: {'svc_c': 64.05926901320352, 'svc_gamma': 12.718424248530079}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:38:48,856]\u001b[0m Trial 47 finished with value: 0.6941431670281996 and parameters: {'svc_c': 55.6135759369438, 'svc_gamma': 0.12339701632244378}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:38:51,992]\u001b[0m Trial 48 finished with value: 0.5488069414316703 and parameters: {'svc_c': 56.55455293879736, 'svc_gamma': 6.096462747345185}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:38:54,982]\u001b[0m Trial 49 finished with value: 0.5466377440347071 and parameters: {'svc_c': 61.37395483989655, 'svc_gamma': 18.324187199375842}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:38:57,842]\u001b[0m Trial 50 finished with value: 0.5466377440347071 and parameters: {'svc_c': 46.58727641008291, 'svc_gamma': 25.853139002897507}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:39:00,680]\u001b[0m Trial 51 finished with value: 0.5531453362255966 and parameters: {'svc_c': 52.677373351222066, 'svc_gamma': 0.5509744681562192}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:39:03,578]\u001b[0m Trial 52 finished with value: 0.5488069414316703 and parameters: {'svc_c': 48.93745056854481, 'svc_gamma': 4.788250528975984}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:39:06,600]\u001b[0m Trial 53 finished with value: 0.5466377440347071 and parameters: {'svc_c': 55.266813816687794, 'svc_gamma': 11.211589395860976}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:39:09,638]\u001b[0m Trial 54 finished with value: 0.5488069414316703 and parameters: {'svc_c': 63.211565864671, 'svc_gamma': 3.786111951739576}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:39:12,642]\u001b[0m Trial 55 finished with value: 0.5553145336225597 and parameters: {'svc_c': 67.49189622492575, 'svc_gamma': 0.4902529999035916}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:39:15,688]\u001b[0m Trial 56 finished with value: 0.5466377440347071 and parameters: {'svc_c': 57.66679634837265, 'svc_gamma': 9.302533966133632}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:39:18,623]\u001b[0m Trial 57 finished with value: 0.5466377440347071 and parameters: {'svc_c': 49.758699178441894, 'svc_gamma': 14.246599762204426}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:39:21,714]\u001b[0m Trial 58 finished with value: 0.5466377440347071 and parameters: {'svc_c': 73.24599012514896, 'svc_gamma': 8.463526492427176}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:39:24,680]\u001b[0m Trial 59 finished with value: 0.5488069414316703 and parameters: {'svc_c': 52.79753067152861, 'svc_gamma': 3.686246163618179}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:39:27,713]\u001b[0m Trial 60 finished with value: 0.5509761388286334 and parameters: {'svc_c': 58.15754550424648, 'svc_gamma': 3.338553878659169}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:39:30,687]\u001b[0m Trial 61 finished with value: 0.6377440347071583 and parameters: {'svc_c': 66.31293726236105, 'svc_gamma': 0.2032810630137255}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:39:33,660]\u001b[0m Trial 62 finished with value: 0.5509761388286334 and parameters: {'svc_c': 64.10048148818328, 'svc_gamma': 3.3314252967617017}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:39:36,846]\u001b[0m Trial 63 finished with value: 0.5466377440347071 and parameters: {'svc_c': 68.55415482391666, 'svc_gamma': 8.394063077782034}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:39:39,811]\u001b[0m Trial 64 finished with value: 0.5553145336225597 and parameters: {'svc_c': 54.12163961154959, 'svc_gamma': 0.4955272496292459}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:39:43,009]\u001b[0m Trial 65 finished with value: 0.5466377440347071 and parameters: {'svc_c': 59.91747931143787, 'svc_gamma': 12.689910309622396}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:39:46,175]\u001b[0m Trial 66 finished with value: 0.5488069414316703 and parameters: {'svc_c': 65.60607816409455, 'svc_gamma': 6.444433978213835}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:39:49,316]\u001b[0m Trial 67 finished with value: 0.6681127982646421 and parameters: {'svc_c': 47.759014038529564, 'svc_gamma': 0.1447104746699477}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:39:52,477]\u001b[0m Trial 68 finished with value: 0.5466377440347071 and parameters: {'svc_c': 45.75796250237845, 'svc_gamma': 10.53354273423238}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:39:55,472]\u001b[0m Trial 69 finished with value: 0.5509761388286334 and parameters: {'svc_c': 56.65387586653195, 'svc_gamma': 3.4979838614403853}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:39:58,495]\u001b[0m Trial 70 finished with value: 0.5466377440347071 and parameters: {'svc_c': 62.774296462989646, 'svc_gamma': 18.940943811184525}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:40:01,370]\u001b[0m Trial 71 finished with value: 0.5509761388286334 and parameters: {'svc_c': 48.89289415231971, 'svc_gamma': 2.3763473839825755}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:40:04,268]\u001b[0m Trial 72 finished with value: 0.5488069414316703 and parameters: {'svc_c': 55.218407522794976, 'svc_gamma': 6.64260845867803}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:40:07,021]\u001b[0m Trial 73 finished with value: 0.5661605206073753 and parameters: {'svc_c': 59.194483878688686, 'svc_gamma': 0.4112842276607777}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:40:09,917]\u001b[0m Trial 74 finished with value: 0.5639913232104121 and parameters: {'svc_c': 51.933998437099206, 'svc_gamma': 0.44014251616082073}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:40:12,931]\u001b[0m Trial 75 finished with value: 0.5488069414316703 and parameters: {'svc_c': 43.26059645677165, 'svc_gamma': 6.477839034828377}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:40:15,915]\u001b[0m Trial 76 finished with value: 0.5466377440347071 and parameters: {'svc_c': 61.340699211054385, 'svc_gamma': 12.34640723397614}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:40:18,899]\u001b[0m Trial 77 finished with value: 0.5466377440347071 and parameters: {'svc_c': 47.353311793492466, 'svc_gamma': 16.321367138642287}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:40:22,105]\u001b[0m Trial 78 finished with value: 0.5466377440347071 and parameters: {'svc_c': 49.8362130747184, 'svc_gamma': 8.704627651591982}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:40:25,200]\u001b[0m Trial 79 finished with value: 0.5509761388286334 and parameters: {'svc_c': 54.404955989651896, 'svc_gamma': 3.032224970828267}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:40:28,240]\u001b[0m Trial 80 finished with value: 0.5488069414316703 and parameters: {'svc_c': 66.29681822517553, 'svc_gamma': 5.32337814979642}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:40:31,253]\u001b[0m Trial 81 finished with value: 0.5509761388286334 and parameters: {'svc_c': 58.149714737075705, 'svc_gamma': 2.316377013670471}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:40:34,127]\u001b[0m Trial 82 finished with value: 0.6572668112798264 and parameters: {'svc_c': 59.977125135320144, 'svc_gamma': 0.1673128284685938}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:40:36,990]\u001b[0m Trial 83 finished with value: 0.6052060737527115 and parameters: {'svc_c': 71.27480307383426, 'svc_gamma': 0.27805301879509486}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:40:40,060]\u001b[0m Trial 84 finished with value: 0.5488069414316703 and parameters: {'svc_c': 71.01775840992391, 'svc_gamma': 5.015125293061655}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:40:42,960]\u001b[0m Trial 85 finished with value: 0.6681127982646421 and parameters: {'svc_c': 62.58424146044168, 'svc_gamma': 0.14852425063758373}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:40:46,096]\u001b[0m Trial 86 finished with value: 0.5466377440347071 and parameters: {'svc_c': 61.877275688839404, 'svc_gamma': 9.803213980404836}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:40:49,223]\u001b[0m Trial 87 finished with value: 0.5488069414316703 and parameters: {'svc_c': 74.8134110612205, 'svc_gamma': 7.403935377214547}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:40:52,275]\u001b[0m Trial 88 finished with value: 0.5509761388286334 and parameters: {'svc_c': 68.05113978074627, 'svc_gamma': 3.0263691137136646}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:40:55,325]\u001b[0m Trial 89 finished with value: 0.5488069414316703 and parameters: {'svc_c': 70.07710479163049, 'svc_gamma': 5.079414925881698}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:40:58,503]\u001b[0m Trial 90 finished with value: 0.5466377440347071 and parameters: {'svc_c': 62.666014080344596, 'svc_gamma': 11.872962825690331}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:41:01,385]\u001b[0m Trial 91 finished with value: 0.6420824295010846 and parameters: {'svc_c': 65.20631381984917, 'svc_gamma': 0.1832770151167178}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:41:04,231]\u001b[0m Trial 92 finished with value: 0.7114967462039046 and parameters: {'svc_c': 66.77181038181975, 'svc_gamma': 0.10820103957455687}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:41:07,225]\u001b[0m Trial 93 finished with value: 0.5509761388286334 and parameters: {'svc_c': 77.51496000247244, 'svc_gamma': 2.4281649922149615}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:41:10,326]\u001b[0m Trial 94 finished with value: 0.5509761388286334 and parameters: {'svc_c': 70.1611926165321, 'svc_gamma': 2.2269986956229837}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:41:13,355]\u001b[0m Trial 95 finished with value: 0.5488069414316703 and parameters: {'svc_c': 64.58929399871543, 'svc_gamma': 5.494389764068987}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:41:16,906]\u001b[0m Trial 96 finished with value: 0.5466377440347071 and parameters: {'svc_c': 67.16202190465188, 'svc_gamma': 8.307494041735499}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:41:19,988]\u001b[0m Trial 97 finished with value: 0.5509761388286334 and parameters: {'svc_c': 58.78908353394081, 'svc_gamma': 2.5049834108577893}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:41:22,544]\u001b[0m Trial 98 finished with value: 0.7700650759219089 and parameters: {'svc_c': 71.73905597377208, 'svc_gamma': 0.06924905748096916}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:41:25,529]\u001b[0m Trial 99 finished with value: 0.5488069414316703 and parameters: {'svc_c': 72.85437439130462, 'svc_gamma': 4.814159928047049}. Best is trial 41 with value: 0.8655097613882863.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:41:25,538]\u001b[0m A new study created in memory with name: no-name-2deec53c-9013-4c36-8b9c-4fc16853e1a6\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_type               model with_hypertuning  accuracy   \n",
      "index          AAC  LogisticRegression            False  0.870562  \\\n",
      "index          AAC                 SVC            False  0.895351   \n",
      "index          AAC       XGBClassifier            False  0.878837   \n",
      "index          AAC      LGBMClassifier            False  0.885530   \n",
      "index          AAC                 SVC             True  0.867679   \n",
      "index          AAC       XGBClassifier             True  0.891540   \n",
      "index          AAC      LGBMClassifier             True  0.885033   \n",
      "index        APAAC  LogisticRegression            False  0.874261   \n",
      "index        APAAC                 SVC            False  0.870301   \n",
      "index        APAAC       XGBClassifier            False  0.880982   \n",
      "index        APAAC      LGBMClassifier            False  0.885727   \n",
      "index        APAAC                 SVC             True  0.570499   \n",
      "index        APAAC       XGBClassifier             True  0.893709   \n",
      "index        APAAC      LGBMClassifier             True  0.895879   \n",
      "index          CTD  LogisticRegression            False  0.702615   \n",
      "index          CTD                 SVC            False  0.675452   \n",
      "index          CTD       XGBClassifier            False  0.854839   \n",
      "index          CTD      LGBMClassifier            False  0.858768   \n",
      "index          CTD                 SVC             True  0.555315   \n",
      "index          CTD       XGBClassifier             True  0.861171   \n",
      "index          CTD      LGBMClassifier             True  0.850325   \n",
      "index          DPC  LogisticRegression            False  0.862727   \n",
      "index          DPC                 SVC            False  0.893407   \n",
      "index          DPC       XGBClassifier            False  0.877664   \n",
      "index          DPC      LGBMClassifier            False  0.878062   \n",
      "index          DPC                 SVC             True  0.865510   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.875000     0.924051   0.915888  0.894977  0.800787  \\\n",
      "index     0.825893     0.940928   0.929648  0.874704  0.773776   \n",
      "index     0.834821     0.915612   0.903382  0.867749  0.754064   \n",
      "index     0.812500     0.924051   0.910000  0.858491  0.742789   \n",
      "index     0.803571     0.928270   0.913706  0.855107  0.739401   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.830357     0.936709   0.925373  0.875294  0.773119   \n",
      "index     0.870536     0.928270   0.919811  0.894495  0.801072   \n",
      "index     0.843750     0.936709   0.926471  0.883178  0.785356   \n",
      "index     0.825893     0.928270   0.915842  0.868545  0.759692   \n",
      "index     0.821429     0.924051   0.910891  0.863850  0.750945   \n",
      "index     0.129464     0.987342   0.906250  0.226562  0.229699   \n",
      "index     0.857143     0.928270   0.918660  0.886836  0.788538   \n",
      "index     0.852679     0.936709   0.927184  0.888372  0.793569   \n",
      "index     0.678571     0.548523   0.586873  0.629400  0.228760   \n",
      "index     0.866071     0.248945   0.521505  0.651007  0.145644   \n",
      "index     0.808036     0.869198   0.853774  0.830275  0.679156   \n",
      "index     0.767857     0.902954   0.882051  0.821002  0.678641   \n",
      "index     0.084821     1.000000   1.000000  0.156379  0.213263   \n",
      "index     0.803571     0.915612   0.900000  0.849057  0.725275   \n",
      "index     0.767857     0.928270   0.910053  0.832930  0.707410   \n",
      "index     0.852679     0.886076   0.876147  0.864253  0.739549   \n",
      "index     0.794643     0.945148   0.931937  0.857831  0.750600   \n",
      "index     0.812500     0.949367   0.938144  0.870813  0.771296   \n",
      "index     0.812500     0.915612   0.900990  0.854460  0.733450   \n",
      "index     0.812500     0.915612   0.900990  0.854460  0.733450   \n",
      "\n",
      "                                         index  \n",
      "index    AAC_LogisticRegression_no_hypertuning  \n",
      "index                   AAC_SVC_no_hypertuning  \n",
      "index         AAC_XGBClassifier_no_hypertuning  \n",
      "index        AAC_LGBMClassifier_no_hypertuning  \n",
      "index                 AAC_SVC_with_hypertuning  \n",
      "index       AAC_XGBClassifier_with_hypertuning  \n",
      "index      AAC_LGBMClassifier_with_hypertuning  \n",
      "index  APAAC_LogisticRegression_no_hypertuning  \n",
      "index                 APAAC_SVC_no_hypertuning  \n",
      "index       APAAC_XGBClassifier_no_hypertuning  \n",
      "index      APAAC_LGBMClassifier_no_hypertuning  \n",
      "index               APAAC_SVC_with_hypertuning  \n",
      "index     APAAC_XGBClassifier_with_hypertuning  \n",
      "index    APAAC_LGBMClassifier_with_hypertuning  \n",
      "index    CTD_LogisticRegression_no_hypertuning  \n",
      "index                   CTD_SVC_no_hypertuning  \n",
      "index         CTD_XGBClassifier_no_hypertuning  \n",
      "index        CTD_LGBMClassifier_no_hypertuning  \n",
      "index                 CTD_SVC_with_hypertuning  \n",
      "index       CTD_XGBClassifier_with_hypertuning  \n",
      "index      CTD_LGBMClassifier_with_hypertuning  \n",
      "index    DPC_LogisticRegression_no_hypertuning  \n",
      "index                   DPC_SVC_no_hypertuning  \n",
      "index         DPC_XGBClassifier_no_hypertuning  \n",
      "index        DPC_LGBMClassifier_no_hypertuning  \n",
      "index                 DPC_SVC_with_hypertuning  \n",
      "Optimizing DPC XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-13 11:41:27,512]\u001b[0m Trial 0 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.117932374925602, 'max_depth': 4, 'n_estimators': 153}. Best is trial 0 with value: 0.8763557483731019.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:41:30,853]\u001b[0m Trial 1 finished with value: 0.8698481561822126 and parameters: {'learning_rate': 0.263676449979134, 'max_depth': 3, 'n_estimators': 374}. Best is trial 0 with value: 0.8763557483731019.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:41:43,922]\u001b[0m Trial 2 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.09859988627417328, 'max_depth': 5, 'n_estimators': 890}. Best is trial 0 with value: 0.8763557483731019.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:41:50,131]\u001b[0m Trial 3 finished with value: 0.8720173535791758 and parameters: {'learning_rate': 0.2298134275342802, 'max_depth': 3, 'n_estimators': 439}. Best is trial 0 with value: 0.8763557483731019.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:41:53,208]\u001b[0m Trial 4 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.11111080307020156, 'max_depth': 5, 'n_estimators': 150}. Best is trial 0 with value: 0.8763557483731019.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:41:58,359]\u001b[0m Trial 5 finished with value: 0.8785249457700651 and parameters: {'learning_rate': 0.1703392042861312, 'max_depth': 3, 'n_estimators': 433}. Best is trial 5 with value: 0.8785249457700651.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:42:05,385]\u001b[0m Trial 6 finished with value: 0.8720173535791758 and parameters: {'learning_rate': 0.048046753314051824, 'max_depth': 4, 'n_estimators': 405}. Best is trial 5 with value: 0.8785249457700651.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:42:27,925]\u001b[0m Trial 7 finished with value: 0.8828633405639913 and parameters: {'learning_rate': 0.10145911737796039, 'max_depth': 6, 'n_estimators': 735}. Best is trial 7 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:42:38,685]\u001b[0m Trial 8 finished with value: 0.8698481561822126 and parameters: {'learning_rate': 0.2902978593876055, 'max_depth': 2, 'n_estimators': 988}. Best is trial 7 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:42:57,106]\u001b[0m Trial 9 finished with value: 0.8655097613882863 and parameters: {'learning_rate': 0.019949947180176876, 'max_depth': 6, 'n_estimators': 652}. Best is trial 7 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:43:12,314]\u001b[0m Trial 10 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.17150883918640664, 'max_depth': 6, 'n_estimators': 720}. Best is trial 7 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:43:19,801]\u001b[0m Trial 11 finished with value: 0.8720173535791758 and parameters: {'learning_rate': 0.1797496035754943, 'max_depth': 2, 'n_estimators': 727}. Best is trial 7 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:43:26,828]\u001b[0m Trial 12 finished with value: 0.8785249457700651 and parameters: {'learning_rate': 0.2108611888799889, 'max_depth': 3, 'n_estimators': 568}. Best is trial 7 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:43:40,542]\u001b[0m Trial 13 finished with value: 0.8828633405639913 and parameters: {'learning_rate': 0.139716072140151, 'max_depth': 5, 'n_estimators': 815}. Best is trial 7 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:43:54,577]\u001b[0m Trial 14 finished with value: 0.8763557483731019 and parameters: {'learning_rate': 0.13253730867985247, 'max_depth': 5, 'n_estimators': 851}. Best is trial 7 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:44:10,092]\u001b[0m Trial 15 finished with value: 0.8828633405639913 and parameters: {'learning_rate': 0.07614771722122805, 'max_depth': 6, 'n_estimators': 812}. Best is trial 7 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:44:26,231]\u001b[0m Trial 16 finished with value: 0.8828633405639913 and parameters: {'learning_rate': 0.14077722371228127, 'max_depth': 5, 'n_estimators': 958}. Best is trial 7 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:44:38,677]\u001b[0m Trial 17 finished with value: 0.8741865509761388 and parameters: {'learning_rate': 0.07163226705107965, 'max_depth': 6, 'n_estimators': 589}. Best is trial 7 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:44:52,777]\u001b[0m Trial 18 finished with value: 0.8828633405639913 and parameters: {'learning_rate': 0.14508314676000839, 'max_depth': 4, 'n_estimators': 761}. Best is trial 7 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:45:21,172]\u001b[0m Trial 19 finished with value: 0.8806941431670282 and parameters: {'learning_rate': 0.10160733149761284, 'max_depth': 5, 'n_estimators': 660}. Best is trial 7 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:45:43,867]\u001b[0m Trial 20 finished with value: 0.8698481561822126 and parameters: {'learning_rate': 0.07597095959507262, 'max_depth': 6, 'n_estimators': 908}. Best is trial 7 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:46:01,628]\u001b[0m Trial 21 finished with value: 0.8785249457700651 and parameters: {'learning_rate': 0.07002004873725783, 'max_depth': 6, 'n_estimators': 809}. Best is trial 7 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:46:37,428]\u001b[0m Trial 22 finished with value: 0.8698481561822126 and parameters: {'learning_rate': 0.011936354204167929, 'max_depth': 6, 'n_estimators': 818}. Best is trial 7 with value: 0.8828633405639913.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:46:54,917]\u001b[0m Trial 23 finished with value: 0.8850325379609545 and parameters: {'learning_rate': 0.12679112317793442, 'max_depth': 5, 'n_estimators': 664}. Best is trial 23 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:47:05,848]\u001b[0m Trial 24 finished with value: 0.8806941431670282 and parameters: {'learning_rate': 0.12434890660029302, 'max_depth': 5, 'n_estimators': 498}. Best is trial 23 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:47:17,977]\u001b[0m Trial 25 finished with value: 0.8698481561822126 and parameters: {'learning_rate': 0.16309760515768762, 'max_depth': 5, 'n_estimators': 630}. Best is trial 23 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:47:22,858]\u001b[0m Trial 26 finished with value: 0.8806941431670282 and parameters: {'learning_rate': 0.14135124892193235, 'max_depth': 4, 'n_estimators': 259}. Best is trial 23 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:47:34,942]\u001b[0m Trial 27 finished with value: 0.8806941431670282 and parameters: {'learning_rate': 0.09851426754006899, 'max_depth': 5, 'n_estimators': 517}. Best is trial 23 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:47:47,921]\u001b[0m Trial 28 finished with value: 0.8850325379609545 and parameters: {'learning_rate': 0.1547269053280842, 'max_depth': 4, 'n_estimators': 740}. Best is trial 23 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:48:00,300]\u001b[0m Trial 29 finished with value: 0.8785249457700651 and parameters: {'learning_rate': 0.11700876611691605, 'max_depth': 4, 'n_estimators': 696}. Best is trial 23 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:48:12,273]\u001b[0m Trial 30 finished with value: 0.8720173535791758 and parameters: {'learning_rate': 0.1879092748559185, 'max_depth': 4, 'n_estimators': 759}. Best is trial 23 with value: 0.8850325379609545.\u001b[0m\n",
      "\u001b[32m[I 2023-05-13 11:48:23,193]\u001b[0m Trial 31 finished with value: 0.8828633405639913 and parameters: {'learning_rate': 0.1587630362543204, 'max_depth': 4, 'n_estimators': 608}. Best is trial 23 with value: 0.8850325379609545.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, recall_score, precision_score, f1_score\n",
    "\n",
    "import optuna\n",
    "\n",
    "data_dir = '/home/darshana/Projects/druggable_proteins/processed_dataset'\n",
    "\n",
    "feature_types = ['AAC', 'APAAC', 'CTD', 'DPC', 'PAAC']\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "\n",
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test, results_dataframe, feature_type):\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    accuracy = scores.mean()\n",
    "\n",
    "    # fit the model on the training set\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict the test set results\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # compute the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # calculate precision, recall (sensitivity), f1-score\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # calculate specificity\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "\n",
    "    # calculate MCC\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "    temp_df = pd.DataFrame({\n",
    "        'feature_type': feature_type, \n",
    "        'model': name, \n",
    "        'with_hypertuning': False, \n",
    "        'accuracy': accuracy, \n",
    "        'sensitivity': recall, \n",
    "        'specificity': specificity, \n",
    "        'precision': precision, \n",
    "        'f1': f1, \n",
    "        'mcc': mcc,\n",
    "        'index': f'{feature_type}_{name}_no_hypertuning'\n",
    "        }, index=['index'])\n",
    "    # results_dataframe is an empty dataframe to store results with the columns feature_type, model, with_hypertuning, accuracy, sensitivity, specificity, precision, f1, mcc\n",
    "    return pd.concat([results_dataframe, temp_df])\n",
    "\n",
    "\n",
    "def optimize_hyperparameters(name, model, objective, trials, results_dataframe, feature_type):\n",
    "    def optuna_objective(trial):\n",
    "        params = objective(trial)\n",
    "        model_instance = model(**params)\n",
    "        model_instance.fit(X_train, y_train)\n",
    "        y_pred = model_instance.predict(X_test)\n",
    "\n",
    "        # compute the confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        # calculate precision, recall (sensitivity), f1-score\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        # calculate specificity\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        specificity = tn / (tn+fp)\n",
    "\n",
    "        # calculate MCC\n",
    "        mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "        # Set user attributes\n",
    "        trial.set_user_attr(\"precision\", precision)\n",
    "        trial.set_user_attr(\"recall\", recall)\n",
    "        trial.set_user_attr(\"f1\", f1)\n",
    "        trial.set_user_attr(\"specificity\", specificity)\n",
    "        trial.set_user_attr(\"mcc\", mcc)\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(optuna_objective, n_trials=trials)\n",
    "\n",
    "    temp_df = pd.DataFrame({\n",
    "        'feature_type': feature_type, \n",
    "        'model': name, \n",
    "        'with_hypertuning': True, \n",
    "        'accuracy': study.best_trial.value, \n",
    "        'sensitivity': study.best_trial.user_attrs['recall'], \n",
    "        'specificity': study.best_trial.user_attrs['specificity'], \n",
    "        'precision': study.best_trial.user_attrs['precision'], \n",
    "        'f1': study.best_trial.user_attrs['f1'], \n",
    "        'mcc': study.best_trial.user_attrs['mcc'],\n",
    "        'index': f'{feature_type}_{name}_with_hypertuning'\n",
    "        }, index=['index'])\n",
    "    results_dataframe = pd.concat([results_dataframe, temp_df])\n",
    "    return results_dataframe\n",
    "\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'SVC': SVC(),\n",
    "    'XGBClassifier': XGBClassifier(),\n",
    "    'LGBMClassifier': LGBMClassifier()\n",
    "}\n",
    "\n",
    "models_ = {\n",
    "    'LogisticRegression': LogisticRegression,\n",
    "    'SVC': SVC,\n",
    "    'XGBClassifier': XGBClassifier,\n",
    "    'LGBMClassifier': LGBMClassifier\n",
    "}\n",
    "\n",
    "# Define objectives for hyperparameters tuning\n",
    "objectives = {\n",
    "    'LogisticRegression': None,  # no tuning for LogisticRegression in your original code\n",
    "    'SVC': lambda trial: {\n",
    "        'C': trial.suggest_float('svc_c', 1e-2, 1e2),\n",
    "        'gamma': trial.suggest_float('svc_gamma', 1e-2, 1e2),\n",
    "    },\n",
    "    'XGBClassifier': lambda trial: {\n",
    "        'learning_rate': trial.suggest_float(\"learning_rate\", 1e-2, 0.3),\n",
    "        'max_depth': trial.suggest_int(\"max_depth\", 2, 6),\n",
    "        'n_estimators': trial.suggest_int(\"n_estimators\", 100, 1000)\n",
    "    },\n",
    "    'LGBMClassifier': lambda trial: {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 50),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 2000)\n",
    "    }\n",
    "}\n",
    "\n",
    "# empty dataframe to store results with the columns feature_type, model, with_hypertuning, accuracy, sensitivity, specificity, precision, f1, mcc\n",
    "results = pd.DataFrame(columns=['feature_type', 'model', 'with_hypertuning', 'accuracy', 'sensitivity', 'specificity', 'precision', 'f1', 'mcc', 'index'])\n",
    "\n",
    "for feature_type in feature_types:\n",
    "\n",
    "    # Load the training dataset\n",
    "    train_data = pd.read_csv(f'{data_dir}/TR_{feature_type}.csv')\n",
    "    test_data = pd.read_csv(f'{data_dir}/TS_{feature_type}.csv')\n",
    "\n",
    "    # Separate features and target\n",
    "    X_train = train_data.drop(columns=['label', 'id'], axis=1)\n",
    "    y_train = train_data['label']\n",
    "\n",
    "    X_test = test_data.drop(columns=['label', 'id'], axis=1)\n",
    "    y_test = test_data['label']\n",
    "\n",
    "    # Evaluate models without hyperparameters tuning\n",
    "    for name, model in models.items():\n",
    "        print(f\"Evaluating {feature_type} {name}\")\n",
    "        results = evaluate_model(name, model, X_train, y_train, X_test, y_test, results, feature_type)\n",
    "        print(results)\n",
    "\n",
    "    # Optimize hyperparameters\n",
    "    for name, model in models_.items():\n",
    "        objective = objectives.get(name)\n",
    "        if objective is not None:\n",
    "            print(f\"Optimizing {feature_type} {name}\")\n",
    "            results = optimize_hyperparameters(name, model, objective, trials=100, results_dataframe=results, feature_type=feature_type)\n",
    "            print(results)\n",
    "\n",
    "results.to_csv('results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "druggable_proteins",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
