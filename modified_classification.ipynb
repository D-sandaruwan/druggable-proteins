{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import optuna\n",
    "import ast\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, recall_score, precision_score, f1_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "data_dir = '/home/darshana/Projects/druggable_proteins/processed_dataset'\n",
    "feature_engineered_data_dir = '/home/darshana/Projects/druggable_proteins/feature_engineered_dataset'\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "\n",
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test, results_dataframe, feature_type):\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    accuracy = scores.mean()\n",
    "\n",
    "    # fit the model on the training set\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict the test set results\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # compute the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # calculate precision, recall (sensitivity), f1-score\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # calculate specificity\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "\n",
    "    # calculate MCC\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "    temp_df = pd.DataFrame({\n",
    "        'feature_type': feature_type, \n",
    "        'model': name, \n",
    "        'with_hypertuning': False,\n",
    "        'best_params': 'None',\n",
    "        'accuracy': accuracy, \n",
    "        'sensitivity': recall, \n",
    "        'specificity': specificity, \n",
    "        'precision': precision, \n",
    "        'f1': f1, \n",
    "        'mcc': mcc,\n",
    "        'index': f'{feature_type}_{name}_no_hypertuning'\n",
    "        }, index=['index'])\n",
    "    # results_dataframe is an empty dataframe to store results with the columns feature_type, model, with_hypertuning, accuracy, sensitivity, specificity, precision, f1, mcc\n",
    "    return pd.concat([results_dataframe, temp_df])\n",
    "\n",
    "\n",
    "def optimize_hyperparameters(name, model, objective, trials, results_dataframe, feature_type, X_train, y_train, X_test, y_test):\n",
    "    def optuna_objective(trial):\n",
    "        params = objective(trial)\n",
    "        model_instance = model(**params)\n",
    "        model_instance.fit(X_train, y_train)\n",
    "        y_pred = model_instance.predict(X_test)\n",
    "\n",
    "        # compute the confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        # calculate precision, recall (sensitivity), f1-score\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        # calculate specificity\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        specificity = tn / (tn+fp)\n",
    "\n",
    "        # calculate MCC\n",
    "        mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "        # Set user attributes\n",
    "        trial.set_user_attr(\"precision\", precision)\n",
    "        trial.set_user_attr(\"recall\", recall)\n",
    "        trial.set_user_attr(\"f1\", f1)\n",
    "        trial.set_user_attr(\"specificity\", specificity)\n",
    "        trial.set_user_attr(\"mcc\", mcc)\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(optuna_objective, n_trials=trials)\n",
    "\n",
    "    temp_df = pd.DataFrame({\n",
    "        'feature_type': feature_type, \n",
    "        'model': name, \n",
    "        'with_hypertuning': True,\n",
    "        'best_params': [str(study.best_trial.params)],\n",
    "        'accuracy': study.best_trial.value, \n",
    "        'sensitivity': study.best_trial.user_attrs['recall'], \n",
    "        'specificity': study.best_trial.user_attrs['specificity'], \n",
    "        'precision': study.best_trial.user_attrs['precision'], \n",
    "        'f1': study.best_trial.user_attrs['f1'], \n",
    "        'mcc': study.best_trial.user_attrs['mcc'],\n",
    "        'index': f'{feature_type}_{name}_with_hypertuning'\n",
    "        }, index=['index'])\n",
    "    results_dataframe = pd.concat([results_dataframe, temp_df])\n",
    "    return results_dataframe\n",
    "\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'SVC': SVC(),\n",
    "    'XGBClassifier': XGBClassifier(),\n",
    "    'LGBMClassifier': LGBMClassifier()\n",
    "}\n",
    "\n",
    "models_ = {\n",
    "    'LogisticRegression': LogisticRegression,\n",
    "    'SVC': SVC,\n",
    "    'XGBClassifier': XGBClassifier,\n",
    "    'LGBMClassifier': LGBMClassifier\n",
    "}\n",
    "\n",
    "# Define objectives for hyperparameters tuning\n",
    "objectives = {\n",
    "    'LogisticRegression': lambda trial: {\n",
    "        'C': trial.suggest_float('C', 1e-2, 1e-1),\n",
    "        'penalty': trial.suggest_categorical('penalty', ['l1', 'l2']),\n",
    "        'solver': trial.suggest_categorical('solver', ['liblinear', 'saga']),\n",
    "        'max_iter': trial.suggest_int('max_iter', 100, 1000)\n",
    "    },\n",
    "    'SVC': lambda trial: {\n",
    "        'C': trial.suggest_float('svc_c', 1e-2, 1e2),\n",
    "        'gamma': trial.suggest_float('svc_gamma', 1e-2, 1e2),\n",
    "    },\n",
    "    'XGBClassifier': lambda trial: {\n",
    "        'learning_rate': trial.suggest_float(\"learning_rate\", 1e-2, 0.3),\n",
    "        'max_depth': trial.suggest_int(\"max_depth\", 2, 6),\n",
    "        'n_estimators': trial.suggest_int(\"n_estimators\", 100, 1000)\n",
    "    },\n",
    "    'LGBMClassifier': lambda trial: {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 50),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 2000)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty dataframe to store results with the columns feature_type, model, with_hypertuning, accuracy, sensitivity, specificity, precision, f1, mcc\n",
    "results = pd.DataFrame(columns=['feature_type', 'model', 'with_hypertuning', 'best_params', 'accuracy', 'sensitivity', 'specificity', 'precision', 'f1', 'mcc', 'index'])\n",
    "feature_types = ['AAC', 'APAAC', 'CTD', 'DPC', 'PAAC']\n",
    "for feature_type in feature_types:\n",
    "\n",
    "    # Load the training dataset\n",
    "    data = pd.read_csv(f'{data_dir}/TR_{feature_type}.csv')\n",
    "\n",
    "    # Separate features and target\n",
    "    X = data.drop(columns=['label', 'id'], axis=1)\n",
    "    y = data['label']\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Evaluate models without hyperparameters tuning\n",
    "    for name, model in models.items():\n",
    "        print(f\"Evaluating {feature_type} {name}\")\n",
    "        results = evaluate_model(name, model, X_train, y_train, X_test, y_test, results, feature_type)\n",
    "        print(results)\n",
    "\n",
    "    # Optimize hyperparameters\n",
    "    for name, model in models_.items():\n",
    "        objective = objectives.get(name)\n",
    "        if objective is not None:\n",
    "            print(f\"Optimizing {feature_type} {name}\")\n",
    "            results = optimize_hyperparameters(name, model, objective, trials=100, results_dataframe=results, feature_type=feature_type, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)\n",
    "            print(results)\n",
    "\n",
    "results.to_csv('results_v2.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating selected_features_all_best20 LogisticRegression\n",
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "\n",
      "      best_params  accuracy  sensitivity  specificity  precision        f1   \n",
      "index        None   0.86163     0.832653     0.850575   0.839506  0.836066  \\\n",
      "\n",
      "           mcc                                              index  \n",
      "index  0.68342  selected_features_all_best20_LogisticRegressio...  \n",
      "Evaluating selected_features_all_best20 SVC\n",
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "\n",
      "      best_params  accuracy  sensitivity  specificity  precision        f1   \n",
      "index        None  0.861630     0.832653     0.850575   0.839506  0.836066  \\\n",
      "index        None  0.884356     0.816327     0.915709   0.900901  0.856531   \n",
      "\n",
      "            mcc                                              index  \n",
      "index  0.683420  selected_features_all_best20_LogisticRegressio...  \n",
      "index  0.737224    selected_features_all_best20_SVC_no_hypertuning  \n",
      "Evaluating selected_features_all_best20 XGBClassifier\n",
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "\n",
      "      best_params  accuracy  sensitivity  specificity  precision        f1   \n",
      "index        None  0.861630     0.832653     0.850575   0.839506  0.836066  \\\n",
      "index        None  0.884356     0.816327     0.915709   0.900901  0.856531   \n",
      "index        None  0.865564     0.840816     0.908046   0.895652  0.867368   \n",
      "\n",
      "            mcc                                              index  \n",
      "index  0.683420  selected_features_all_best20_LogisticRegressio...  \n",
      "index  0.737224    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  0.751600  selected_features_all_best20_XGBClassifier_no_...  \n",
      "Evaluating selected_features_all_best20 LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:32:32,517]\u001b[0m A new study created in memory with name: no-name-3df58edf-44c6-4cf2-9751-20d6cafa617a\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:32,628]\u001b[0m Trial 0 finished with value: 0.857707509881423 and parameters: {'C': 0.07403839557995674, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 496}. Best is trial 0 with value: 0.857707509881423.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:32,657]\u001b[0m Trial 1 finished with value: 0.8537549407114624 and parameters: {'C': 0.0810939833636358, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 522}. Best is trial 0 with value: 0.857707509881423.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:32,684]\u001b[0m Trial 2 finished with value: 0.857707509881423 and parameters: {'C': 0.08162923941197098, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 802}. Best is trial 0 with value: 0.857707509881423.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "\n",
      "      best_params  accuracy  sensitivity  specificity  precision        f1   \n",
      "index        None  0.861630     0.832653     0.850575   0.839506  0.836066  \\\n",
      "index        None  0.884356     0.816327     0.915709   0.900901  0.856531   \n",
      "index        None  0.865564     0.840816     0.908046   0.895652  0.867368   \n",
      "index        None  0.870999     0.832653     0.919540   0.906667  0.868085   \n",
      "\n",
      "            mcc                                              index  \n",
      "index  0.683420  selected_features_all_best20_LogisticRegressio...  \n",
      "index  0.737224    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  0.751600  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  0.756464  selected_features_all_best20_LGBMClassifier_no...  \n",
      "Optimizing selected_features_all_best20 LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:32:32,872]\u001b[0m Trial 3 finished with value: 0.8596837944664032 and parameters: {'C': 0.06441953223187927, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 574}. Best is trial 3 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:32,897]\u001b[0m Trial 4 finished with value: 0.857707509881423 and parameters: {'C': 0.040412568834002696, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 939}. Best is trial 3 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:32,923]\u001b[0m Trial 5 finished with value: 0.857707509881423 and parameters: {'C': 0.026477898873890016, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 184}. Best is trial 3 with value: 0.8596837944664032.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:33,059]\u001b[0m Trial 6 finished with value: 0.8616600790513834 and parameters: {'C': 0.03342895231698814, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 773}. Best is trial 6 with value: 0.8616600790513834.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:33,079]\u001b[0m Trial 7 finished with value: 0.8537549407114624 and parameters: {'C': 0.047323057418438036, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 133}. Best is trial 6 with value: 0.8616600790513834.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:33,106]\u001b[0m Trial 8 finished with value: 0.8636363636363636 and parameters: {'C': 0.05772645471274076, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 445}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:32:33,260]\u001b[0m Trial 9 finished with value: 0.8596837944664032 and parameters: {'C': 0.06977402770709727, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 149}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:33,290]\u001b[0m Trial 10 finished with value: 0.8300395256916996 and parameters: {'C': 0.01045672514208975, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 339}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:33,669]\u001b[0m Trial 11 finished with value: 0.857707509881423 and parameters: {'C': 0.09786449680425763, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 736}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:33,839]\u001b[0m Trial 12 finished with value: 0.8596837944664032 and parameters: {'C': 0.05673096506439872, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 693}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,020]\u001b[0m Trial 13 finished with value: 0.8596837944664032 and parameters: {'C': 0.03912418381532872, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 338}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,064]\u001b[0m Trial 14 finished with value: 0.8616600790513834 and parameters: {'C': 0.050731051144353126, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 948}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,200]\u001b[0m Trial 15 finished with value: 0.8616600790513834 and parameters: {'C': 0.029122413372611355, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 391}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,240]\u001b[0m Trial 16 finished with value: 0.8636363636363636 and parameters: {'C': 0.05909741496270693, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 634}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,275]\u001b[0m Trial 17 finished with value: 0.8636363636363636 and parameters: {'C': 0.05909782949408206, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 611}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,314]\u001b[0m Trial 18 finished with value: 0.8616600790513834 and parameters: {'C': 0.05953245981467457, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 460}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,355]\u001b[0m Trial 19 finished with value: 0.8616600790513834 and parameters: {'C': 0.04830236258863719, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 248}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,404]\u001b[0m Trial 20 finished with value: 0.8596837944664032 and parameters: {'C': 0.06628959410164054, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 678}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,446]\u001b[0m Trial 21 finished with value: 0.8636363636363636 and parameters: {'C': 0.05700908742113705, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 622}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,499]\u001b[0m Trial 22 finished with value: 0.8636363636363636 and parameters: {'C': 0.05656047716055376, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 623}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,546]\u001b[0m Trial 23 finished with value: 0.8616600790513834 and parameters: {'C': 0.06320678006102545, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 841}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,581]\u001b[0m Trial 24 finished with value: 0.8616600790513834 and parameters: {'C': 0.05157302869820576, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 429}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,631]\u001b[0m Trial 25 finished with value: 0.8596837944664032 and parameters: {'C': 0.06983993712954922, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 605}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,682]\u001b[0m Trial 26 finished with value: 0.8616600790513834 and parameters: {'C': 0.06116895491329644, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 547}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,720]\u001b[0m Trial 27 finished with value: 0.8557312252964426 and parameters: {'C': 0.04501655941833319, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 670}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,762]\u001b[0m Trial 28 finished with value: 0.8616600790513834 and parameters: {'C': 0.05380360215530175, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 881}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,810]\u001b[0m Trial 29 finished with value: 0.8557312252964426 and parameters: {'C': 0.07300244558210409, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 465}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,861]\u001b[0m Trial 30 finished with value: 0.857707509881423 and parameters: {'C': 0.07811063042909394, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 288}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,910]\u001b[0m Trial 31 finished with value: 0.8636363636363636 and parameters: {'C': 0.057564029478763316, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 637}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,954]\u001b[0m Trial 32 finished with value: 0.8616600790513834 and parameters: {'C': 0.053901423287986125, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 522}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:34,992]\u001b[0m Trial 33 finished with value: 0.8616600790513834 and parameters: {'C': 0.06301016156055417, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 508}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,030]\u001b[0m Trial 34 finished with value: 0.8596837944664032 and parameters: {'C': 0.0670352445660587, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 573}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,072]\u001b[0m Trial 35 finished with value: 0.8557312252964426 and parameters: {'C': 0.07600306213540742, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 736}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,116]\u001b[0m Trial 36 finished with value: 0.8616600790513834 and parameters: {'C': 0.0609482947484404, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 399}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,156]\u001b[0m Trial 37 finished with value: 0.8596837944664032 and parameters: {'C': 0.04471814766412548, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 590}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,195]\u001b[0m Trial 38 finished with value: 0.8537549407114624 and parameters: {'C': 0.05357015309371175, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 778}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,239]\u001b[0m Trial 39 finished with value: 0.8596837944664032 and parameters: {'C': 0.07069962486828466, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 543}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,334]\u001b[0m Trial 40 finished with value: 0.8557312252964426 and parameters: {'C': 0.06424951737346378, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 716}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,381]\u001b[0m Trial 41 finished with value: 0.8636363636363636 and parameters: {'C': 0.059120329147581537, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 633}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,422]\u001b[0m Trial 42 finished with value: 0.8636363636363636 and parameters: {'C': 0.05648859154715334, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 635}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,460]\u001b[0m Trial 43 finished with value: 0.8616600790513834 and parameters: {'C': 0.049779418766912956, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 485}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,507]\u001b[0m Trial 44 finished with value: 0.8636363636363636 and parameters: {'C': 0.056415753791393214, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 612}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,557]\u001b[0m Trial 45 finished with value: 0.8596837944664032 and parameters: {'C': 0.06713146885240931, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 564}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,720]\u001b[0m Trial 46 finished with value: 0.8596837944664032 and parameters: {'C': 0.042724927261083706, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 663}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,766]\u001b[0m Trial 47 finished with value: 0.8616600790513834 and parameters: {'C': 0.04842347453305687, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 804}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:35,811]\u001b[0m Trial 48 finished with value: 0.8537549407114624 and parameters: {'C': 0.03894975348864854, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 708}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,017]\u001b[0m Trial 49 finished with value: 0.8596837944664032 and parameters: {'C': 0.0590074332598247, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 503}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,057]\u001b[0m Trial 50 finished with value: 0.8616600790513834 and parameters: {'C': 0.052676148953571, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 350}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,101]\u001b[0m Trial 51 finished with value: 0.8636363636363636 and parameters: {'C': 0.05667115812863114, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 662}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,156]\u001b[0m Trial 52 finished with value: 0.8616600790513834 and parameters: {'C': 0.06345199782986052, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 620}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,193]\u001b[0m Trial 53 finished with value: 0.8616600790513834 and parameters: {'C': 0.0505863129124692, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 751}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,231]\u001b[0m Trial 54 finished with value: 0.8636363636363636 and parameters: {'C': 0.05875716260990708, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 538}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,275]\u001b[0m Trial 55 finished with value: 0.8636363636363636 and parameters: {'C': 0.05549344169205558, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 448}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,326]\u001b[0m Trial 56 finished with value: 0.8596837944664032 and parameters: {'C': 0.0663261297000495, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 648}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,383]\u001b[0m Trial 57 finished with value: 0.8616600790513834 and parameters: {'C': 0.061589905226694434, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 994}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,478]\u001b[0m Trial 58 finished with value: 0.8557312252964426 and parameters: {'C': 0.0470993842766634, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 591}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,525]\u001b[0m Trial 59 finished with value: 0.8636363636363636 and parameters: {'C': 0.05785954353456705, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 712}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,574]\u001b[0m Trial 60 finished with value: 0.8616600790513834 and parameters: {'C': 0.0532887915406989, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 410}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,627]\u001b[0m Trial 61 finished with value: 0.8616600790513834 and parameters: {'C': 0.05940366950075743, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 633}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,674]\u001b[0m Trial 62 finished with value: 0.8616600790513834 and parameters: {'C': 0.059753311435161875, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 686}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,739]\u001b[0m Trial 63 finished with value: 0.8616600790513834 and parameters: {'C': 0.06433652071713634, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 584}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,800]\u001b[0m Trial 64 finished with value: 0.8616600790513834 and parameters: {'C': 0.051066512589696376, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 613}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,846]\u001b[0m Trial 65 finished with value: 0.8636363636363636 and parameters: {'C': 0.05662395503355684, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 475}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,895]\u001b[0m Trial 66 finished with value: 0.8616600790513834 and parameters: {'C': 0.06166710946790731, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 567}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,948]\u001b[0m Trial 67 finished with value: 0.8616600790513834 and parameters: {'C': 0.05482933670915175, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 524}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:36,993]\u001b[0m Trial 68 finished with value: 0.8557312252964426 and parameters: {'C': 0.06850600842807479, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 643}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,053]\u001b[0m Trial 69 finished with value: 0.8596837944664032 and parameters: {'C': 0.07108667159267099, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 372}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,300]\u001b[0m Trial 70 finished with value: 0.8596837944664032 and parameters: {'C': 0.065571955581536, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 758}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,344]\u001b[0m Trial 71 finished with value: 0.8636363636363636 and parameters: {'C': 0.0563483275817598, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 643}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,392]\u001b[0m Trial 72 finished with value: 0.8616600790513834 and parameters: {'C': 0.06223470677964912, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 604}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,437]\u001b[0m Trial 73 finished with value: 0.8616600790513834 and parameters: {'C': 0.05283654206859812, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 102}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,494]\u001b[0m Trial 74 finished with value: 0.8636363636363636 and parameters: {'C': 0.05877689028573643, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 689}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,544]\u001b[0m Trial 75 finished with value: 0.8616600790513834 and parameters: {'C': 0.054926022671086164, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 563}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,591]\u001b[0m Trial 76 finished with value: 0.8616600790513834 and parameters: {'C': 0.060732137450273525, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 662}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,635]\u001b[0m Trial 77 finished with value: 0.8616600790513834 and parameters: {'C': 0.04942150016807421, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 727}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,680]\u001b[0m Trial 78 finished with value: 0.8616600790513834 and parameters: {'C': 0.06428413210178302, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 279}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,726]\u001b[0m Trial 79 finished with value: 0.8537549407114624 and parameters: {'C': 0.05731897448629699, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 633}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,772]\u001b[0m Trial 80 finished with value: 0.8616600790513834 and parameters: {'C': 0.05195692462407146, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 790}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,817]\u001b[0m Trial 81 finished with value: 0.8636363636363636 and parameters: {'C': 0.05567969222463778, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 609}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,860]\u001b[0m Trial 82 finished with value: 0.8636363636363636 and parameters: {'C': 0.05821560454490869, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 698}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,908]\u001b[0m Trial 83 finished with value: 0.8616600790513834 and parameters: {'C': 0.061091479302426865, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 547}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:37,959]\u001b[0m Trial 84 finished with value: 0.8616600790513834 and parameters: {'C': 0.05419522389078348, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 592}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:38,005]\u001b[0m Trial 85 finished with value: 0.8616600790513834 and parameters: {'C': 0.06319373859716235, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 623}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:38,177]\u001b[0m Trial 86 finished with value: 0.8596837944664032 and parameters: {'C': 0.047512048335398474, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 675}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:38,218]\u001b[0m Trial 87 finished with value: 0.8616600790513834 and parameters: {'C': 0.050866962556988124, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 519}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:38,261]\u001b[0m Trial 88 finished with value: 0.8596837944664032 and parameters: {'C': 0.06809937442602666, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 573}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:38,314]\u001b[0m Trial 89 finished with value: 0.8636363636363636 and parameters: {'C': 0.05737565461068901, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 494}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:38,358]\u001b[0m Trial 90 finished with value: 0.8596837944664032 and parameters: {'C': 0.0655125793356484, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 652}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:38,404]\u001b[0m Trial 91 finished with value: 0.8636363636363636 and parameters: {'C': 0.05643774879582355, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 678}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:38,453]\u001b[0m Trial 92 finished with value: 0.8616600790513834 and parameters: {'C': 0.05988862293052031, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 626}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:38,501]\u001b[0m Trial 93 finished with value: 0.8616600790513834 and parameters: {'C': 0.05294996774956759, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 599}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:38,555]\u001b[0m Trial 94 finished with value: 0.8636363636363636 and parameters: {'C': 0.05501538496634102, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 658}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:38,607]\u001b[0m Trial 95 finished with value: 0.8636363636363636 and parameters: {'C': 0.05783250309769649, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 703}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:38,674]\u001b[0m Trial 96 finished with value: 0.8557312252964426 and parameters: {'C': 0.06234971992648308, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 729}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:38,744]\u001b[0m Trial 97 finished with value: 0.8616600790513834 and parameters: {'C': 0.06039678449749958, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 440}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:38,970]\u001b[0m Trial 98 finished with value: 0.8596837944664032 and parameters: {'C': 0.052031240101354265, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 553}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:39,021]\u001b[0m Trial 99 finished with value: 0.8636363636363636 and parameters: {'C': 0.05636027470366541, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 585}. Best is trial 8 with value: 0.8636363636363636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:39,032]\u001b[0m A new study created in memory with name: no-name-ac209f18-8a93-42f6-a994-2e4e315bde4a\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "Optimizing selected_features_all_best20 SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:32:39,517]\u001b[0m Trial 0 finished with value: 0.5177865612648221 and parameters: {'svc_c': 10.7533945146195, 'svc_gamma': 73.75896312119299}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:39,983]\u001b[0m Trial 1 finished with value: 0.5177865612648221 and parameters: {'svc_c': 13.280062430077226, 'svc_gamma': 79.73462726837084}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:40,413]\u001b[0m Trial 2 finished with value: 0.5177865612648221 and parameters: {'svc_c': 88.65711768594213, 'svc_gamma': 70.64852112597094}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:40,929]\u001b[0m Trial 3 finished with value: 0.5177865612648221 and parameters: {'svc_c': 18.089833877835254, 'svc_gamma': 67.08274284473659}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:41,457]\u001b[0m Trial 4 finished with value: 0.5177865612648221 and parameters: {'svc_c': 86.76762802466011, 'svc_gamma': 86.261841557179}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:42,000]\u001b[0m Trial 5 finished with value: 0.5177865612648221 and parameters: {'svc_c': 45.0111788401077, 'svc_gamma': 76.43167762851253}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:42,429]\u001b[0m Trial 6 finished with value: 0.5197628458498024 and parameters: {'svc_c': 94.03484798817581, 'svc_gamma': 10.646903345225624}. Best is trial 6 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:42,838]\u001b[0m Trial 7 finished with value: 0.5177865612648221 and parameters: {'svc_c': 93.73765019017729, 'svc_gamma': 66.87758981210082}. Best is trial 6 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:43,452]\u001b[0m Trial 8 finished with value: 0.5177865612648221 and parameters: {'svc_c': 16.776081739552335, 'svc_gamma': 40.054696861872394}. Best is trial 6 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:43,961]\u001b[0m Trial 9 finished with value: 0.5177865612648221 and parameters: {'svc_c': 66.4061807406478, 'svc_gamma': 46.22185414175125}. Best is trial 6 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:44,525]\u001b[0m Trial 10 finished with value: 0.6877470355731226 and parameters: {'svc_c': 70.14142241951059, 'svc_gamma': 2.5841367782986424}. Best is trial 10 with value: 0.6877470355731226.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:44,885]\u001b[0m Trial 11 finished with value: 0.5928853754940712 and parameters: {'svc_c': 69.16368691756455, 'svc_gamma': 3.7843237063995527}. Best is trial 10 with value: 0.6877470355731226.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:45,303]\u001b[0m Trial 12 finished with value: 0.7786561264822134 and parameters: {'svc_c': 66.51417984992877, 'svc_gamma': 1.3825927313893445}. Best is trial 12 with value: 0.7786561264822134.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:45,894]\u001b[0m Trial 13 finished with value: 0.5177865612648221 and parameters: {'svc_c': 48.73317223378904, 'svc_gamma': 19.263257922469663}. Best is trial 12 with value: 0.7786561264822134.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:46,415]\u001b[0m Trial 14 finished with value: 0.5177865612648221 and parameters: {'svc_c': 68.0864725917972, 'svc_gamma': 23.596225845879882}. Best is trial 12 with value: 0.7786561264822134.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:46,789]\u001b[0m Trial 15 finished with value: 0.7154150197628458 and parameters: {'svc_c': 59.8463176149895, 'svc_gamma': 2.249974916929832}. Best is trial 12 with value: 0.7786561264822134.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:47,041]\u001b[0m Trial 16 finished with value: 0.8181818181818182 and parameters: {'svc_c': 37.07489737871984, 'svc_gamma': 0.15944008985926517}. Best is trial 16 with value: 0.8181818181818182.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:47,497]\u001b[0m Trial 17 finished with value: 0.5177865612648221 and parameters: {'svc_c': 34.01942409690148, 'svc_gamma': 29.33101475359978}. Best is trial 16 with value: 0.8181818181818182.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:48,022]\u001b[0m Trial 18 finished with value: 0.5197628458498024 and parameters: {'svc_c': 33.56648011867069, 'svc_gamma': 18.336076106883407}. Best is trial 16 with value: 0.8181818181818182.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:48,470]\u001b[0m Trial 19 finished with value: 0.5177865612648221 and parameters: {'svc_c': 37.718549468181365, 'svc_gamma': 34.4861166046813}. Best is trial 16 with value: 0.8181818181818182.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 11:32:48,950]\u001b[0m Trial 20 finished with value: 0.5158102766798419 and parameters: {'svc_c': 0.40170932567681916, 'svc_gamma': 14.796108462597267}. Best is trial 16 with value: 0.8181818181818182.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:49,390]\u001b[0m Trial 21 finished with value: 0.7569169960474308 and parameters: {'svc_c': 57.34739705424128, 'svc_gamma': 1.664686918095824}. Best is trial 16 with value: 0.8181818181818182.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:49,794]\u001b[0m Trial 22 finished with value: 0.5197628458498024 and parameters: {'svc_c': 53.16229073351222, 'svc_gamma': 10.160821830026793}. Best is trial 16 with value: 0.8181818181818182.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:50,121]\u001b[0m Trial 23 finished with value: 0.8023715415019763 and parameters: {'svc_c': 77.99642194333231, 'svc_gamma': 1.0192954158328704}. Best is trial 16 with value: 0.8181818181818182.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:50,617]\u001b[0m Trial 24 finished with value: 0.5177865612648221 and parameters: {'svc_c': 78.24236363330536, 'svc_gamma': 25.95015641254531}. Best is trial 16 with value: 0.8181818181818182.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:50,967]\u001b[0m Trial 25 finished with value: 0.5197628458498024 and parameters: {'svc_c': 83.75031476936752, 'svc_gamma': 9.911331149526994}. Best is trial 16 with value: 0.8181818181818182.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:51,553]\u001b[0m Trial 26 finished with value: 0.5197628458498024 and parameters: {'svc_c': 79.69023725884426, 'svc_gamma': 15.98596604673967}. Best is trial 16 with value: 0.8181818181818182.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:51,953]\u001b[0m Trial 27 finished with value: 0.5276679841897233 and parameters: {'svc_c': 75.90133889263825, 'svc_gamma': 7.8450475691114345}. Best is trial 16 with value: 0.8181818181818182.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:52,213]\u001b[0m Trial 28 finished with value: 0.8241106719367589 and parameters: {'svc_c': 97.89965014124971, 'svc_gamma': 0.08045326609782855}. Best is trial 28 with value: 0.8241106719367589.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:52,639]\u001b[0m Trial 29 finished with value: 0.5177865612648221 and parameters: {'svc_c': 95.45814207166197, 'svc_gamma': 22.5606170868493}. Best is trial 28 with value: 0.8241106719367589.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:53,066]\u001b[0m Trial 30 finished with value: 0.5197628458498024 and parameters: {'svc_c': 88.96076131473404, 'svc_gamma': 13.924463210000388}. Best is trial 28 with value: 0.8241106719367589.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:53,465]\u001b[0m Trial 31 finished with value: 0.5355731225296443 and parameters: {'svc_c': 75.57050081122048, 'svc_gamma': 6.607584786690114}. Best is trial 28 with value: 0.8241106719367589.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:53,837]\u001b[0m Trial 32 finished with value: 0.8102766798418972 and parameters: {'svc_c': 99.92198145182225, 'svc_gamma': 0.7821446225772153}. Best is trial 28 with value: 0.8241106719367589.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:54,184]\u001b[0m Trial 33 finished with value: 0.8280632411067194 and parameters: {'svc_c': 98.69873448040302, 'svc_gamma': 0.4643593113155191}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:54,570]\u001b[0m Trial 34 finished with value: 0.525691699604743 and parameters: {'svc_c': 99.04149325979189, 'svc_gamma': 8.82532568394795}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:54,944]\u001b[0m Trial 35 finished with value: 0.5197628458498024 and parameters: {'svc_c': 89.7355711856678, 'svc_gamma': 13.54210573218669}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:55,309]\u001b[0m Trial 36 finished with value: 0.5355731225296443 and parameters: {'svc_c': 95.67177782938037, 'svc_gamma': 6.727379117242995}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:55,763]\u001b[0m Trial 37 finished with value: 0.5177865612648221 and parameters: {'svc_c': 98.65020793539023, 'svc_gamma': 19.474118615372397}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:56,200]\u001b[0m Trial 38 finished with value: 0.5197628458498024 and parameters: {'svc_c': 99.93687696187162, 'svc_gamma': 13.129946711367358}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:56,496]\u001b[0m Trial 39 finished with value: 0.8181818181818182 and parameters: {'svc_c': 84.7928760855722, 'svc_gamma': 0.12183800881659967}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:56,884]\u001b[0m Trial 40 finished with value: 0.5355731225296443 and parameters: {'svc_c': 85.97370797152502, 'svc_gamma': 6.131646295869807}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:57,207]\u001b[0m Trial 41 finished with value: 0.8280632411067194 and parameters: {'svc_c': 91.77681043257584, 'svc_gamma': 0.4788014321308523}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:57,511]\u001b[0m Trial 42 finished with value: 0.8162055335968379 and parameters: {'svc_c': 90.73680131429393, 'svc_gamma': 0.11202916566958396}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:57,923]\u001b[0m Trial 43 finished with value: 0.5355731225296443 and parameters: {'svc_c': 93.05727110447582, 'svc_gamma': 6.164337021419281}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:58,326]\u001b[0m Trial 44 finished with value: 0.5197628458498024 and parameters: {'svc_c': 85.14660518655492, 'svc_gamma': 10.23032804228235}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:58,757]\u001b[0m Trial 45 finished with value: 0.541501976284585 and parameters: {'svc_c': 91.4504679351348, 'svc_gamma': 5.56659427138406}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:59,213]\u001b[0m Trial 46 finished with value: 0.5197628458498024 and parameters: {'svc_c': 82.81087128768797, 'svc_gamma': 12.821159127570136}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:32:59,708]\u001b[0m Trial 47 finished with value: 0.5177865612648221 and parameters: {'svc_c': 87.34600935308919, 'svc_gamma': 50.98253587305013}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:00,060]\u001b[0m Trial 48 finished with value: 0.5592885375494071 and parameters: {'svc_c': 94.33411769755047, 'svc_gamma': 4.710795974128629}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:00,500]\u001b[0m Trial 49 finished with value: 0.5197628458498024 and parameters: {'svc_c': 81.85683352824181, 'svc_gamma': 16.77037313596435}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:00,873]\u001b[0m Trial 50 finished with value: 0.5691699604743083 and parameters: {'svc_c': 88.19076376550295, 'svc_gamma': 4.277209973303253}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:01,340]\u001b[0m Trial 51 finished with value: 0.5197628458498024 and parameters: {'svc_c': 91.72545217495508, 'svc_gamma': 9.88448942785941}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:01,695]\u001b[0m Trial 52 finished with value: 0.8221343873517787 and parameters: {'svc_c': 90.68835778706655, 'svc_gamma': 0.12809606599435977}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:02,062]\u001b[0m Trial 53 finished with value: 0.8201581027667985 and parameters: {'svc_c': 96.45161575704608, 'svc_gamma': 0.674088794229222}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:02,382]\u001b[0m Trial 54 finished with value: 0.5810276679841897 and parameters: {'svc_c': 96.02895318238393, 'svc_gamma': 4.108095971387438}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:02,750]\u001b[0m Trial 55 finished with value: 0.8221343873517787 and parameters: {'svc_c': 96.30150614209674, 'svc_gamma': 0.6144119479848883}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:03,135]\u001b[0m Trial 56 finished with value: 0.5197628458498024 and parameters: {'svc_c': 95.60836123451662, 'svc_gamma': 10.064339239515501}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:03,532]\u001b[0m Trial 57 finished with value: 0.5849802371541502 and parameters: {'svc_c': 91.16997747996747, 'svc_gamma': 4.01038021343521}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:03,965]\u001b[0m Trial 58 finished with value: 0.5177865612648221 and parameters: {'svc_c': 97.25596255814766, 'svc_gamma': 20.503938493325872}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:04,520]\u001b[0m Trial 59 finished with value: 0.5197628458498024 and parameters: {'svc_c': 92.69882161965323, 'svc_gamma': 17.523151340283334}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:04,843]\u001b[0m Trial 60 finished with value: 0.6185770750988142 and parameters: {'svc_c': 87.9994262611391, 'svc_gamma': 3.363929557438099}. Best is trial 33 with value: 0.8280632411067194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:05,128]\u001b[0m Trial 61 finished with value: 0.83399209486166 and parameters: {'svc_c': 95.94113392322917, 'svc_gamma': 0.23308824330559652}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:05,444]\u001b[0m Trial 62 finished with value: 0.8162055335968379 and parameters: {'svc_c': 96.78479916822002, 'svc_gamma': 0.3216122718296851}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:05,822]\u001b[0m Trial 63 finished with value: 0.5276679841897233 and parameters: {'svc_c': 94.66737245833846, 'svc_gamma': 7.7145749426867285}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:06,221]\u001b[0m Trial 64 finished with value: 0.5197628458498024 and parameters: {'svc_c': 92.38059216091821, 'svc_gamma': 11.50644558414048}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:06,548]\u001b[0m Trial 65 finished with value: 0.6185770750988142 and parameters: {'svc_c': 98.46855413744521, 'svc_gamma': 3.3536225560758575}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:06,952]\u001b[0m Trial 66 finished with value: 0.5276679841897233 and parameters: {'svc_c': 89.34562793337453, 'svc_gamma': 8.05716114831784}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:07,357]\u001b[0m Trial 67 finished with value: 0.5197628458498024 and parameters: {'svc_c': 99.96388552998269, 'svc_gamma': 14.483651916687343}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:07,673]\u001b[0m Trial 68 finished with value: 0.6897233201581028 and parameters: {'svc_c': 81.67500128235184, 'svc_gamma': 2.5520193585105884}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:08,046]\u001b[0m Trial 69 finished with value: 0.5355731225296443 and parameters: {'svc_c': 87.32219711877846, 'svc_gamma': 6.75239932015311}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:08,337]\u001b[0m Trial 70 finished with value: 0.8181818181818182 and parameters: {'svc_c': 93.9828253656245, 'svc_gamma': 0.3081195943750008}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:08,720]\u001b[0m Trial 71 finished with value: 0.5988142292490118 and parameters: {'svc_c': 95.76924262365897, 'svc_gamma': 3.6990970758586683}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:09,109]\u001b[0m Trial 72 finished with value: 0.5197628458498024 and parameters: {'svc_c': 97.13892567311967, 'svc_gamma': 11.756908377542382}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:09,521]\u001b[0m Trial 73 finished with value: 0.6818181818181818 and parameters: {'svc_c': 90.24760600490184, 'svc_gamma': 2.65450088552239}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:09,910]\u001b[0m Trial 74 finished with value: 0.5276679841897233 and parameters: {'svc_c': 85.36637347073923, 'svc_gamma': 7.699248057675818}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:10,226]\u001b[0m Trial 75 finished with value: 0.83399209486166 and parameters: {'svc_c': 92.89666907314263, 'svc_gamma': 0.23085825484084396}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:10,592]\u001b[0m Trial 76 finished with value: 0.5434782608695652 and parameters: {'svc_c': 93.24100362145701, 'svc_gamma': 5.322857621318447}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:10,940]\u001b[0m Trial 77 finished with value: 0.8221343873517787 and parameters: {'svc_c': 99.86737439717268, 'svc_gamma': 0.26632861929353957}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:11,298]\u001b[0m Trial 78 finished with value: 0.525691699604743 and parameters: {'svc_c': 99.11130281353404, 'svc_gamma': 8.337090409729594}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:11,799]\u001b[0m Trial 79 finished with value: 0.5197628458498024 and parameters: {'svc_c': 88.8347907286161, 'svc_gamma': 15.77133734486739}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:12,173]\u001b[0m Trial 80 finished with value: 0.5197628458498024 and parameters: {'svc_c': 99.98593159486062, 'svc_gamma': 11.357348990468681}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:12,446]\u001b[0m Trial 81 finished with value: 0.8241106719367589 and parameters: {'svc_c': 97.04722184799567, 'svc_gamma': 0.15347001297696627}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:12,802]\u001b[0m Trial 82 finished with value: 0.691699604743083 and parameters: {'svc_c': 93.39824999059394, 'svc_gamma': 2.5155010768215544}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:13,146]\u001b[0m Trial 83 finished with value: 0.8260869565217391 and parameters: {'svc_c': 97.45415674467023, 'svc_gamma': 0.08510194647479126}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:13,497]\u001b[0m Trial 84 finished with value: 0.541501976284585 and parameters: {'svc_c': 90.62213251219914, 'svc_gamma': 5.557487700381568}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:13,823]\u001b[0m Trial 85 finished with value: 0.6877470355731226 and parameters: {'svc_c': 86.49992232705637, 'svc_gamma': 2.59048944880009}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:14,179]\u001b[0m Trial 86 finished with value: 0.5355731225296443 and parameters: {'svc_c': 97.14760724768588, 'svc_gamma': 5.7835805707036005}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:14,538]\u001b[0m Trial 87 finished with value: 0.5276679841897233 and parameters: {'svc_c': 94.21960826085106, 'svc_gamma': 7.801374138105444}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:14,785]\u001b[0m Trial 88 finished with value: 0.8201581027667985 and parameters: {'svc_c': 84.24270038225359, 'svc_gamma': 0.13707962404309176}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:15,147]\u001b[0m Trial 89 finished with value: 0.5197628458498024 and parameters: {'svc_c': 90.84833948108498, 'svc_gamma': 10.050539756162127}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:15,557]\u001b[0m Trial 90 finished with value: 0.66600790513834 and parameters: {'svc_c': 97.3342981668992, 'svc_gamma': 2.804740467826482}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:15,863]\u001b[0m Trial 91 finished with value: 0.7351778656126482 and parameters: {'svc_c': 95.38863518576392, 'svc_gamma': 1.962202207381119}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:16,104]\u001b[0m Trial 92 finished with value: 0.8221343873517787 and parameters: {'svc_c': 98.37431520248686, 'svc_gamma': 0.07321286626343651}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:16,467]\u001b[0m Trial 93 finished with value: 0.5454545454545454 and parameters: {'svc_c': 92.62809110555759, 'svc_gamma': 5.209637227282405}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:16,829]\u001b[0m Trial 94 finished with value: 0.525691699604743 and parameters: {'svc_c': 94.35313148052809, 'svc_gamma': 8.80714114366759}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:17,189]\u001b[0m Trial 95 finished with value: 0.5474308300395256 and parameters: {'svc_c': 89.44031434406187, 'svc_gamma': 5.155424679466674}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:17,503]\u001b[0m Trial 96 finished with value: 0.7371541501976284 and parameters: {'svc_c': 99.96491768683912, 'svc_gamma': 1.8508059313742953}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:17,860]\u001b[0m Trial 97 finished with value: 0.5197628458498024 and parameters: {'svc_c': 97.32360899780586, 'svc_gamma': 13.209326426429326}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:18,167]\u001b[0m Trial 98 finished with value: 0.5830039525691699 and parameters: {'svc_c': 92.22289218667083, 'svc_gamma': 4.017876880603733}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:18,581]\u001b[0m Trial 99 finished with value: 0.5276679841897233 and parameters: {'svc_c': 86.71775497587264, 'svc_gamma': 7.673433538008205}. Best is trial 61 with value: 0.83399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:18,589]\u001b[0m A new study created in memory with name: no-name-4ae08fcf-ddf1-483c-9f1b-c951d687d314\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "Optimizing selected_features_all_best20 XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:33:19,624]\u001b[0m Trial 0 finished with value: 0.8656126482213439 and parameters: {'learning_rate': 0.07874189857592591, 'max_depth': 6, 'n_estimators': 154}. Best is trial 0 with value: 0.8656126482213439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:20,400]\u001b[0m Trial 1 finished with value: 0.8596837944664032 and parameters: {'learning_rate': 0.1705788115114957, 'max_depth': 3, 'n_estimators': 484}. Best is trial 0 with value: 0.8656126482213439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:20,881]\u001b[0m Trial 2 finished with value: 0.8557312252964426 and parameters: {'learning_rate': 0.07877682785006325, 'max_depth': 2, 'n_estimators': 451}. Best is trial 0 with value: 0.8656126482213439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:21,344]\u001b[0m Trial 3 finished with value: 0.8537549407114624 and parameters: {'learning_rate': 0.14347569237428598, 'max_depth': 4, 'n_estimators': 268}. Best is trial 0 with value: 0.8656126482213439.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:22,881]\u001b[0m Trial 4 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.05161809525480359, 'max_depth': 6, 'n_estimators': 585}. Best is trial 4 with value: 0.8715415019762845.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:23,242]\u001b[0m Trial 5 finished with value: 0.8616600790513834 and parameters: {'learning_rate': 0.013162697927781046, 'max_depth': 5, 'n_estimators': 118}. Best is trial 4 with value: 0.8715415019762845.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:23,477]\u001b[0m Trial 6 finished with value: 0.8636363636363636 and parameters: {'learning_rate': 0.08295048218460643, 'max_depth': 2, 'n_estimators': 182}. Best is trial 4 with value: 0.8715415019762845.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:24,179]\u001b[0m Trial 7 finished with value: 0.8596837944664032 and parameters: {'learning_rate': 0.14642728790901208, 'max_depth': 3, 'n_estimators': 397}. Best is trial 4 with value: 0.8715415019762845.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:26,269]\u001b[0m Trial 8 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.2617326999844464, 'max_depth': 6, 'n_estimators': 965}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:29,311]\u001b[0m Trial 9 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.025277742178529496, 'max_depth': 5, 'n_estimators': 794}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:31,144]\u001b[0m Trial 10 finished with value: 0.8636363636363636 and parameters: {'learning_rate': 0.2980374976006557, 'max_depth': 5, 'n_estimators': 1000}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:33,167]\u001b[0m Trial 11 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.2603462316372846, 'max_depth': 5, 'n_estimators': 958}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:34,860]\u001b[0m Trial 12 finished with value: 0.8675889328063241 and parameters: {'learning_rate': 0.21032268256858289, 'max_depth': 6, 'n_estimators': 770}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:37,039]\u001b[0m Trial 13 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.2244137696294578, 'max_depth': 5, 'n_estimators': 825}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:39,084]\u001b[0m Trial 14 finished with value: 0.8636363636363636 and parameters: {'learning_rate': 0.010212228899937434, 'max_depth': 4, 'n_estimators': 705}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:41,538]\u001b[0m Trial 15 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.11067463668384378, 'max_depth': 6, 'n_estimators': 879}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:42,978]\u001b[0m Trial 16 finished with value: 0.8636363636363636 and parameters: {'learning_rate': 0.18735981315298436, 'max_depth': 5, 'n_estimators': 657}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:45,099]\u001b[0m Trial 17 finished with value: 0.8656126482213439 and parameters: {'learning_rate': 0.1273270174768016, 'max_depth': 6, 'n_estimators': 885}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:47,013]\u001b[0m Trial 18 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.17656097791808784, 'max_depth': 4, 'n_estimators': 756}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:48,568]\u001b[0m Trial 19 finished with value: 0.8675889328063241 and parameters: {'learning_rate': 0.25695150372928693, 'max_depth': 5, 'n_estimators': 601}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:50,115]\u001b[0m Trial 20 finished with value: 0.8636363636363636 and parameters: {'learning_rate': 0.1254420815492506, 'max_depth': 3, 'n_estimators': 916}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:52,485]\u001b[0m Trial 21 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.25547410884348415, 'max_depth': 5, 'n_estimators': 997}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:54,205]\u001b[0m Trial 22 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.2153314593196333, 'max_depth': 5, 'n_estimators': 827}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:56,199]\u001b[0m Trial 23 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.29249740921169115, 'max_depth': 6, 'n_estimators': 999}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:33:58,279]\u001b[0m Trial 24 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.28421135863099634, 'max_depth': 6, 'n_estimators': 998}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:00,544]\u001b[0m Trial 25 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.26429909843093646, 'max_depth': 6, 'n_estimators': 922}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:02,445]\u001b[0m Trial 26 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.2417674411104334, 'max_depth': 6, 'n_estimators': 858}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:04,395]\u001b[0m Trial 27 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.2974508497247197, 'max_depth': 6, 'n_estimators': 957}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:06,734]\u001b[0m Trial 28 finished with value: 0.8656126482213439 and parameters: {'learning_rate': 0.23734514358278647, 'max_depth': 5, 'n_estimators': 689}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:08,543]\u001b[0m Trial 29 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.279636757923362, 'max_depth': 4, 'n_estimators': 936}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:10,324]\u001b[0m Trial 30 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.27592430251570627, 'max_depth': 6, 'n_estimators': 733}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:12,287]\u001b[0m Trial 31 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.27644292952919736, 'max_depth': 6, 'n_estimators': 733}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:14,463]\u001b[0m Trial 32 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.24565944294167458, 'max_depth': 6, 'n_estimators': 993}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:16,342]\u001b[0m Trial 33 finished with value: 0.8675889328063241 and parameters: {'learning_rate': 0.2733695450368448, 'max_depth': 6, 'n_estimators': 865}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:18,176]\u001b[0m Trial 34 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.2993867863611667, 'max_depth': 6, 'n_estimators': 523}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:19,374]\u001b[0m Trial 35 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.26004438273438757, 'max_depth': 5, 'n_estimators': 425}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:21,068]\u001b[0m Trial 36 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.23328706034672236, 'max_depth': 6, 'n_estimators': 624}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:21,977]\u001b[0m Trial 37 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.25113938086699555, 'max_depth': 6, 'n_estimators': 303}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:22,767]\u001b[0m Trial 38 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.20347044987622895, 'max_depth': 4, 'n_estimators': 330}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:23,410]\u001b[0m Trial 39 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.2275917381491373, 'max_depth': 5, 'n_estimators': 202}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:23,860]\u001b[0m Trial 40 finished with value: 0.849802371541502 and parameters: {'learning_rate': 0.24746608869035874, 'max_depth': 2, 'n_estimators': 342}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:24,486]\u001b[0m Trial 41 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.283746337027493, 'max_depth': 6, 'n_estimators': 223}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:25,255]\u001b[0m Trial 42 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.25402771852509903, 'max_depth': 6, 'n_estimators': 274}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:25,637]\u001b[0m Trial 43 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.2907521184563967, 'max_depth': 6, 'n_estimators': 104}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:26,345]\u001b[0m Trial 44 finished with value: 0.8656126482213439 and parameters: {'learning_rate': 0.2691802327567147, 'max_depth': 6, 'n_estimators': 255}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:27,483]\u001b[0m Trial 45 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.2849439434503215, 'max_depth': 5, 'n_estimators': 482}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:28,377]\u001b[0m Trial 46 finished with value: 0.8616600790513834 and parameters: {'learning_rate': 0.26349920216857203, 'max_depth': 6, 'n_estimators': 146}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:29,017]\u001b[0m Trial 47 finished with value: 0.8656126482213439 and parameters: {'learning_rate': 0.24953383425626025, 'max_depth': 5, 'n_estimators': 224}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:29,920]\u001b[0m Trial 48 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.28937230766416355, 'max_depth': 6, 'n_estimators': 322}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:30,464]\u001b[0m Trial 49 finished with value: 0.8596837944664032 and parameters: {'learning_rate': 0.2678695277282534, 'max_depth': 5, 'n_estimators': 158}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:31,578]\u001b[0m Trial 50 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.22509475841819404, 'max_depth': 6, 'n_estimators': 368}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:33,821]\u001b[0m Trial 51 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.27611698841673643, 'max_depth': 6, 'n_estimators': 965}. Best is trial 8 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:35,624]\u001b[0m Trial 52 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.2864574636954692, 'max_depth': 6, 'n_estimators': 565}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:37,125]\u001b[0m Trial 53 finished with value: 0.8636363636363636 and parameters: {'learning_rate': 0.2881079183458681, 'max_depth': 6, 'n_estimators': 551}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:37,857]\u001b[0m Trial 54 finished with value: 0.8616600790513834 and parameters: {'learning_rate': 0.29843033374905076, 'max_depth': 5, 'n_estimators': 262}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:39,810]\u001b[0m Trial 55 finished with value: 0.8675889328063241 and parameters: {'learning_rate': 0.25500388200099694, 'max_depth': 6, 'n_estimators': 816}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:42,176]\u001b[0m Trial 56 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.23701446978109836, 'max_depth': 6, 'n_estimators': 895}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:43,011]\u001b[0m Trial 57 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.26513891556880287, 'max_depth': 6, 'n_estimators': 301}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:43,987]\u001b[0m Trial 58 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.28522614465555995, 'max_depth': 5, 'n_estimators': 407}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:45,516]\u001b[0m Trial 59 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.25855416451868046, 'max_depth': 3, 'n_estimators': 954}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:47,473]\u001b[0m Trial 60 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.24789833102121456, 'max_depth': 6, 'n_estimators': 906}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:49,828]\u001b[0m Trial 61 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.24742414623196107, 'max_depth': 6, 'n_estimators': 906}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:51,971]\u001b[0m Trial 62 finished with value: 0.8596837944664032 and parameters: {'learning_rate': 0.2721089104882582, 'max_depth': 6, 'n_estimators': 970}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:53,876]\u001b[0m Trial 63 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.278464324831182, 'max_depth': 6, 'n_estimators': 927}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:56,455]\u001b[0m Trial 64 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.21635813539103937, 'max_depth': 6, 'n_estimators': 986}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:34:58,356]\u001b[0m Trial 65 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.2418813994401231, 'max_depth': 6, 'n_estimators': 846}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:00,171]\u001b[0m Trial 66 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.29163177673120777, 'max_depth': 4, 'n_estimators': 945}. Best is trial 52 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:02,348]\u001b[0m Trial 67 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.2530441854025399, 'max_depth': 6, 'n_estimators': 786}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:03,951]\u001b[0m Trial 68 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.2532537947329484, 'max_depth': 5, 'n_estimators': 776}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:05,493]\u001b[0m Trial 69 finished with value: 0.8675889328063241 and parameters: {'learning_rate': 0.2362924479319226, 'max_depth': 6, 'n_estimators': 636}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:06,673]\u001b[0m Trial 70 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.26251676266459134, 'max_depth': 6, 'n_estimators': 467}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:08,430]\u001b[0m Trial 71 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.2802979597722225, 'max_depth': 6, 'n_estimators': 520}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:09,745]\u001b[0m Trial 72 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.2796125977020901, 'max_depth': 6, 'n_estimators': 517}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:11,809]\u001b[0m Trial 73 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.26975267508751966, 'max_depth': 6, 'n_estimators': 676}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:13,297]\u001b[0m Trial 74 finished with value: 0.8636363636363636 and parameters: {'learning_rate': 0.2543393607567899, 'max_depth': 6, 'n_estimators': 577}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:15,249]\u001b[0m Trial 75 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.24415215820600253, 'max_depth': 6, 'n_estimators': 799}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:16,241]\u001b[0m Trial 76 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.2818405125664437, 'max_depth': 5, 'n_estimators': 375}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:16,944]\u001b[0m Trial 77 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.261147250137779, 'max_depth': 6, 'n_estimators': 213}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:18,918]\u001b[0m Trial 78 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.271851720208209, 'max_depth': 6, 'n_estimators': 713}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:20,159]\u001b[0m Trial 79 finished with value: 0.8656126482213439 and parameters: {'learning_rate': 0.23198244556335407, 'max_depth': 5, 'n_estimators': 433}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:22,173]\u001b[0m Trial 80 finished with value: 0.8636363636363636 and parameters: {'learning_rate': 0.29878266039717405, 'max_depth': 6, 'n_estimators': 884}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:24,600]\u001b[0m Trial 81 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.28193586941527515, 'max_depth': 6, 'n_estimators': 917}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:27,004]\u001b[0m Trial 82 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.28952431410518936, 'max_depth': 6, 'n_estimators': 992}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:29,109]\u001b[0m Trial 83 finished with value: 0.8675889328063241 and parameters: {'learning_rate': 0.26763037908072423, 'max_depth': 6, 'n_estimators': 848}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:31,550]\u001b[0m Trial 84 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.2928252307486335, 'max_depth': 6, 'n_estimators': 965}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:33,059]\u001b[0m Trial 85 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.25124021856451617, 'max_depth': 6, 'n_estimators': 512}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:34,667]\u001b[0m Trial 86 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.25061694235663196, 'max_depth': 6, 'n_estimators': 609}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:35,376]\u001b[0m Trial 87 finished with value: 0.857707509881423 and parameters: {'learning_rate': 0.2419677797064207, 'max_depth': 2, 'n_estimators': 530}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:37,299]\u001b[0m Trial 88 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.256425770525542, 'max_depth': 6, 'n_estimators': 569}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:38,399]\u001b[0m Trial 89 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.26328306422697295, 'max_depth': 4, 'n_estimators': 500}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:39,011]\u001b[0m Trial 90 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.2721033000899167, 'max_depth': 6, 'n_estimators': 175}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:40,260]\u001b[0m Trial 91 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.27925593040688024, 'max_depth': 6, 'n_estimators': 458}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:42,839]\u001b[0m Trial 92 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.28431764236068297, 'max_depth': 6, 'n_estimators': 940}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:45,149]\u001b[0m Trial 93 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.24851721384374387, 'max_depth': 6, 'n_estimators': 1000}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:46,530]\u001b[0m Trial 94 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.2944304873360692, 'max_depth': 6, 'n_estimators': 551}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:49,003]\u001b[0m Trial 95 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.27344717350005954, 'max_depth': 6, 'n_estimators': 900}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:49,669]\u001b[0m Trial 96 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.25878831186680146, 'max_depth': 5, 'n_estimators': 230}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:50,332]\u001b[0m Trial 97 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.25815752205395237, 'max_depth': 4, 'n_estimators': 281}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:51,082]\u001b[0m Trial 98 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.2284895698380962, 'max_depth': 5, 'n_estimators': 245}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:51,910]\u001b[0m Trial 99 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.23996016096811634, 'max_depth': 5, 'n_estimators': 294}. Best is trial 67 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:51,924]\u001b[0m A new study created in memory with name: no-name-07143fb0-2c41-4081-a2dd-ac0fba87b50d\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "Optimizing selected_features_all_best20 LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:35:53,434]\u001b[0m Trial 0 finished with value: 0.8754940711462451 and parameters: {'num_leaves': 103, 'max_depth': 11, 'learning_rate': 0.03276897858896604, 'n_estimators': 488}. Best is trial 0 with value: 0.8754940711462451.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:54,516]\u001b[0m Trial 1 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 139, 'max_depth': 18, 'learning_rate': 0.20546953893784983, 'n_estimators': 633}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:55,226]\u001b[0m Trial 2 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 45, 'max_depth': 10, 'learning_rate': 0.060968532596519846, 'n_estimators': 334}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:56,912]\u001b[0m Trial 3 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 211, 'max_depth': 48, 'learning_rate': 0.046618425613169104, 'n_estimators': 312}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:35:59,155]\u001b[0m Trial 4 finished with value: 0.8656126482213439 and parameters: {'num_leaves': 236, 'max_depth': 43, 'learning_rate': 0.13229915296175454, 'n_estimators': 1993}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:02,288]\u001b[0m Trial 5 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 210, 'max_depth': 19, 'learning_rate': 0.0486461978936011, 'n_estimators': 1554}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:03,646]\u001b[0m Trial 6 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 38, 'max_depth': 23, 'learning_rate': 0.14784622249836266, 'n_estimators': 1297}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:03,835]\u001b[0m Trial 7 finished with value: 0.857707509881423 and parameters: {'num_leaves': 5, 'max_depth': 15, 'learning_rate': 0.12351697313538491, 'n_estimators': 312}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:05,355]\u001b[0m Trial 8 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 238, 'max_depth': 50, 'learning_rate': 0.16512210404267277, 'n_estimators': 996}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:07,914]\u001b[0m Trial 9 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 109, 'max_depth': 49, 'learning_rate': 0.06859561999845833, 'n_estimators': 1968}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:08,784]\u001b[0m Trial 10 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 156, 'max_depth': 33, 'learning_rate': 0.25117121719933, 'n_estimators': 731}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:09,035]\u001b[0m Trial 11 finished with value: 0.8517786561264822 and parameters: {'num_leaves': 111, 'max_depth': 2, 'learning_rate': 0.012500627462193766, 'n_estimators': 713}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:09,880]\u001b[0m Trial 12 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 157, 'max_depth': 32, 'learning_rate': 0.22696531776261009, 'n_estimators': 659}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:10,210]\u001b[0m Trial 13 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 79, 'max_depth': 8, 'learning_rate': 0.2863436481070751, 'n_estimators': 146}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:11,425]\u001b[0m Trial 14 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 153, 'max_depth': 28, 'learning_rate': 0.199578614140898, 'n_estimators': 980}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:13,680]\u001b[0m Trial 15 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 85, 'max_depth': 14, 'learning_rate': 0.006788437281460613, 'n_estimators': 534}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:14,825]\u001b[0m Trial 16 finished with value: 0.8616600790513834 and parameters: {'num_leaves': 182, 'max_depth': 6, 'learning_rate': 0.11308493420810542, 'n_estimators': 1164}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:16,194]\u001b[0m Trial 17 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 126, 'max_depth': 21, 'learning_rate': 0.17365403110423594, 'n_estimators': 494}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:18,443]\u001b[0m Trial 18 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 73, 'max_depth': 14, 'learning_rate': 0.10055754610316785, 'n_estimators': 852}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:18,548]\u001b[0m Trial 19 finished with value: 0.857707509881423 and parameters: {'num_leaves': 180, 'max_depth': 2, 'learning_rate': 0.18606685123075306, 'n_estimators': 100}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:20,544]\u001b[0m Trial 20 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 104, 'max_depth': 27, 'learning_rate': 0.08840248915282073, 'n_estimators': 1520}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:22,882]\u001b[0m Trial 21 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 211, 'max_depth': 39, 'learning_rate': 0.033789637453431914, 'n_estimators': 382}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:25,262]\u001b[0m Trial 22 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 191, 'max_depth': 38, 'learning_rate': 0.03068440909362141, 'n_estimators': 481}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:27,023]\u001b[0m Trial 23 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 137, 'max_depth': 17, 'learning_rate': 0.07695935698549804, 'n_estimators': 632}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:28,737]\u001b[0m Trial 24 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 251, 'max_depth': 39, 'learning_rate': 0.014141998764718864, 'n_estimators': 394}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:30,012]\u001b[0m Trial 25 finished with value: 0.8754940711462451 and parameters: {'num_leaves': 50, 'max_depth': 11, 'learning_rate': 0.09578500036776277, 'n_estimators': 765}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:31,005]\u001b[0m Trial 26 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 134, 'max_depth': 24, 'learning_rate': 0.033501097463203365, 'n_estimators': 224}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:33,402]\u001b[0m Trial 27 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 203, 'max_depth': 30, 'learning_rate': 0.06476482739388424, 'n_estimators': 847}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:34,602]\u001b[0m Trial 28 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 167, 'max_depth': 42, 'learning_rate': 0.143492324803507, 'n_estimators': 492}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:35,733]\u001b[0m Trial 29 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 57, 'max_depth': 11, 'learning_rate': 0.05530059909908009, 'n_estimators': 372}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:37,556]\u001b[0m Trial 30 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 99, 'max_depth': 6, 'learning_rate': 0.08326190318841924, 'n_estimators': 592}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:38,801]\u001b[0m Trial 31 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 33, 'max_depth': 11, 'learning_rate': 0.11035095151388082, 'n_estimators': 821}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:39,061]\u001b[0m Trial 32 finished with value: 0.8656126482213439 and parameters: {'num_leaves': 10, 'max_depth': 18, 'learning_rate': 0.029937533801905135, 'n_estimators': 258}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:41,115]\u001b[0m Trial 33 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 61, 'max_depth': 12, 'learning_rate': 0.05075210067240751, 'n_estimators': 779}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:42,259]\u001b[0m Trial 34 finished with value: 0.8656126482213439 and parameters: {'num_leaves': 221, 'max_depth': 8, 'learning_rate': 0.0021643944720928163, 'n_estimators': 408}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:44,526]\u001b[0m Trial 35 finished with value: 0.8656126482213439 and parameters: {'num_leaves': 122, 'max_depth': 22, 'learning_rate': 0.09207341297451598, 'n_estimators': 1114}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:45,590]\u001b[0m Trial 36 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 22, 'max_depth': 19, 'learning_rate': 0.12900397208941752, 'n_estimators': 921}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:47,086]\u001b[0m Trial 37 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 49, 'max_depth': 16, 'learning_rate': 0.059208888810784184, 'n_estimators': 573}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:50,066]\u001b[0m Trial 38 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 220, 'max_depth': 36, 'learning_rate': 0.07713607513075317, 'n_estimators': 1312}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:50,825]\u001b[0m Trial 39 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 143, 'max_depth': 46, 'learning_rate': 0.15495670807252596, 'n_estimators': 235}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:52,590]\u001b[0m Trial 40 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 92, 'max_depth': 25, 'learning_rate': 0.04185228799214488, 'n_estimators': 404}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:54,888]\u001b[0m Trial 41 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 232, 'max_depth': 48, 'learning_rate': 0.06750676096374679, 'n_estimators': 683}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:56,357]\u001b[0m Trial 42 finished with value: 0.8656126482213439 and parameters: {'num_leaves': 205, 'max_depth': 41, 'learning_rate': 0.023767049013347065, 'n_estimators': 305}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:36:59,700]\u001b[0m Trial 43 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 69, 'max_depth': 44, 'learning_rate': 0.042225868782817, 'n_estimators': 1898}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:00,457]\u001b[0m Trial 44 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 255, 'max_depth': 34, 'learning_rate': 0.016380836563279433, 'n_estimators': 187}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:01,906]\u001b[0m Trial 45 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 174, 'max_depth': 50, 'learning_rate': 0.045532894542348226, 'n_estimators': 307}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:03,438]\u001b[0m Trial 46 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 116, 'max_depth': 9, 'learning_rate': 0.05675920221814258, 'n_estimators': 762}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:04,047]\u001b[0m Trial 47 finished with value: 0.8754940711462451 and parameters: {'num_leaves': 189, 'max_depth': 5, 'learning_rate': 0.021276202856070285, 'n_estimators': 636}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:04,706]\u001b[0m Trial 48 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 195, 'max_depth': 5, 'learning_rate': 0.025305225706015164, 'n_estimators': 676}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:05,384]\u001b[0m Trial 49 finished with value: 0.8616600790513834 and parameters: {'num_leaves': 148, 'max_depth': 4, 'learning_rate': 0.0072906378203621055, 'n_estimators': 967}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:07,781]\u001b[0m Trial 50 finished with value: 0.8656126482213439 and parameters: {'num_leaves': 163, 'max_depth': 13, 'learning_rate': 0.0015367799759276185, 'n_estimators': 565}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:08,919]\u001b[0m Trial 51 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 219, 'max_depth': 9, 'learning_rate': 0.03905748337068561, 'n_estimators': 453}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:09,948]\u001b[0m Trial 52 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 216, 'max_depth': 8, 'learning_rate': 0.036718097105493445, 'n_estimators': 453}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:11,852]\u001b[0m Trial 53 finished with value: 0.8636363636363636 and parameters: {'num_leaves': 230, 'max_depth': 10, 'learning_rate': 0.045627959096287043, 'n_estimators': 533}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:14,587]\u001b[0m Trial 54 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 242, 'max_depth': 15, 'learning_rate': 0.02568024831718879, 'n_estimators': 624}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:18,366]\u001b[0m Trial 55 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 187, 'max_depth': 20, 'learning_rate': 0.01679069157339014, 'n_estimators': 738}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:18,696]\u001b[0m Trial 56 finished with value: 0.857707509881423 and parameters: {'num_leaves': 197, 'max_depth': 2, 'learning_rate': 0.05927673707730456, 'n_estimators': 890}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:19,523]\u001b[0m Trial 57 finished with value: 0.8636363636363636 and parameters: {'num_leaves': 210, 'max_depth': 7, 'learning_rate': 0.07499996657729463, 'n_estimators': 471}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:19,823]\u001b[0m Trial 58 finished with value: 0.857707509881423 and parameters: {'num_leaves': 81, 'max_depth': 4, 'learning_rate': 0.015580131833725676, 'n_estimators': 337}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:23,415]\u001b[0m Trial 59 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 175, 'max_depth': 13, 'learning_rate': 0.03648346496215998, 'n_estimators': 1064}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:24,736]\u001b[0m Trial 60 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 244, 'max_depth': 10, 'learning_rate': 0.0940127229213565, 'n_estimators': 637}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:26,701]\u001b[0m Trial 61 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 226, 'max_depth': 47, 'learning_rate': 0.048207311075776874, 'n_estimators': 433}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:28,640]\u001b[0m Trial 62 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 202, 'max_depth': 17, 'learning_rate': 0.06876239497865114, 'n_estimators': 505}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:29,427]\u001b[0m Trial 63 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 213, 'max_depth': 30, 'learning_rate': 0.034533615861514794, 'n_estimators': 172}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:29,922]\u001b[0m Trial 64 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 187, 'max_depth': 45, 'learning_rate': 0.021467961797443508, 'n_estimators': 127}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:30,838]\u001b[0m Trial 65 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 90, 'max_depth': 40, 'learning_rate': 0.11220002718460148, 'n_estimators': 271}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:31,830]\u001b[0m Trial 66 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 97, 'max_depth': 38, 'learning_rate': 0.13805572503783978, 'n_estimators': 324}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:34,907]\u001b[0m Trial 67 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 94, 'max_depth': 39, 'learning_rate': 0.12134299985518639, 'n_estimators': 351}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:36,073]\u001b[0m Trial 68 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 108, 'max_depth': 36, 'learning_rate': 0.13927269453216046, 'n_estimators': 280}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:37,255]\u001b[0m Trial 69 finished with value: 0.8636363636363636 and parameters: {'num_leaves': 119, 'max_depth': 41, 'learning_rate': 0.13891419577177583, 'n_estimators': 371}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:38,667]\u001b[0m Trial 70 finished with value: 0.8656126482213439 and parameters: {'num_leaves': 129, 'max_depth': 37, 'learning_rate': 0.10360326788631942, 'n_estimators': 205}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:39,639]\u001b[0m Trial 71 finished with value: 0.8754940711462451 and parameters: {'num_leaves': 90, 'max_depth': 33, 'learning_rate': 0.15328634604704008, 'n_estimators': 570}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:41,102]\u001b[0m Trial 72 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 73, 'max_depth': 40, 'learning_rate': 0.11407446636539742, 'n_estimators': 438}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:42,986]\u001b[0m Trial 73 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 99, 'max_depth': 12, 'learning_rate': 0.08391286449814628, 'n_estimators': 262}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:43,742]\u001b[0m Trial 74 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 39, 'max_depth': 6, 'learning_rate': 0.12809706846130442, 'n_estimators': 705}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:45,261]\u001b[0m Trial 75 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 64, 'max_depth': 43, 'learning_rate': 0.09896267150167808, 'n_estimators': 812}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:45,664]\u001b[0m Trial 76 finished with value: 0.8656126482213439 and parameters: {'num_leaves': 54, 'max_depth': 4, 'learning_rate': 0.12120014577676431, 'n_estimators': 513}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:48,407]\u001b[0m Trial 77 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 137, 'max_depth': 15, 'learning_rate': 0.010041059680015878, 'n_estimators': 627}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:49,592]\u001b[0m Trial 78 finished with value: 0.8656126482213439 and parameters: {'num_leaves': 85, 'max_depth': 35, 'learning_rate': 0.171706990487361, 'n_estimators': 385}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:51,105]\u001b[0m Trial 79 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 107, 'max_depth': 29, 'learning_rate': 0.20706716301884107, 'n_estimators': 1286}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:51,665]\u001b[0m Trial 80 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 28, 'max_depth': 38, 'learning_rate': 0.052462432849149046, 'n_estimators': 319}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:52,754]\u001b[0m Trial 81 finished with value: 0.8636363636363636 and parameters: {'num_leaves': 92, 'max_depth': 31, 'learning_rate': 0.16267721512658753, 'n_estimators': 571}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:53,671]\u001b[0m Trial 82 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 85, 'max_depth': 33, 'learning_rate': 0.15183634358100354, 'n_estimators': 528}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:54,922]\u001b[0m Trial 83 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 116, 'max_depth': 26, 'learning_rate': 0.13505716533700998, 'n_estimators': 583}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:56,518]\u001b[0m Trial 84 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 103, 'max_depth': 9, 'learning_rate': 0.13251009080701984, 'n_estimators': 671}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:57,435]\u001b[0m Trial 85 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 74, 'max_depth': 42, 'learning_rate': 0.14454699530506654, 'n_estimators': 458}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:58,801]\u001b[0m Trial 86 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 95, 'max_depth': 11, 'learning_rate': 0.030722647249520382, 'n_estimators': 417}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:37:59,805]\u001b[0m Trial 87 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 44, 'max_depth': 38, 'learning_rate': 0.10547643222307156, 'n_estimators': 732}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:02,061]\u001b[0m Trial 88 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 125, 'max_depth': 33, 'learning_rate': 0.11644256119822269, 'n_estimators': 1718}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:03,302]\u001b[0m Trial 89 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 113, 'max_depth': 7, 'learning_rate': 0.0881461073549341, 'n_estimators': 781}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:04,317]\u001b[0m Trial 90 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 146, 'max_depth': 35, 'learning_rate': 0.14875534622742198, 'n_estimators': 611}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:05,531]\u001b[0m Trial 91 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 224, 'max_depth': 49, 'learning_rate': 0.039574053170642304, 'n_estimators': 253}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:07,199]\u001b[0m Trial 92 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 207, 'max_depth': 22, 'learning_rate': 0.05206128210875799, 'n_estimators': 343}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:07,791]\u001b[0m Trial 93 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 13, 'max_depth': 44, 'learning_rate': 0.06187043635938776, 'n_estimators': 481}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:08,275]\u001b[0m Trial 94 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 218, 'max_depth': 40, 'learning_rate': 0.02753101679173727, 'n_estimators': 109}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:09,735]\u001b[0m Trial 95 finished with value: 0.8616600790513834 and parameters: {'num_leaves': 232, 'max_depth': 9, 'learning_rate': 0.017520690963150985, 'n_estimators': 543}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:10,159]\u001b[0m Trial 96 finished with value: 0.8715415019762845 and parameters: {'num_leaves': 193, 'max_depth': 5, 'learning_rate': 0.042573434258777715, 'n_estimators': 383}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:10,881]\u001b[0m Trial 97 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 161, 'max_depth': 46, 'learning_rate': 0.10798439881688172, 'n_estimators': 169}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:12,719]\u001b[0m Trial 98 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 201, 'max_depth': 14, 'learning_rate': 0.034691771086145864, 'n_estimators': 291}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:14,366]\u001b[0m Trial 99 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 78, 'max_depth': 14, 'learning_rate': 0.03325394180621997, 'n_estimators': 432}. Best is trial 1 with value: 0.8794466403162056.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "Evaluating selected_features_all_best30 LogisticRegression\n",
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "Evaluating selected_features_all_best30 SVC\n",
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "Evaluating selected_features_all_best30 XGBClassifier\n",
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "index  selected_features_all_best30       XGBClassifier            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "Evaluating selected_features_all_best30 LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:38:23,091]\u001b[0m A new study created in memory with name: no-name-c0c0039d-afa3-4213-8124-122d20179b0c\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:23,130]\u001b[0m Trial 0 finished with value: 0.8893280632411067 and parameters: {'C': 0.09688479766360383, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 289}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "index  selected_features_all_best30       XGBClassifier            False   \n",
      "index  selected_features_all_best30      LGBMClassifier            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "Optimizing selected_features_all_best30 LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:38:23,387]\u001b[0m Trial 1 finished with value: 0.8893280632411067 and parameters: {'C': 0.08105103415050194, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 562}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:23,415]\u001b[0m Trial 2 finished with value: 0.8873517786561265 and parameters: {'C': 0.046218227368261915, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 907}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:23,444]\u001b[0m Trial 3 finished with value: 0.8873517786561265 and parameters: {'C': 0.05199988061090262, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 492}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:38:23,967]\u001b[0m Trial 4 finished with value: 0.8853754940711462 and parameters: {'C': 0.06651836663093466, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 333}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:24,171]\u001b[0m Trial 5 finished with value: 0.8893280632411067 and parameters: {'C': 0.07979345064311186, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 569}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:24,206]\u001b[0m Trial 6 finished with value: 0.883399209486166 and parameters: {'C': 0.08392487529460053, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 808}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:24,373]\u001b[0m Trial 7 finished with value: 0.8893280632411067 and parameters: {'C': 0.05793875465843212, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 501}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:24,398]\u001b[0m Trial 8 finished with value: 0.8814229249011858 and parameters: {'C': 0.04824785317518836, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 644}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:25,213]\u001b[0m Trial 9 finished with value: 0.8853754940711462 and parameters: {'C': 0.05475304646639717, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 860}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:25,253]\u001b[0m Trial 10 finished with value: 0.8893280632411067 and parameters: {'C': 0.09979625616881578, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 127}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:25,357]\u001b[0m Trial 11 finished with value: 0.8754940711462451 and parameters: {'C': 0.017393311451135297, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 258}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:25,395]\u001b[0m Trial 12 finished with value: 0.8893280632411067 and parameters: {'C': 0.09504522020623751, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 348}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:25,610]\u001b[0m Trial 13 finished with value: 0.8893280632411067 and parameters: {'C': 0.08519052750958146, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 713}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:38:25,795]\u001b[0m Trial 14 finished with value: 0.8893280632411067 and parameters: {'C': 0.09676528485511153, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 130}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:25,843]\u001b[0m Trial 15 finished with value: 0.8893280632411067 and parameters: {'C': 0.07926755464198076, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 390}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:26,040]\u001b[0m Trial 16 finished with value: 0.8913043478260869 and parameters: {'C': 0.0722445950942323, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 1000}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:26,090]\u001b[0m Trial 17 finished with value: 0.8893280632411067 and parameters: {'C': 0.06861839793324258, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 751}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:27,013]\u001b[0m Trial 18 finished with value: 0.8873517786561265 and parameters: {'C': 0.08867263893111527, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 998}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:27,062]\u001b[0m Trial 19 finished with value: 0.8873517786561265 and parameters: {'C': 0.07215526948962023, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 228}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:27,110]\u001b[0m Trial 20 finished with value: 0.8913043478260869 and parameters: {'C': 0.09281586663509098, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 970}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:27,152]\u001b[0m Trial 21 finished with value: 0.8913043478260869 and parameters: {'C': 0.08950953842748537, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 1000}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:27,200]\u001b[0m Trial 22 finished with value: 0.8913043478260869 and parameters: {'C': 0.08953998818441548, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 995}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:27,245]\u001b[0m Trial 23 finished with value: 0.8913043478260869 and parameters: {'C': 0.09033258398889629, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 916}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:27,285]\u001b[0m Trial 24 finished with value: 0.8893280632411067 and parameters: {'C': 0.07617447533968723, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 935}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:27,329]\u001b[0m Trial 25 finished with value: 0.8913043478260869 and parameters: {'C': 0.088314941228041, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 826}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:27,578]\u001b[0m Trial 26 finished with value: 0.8893280632411067 and parameters: {'C': 0.09984335914599755, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 752}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:27,639]\u001b[0m Trial 27 finished with value: 0.883399209486166 and parameters: {'C': 0.07453668468644857, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 941}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:27,852]\u001b[0m Trial 28 finished with value: 0.8893280632411067 and parameters: {'C': 0.09225458658818822, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 999}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:27,893]\u001b[0m Trial 29 finished with value: 0.8913043478260869 and parameters: {'C': 0.08475979569133607, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 887}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:27,934]\u001b[0m Trial 30 finished with value: 0.8893280632411067 and parameters: {'C': 0.09486508478099327, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 664}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:27,977]\u001b[0m Trial 31 finished with value: 0.8913043478260869 and parameters: {'C': 0.09003986362631705, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 990}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:28,023]\u001b[0m Trial 32 finished with value: 0.8913043478260869 and parameters: {'C': 0.08225124967237799, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 832}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:28,073]\u001b[0m Trial 33 finished with value: 0.8913043478260869 and parameters: {'C': 0.09224071136056185, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 944}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:28,125]\u001b[0m Trial 34 finished with value: 0.8893280632411067 and parameters: {'C': 0.08043144785927425, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 892}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:28,172]\u001b[0m Trial 35 finished with value: 0.8913043478260869 and parameters: {'C': 0.08692363012289911, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 974}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:28,375]\u001b[0m Trial 36 finished with value: 0.8913043478260869 and parameters: {'C': 0.07682412128104629, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 777}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:28,426]\u001b[0m Trial 37 finished with value: 0.883399209486166 and parameters: {'C': 0.09518547612564986, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 855}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:28,611]\u001b[0m Trial 38 finished with value: 0.8873517786561265 and parameters: {'C': 0.06498163134490617, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 951}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:28,657]\u001b[0m Trial 39 finished with value: 0.8893280632411067 and parameters: {'C': 0.0808864976324435, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 881}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:28,704]\u001b[0m Trial 40 finished with value: 0.8853754940711462 and parameters: {'C': 0.0715216526981884, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 921}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:28,749]\u001b[0m Trial 41 finished with value: 0.8913043478260869 and parameters: {'C': 0.09083131859974918, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 914}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:28,799]\u001b[0m Trial 42 finished with value: 0.8913043478260869 and parameters: {'C': 0.08567439636080386, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 998}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:28,849]\u001b[0m Trial 43 finished with value: 0.8913043478260869 and parameters: {'C': 0.09198890791583919, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 954}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:28,898]\u001b[0m Trial 44 finished with value: 0.8913043478260869 and parameters: {'C': 0.08375391989018764, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 803}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:29,125]\u001b[0m Trial 45 finished with value: 0.8893280632411067 and parameters: {'C': 0.09841892049584278, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 865}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:29,171]\u001b[0m Trial 46 finished with value: 0.8913043478260869 and parameters: {'C': 0.08816773199232608, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 606}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:29,223]\u001b[0m Trial 47 finished with value: 0.8893280632411067 and parameters: {'C': 0.09518637115804471, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 506}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:29,427]\u001b[0m Trial 48 finished with value: 0.8893280632411067 and parameters: {'C': 0.08319425643982649, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 905}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:29,482]\u001b[0m Trial 49 finished with value: 0.883399209486166 and parameters: {'C': 0.07885511737423206, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 702}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:29,659]\u001b[0m Trial 50 finished with value: 0.8873517786561265 and parameters: {'C': 0.06214675585424576, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 958}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:29,703]\u001b[0m Trial 51 finished with value: 0.8913043478260869 and parameters: {'C': 0.08863533926647708, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 819}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:29,748]\u001b[0m Trial 52 finished with value: 0.8913043478260869 and parameters: {'C': 0.08708605380318553, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 855}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:29,793]\u001b[0m Trial 53 finished with value: 0.8893280632411067 and parameters: {'C': 0.09784154994338735, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 919}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:29,838]\u001b[0m Trial 54 finished with value: 0.8913043478260869 and parameters: {'C': 0.09246323726115643, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 971}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:29,880]\u001b[0m Trial 55 finished with value: 0.8893280632411067 and parameters: {'C': 0.07898842509891725, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 838}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:29,925]\u001b[0m Trial 56 finished with value: 0.8913043478260869 and parameters: {'C': 0.08618006756724493, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 787}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:30,165]\u001b[0m Trial 57 finished with value: 0.8893280632411067 and parameters: {'C': 0.09936811100461149, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 969}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:30,218]\u001b[0m Trial 58 finished with value: 0.8853754940711462 and parameters: {'C': 0.07411311973239079, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 909}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:30,263]\u001b[0m Trial 59 finished with value: 0.8913043478260869 and parameters: {'C': 0.09422942310516268, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 997}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:30,307]\u001b[0m Trial 60 finished with value: 0.8893280632411067 and parameters: {'C': 0.08187745013087575, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 881}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:30,356]\u001b[0m Trial 61 finished with value: 0.8913043478260869 and parameters: {'C': 0.08975201520809827, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 939}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:30,405]\u001b[0m Trial 62 finished with value: 0.8913043478260869 and parameters: {'C': 0.0831749480739995, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 876}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:30,455]\u001b[0m Trial 63 finished with value: 0.8913043478260869 and parameters: {'C': 0.08555460734260809, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 904}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:30,505]\u001b[0m Trial 64 finished with value: 0.8913043478260869 and parameters: {'C': 0.09006777536651368, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 964}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:30,554]\u001b[0m Trial 65 finished with value: 0.8893280632411067 and parameters: {'C': 0.09663000670799662, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 436}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:30,786]\u001b[0m Trial 66 finished with value: 0.8893280632411067 and parameters: {'C': 0.09265984242612328, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 837}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:30,837]\u001b[0m Trial 67 finished with value: 0.8913043478260869 and parameters: {'C': 0.0882630007234697, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 759}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:30,882]\u001b[0m Trial 68 finished with value: 0.8893280632411067 and parameters: {'C': 0.07719165263652522, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 711}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:31,786]\u001b[0m Trial 69 finished with value: 0.8873517786561265 and parameters: {'C': 0.0850788983115437, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 981}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:31,843]\u001b[0m Trial 70 finished with value: 0.8913043478260869 and parameters: {'C': 0.09396581958047945, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 937}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:31,902]\u001b[0m Trial 71 finished with value: 0.8913043478260869 and parameters: {'C': 0.08966411659996543, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 997}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:31,958]\u001b[0m Trial 72 finished with value: 0.8893280632411067 and parameters: {'C': 0.09652968488280647, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 937}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:32,004]\u001b[0m Trial 73 finished with value: 0.8913043478260869 and parameters: {'C': 0.09048742734404658, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 976}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:32,054]\u001b[0m Trial 74 finished with value: 0.8913043478260869 and parameters: {'C': 0.08412718313249985, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 928}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:32,105]\u001b[0m Trial 75 finished with value: 0.8893280632411067 and parameters: {'C': 0.08057024036101641, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 887}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:32,157]\u001b[0m Trial 76 finished with value: 0.8913043478260869 and parameters: {'C': 0.08703566664401269, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 185}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:32,213]\u001b[0m Trial 77 finished with value: 0.8913043478260869 and parameters: {'C': 0.0922737319646602, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 979}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:32,426]\u001b[0m Trial 78 finished with value: 0.8893280632411067 and parameters: {'C': 0.08187874556945501, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 954}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:32,479]\u001b[0m Trial 79 finished with value: 0.8893280632411067 and parameters: {'C': 0.09673110843159129, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 897}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:32,527]\u001b[0m Trial 80 finished with value: 0.8853754940711462 and parameters: {'C': 0.09971352226287279, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 852}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:32,577]\u001b[0m Trial 81 finished with value: 0.8913043478260869 and parameters: {'C': 0.08842155829257906, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 998}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:32,627]\u001b[0m Trial 82 finished with value: 0.8913043478260869 and parameters: {'C': 0.08376557971406026, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 826}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:32,678]\u001b[0m Trial 83 finished with value: 0.8913043478260869 and parameters: {'C': 0.08669678353468813, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 804}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:32,733]\u001b[0m Trial 84 finished with value: 0.8913043478260869 and parameters: {'C': 0.09131822151996723, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 931}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:32,785]\u001b[0m Trial 85 finished with value: 0.8893280632411067 and parameters: {'C': 0.08113411868756211, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 733}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:33,017]\u001b[0m Trial 86 finished with value: 0.8893280632411067 and parameters: {'C': 0.09406035693374726, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 955}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:33,067]\u001b[0m Trial 87 finished with value: 0.8893280632411067 and parameters: {'C': 0.0772727053100038, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 868}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:33,119]\u001b[0m Trial 88 finished with value: 0.8913043478260869 and parameters: {'C': 0.08554999855580532, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 910}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:33,179]\u001b[0m Trial 89 finished with value: 0.8913043478260869 and parameters: {'C': 0.0898784157617974, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 681}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:33,393]\u001b[0m Trial 90 finished with value: 0.8893280632411067 and parameters: {'C': 0.07861155300766187, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 984}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:33,452]\u001b[0m Trial 91 finished with value: 0.8913043478260869 and parameters: {'C': 0.09315295756060238, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 950}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:33,506]\u001b[0m Trial 92 finished with value: 0.8913043478260869 and parameters: {'C': 0.09130091257056328, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 919}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:33,562]\u001b[0m Trial 93 finished with value: 0.8913043478260869 and parameters: {'C': 0.0876498602691753, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 891}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:33,614]\u001b[0m Trial 94 finished with value: 0.8893280632411067 and parameters: {'C': 0.0952062104878643, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 964}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:33,669]\u001b[0m Trial 95 finished with value: 0.8913043478260869 and parameters: {'C': 0.08308928169997379, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 326}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:33,716]\u001b[0m Trial 96 finished with value: 0.883399209486166 and parameters: {'C': 0.08841648440830982, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 848}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:33,763]\u001b[0m Trial 97 finished with value: 0.8913043478260869 and parameters: {'C': 0.09153181190173958, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 607}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:33,809]\u001b[0m Trial 98 finished with value: 0.8913043478260869 and parameters: {'C': 0.0846461835869865, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 1000}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:34,033]\u001b[0m Trial 99 finished with value: 0.8893280632411067 and parameters: {'C': 0.09578467292227531, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 870}. Best is trial 16 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:34,044]\u001b[0m A new study created in memory with name: no-name-09302117-de2e-4053-b5ed-a1ab958005a2\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "index  selected_features_all_best30       XGBClassifier            False   \n",
      "index  selected_features_all_best30      LGBMClassifier            False   \n",
      "index  selected_features_all_best30  LogisticRegression             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "Optimizing selected_features_all_best30 SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:38:34,655]\u001b[0m Trial 0 finished with value: 0.5177865612648221 and parameters: {'svc_c': 45.48258663520493, 'svc_gamma': 29.982864410821676}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:35,190]\u001b[0m Trial 1 finished with value: 0.5177865612648221 and parameters: {'svc_c': 69.03665719583451, 'svc_gamma': 63.58316045628349}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:35,674]\u001b[0m Trial 2 finished with value: 0.5138339920948617 and parameters: {'svc_c': 10.981700362263517, 'svc_gamma': 92.44976306738184}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:36,196]\u001b[0m Trial 3 finished with value: 0.5177865612648221 and parameters: {'svc_c': 45.78783115598922, 'svc_gamma': 6.90138642611082}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:36,757]\u001b[0m Trial 4 finished with value: 0.5177865612648221 and parameters: {'svc_c': 11.490446606635224, 'svc_gamma': 20.115057674413546}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:37,209]\u001b[0m Trial 5 finished with value: 0.5177865612648221 and parameters: {'svc_c': 67.50347472615543, 'svc_gamma': 70.20902309080607}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:37,741]\u001b[0m Trial 6 finished with value: 0.5177865612648221 and parameters: {'svc_c': 68.40945446928782, 'svc_gamma': 14.164106880385923}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:38,253]\u001b[0m Trial 7 finished with value: 0.5177865612648221 and parameters: {'svc_c': 45.93499843337403, 'svc_gamma': 33.22328107913082}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:38,688]\u001b[0m Trial 8 finished with value: 0.5158102766798419 and parameters: {'svc_c': 66.49863428320074, 'svc_gamma': 89.7492346948768}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:39,193]\u001b[0m Trial 9 finished with value: 0.5177865612648221 and parameters: {'svc_c': 9.713994652121837, 'svc_gamma': 11.632307786539249}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:39,753]\u001b[0m Trial 10 finished with value: 0.5177865612648221 and parameters: {'svc_c': 96.32032272009538, 'svc_gamma': 39.706998633041216}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:40,252]\u001b[0m Trial 11 finished with value: 0.5177865612648221 and parameters: {'svc_c': 32.38022143375902, 'svc_gamma': 53.70038763480426}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:40,807]\u001b[0m Trial 12 finished with value: 0.5177865612648221 and parameters: {'svc_c': 85.99514531908538, 'svc_gamma': 60.18265161206364}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:41,361]\u001b[0m Trial 13 finished with value: 0.5177865612648221 and parameters: {'svc_c': 32.814348082647356, 'svc_gamma': 37.46218864034215}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:41,845]\u001b[0m Trial 14 finished with value: 0.5177865612648221 and parameters: {'svc_c': 59.75202047459656, 'svc_gamma': 70.90728020843892}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:42,406]\u001b[0m Trial 15 finished with value: 0.5177865612648221 and parameters: {'svc_c': 82.16640665707472, 'svc_gamma': 24.623854577789473}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:42,897]\u001b[0m Trial 16 finished with value: 0.5177865612648221 and parameters: {'svc_c': 56.52724306502789, 'svc_gamma': 46.20460440053172}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:43,307]\u001b[0m Trial 17 finished with value: 0.6818181818181818 and parameters: {'svc_c': 77.37138590892467, 'svc_gamma': 1.1703614860118705}. Best is trial 17 with value: 0.6818181818181818.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:43,767]\u001b[0m Trial 18 finished with value: 0.6996047430830039 and parameters: {'svc_c': 85.91942883897018, 'svc_gamma': 1.0428954629460672}. Best is trial 18 with value: 0.6996047430830039.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:44,254]\u001b[0m Trial 19 finished with value: 0.6541501976284585 and parameters: {'svc_c': 99.68899194167612, 'svc_gamma': 1.3506704781663856}. Best is trial 18 with value: 0.6996047430830039.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:44,705]\u001b[0m Trial 20 finished with value: 0.525691699604743 and parameters: {'svc_c': 79.94733652823398, 'svc_gamma': 3.9062244048926598}. Best is trial 18 with value: 0.6996047430830039.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:45,219]\u001b[0m Trial 21 finished with value: 0.525691699604743 and parameters: {'svc_c': 99.4102411564393, 'svc_gamma': 3.9919871428856846}. Best is trial 18 with value: 0.6996047430830039.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:45,678]\u001b[0m Trial 22 finished with value: 0.541501976284585 and parameters: {'svc_c': 92.71542521177835, 'svc_gamma': 2.927654316656664}. Best is trial 18 with value: 0.6996047430830039.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:46,053]\u001b[0m Trial 23 finished with value: 0.8478260869565217 and parameters: {'svc_c': 87.16748444581143, 'svc_gamma': 0.2406386614453394}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:46,577]\u001b[0m Trial 24 finished with value: 0.5177865612648221 and parameters: {'svc_c': 77.52123351238913, 'svc_gamma': 15.55100989635695}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:47,172]\u001b[0m Trial 25 finished with value: 0.5177865612648221 and parameters: {'svc_c': 88.57477501485069, 'svc_gamma': 24.16865585313952}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:47,704]\u001b[0m Trial 26 finished with value: 0.5177865612648221 and parameters: {'svc_c': 89.71280687879967, 'svc_gamma': 12.21113686286158}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:48,052]\u001b[0m Trial 27 finished with value: 0.8478260869565217 and parameters: {'svc_c': 76.54177076248392, 'svc_gamma': 0.19355182630180542}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:48,560]\u001b[0m Trial 28 finished with value: 0.5177865612648221 and parameters: {'svc_c': 86.028866556259, 'svc_gamma': 9.583822899806997}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:49,078]\u001b[0m Trial 29 finished with value: 0.5177865612648221 and parameters: {'svc_c': 91.59911457709465, 'svc_gamma': 21.327522558862018}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:49,612]\u001b[0m Trial 30 finished with value: 0.5177865612648221 and parameters: {'svc_c': 72.91544035987002, 'svc_gamma': 16.188487716604616}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:49,962]\u001b[0m Trial 31 finished with value: 0.841897233201581 and parameters: {'svc_c': 77.97820115765317, 'svc_gamma': 0.1798407975423284}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:50,454]\u001b[0m Trial 32 finished with value: 0.5177865612648221 and parameters: {'svc_c': 82.86434991776875, 'svc_gamma': 8.209430742327152}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:50,853]\u001b[0m Trial 33 finished with value: 0.8320158102766798 and parameters: {'svc_c': 77.31362285428145, 'svc_gamma': 0.3217799952653145}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:51,314]\u001b[0m Trial 34 finished with value: 0.5177865612648221 and parameters: {'svc_c': 74.25335439116041, 'svc_gamma': 8.096879166168371}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:51,822]\u001b[0m Trial 35 finished with value: 0.5177865612648221 and parameters: {'svc_c': 73.91700518319605, 'svc_gamma': 26.92346489336291}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:52,391]\u001b[0m Trial 36 finished with value: 0.5177865612648221 and parameters: {'svc_c': 79.42077036050077, 'svc_gamma': 19.22475242395663}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:52,863]\u001b[0m Trial 37 finished with value: 0.5177865612648221 and parameters: {'svc_c': 62.95429688954195, 'svc_gamma': 8.051600488505468}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:53,396]\u001b[0m Trial 38 finished with value: 0.5177865612648221 and parameters: {'svc_c': 70.61376127662791, 'svc_gamma': 16.67731884201437}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:53,806]\u001b[0m Trial 39 finished with value: 0.7944664031620553 and parameters: {'svc_c': 92.66031591533701, 'svc_gamma': 0.5330813097115876}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:54,308]\u001b[0m Trial 40 finished with value: 0.5177865612648221 and parameters: {'svc_c': 66.37939891512042, 'svc_gamma': 12.420644107635447}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:54,755]\u001b[0m Trial 41 finished with value: 0.5177865612648221 and parameters: {'svc_c': 94.20058803551494, 'svc_gamma': 5.582081455035478}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:55,122]\u001b[0m Trial 42 finished with value: 0.7272727272727273 and parameters: {'svc_c': 83.72268792934942, 'svc_gamma': 0.9360961248652081}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:55,541]\u001b[0m Trial 43 finished with value: 0.5177865612648221 and parameters: {'svc_c': 89.65253917105153, 'svc_gamma': 6.504201233736848}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:55,897]\u001b[0m Trial 44 finished with value: 0.8438735177865613 and parameters: {'svc_c': 94.25687526097914, 'svc_gamma': 0.17548137315324816}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:56,368]\u001b[0m Trial 45 finished with value: 0.5177865612648221 and parameters: {'svc_c': 75.71896843670355, 'svc_gamma': 11.674996973605653}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:56,802]\u001b[0m Trial 46 finished with value: 0.5177865612648221 and parameters: {'svc_c': 96.3644197216184, 'svc_gamma': 6.667731990287301}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:57,342]\u001b[0m Trial 47 finished with value: 0.5177865612648221 and parameters: {'svc_c': 81.18845607912836, 'svc_gamma': 19.47470727073788}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:57,939]\u001b[0m Trial 48 finished with value: 0.5177865612648221 and parameters: {'svc_c': 69.84454641185893, 'svc_gamma': 13.780934612225378}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:58,228]\u001b[0m Trial 49 finished with value: 0.8438735177865613 and parameters: {'svc_c': 86.99932590025634, 'svc_gamma': 0.09400740759157292}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:58,790]\u001b[0m Trial 50 finished with value: 0.5177865612648221 and parameters: {'svc_c': 87.61170653227539, 'svc_gamma': 28.88043131343466}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:59,183]\u001b[0m Trial 51 finished with value: 0.5217391304347826 and parameters: {'svc_c': 83.50464955973712, 'svc_gamma': 4.805141810824943}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:38:59,640]\u001b[0m Trial 52 finished with value: 0.5177865612648221 and parameters: {'svc_c': 79.15619068984142, 'svc_gamma': 9.891066565563074}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:00,039]\u001b[0m Trial 53 finished with value: 0.525691699604743 and parameters: {'svc_c': 95.05600464057467, 'svc_gamma': 3.969941093733127}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:00,394]\u001b[0m Trial 54 finished with value: 0.6561264822134387 and parameters: {'svc_c': 86.75018408699152, 'svc_gamma': 1.3373625071500947}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:00,736]\u001b[0m Trial 55 finished with value: 0.8162055335968379 and parameters: {'svc_c': 76.32560603128174, 'svc_gamma': 0.42093227868556926}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:01,220]\u001b[0m Trial 56 finished with value: 0.5177865612648221 and parameters: {'svc_c': 90.646427253239, 'svc_gamma': 9.941723850699761}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:01,649]\u001b[0m Trial 57 finished with value: 0.5177865612648221 and parameters: {'svc_c': 97.5055068775598, 'svc_gamma': 5.291284210590642}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:02,104]\u001b[0m Trial 58 finished with value: 0.5177865612648221 and parameters: {'svc_c': 83.76186714616547, 'svc_gamma': 12.806695157832005}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:02,362]\u001b[0m Trial 59 finished with value: 0.8399209486166008 and parameters: {'svc_c': 79.46496557088942, 'svc_gamma': 0.11282937854458226}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:02,836]\u001b[0m Trial 60 finished with value: 0.5177865612648221 and parameters: {'svc_c': 98.81903782932514, 'svc_gamma': 5.61832985250744}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:03,216]\u001b[0m Trial 61 finished with value: 0.5296442687747036 and parameters: {'svc_c': 79.58068809622803, 'svc_gamma': 3.3260827094494285}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:03,709]\u001b[0m Trial 62 finished with value: 0.5177865612648221 and parameters: {'svc_c': 86.39840799265123, 'svc_gamma': 10.121096530718182}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:04,102]\u001b[0m Trial 63 finished with value: 0.841897233201581 and parameters: {'svc_c': 72.79220685235457, 'svc_gamma': 0.163263291541208}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:04,525]\u001b[0m Trial 64 finished with value: 0.5276679841897233 and parameters: {'svc_c': 73.01254517513537, 'svc_gamma': 3.697027625347165}. Best is trial 23 with value: 0.8478260869565217.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:04,820]\u001b[0m Trial 65 finished with value: 0.8537549407114624 and parameters: {'svc_c': 91.89133569306787, 'svc_gamma': 0.03375857107899616}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:05,347]\u001b[0m Trial 66 finished with value: 0.5177865612648221 and parameters: {'svc_c': 92.40252501622723, 'svc_gamma': 8.730925486534154}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:05,950]\u001b[0m Trial 67 finished with value: 0.5177865612648221 and parameters: {'svc_c': 89.16985398351636, 'svc_gamma': 15.533641860212795}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:06,491]\u001b[0m Trial 68 finished with value: 0.5177865612648221 and parameters: {'svc_c': 94.61287550467502, 'svc_gamma': 7.039065280646691}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:06,966]\u001b[0m Trial 69 finished with value: 0.525691699604743 and parameters: {'svc_c': 84.27777575230625, 'svc_gamma': 3.854808582551045}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:07,533]\u001b[0m Trial 70 finished with value: 0.5177865612648221 and parameters: {'svc_c': 99.84608634136055, 'svc_gamma': 13.110828415688395}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:07,941]\u001b[0m Trial 71 finished with value: 0.7391304347826086 and parameters: {'svc_c': 80.6898897705361, 'svc_gamma': 0.8491080301751474}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:08,200]\u001b[0m Trial 72 finished with value: 0.83399209486166 and parameters: {'svc_c': 89.5378549063662, 'svc_gamma': 0.0575616160843706}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:08,655]\u001b[0m Trial 73 finished with value: 0.5296442687747036 and parameters: {'svc_c': 82.38528400207757, 'svc_gamma': 3.268559316741283}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:09,155]\u001b[0m Trial 74 finished with value: 0.5177865612648221 and parameters: {'svc_c': 77.29763618399154, 'svc_gamma': 7.521665148567761}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:09,614]\u001b[0m Trial 75 finished with value: 0.5296442687747036 and parameters: {'svc_c': 85.60794397376866, 'svc_gamma': 3.501519669690061}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:10,115]\u001b[0m Trial 76 finished with value: 0.5177865612648221 and parameters: {'svc_c': 71.63486406261426, 'svc_gamma': 9.37686439753802}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:10,371]\u001b[0m Trial 77 finished with value: 0.8438735177865613 and parameters: {'svc_c': 92.92504331161464, 'svc_gamma': 0.08223598906474278}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:10,783]\u001b[0m Trial 78 finished with value: 0.5177865612648221 and parameters: {'svc_c': 90.30837910394078, 'svc_gamma': 5.713915742365072}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:11,282]\u001b[0m Trial 79 finished with value: 0.5177865612648221 and parameters: {'svc_c': 93.40438300276396, 'svc_gamma': 17.96635902190414}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:11,833]\u001b[0m Trial 80 finished with value: 0.5177865612648221 and parameters: {'svc_c': 95.84086155877696, 'svc_gamma': 14.7008156474346}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:12,242]\u001b[0m Trial 81 finished with value: 0.5474308300395256 and parameters: {'svc_c': 86.91828231327588, 'svc_gamma': 2.4916152166608976}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:12,605]\u001b[0m Trial 82 finished with value: 0.841897233201581 and parameters: {'svc_c': 92.04429940353245, 'svc_gamma': 0.2644287688855034}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:13,074]\u001b[0m Trial 83 finished with value: 0.5177865612648221 and parameters: {'svc_c': 91.61922621907122, 'svc_gamma': 6.264804945896755}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:13,598]\u001b[0m Trial 84 finished with value: 0.5177865612648221 and parameters: {'svc_c': 96.72298795366042, 'svc_gamma': 11.075722836814212}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:14,071]\u001b[0m Trial 85 finished with value: 0.5454545454545454 and parameters: {'svc_c': 93.19553735885214, 'svc_gamma': 2.6437608180264642}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:14,573]\u001b[0m Trial 86 finished with value: 0.5177865612648221 and parameters: {'svc_c': 87.73227503141142, 'svc_gamma': 7.466300180912838}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:14,984]\u001b[0m Trial 87 finished with value: 0.5474308300395256 and parameters: {'svc_c': 81.68625890094104, 'svc_gamma': 2.486580707502646}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:15,417]\u001b[0m Trial 88 finished with value: 0.5177865612648221 and parameters: {'svc_c': 96.95283641270436, 'svc_gamma': 5.474726558701071}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:15,928]\u001b[0m Trial 89 finished with value: 0.5177865612648221 and parameters: {'svc_c': 85.25436380978641, 'svc_gamma': 11.28598716242542}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:16,440]\u001b[0m Trial 90 finished with value: 0.5177865612648221 and parameters: {'svc_c': 88.42619739777825, 'svc_gamma': 8.41125985525686}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:16,836]\u001b[0m Trial 91 finished with value: 0.8438735177865613 and parameters: {'svc_c': 91.19719628142487, 'svc_gamma': 0.2515833462400049}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:17,204]\u001b[0m Trial 92 finished with value: 0.8438735177865613 and parameters: {'svc_c': 91.23933069265385, 'svc_gamma': 0.1761835640258373}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:17,635]\u001b[0m Trial 93 finished with value: 0.5474308300395256 and parameters: {'svc_c': 94.34874521650181, 'svc_gamma': 2.561909508033491}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:18,080]\u001b[0m Trial 94 finished with value: 0.5177865612648221 and parameters: {'svc_c': 74.7746816954322, 'svc_gamma': 5.419095217667932}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:18,595]\u001b[0m Trial 95 finished with value: 0.5434782608695652 and parameters: {'svc_c': 89.57213608876381, 'svc_gamma': 2.7244043843318804}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:18,943]\u001b[0m Trial 96 finished with value: 0.8399209486166008 and parameters: {'svc_c': 84.16031933674066, 'svc_gamma': 0.13814990885488615}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:19,390]\u001b[0m Trial 97 finished with value: 0.5197628458498024 and parameters: {'svc_c': 91.42950566974825, 'svc_gamma': 4.93476295601378}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:19,816]\u001b[0m Trial 98 finished with value: 0.5177865612648221 and parameters: {'svc_c': 98.30244586687475, 'svc_gamma': 7.544069978300236}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:20,262]\u001b[0m Trial 99 finished with value: 0.5177865612648221 and parameters: {'svc_c': 87.55919129919242, 'svc_gamma': 9.907378178807395}. Best is trial 65 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:20,270]\u001b[0m A new study created in memory with name: no-name-39b321f9-5702-4f41-9342-47421ec59254\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "index  selected_features_all_best30       XGBClassifier            False   \n",
      "index  selected_features_all_best30      LGBMClassifier            False   \n",
      "index  selected_features_all_best30  LogisticRegression             True   \n",
      "index  selected_features_all_best30                 SVC             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "Optimizing selected_features_all_best30 XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:39:22,560]\u001b[0m Trial 0 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.15309337268637435, 'max_depth': 3, 'n_estimators': 993}. Best is trial 0 with value: 0.883399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:23,772]\u001b[0m Trial 1 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.22028169260786543, 'max_depth': 3, 'n_estimators': 496}. Best is trial 1 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:24,947]\u001b[0m Trial 2 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.14942829827562668, 'max_depth': 4, 'n_estimators': 392}. Best is trial 1 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:26,892]\u001b[0m Trial 3 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.04132576060911622, 'max_depth': 4, 'n_estimators': 502}. Best is trial 3 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:29,048]\u001b[0m Trial 4 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.20691986423971134, 'max_depth': 3, 'n_estimators': 966}. Best is trial 3 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:29,750]\u001b[0m Trial 5 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.1331776796999549, 'max_depth': 4, 'n_estimators': 216}. Best is trial 3 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:34,025]\u001b[0m Trial 6 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.01692933565588608, 'max_depth': 6, 'n_estimators': 824}. Best is trial 3 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:36,465]\u001b[0m Trial 7 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.1638122019388684, 'max_depth': 3, 'n_estimators': 823}. Best is trial 3 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:38,125]\u001b[0m Trial 8 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.27684692348726875, 'max_depth': 3, 'n_estimators': 680}. Best is trial 3 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:41,003]\u001b[0m Trial 9 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.1159715719060044, 'max_depth': 4, 'n_estimators': 981}. Best is trial 3 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:41,780]\u001b[0m Trial 10 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.014806307424100416, 'max_depth': 6, 'n_estimators': 109}. Best is trial 3 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:42,777]\u001b[0m Trial 11 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.07689986005498053, 'max_depth': 5, 'n_estimators': 226}. Best is trial 3 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:44,505]\u001b[0m Trial 12 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.07499909022825951, 'max_depth': 5, 'n_estimators': 327}. Best is trial 3 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:45,671]\u001b[0m Trial 13 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.056486770986670674, 'max_depth': 2, 'n_estimators': 576}. Best is trial 3 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:46,535]\u001b[0m Trial 14 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.10204292905866474, 'max_depth': 5, 'n_estimators': 206}. Best is trial 3 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:47,993]\u001b[0m Trial 15 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.05223640009387301, 'max_depth': 4, 'n_estimators': 425}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:49,041]\u001b[0m Trial 16 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.04853356355909669, 'max_depth': 2, 'n_estimators': 484}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:51,962]\u001b[0m Trial 17 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.043204507970566235, 'max_depth': 5, 'n_estimators': 627}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:54,382]\u001b[0m Trial 18 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.09542186631562881, 'max_depth': 5, 'n_estimators': 638}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:58,336]\u001b[0m Trial 19 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.015295342853059501, 'max_depth': 6, 'n_estimators': 722}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:39:59,907]\u001b[0m Trial 20 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.07541165005648509, 'max_depth': 5, 'n_estimators': 340}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:01,689]\u001b[0m Trial 21 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.041415126655961455, 'max_depth': 4, 'n_estimators': 458}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:03,944]\u001b[0m Trial 22 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.05556549111390849, 'max_depth': 4, 'n_estimators': 579}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:05,837]\u001b[0m Trial 23 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.06141184160596341, 'max_depth': 4, 'n_estimators': 574}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:09,063]\u001b[0m Trial 24 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.03285729279367465, 'max_depth': 5, 'n_estimators': 747}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:13,116]\u001b[0m Trial 25 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.023502010408716953, 'max_depth': 5, 'n_estimators': 776}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:16,728]\u001b[0m Trial 26 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.03832566062804142, 'max_depth': 6, 'n_estimators': 653}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:19,577]\u001b[0m Trial 27 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.08335952321883838, 'max_depth': 5, 'n_estimators': 739}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:23,380]\u001b[0m Trial 28 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.03215578148788725, 'max_depth': 5, 'n_estimators': 842}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:25,402]\u001b[0m Trial 29 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.0630922733594748, 'max_depth': 6, 'n_estimators': 410}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:28,319]\u001b[0m Trial 30 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.09845224135532113, 'max_depth': 5, 'n_estimators': 888}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:30,868]\u001b[0m Trial 31 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.010350215868469542, 'max_depth': 4, 'n_estimators': 598}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:32,793]\u001b[0m Trial 32 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.0552854870804811, 'max_depth': 4, 'n_estimators': 527}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:35,245]\u001b[0m Trial 33 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.031009371951054326, 'max_depth': 4, 'n_estimators': 625}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:37,611]\u001b[0m Trial 34 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.04064547733632328, 'max_depth': 3, 'n_estimators': 698}. Best is trial 15 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:39,500]\u001b[0m Trial 35 finished with value: 0.9011857707509882 and parameters: {'learning_rate': 0.05933139707386613, 'max_depth': 4, 'n_estimators': 540}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:41,109]\u001b[0m Trial 36 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.035262629827263775, 'max_depth': 4, 'n_estimators': 429}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:42,257]\u001b[0m Trial 37 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.07045007043160426, 'max_depth': 3, 'n_estimators': 353}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:44,440]\u001b[0m Trial 38 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.04976108346394982, 'max_depth': 4, 'n_estimators': 525}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:48,100]\u001b[0m Trial 39 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.02582040716339055, 'max_depth': 5, 'n_estimators': 930}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:49,949]\u001b[0m Trial 40 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.12370929424233504, 'max_depth': 4, 'n_estimators': 463}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:51,459]\u001b[0m Trial 41 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.12638882167173518, 'max_depth': 4, 'n_estimators': 463}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:52,520]\u001b[0m Trial 42 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.12934441364567123, 'max_depth': 4, 'n_estimators': 285}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:54,208]\u001b[0m Trial 43 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.15343270747476392, 'max_depth': 3, 'n_estimators': 465}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:55,547]\u001b[0m Trial 44 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.16943173217739743, 'max_depth': 4, 'n_estimators': 396}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:56,958]\u001b[0m Trial 45 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.12846963141277673, 'max_depth': 3, 'n_estimators': 516}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:58,824]\u001b[0m Trial 46 finished with value: 0.9011857707509882 and parameters: {'learning_rate': 0.09254639621451684, 'max_depth': 4, 'n_estimators': 451}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:40:59,795]\u001b[0m Trial 47 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.09151882280184646, 'max_depth': 4, 'n_estimators': 293}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:00,746]\u001b[0m Trial 48 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.10811827422766677, 'max_depth': 3, 'n_estimators': 371}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:02,352]\u001b[0m Trial 49 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.0877771125623509, 'max_depth': 4, 'n_estimators': 441}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:04,386]\u001b[0m Trial 50 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.11082581960271255, 'max_depth': 4, 'n_estimators': 537}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:06,273]\u001b[0m Trial 51 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.1194828232008539, 'max_depth': 4, 'n_estimators': 483}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:07,603]\u001b[0m Trial 52 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.0837303963128758, 'max_depth': 4, 'n_estimators': 390}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:09,359]\u001b[0m Trial 53 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.0632441595450512, 'max_depth': 4, 'n_estimators': 505}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:11,278]\u001b[0m Trial 54 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.0712302833139265, 'max_depth': 4, 'n_estimators': 423}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:12,126]\u001b[0m Trial 55 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.14122632385628336, 'max_depth': 3, 'n_estimators': 309}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:16,145]\u001b[0m Trial 56 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.10188969833705805, 'max_depth': 5, 'n_estimators': 560}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:17,958]\u001b[0m Trial 57 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.11962581263867618, 'max_depth': 4, 'n_estimators': 471}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:18,637]\u001b[0m Trial 58 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.08237146279889011, 'max_depth': 3, 'n_estimators': 243}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:19,306]\u001b[0m Trial 59 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.0947942440694526, 'max_depth': 2, 'n_estimators': 368}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:21,155]\u001b[0m Trial 60 finished with value: 0.9011857707509882 and parameters: {'learning_rate': 0.048429943326810096, 'max_depth': 4, 'n_estimators': 446}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:22,757]\u001b[0m Trial 61 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.0468605058796996, 'max_depth': 4, 'n_estimators': 448}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:24,578]\u001b[0m Trial 62 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.02117081718053298, 'max_depth': 4, 'n_estimators': 493}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:26,356]\u001b[0m Trial 63 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.0631874197620102, 'max_depth': 4, 'n_estimators': 403}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:28,808]\u001b[0m Trial 64 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.05064102330809582, 'max_depth': 5, 'n_estimators': 602}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:30,703]\u001b[0m Trial 65 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.0736871193651559, 'max_depth': 4, 'n_estimators': 555}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:32,341]\u001b[0m Trial 66 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.028582026533660557, 'max_depth': 4, 'n_estimators': 455}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:35,177]\u001b[0m Trial 67 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.04321979066814, 'max_depth': 4, 'n_estimators': 770}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:37,410]\u001b[0m Trial 68 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.05726475691377695, 'max_depth': 5, 'n_estimators': 491}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:37,943]\u001b[0m Trial 69 finished with value: 0.8636363636363636 and parameters: {'learning_rate': 0.010052887324637251, 'max_depth': 4, 'n_estimators': 137}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:40,382]\u001b[0m Trial 70 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.06581792352871052, 'max_depth': 4, 'n_estimators': 657}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:40,982]\u001b[0m Trial 71 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.14274990225330567, 'max_depth': 2, 'n_estimators': 308}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:41,663]\u001b[0m Trial 72 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.14696584152875394, 'max_depth': 3, 'n_estimators': 252}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:42,517]\u001b[0m Trial 73 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.08117540425773286, 'max_depth': 3, 'n_estimators': 343}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:43,331]\u001b[0m Trial 74 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.0329390534756944, 'max_depth': 3, 'n_estimators': 321}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:45,521]\u001b[0m Trial 75 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.019997727911287753, 'max_depth': 6, 'n_estimators': 419}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:46,758]\u001b[0m Trial 76 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.13594459486708027, 'max_depth': 4, 'n_estimators': 370}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:48,965]\u001b[0m Trial 77 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.1655606340465659, 'max_depth': 5, 'n_estimators': 537}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:50,323]\u001b[0m Trial 78 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.09391488677993196, 'max_depth': 2, 'n_estimators': 598}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:51,177]\u001b[0m Trial 79 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.05297582895924331, 'max_depth': 5, 'n_estimators': 185}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:52,551]\u001b[0m Trial 80 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.10479132467159438, 'max_depth': 3, 'n_estimators': 512}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:55,743]\u001b[0m Trial 81 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.03903602454440884, 'max_depth': 5, 'n_estimators': 696}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:41:59,200]\u001b[0m Trial 82 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.03354611218785408, 'max_depth': 5, 'n_estimators': 777}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:02,358]\u001b[0m Trial 83 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.0409081127232557, 'max_depth': 5, 'n_estimators': 731}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:05,531]\u001b[0m Trial 84 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.05602833420165163, 'max_depth': 4, 'n_estimators': 795}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:08,488]\u001b[0m Trial 85 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.06574854749627393, 'max_depth': 6, 'n_estimators': 685}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:10,331]\u001b[0m Trial 86 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.04519412475700863, 'max_depth': 4, 'n_estimators': 476}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:13,499]\u001b[0m Trial 87 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.027127749334393998, 'max_depth': 4, 'n_estimators': 886}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:15,238]\u001b[0m Trial 88 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.11455087021644941, 'max_depth': 5, 'n_estimators': 433}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:17,259]\u001b[0m Trial 89 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.03852960777030704, 'max_depth': 4, 'n_estimators': 568}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:21,423]\u001b[0m Trial 90 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.01635664496864219, 'max_depth': 5, 'n_estimators': 849}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:24,791]\u001b[0m Trial 91 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.026333154759437274, 'max_depth': 4, 'n_estimators': 925}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:27,841]\u001b[0m Trial 92 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.04883018182791316, 'max_depth': 4, 'n_estimators': 853}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:31,303]\u001b[0m Trial 93 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.025585673228515824, 'max_depth': 4, 'n_estimators': 881}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:32,866]\u001b[0m Trial 94 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.03386851366219143, 'max_depth': 4, 'n_estimators': 391}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:35,468]\u001b[0m Trial 95 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.05792721010014622, 'max_depth': 4, 'n_estimators': 713}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:39,335]\u001b[0m Trial 96 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.07660692201605775, 'max_depth': 4, 'n_estimators': 952}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:41,313]\u001b[0m Trial 97 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.03750443692974461, 'max_depth': 4, 'n_estimators': 446}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:43,260]\u001b[0m Trial 98 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.0453011580863542, 'max_depth': 4, 'n_estimators': 544}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:46,234]\u001b[0m Trial 99 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.06946784152509414, 'max_depth': 5, 'n_estimators': 653}. Best is trial 35 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:46,249]\u001b[0m A new study created in memory with name: no-name-6cb86842-649f-48d1-9777-aa98bae4a598\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "index  selected_features_all_best30       XGBClassifier            False   \n",
      "index  selected_features_all_best30      LGBMClassifier            False   \n",
      "index  selected_features_all_best30  LogisticRegression             True   \n",
      "index  selected_features_all_best30                 SVC             True   \n",
      "index  selected_features_all_best30       XGBClassifier             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "Optimizing selected_features_all_best30 LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:42:48,639]\u001b[0m Trial 0 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 151, 'max_depth': 46, 'learning_rate': 0.124478597224429, 'n_estimators': 1893}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:50,784]\u001b[0m Trial 1 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 137, 'max_depth': 18, 'learning_rate': 0.13594225171487398, 'n_estimators': 1698}. Best is trial 1 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:51,333]\u001b[0m Trial 2 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 141, 'max_depth': 11, 'learning_rate': 0.25414532320145833, 'n_estimators': 187}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:54,517]\u001b[0m Trial 3 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 219, 'max_depth': 45, 'learning_rate': 0.060002349042560445, 'n_estimators': 1210}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:55,893]\u001b[0m Trial 4 finished with value: 0.883399209486166 and parameters: {'num_leaves': 176, 'max_depth': 33, 'learning_rate': 0.10800270883786339, 'n_estimators': 333}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:56,579]\u001b[0m Trial 5 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 227, 'max_depth': 7, 'learning_rate': 0.11610164306041397, 'n_estimators': 261}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:42:59,328]\u001b[0m Trial 6 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 196, 'max_depth': 50, 'learning_rate': 0.017176347163758366, 'n_estimators': 469}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:04,798]\u001b[0m Trial 7 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 178, 'max_depth': 39, 'learning_rate': 0.028848395944330384, 'n_estimators': 1567}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:08,435]\u001b[0m Trial 8 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 201, 'max_depth': 50, 'learning_rate': 0.04929188588622131, 'n_estimators': 1537}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:10,295]\u001b[0m Trial 9 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 244, 'max_depth': 34, 'learning_rate': 0.23785250875386793, 'n_estimators': 1655}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:10,816]\u001b[0m Trial 10 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 48, 'max_depth': 3, 'learning_rate': 0.2606692182172288, 'n_estimators': 806}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:12,588]\u001b[0m Trial 11 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 86, 'max_depth': 20, 'learning_rate': 0.29927270938775724, 'n_estimators': 1152}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:14,014]\u001b[0m Trial 12 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 101, 'max_depth': 14, 'learning_rate': 0.17972893431230677, 'n_estimators': 765}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:16,268]\u001b[0m Trial 13 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 106, 'max_depth': 31, 'learning_rate': 0.1909248503726424, 'n_estimators': 1345}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:16,493]\u001b[0m Trial 14 finished with value: 0.8596837944664032 and parameters: {'num_leaves': 14, 'max_depth': 38, 'learning_rate': 0.011151576350973663, 'n_estimators': 101}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:18,185]\u001b[0m Trial 15 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 165, 'max_depth': 26, 'learning_rate': 0.18428520190639303, 'n_estimators': 845}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:21,228]\u001b[0m Trial 16 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 124, 'max_depth': 26, 'learning_rate': 0.07981219635376566, 'n_estimators': 1931}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:22,405]\u001b[0m Trial 17 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 183, 'max_depth': 11, 'learning_rate': 0.1649109934161007, 'n_estimators': 566}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:26,065]\u001b[0m Trial 18 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 71, 'max_depth': 42, 'learning_rate': 0.2177843846293956, 'n_estimators': 1379}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:26,833]\u001b[0m Trial 19 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 138, 'max_depth': 2, 'learning_rate': 0.1528765919109249, 'n_estimators': 1016}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:28,999]\u001b[0m Trial 20 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 162, 'max_depth': 21, 'learning_rate': 0.0916827811010677, 'n_estimators': 1006}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:30,845]\u001b[0m Trial 21 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 248, 'max_depth': 35, 'learning_rate': 0.23258660458051114, 'n_estimators': 1679}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:32,899]\u001b[0m Trial 22 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 235, 'max_depth': 39, 'learning_rate': 0.25996620955067273, 'n_estimators': 1699}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:34,554]\u001b[0m Trial 23 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 214, 'max_depth': 40, 'learning_rate': 0.2879713253895653, 'n_estimators': 1495}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:36,780]\u001b[0m Trial 24 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 195, 'max_depth': 29, 'learning_rate': 0.2688403703168566, 'n_estimators': 1814}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:39,214]\u001b[0m Trial 25 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 233, 'max_depth': 37, 'learning_rate': 0.20467931940650025, 'n_estimators': 1978}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:41,057]\u001b[0m Trial 26 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 255, 'max_depth': 43, 'learning_rate': 0.25049718776233687, 'n_estimators': 1361}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:42,647]\u001b[0m Trial 27 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 118, 'max_depth': 24, 'learning_rate': 0.27115468360343786, 'n_estimators': 1504}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:43,595]\u001b[0m Trial 28 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 146, 'max_depth': 13, 'learning_rate': 0.2149359254964525, 'n_estimators': 586}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:46,256]\u001b[0m Trial 29 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 162, 'max_depth': 30, 'learning_rate': 0.14930889513764817, 'n_estimators': 1880}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:48,434]\u001b[0m Trial 30 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 210, 'max_depth': 47, 'learning_rate': 0.24517765263825914, 'n_estimators': 1794}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:50,279]\u001b[0m Trial 31 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 234, 'max_depth': 36, 'learning_rate': 0.23746733874665196, 'n_estimators': 1673}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:52,339]\u001b[0m Trial 32 finished with value: 0.883399209486166 and parameters: {'num_leaves': 241, 'max_depth': 40, 'learning_rate': 0.22884699870994835, 'n_estimators': 1595}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:53,837]\u001b[0m Trial 33 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 177, 'max_depth': 33, 'learning_rate': 0.2800015052660114, 'n_estimators': 1281}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:55,717]\u001b[0m Trial 34 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 218, 'max_depth': 33, 'learning_rate': 0.2591883527178805, 'n_estimators': 1785}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:57,841]\u001b[0m Trial 35 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 150, 'max_depth': 42, 'learning_rate': 0.12926030169867445, 'n_estimators': 1168}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:43:59,559]\u001b[0m Trial 36 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 256, 'max_depth': 39, 'learning_rate': 0.25108674640938256, 'n_estimators': 1618}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:01,274]\u001b[0m Trial 37 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 192, 'max_depth': 47, 'learning_rate': 0.2967170706802925, 'n_estimators': 1428}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:01,848]\u001b[0m Trial 38 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 220, 'max_depth': 7, 'learning_rate': 0.27713932558926335, 'n_estimators': 316}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:04,233]\u001b[0m Trial 39 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 183, 'max_depth': 45, 'learning_rate': 0.2027956334629316, 'n_estimators': 1746}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:05,159]\u001b[0m Trial 40 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 207, 'max_depth': 17, 'learning_rate': 0.03556764463537364, 'n_estimators': 170}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:07,820]\u001b[0m Trial 41 finished with value: 0.883399209486166 and parameters: {'num_leaves': 132, 'max_depth': 8, 'learning_rate': 0.06281506139345308, 'n_estimators': 1587}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:10,368]\u001b[0m Trial 42 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 118, 'max_depth': 18, 'learning_rate': 0.11741527336269154, 'n_estimators': 1708}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:15,930]\u001b[0m Trial 43 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 99, 'max_depth': 10, 'learning_rate': 0.025713628925378033, 'n_estimators': 1879}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:22,667]\u001b[0m Trial 44 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 166, 'max_depth': 15, 'learning_rate': 0.007794669542473598, 'n_estimators': 1224}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:25,065]\u001b[0m Trial 45 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 68, 'max_depth': 21, 'learning_rate': 0.0953190831397989, 'n_estimators': 1427}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:27,234]\u001b[0m Trial 46 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 139, 'max_depth': 28, 'learning_rate': 0.1275709547360263, 'n_estimators': 1107}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:28,344]\u001b[0m Trial 47 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 226, 'max_depth': 35, 'learning_rate': 0.2598028857099704, 'n_estimators': 683}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:29,470]\u001b[0m Trial 48 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 13, 'max_depth': 24, 'learning_rate': 0.054620496398876534, 'n_estimators': 937}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:30,846]\u001b[0m Trial 49 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 107, 'max_depth': 32, 'learning_rate': 0.18333994431971506, 'n_estimators': 390}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:32,579]\u001b[0m Trial 50 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 152, 'max_depth': 50, 'learning_rate': 0.22460433554854317, 'n_estimators': 1524}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:33,933]\u001b[0m Trial 51 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 48, 'max_depth': 43, 'learning_rate': 0.2194520887775453, 'n_estimators': 1398}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:35,264]\u001b[0m Trial 52 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 47, 'max_depth': 5, 'learning_rate': 0.2398371916753913, 'n_estimators': 1273}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:37,410]\u001b[0m Trial 53 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 91, 'max_depth': 45, 'learning_rate': 0.19800991793428394, 'n_estimators': 1605}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:39,213]\u001b[0m Trial 54 finished with value: 0.883399209486166 and parameters: {'num_leaves': 77, 'max_depth': 41, 'learning_rate': 0.21455308094604753, 'n_estimators': 1678}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:41,133]\u001b[0m Trial 55 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 29, 'max_depth': 35, 'learning_rate': 0.1761660911610513, 'n_estimators': 1454}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:43,052]\u001b[0m Trial 56 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 244, 'max_depth': 38, 'learning_rate': 0.2303475142748954, 'n_estimators': 1842}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:45,199]\u001b[0m Trial 57 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 126, 'max_depth': 43, 'learning_rate': 0.24219458565698004, 'n_estimators': 1940}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:47,445]\u001b[0m Trial 58 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 111, 'max_depth': 12, 'learning_rate': 0.26584824261432155, 'n_estimators': 1332}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:49,238]\u001b[0m Trial 59 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 199, 'max_depth': 16, 'learning_rate': 0.2550723303630239, 'n_estimators': 1745}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:51,048]\u001b[0m Trial 60 finished with value: 0.883399209486166 and parameters: {'num_leaves': 63, 'max_depth': 19, 'learning_rate': 0.21030325961747692, 'n_estimators': 1535}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:51,465]\u001b[0m Trial 61 finished with value: 0.883399209486166 and parameters: {'num_leaves': 139, 'max_depth': 2, 'learning_rate': 0.1627478999701727, 'n_estimators': 1017}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:52,683]\u001b[0m Trial 62 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 171, 'max_depth': 4, 'learning_rate': 0.19431248718560248, 'n_estimators': 1642}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:55,133]\u001b[0m Trial 63 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 153, 'max_depth': 23, 'learning_rate': 0.06770019060883609, 'n_estimators': 469}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:56,665]\u001b[0m Trial 64 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 136, 'max_depth': 10, 'learning_rate': 0.13956843538889796, 'n_estimators': 826}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:44:59,032]\u001b[0m Trial 65 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 157, 'max_depth': 37, 'learning_rate': 0.10967540944446222, 'n_estimators': 883}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:00,630]\u001b[0m Trial 66 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 122, 'max_depth': 6, 'learning_rate': 0.24606917756337318, 'n_estimators': 1755}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:02,500]\u001b[0m Trial 67 finished with value: 0.883399209486166 and parameters: {'num_leaves': 143, 'max_depth': 27, 'learning_rate': 0.22260685005765346, 'n_estimators': 1573}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:04,693]\u001b[0m Trial 68 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 186, 'max_depth': 40, 'learning_rate': 0.09979217202775412, 'n_estimators': 637}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:05,660]\u001b[0m Trial 69 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 235, 'max_depth': 8, 'learning_rate': 0.2333534641349258, 'n_estimators': 768}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:07,952]\u001b[0m Trial 70 finished with value: 0.883399209486166 and parameters: {'num_leaves': 173, 'max_depth': 14, 'learning_rate': 0.18937963008461842, 'n_estimators': 1997}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:08,433]\u001b[0m Trial 71 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 217, 'max_depth': 7, 'learning_rate': 0.27525001357259027, 'n_estimators': 248}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:08,664]\u001b[0m Trial 72 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 228, 'max_depth': 3, 'learning_rate': 0.28652739175909947, 'n_estimators': 295}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:09,140]\u001b[0m Trial 73 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 208, 'max_depth': 10, 'learning_rate': 0.2678625570342841, 'n_estimators': 128}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:09,465]\u001b[0m Trial 74 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 249, 'max_depth': 5, 'learning_rate': 0.24897057471032233, 'n_estimators': 204}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:09,674]\u001b[0m Trial 75 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 224, 'max_depth': 2, 'learning_rate': 0.0818102962354943, 'n_estimators': 389}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:11,506]\u001b[0m Trial 76 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 236, 'max_depth': 38, 'learning_rate': 0.26234909011688423, 'n_estimators': 1840}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:13,729]\u001b[0m Trial 77 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 114, 'max_depth': 48, 'learning_rate': 0.27581366765302884, 'n_estimators': 1704}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:21,718]\u001b[0m Trial 78 finished with value: 0.8754940711462451 and parameters: {'num_leaves': 129, 'max_depth': 41, 'learning_rate': 0.00256175429595807, 'n_estimators': 1495}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:23,212]\u001b[0m Trial 79 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 98, 'max_depth': 9, 'learning_rate': 0.2542820047786321, 'n_estimators': 1113}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:24,044]\u001b[0m Trial 80 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 188, 'max_depth': 30, 'learning_rate': 0.23489379900419766, 'n_estimators': 351}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:27,029]\u001b[0m Trial 81 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 145, 'max_depth': 18, 'learning_rate': 0.11341372566196965, 'n_estimators': 1636}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:29,762]\u001b[0m Trial 82 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 118, 'max_depth': 21, 'learning_rate': 0.11957874106056524, 'n_estimators': 1713}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:32,068]\u001b[0m Trial 83 finished with value: 0.883399209486166 and parameters: {'num_leaves': 160, 'max_depth': 44, 'learning_rate': 0.1348357021323244, 'n_estimators': 1800}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:34,724]\u001b[0m Trial 84 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 252, 'max_depth': 12, 'learning_rate': 0.11723838326543642, 'n_estimators': 1566}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:36,260]\u001b[0m Trial 85 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 82, 'max_depth': 34, 'learning_rate': 0.16553961764058753, 'n_estimators': 524}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:38,381]\u001b[0m Trial 86 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 35, 'max_depth': 15, 'learning_rate': 0.1486873109325388, 'n_estimators': 1674}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:42,083]\u001b[0m Trial 87 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 241, 'max_depth': 39, 'learning_rate': 0.048032507778536515, 'n_estimators': 1385}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:44,728]\u001b[0m Trial 88 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 132, 'max_depth': 36, 'learning_rate': 0.10691405871237478, 'n_estimators': 1477}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:46,807]\u001b[0m Trial 89 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 201, 'max_depth': 7, 'learning_rate': 0.23975699284451585, 'n_estimators': 1916}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:49,329]\u001b[0m Trial 90 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 177, 'max_depth': 42, 'learning_rate': 0.2056087244271001, 'n_estimators': 1722}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:50,997]\u001b[0m Trial 91 finished with value: 0.883399209486166 and parameters: {'num_leaves': 152, 'max_depth': 23, 'learning_rate': 0.06350957588537785, 'n_estimators': 271}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:52,666]\u001b[0m Trial 92 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 167, 'max_depth': 20, 'learning_rate': 0.12210514077919671, 'n_estimators': 466}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:53,747]\u001b[0m Trial 93 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 155, 'max_depth': 24, 'learning_rate': 0.017982910136485564, 'n_estimators': 206}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:54,875]\u001b[0m Trial 94 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 147, 'max_depth': 22, 'learning_rate': 0.2626342678126744, 'n_estimators': 471}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:55,529]\u001b[0m Trial 95 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 121, 'max_depth': 17, 'learning_rate': 0.25114948636434575, 'n_estimators': 113}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:56,002]\u001b[0m Trial 96 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 3, 'max_depth': 13, 'learning_rate': 0.12975932405905505, 'n_estimators': 1312}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:56,772]\u001b[0m Trial 97 finished with value: 0.8735177865612648 and parameters: {'num_leaves': 135, 'max_depth': 25, 'learning_rate': 0.2827124431379691, 'n_estimators': 328}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:45:59,511]\u001b[0m Trial 98 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 106, 'max_depth': 18, 'learning_rate': 0.08688611497290284, 'n_estimators': 1207}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:01,239]\u001b[0m Trial 99 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 142, 'max_depth': 4, 'learning_rate': 0.07234447291974583, 'n_estimators': 1655}. Best is trial 2 with value: 0.8972332015810277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "index  selected_features_all_best30       XGBClassifier            False   \n",
      "index  selected_features_all_best30      LGBMClassifier            False   \n",
      "index  selected_features_all_best30  LogisticRegression             True   \n",
      "index  selected_features_all_best30                 SVC             True   \n",
      "index  selected_features_all_best30       XGBClassifier             True   \n",
      "index  selected_features_all_best30      LGBMClassifier             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "Evaluating selected_features_all_best50 LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "index  selected_features_all_best30       XGBClassifier            False   \n",
      "index  selected_features_all_best30      LGBMClassifier            False   \n",
      "index  selected_features_all_best30  LogisticRegression             True   \n",
      "index  selected_features_all_best30                 SVC             True   \n",
      "index  selected_features_all_best30       XGBClassifier             True   \n",
      "index  selected_features_all_best30      LGBMClassifier             True   \n",
      "index  selected_features_all_best50  LogisticRegression            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "Evaluating selected_features_all_best50 SVC\n",
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "index  selected_features_all_best30       XGBClassifier            False   \n",
      "index  selected_features_all_best30      LGBMClassifier            False   \n",
      "index  selected_features_all_best30  LogisticRegression             True   \n",
      "index  selected_features_all_best30                 SVC             True   \n",
      "index  selected_features_all_best30       XGBClassifier             True   \n",
      "index  selected_features_all_best30      LGBMClassifier             True   \n",
      "index  selected_features_all_best50  LogisticRegression            False   \n",
      "index  selected_features_all_best50                 SVC            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "Evaluating selected_features_all_best50 XGBClassifier\n",
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "index  selected_features_all_best30       XGBClassifier            False   \n",
      "index  selected_features_all_best30      LGBMClassifier            False   \n",
      "index  selected_features_all_best30  LogisticRegression             True   \n",
      "index  selected_features_all_best30                 SVC             True   \n",
      "index  selected_features_all_best30       XGBClassifier             True   \n",
      "index  selected_features_all_best30      LGBMClassifier             True   \n",
      "index  selected_features_all_best50  LogisticRegression            False   \n",
      "index  selected_features_all_best50                 SVC            False   \n",
      "index  selected_features_all_best50       XGBClassifier            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "index                                               None  0.889811   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "index     0.844898     0.923372   0.911894  0.877119  0.771973   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_no_...  \n",
      "Evaluating selected_features_all_best50 LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:46:12,598]\u001b[0m A new study created in memory with name: no-name-c3ef2b8a-55f4-4ddc-b565-7e3c9cc3467b\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:12,670]\u001b[0m Trial 0 finished with value: 0.8774703557312253 and parameters: {'C': 0.08582067856630485, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 790}. Best is trial 0 with value: 0.8774703557312253.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "index  selected_features_all_best30       XGBClassifier            False   \n",
      "index  selected_features_all_best30      LGBMClassifier            False   \n",
      "index  selected_features_all_best30  LogisticRegression             True   \n",
      "index  selected_features_all_best30                 SVC             True   \n",
      "index  selected_features_all_best30       XGBClassifier             True   \n",
      "index  selected_features_all_best30      LGBMClassifier             True   \n",
      "index  selected_features_all_best50  LogisticRegression            False   \n",
      "index  selected_features_all_best50                 SVC            False   \n",
      "index  selected_features_all_best50       XGBClassifier            False   \n",
      "index  selected_features_all_best50      LGBMClassifier            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.888807   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "index     0.844898     0.923372   0.911894  0.877119  0.771973   \n",
      "index     0.840816     0.923372   0.911504  0.874735  0.768193   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_no_...  \n",
      "index  selected_features_all_best50_LGBMClassifier_no...  \n",
      "Optimizing selected_features_all_best50 LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:46:13,055]\u001b[0m Trial 1 finished with value: 0.8814229249011858 and parameters: {'C': 0.04575595001292701, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 614}. Best is trial 1 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:13,096]\u001b[0m Trial 2 finished with value: 0.8794466403162056 and parameters: {'C': 0.05986810018960859, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 825}. Best is trial 1 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:13,126]\u001b[0m Trial 3 finished with value: 0.8636363636363636 and parameters: {'C': 0.014235066072406884, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 353}. Best is trial 1 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:13,163]\u001b[0m Trial 4 finished with value: 0.8814229249011858 and parameters: {'C': 0.01703248903658563, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 984}. Best is trial 1 with value: 0.8814229249011858.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:13,202]\u001b[0m Trial 5 finished with value: 0.883399209486166 and parameters: {'C': 0.04409940316088003, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 231}. Best is trial 5 with value: 0.883399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:13,474]\u001b[0m Trial 6 finished with value: 0.8814229249011858 and parameters: {'C': 0.0305045861308162, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 316}. Best is trial 5 with value: 0.883399209486166.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:14,902]\u001b[0m Trial 7 finished with value: 0.8893280632411067 and parameters: {'C': 0.024422805336610946, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 670}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:15,492]\u001b[0m Trial 8 finished with value: 0.883399209486166 and parameters: {'C': 0.01650557576780878, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 572}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:15,536]\u001b[0m Trial 9 finished with value: 0.8774703557312253 and parameters: {'C': 0.07926537686102536, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 414}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:46:15,850]\u001b[0m Trial 10 finished with value: 0.8873517786561265 and parameters: {'C': 0.09808077720532851, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 122}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:46:16,120]\u001b[0m Trial 11 finished with value: 0.8873517786561265 and parameters: {'C': 0.0964859451775026, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 100}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:16,683]\u001b[0m Trial 12 finished with value: 0.8873517786561265 and parameters: {'C': 0.06601531179131047, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 701}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:17,349]\u001b[0m Trial 13 finished with value: 0.8873517786561265 and parameters: {'C': 0.09975983861167052, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 512}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:46:17,734]\u001b[0m Trial 14 finished with value: 0.8774703557312253 and parameters: {'C': 0.07114552958850356, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 173}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:18,125]\u001b[0m Trial 15 finished with value: 0.8853754940711462 and parameters: {'C': 0.05035413019434068, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 463}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:46:19,829]\u001b[0m Trial 16 finished with value: 0.8814229249011858 and parameters: {'C': 0.03457417929038219, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 674}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:20,371]\u001b[0m Trial 17 finished with value: 0.8853754940711462 and parameters: {'C': 0.055817726518791494, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 936}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:46:22,227]\u001b[0m Trial 18 finished with value: 0.8754940711462451 and parameters: {'C': 0.08550976773615715, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 764}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:22,795]\u001b[0m Trial 19 finished with value: 0.8873517786561265 and parameters: {'C': 0.06935632384903487, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 891}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:46:23,448]\u001b[0m Trial 20 finished with value: 0.8794466403162056 and parameters: {'C': 0.03276830994370866, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 269}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:46:23,818]\u001b[0m Trial 21 finished with value: 0.8873517786561265 and parameters: {'C': 0.09663918416806704, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 152}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:46:24,083]\u001b[0m Trial 22 finished with value: 0.8873517786561265 and parameters: {'C': 0.0920346179798913, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 109}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:46:24,548]\u001b[0m Trial 23 finished with value: 0.8873517786561265 and parameters: {'C': 0.07806337781157077, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 219}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:25,204]\u001b[0m Trial 24 finished with value: 0.8873517786561265 and parameters: {'C': 0.09868447267704249, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 369}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:46:25,448]\u001b[0m Trial 25 finished with value: 0.8873517786561265 and parameters: {'C': 0.08919649426820317, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 103}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:26,112]\u001b[0m Trial 26 finished with value: 0.8873517786561265 and parameters: {'C': 0.0925818934117907, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 645}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:26,707]\u001b[0m Trial 27 finished with value: 0.8873517786561265 and parameters: {'C': 0.08105848590879432, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 537}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:46:27,664]\u001b[0m Trial 28 finished with value: 0.8754940711462451 and parameters: {'C': 0.07406697157263506, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 448}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:27,709]\u001b[0m Trial 29 finished with value: 0.8774703557312253 and parameters: {'C': 0.08383148482511989, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 733}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:46:28,276]\u001b[0m Trial 30 finished with value: 0.8873517786561265 and parameters: {'C': 0.09006204730362609, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 294}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:28,761]\u001b[0m Trial 31 finished with value: 0.8873517786561265 and parameters: {'C': 0.06435983030827092, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 706}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:29,367]\u001b[0m Trial 32 finished with value: 0.8873517786561265 and parameters: {'C': 0.08524461629010645, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 804}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:29,894]\u001b[0m Trial 33 finished with value: 0.8873517786561265 and parameters: {'C': 0.06555148564957791, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 599}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:46:30,290]\u001b[0m Trial 34 finished with value: 0.8873517786561265 and parameters: {'C': 0.07759166729764307, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 187}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:30,349]\u001b[0m Trial 35 finished with value: 0.8893280632411067 and parameters: {'C': 0.09583796500662806, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 673}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:30,406]\u001b[0m Trial 36 finished with value: 0.8774703557312253 and parameters: {'C': 0.09307511754664655, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 849}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:30,473]\u001b[0m Trial 37 finished with value: 0.8893280632411067 and parameters: {'C': 0.09685543204990817, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 618}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:30,548]\u001b[0m Trial 38 finished with value: 0.8893280632411067 and parameters: {'C': 0.08768758280428067, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 633}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:30,606]\u001b[0m Trial 39 finished with value: 0.8774703557312253 and parameters: {'C': 0.08454143379882442, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 639}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:30,654]\u001b[0m Trial 40 finished with value: 0.8754940711462451 and parameters: {'C': 0.010221679890305521, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 582}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:30,717]\u001b[0m Trial 41 finished with value: 0.8893280632411067 and parameters: {'C': 0.09984298423084186, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 761}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:30,777]\u001b[0m Trial 42 finished with value: 0.8893280632411067 and parameters: {'C': 0.09451104044885447, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 768}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:30,835]\u001b[0m Trial 43 finished with value: 0.8893280632411067 and parameters: {'C': 0.08975373048797732, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 659}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:30,896]\u001b[0m Trial 44 finished with value: 0.8893280632411067 and parameters: {'C': 0.09961952042194742, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 511}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:30,957]\u001b[0m Trial 45 finished with value: 0.8893280632411067 and parameters: {'C': 0.08930313059308372, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 731}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:31,007]\u001b[0m Trial 46 finished with value: 0.8774703557312253 and parameters: {'C': 0.09503322728098948, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 836}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:31,066]\u001b[0m Trial 47 finished with value: 0.8893280632411067 and parameters: {'C': 0.09971588471774986, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 615}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:31,114]\u001b[0m Trial 48 finished with value: 0.8794466403162056 and parameters: {'C': 0.022031907988338054, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 543}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:31,182]\u001b[0m Trial 49 finished with value: 0.8774703557312253 and parameters: {'C': 0.0955002990444305, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 712}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:31,243]\u001b[0m Trial 50 finished with value: 0.8893280632411067 and parameters: {'C': 0.08808292529875406, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 789}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:31,317]\u001b[0m Trial 51 finished with value: 0.8893280632411067 and parameters: {'C': 0.0946054519979635, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 748}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:31,394]\u001b[0m Trial 52 finished with value: 0.8893280632411067 and parameters: {'C': 0.09309854237702367, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 680}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:31,474]\u001b[0m Trial 53 finished with value: 0.8893280632411067 and parameters: {'C': 0.09564715802670763, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 876}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:31,571]\u001b[0m Trial 54 finished with value: 0.8873517786561265 and parameters: {'C': 0.08639446135222627, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 764}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:31,670]\u001b[0m Trial 55 finished with value: 0.8873517786561265 and parameters: {'C': 0.08288480859170431, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 625}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:31,745]\u001b[0m Trial 56 finished with value: 0.8794466403162056 and parameters: {'C': 0.09988969468973924, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 675}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:31,811]\u001b[0m Trial 57 finished with value: 0.8893280632411067 and parameters: {'C': 0.041420143794679135, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 798}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:31,881]\u001b[0m Trial 58 finished with value: 0.8893280632411067 and parameters: {'C': 0.09102959221544998, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 572}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:31,947]\u001b[0m Trial 59 finished with value: 0.8893280632411067 and parameters: {'C': 0.09649515688973659, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 986}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,014]\u001b[0m Trial 60 finished with value: 0.8774703557312253 and parameters: {'C': 0.08787313494794527, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 929}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,079]\u001b[0m Trial 61 finished with value: 0.8893280632411067 and parameters: {'C': 0.09226643402027108, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 637}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,143]\u001b[0m Trial 62 finished with value: 0.8853754940711462 and parameters: {'C': 0.08119960563875005, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 680}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,203]\u001b[0m Trial 63 finished with value: 0.8893280632411067 and parameters: {'C': 0.08982294892602871, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 668}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,268]\u001b[0m Trial 64 finished with value: 0.8893280632411067 and parameters: {'C': 0.09662565119653509, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 772}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,335]\u001b[0m Trial 65 finished with value: 0.8873517786561265 and parameters: {'C': 0.08637651002134569, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 488}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,399]\u001b[0m Trial 66 finished with value: 0.8893280632411067 and parameters: {'C': 0.09377678565231955, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 594}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,480]\u001b[0m Trial 67 finished with value: 0.8893280632411067 and parameters: {'C': 0.097289217347999, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 652}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,555]\u001b[0m Trial 68 finished with value: 0.8774703557312253 and parameters: {'C': 0.09134077741266249, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 707}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,633]\u001b[0m Trial 69 finished with value: 0.8853754940711462 and parameters: {'C': 0.05361154598795756, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 739}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,695]\u001b[0m Trial 70 finished with value: 0.8853754940711462 and parameters: {'C': 0.0764544704807992, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 570}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,756]\u001b[0m Trial 71 finished with value: 0.8893280632411067 and parameters: {'C': 0.09929700037539269, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 507}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,836]\u001b[0m Trial 72 finished with value: 0.8893280632411067 and parameters: {'C': 0.0978546479106677, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 415}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,901]\u001b[0m Trial 73 finished with value: 0.8893280632411067 and parameters: {'C': 0.0937583023454733, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 540}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:32,967]\u001b[0m Trial 74 finished with value: 0.8893280632411067 and parameters: {'C': 0.09979574697294216, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 607}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:33,046]\u001b[0m Trial 75 finished with value: 0.8893280632411067 and parameters: {'C': 0.09045153325372077, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 693}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:33,111]\u001b[0m Trial 76 finished with value: 0.8893280632411067 and parameters: {'C': 0.08783488217244072, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 655}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:33,178]\u001b[0m Trial 77 finished with value: 0.8774703557312253 and parameters: {'C': 0.09665901922583311, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 521}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:33,252]\u001b[0m Trial 78 finished with value: 0.8873517786561265 and parameters: {'C': 0.0830362796779517, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 458}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:33,322]\u001b[0m Trial 79 finished with value: 0.8893280632411067 and parameters: {'C': 0.09364793455013652, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 818}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:33,381]\u001b[0m Trial 80 finished with value: 0.8893280632411067 and parameters: {'C': 0.091143371526798, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 714}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:33,443]\u001b[0m Trial 81 finished with value: 0.8893280632411067 and parameters: {'C': 0.08890368116203812, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 730}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:33,507]\u001b[0m Trial 82 finished with value: 0.8893280632411067 and parameters: {'C': 0.09732614356215283, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 617}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:33,570]\u001b[0m Trial 83 finished with value: 0.8893280632411067 and parameters: {'C': 0.09482193263606808, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 758}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:33,635]\u001b[0m Trial 84 finished with value: 0.8873517786561265 and parameters: {'C': 0.08566711067071164, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 727}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:33,697]\u001b[0m Trial 85 finished with value: 0.8794466403162056 and parameters: {'C': 0.09999621375660517, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 561}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:33,759]\u001b[0m Trial 86 finished with value: 0.8893280632411067 and parameters: {'C': 0.08891694538606906, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 861}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:34,421]\u001b[0m Trial 87 finished with value: 0.8873517786561265 and parameters: {'C': 0.09188625950191667, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 786}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:34,492]\u001b[0m Trial 88 finished with value: 0.8893280632411067 and parameters: {'C': 0.09517847261413138, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 662}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:34,550]\u001b[0m Trial 89 finished with value: 0.8774703557312253 and parameters: {'C': 0.0979703026693422, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 697}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:34,615]\u001b[0m Trial 90 finished with value: 0.8853754940711462 and parameters: {'C': 0.08095836931932832, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 630}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:34,680]\u001b[0m Trial 91 finished with value: 0.8893280632411067 and parameters: {'C': 0.09800647325162831, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 591}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:34,744]\u001b[0m Trial 92 finished with value: 0.8893280632411067 and parameters: {'C': 0.09476185579344343, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 616}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:34,827]\u001b[0m Trial 93 finished with value: 0.8893280632411067 and parameters: {'C': 0.09241057472320813, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 648}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:34,915]\u001b[0m Trial 94 finished with value: 0.8893280632411067 and parameters: {'C': 0.09987596885035735, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 821}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:35,651]\u001b[0m Trial 95 finished with value: 0.8873517786561265 and parameters: {'C': 0.0872642787675507, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 687}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:35,728]\u001b[0m Trial 96 finished with value: 0.8893280632411067 and parameters: {'C': 0.09553047005731004, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 777}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:35,805]\u001b[0m Trial 97 finished with value: 0.8893280632411067 and parameters: {'C': 0.08896970489439683, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 479}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:35,883]\u001b[0m Trial 98 finished with value: 0.8893280632411067 and parameters: {'C': 0.09291850541198267, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 720}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:46:37,263]\u001b[0m Trial 99 finished with value: 0.8754940711462451 and parameters: {'C': 0.09711024832893216, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 558}. Best is trial 7 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:37,275]\u001b[0m A new study created in memory with name: no-name-9baff3fb-2474-47e2-a7d5-90e55b59e8b9\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "index  selected_features_all_best30       XGBClassifier            False   \n",
      "index  selected_features_all_best30      LGBMClassifier            False   \n",
      "index  selected_features_all_best30  LogisticRegression             True   \n",
      "index  selected_features_all_best30                 SVC             True   \n",
      "index  selected_features_all_best30       XGBClassifier             True   \n",
      "index  selected_features_all_best30      LGBMClassifier             True   \n",
      "index  selected_features_all_best50  LogisticRegression            False   \n",
      "index  selected_features_all_best50                 SVC            False   \n",
      "index  selected_features_all_best50       XGBClassifier            False   \n",
      "index  selected_features_all_best50      LGBMClassifier            False   \n",
      "index  selected_features_all_best50  LogisticRegression             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.888807   \n",
      "index  {'C': 0.024422805336610946, 'penalty': 'l1', '...  0.889328   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "index     0.844898     0.923372   0.911894  0.877119  0.771973   \n",
      "index     0.840816     0.923372   0.911504  0.874735  0.768193   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_no_...  \n",
      "index  selected_features_all_best50_LGBMClassifier_no...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "Optimizing selected_features_all_best50 SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:46:37,959]\u001b[0m Trial 0 finished with value: 0.5177865612648221 and parameters: {'svc_c': 40.793552289548295, 'svc_gamma': 12.001104843654636}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:38,414]\u001b[0m Trial 1 finished with value: 0.5138339920948617 and parameters: {'svc_c': 58.707983744808175, 'svc_gamma': 99.07600808314264}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:39,087]\u001b[0m Trial 2 finished with value: 0.5177865612648221 and parameters: {'svc_c': 17.864641376687583, 'svc_gamma': 25.242611630690515}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:39,641]\u001b[0m Trial 3 finished with value: 0.5177865612648221 and parameters: {'svc_c': 98.56400962744742, 'svc_gamma': 44.6188513506334}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:40,244]\u001b[0m Trial 4 finished with value: 0.5177865612648221 and parameters: {'svc_c': 45.454149872922336, 'svc_gamma': 21.408257230042246}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:40,765]\u001b[0m Trial 5 finished with value: 0.5158102766798419 and parameters: {'svc_c': 48.673384105051554, 'svc_gamma': 79.3852485300747}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:41,240]\u001b[0m Trial 6 finished with value: 0.5158102766798419 and parameters: {'svc_c': 64.94990696291977, 'svc_gamma': 64.66940457967901}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:41,784]\u001b[0m Trial 7 finished with value: 0.5158102766798419 and parameters: {'svc_c': 88.65463003156906, 'svc_gamma': 64.71666352002408}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:42,330]\u001b[0m Trial 8 finished with value: 0.5158102766798419 and parameters: {'svc_c': 36.688547231224206, 'svc_gamma': 55.09283922029419}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:42,820]\u001b[0m Trial 9 finished with value: 0.5158102766798419 and parameters: {'svc_c': 23.465857420754272, 'svc_gamma': 63.376296078115}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:43,357]\u001b[0m Trial 10 finished with value: 0.5197628458498024 and parameters: {'svc_c': 6.6878321823533255, 'svc_gamma': 2.7813053211138126}. Best is trial 10 with value: 0.5197628458498024.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 11:46:43,820]\u001b[0m Trial 11 finished with value: 0.5158102766798419 and parameters: {'svc_c': 0.24146524987228268, 'svc_gamma': 0.4863051859183143}. Best is trial 10 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:44,429]\u001b[0m Trial 12 finished with value: 0.5177865612648221 and parameters: {'svc_c': 6.673669490772514, 'svc_gamma': 4.758409502037182}. Best is trial 10 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:44,996]\u001b[0m Trial 13 finished with value: 0.5177865612648221 and parameters: {'svc_c': 21.473225606968285, 'svc_gamma': 17.016105362588863}. Best is trial 10 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:45,575]\u001b[0m Trial 14 finished with value: 0.5177865612648221 and parameters: {'svc_c': 35.23962085544444, 'svc_gamma': 36.89404104202824}. Best is trial 10 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:46,170]\u001b[0m Trial 15 finished with value: 0.5177865612648221 and parameters: {'svc_c': 9.476036368977137, 'svc_gamma': 10.891367935294326}. Best is trial 10 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:46,863]\u001b[0m Trial 16 finished with value: 0.5177865612648221 and parameters: {'svc_c': 28.754733713909992, 'svc_gamma': 29.566057239337105}. Best is trial 10 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:47,469]\u001b[0m Trial 17 finished with value: 0.5177865612648221 and parameters: {'svc_c': 13.290388597701643, 'svc_gamma': 11.46496817026582}. Best is trial 10 with value: 0.5197628458498024.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:48,094]\u001b[0m Trial 18 finished with value: 0.525691699604743 and parameters: {'svc_c': 2.7920914148728713, 'svc_gamma': 1.6821305039510488}. Best is trial 18 with value: 0.525691699604743.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:48,625]\u001b[0m Trial 19 finished with value: 0.5849802371541502 and parameters: {'svc_c': 1.6255774078512009, 'svc_gamma': 0.8517173189704099}. Best is trial 19 with value: 0.5849802371541502.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:49,152]\u001b[0m Trial 20 finished with value: 0.5177865612648221 and parameters: {'svc_c': 2.4052653458834743, 'svc_gamma': 31.752378788367558}. Best is trial 19 with value: 0.5849802371541502.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 11:46:49,785]\u001b[0m Trial 21 finished with value: 0.5158102766798419 and parameters: {'svc_c': 0.2724049296922506, 'svc_gamma': 1.0210160637711567}. Best is trial 19 with value: 0.5849802371541502.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:50,459]\u001b[0m Trial 22 finished with value: 0.5177865612648221 and parameters: {'svc_c': 12.98686674369452, 'svc_gamma': 17.78382912708701}. Best is trial 19 with value: 0.5849802371541502.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:51,089]\u001b[0m Trial 23 finished with value: 0.5177865612648221 and parameters: {'svc_c': 9.270590824365524, 'svc_gamma': 6.354279705627924}. Best is trial 19 with value: 0.5849802371541502.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:51,722]\u001b[0m Trial 24 finished with value: 0.5177865612648221 and parameters: {'svc_c': 17.504419865850757, 'svc_gamma': 18.59407253287751}. Best is trial 19 with value: 0.5849802371541502.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:52,355]\u001b[0m Trial 25 finished with value: 0.5177865612648221 and parameters: {'svc_c': 26.46466993860618, 'svc_gamma': 7.0698534056025855}. Best is trial 19 with value: 0.5849802371541502.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:52,859]\u001b[0m Trial 26 finished with value: 0.7687747035573123 and parameters: {'svc_c': 6.9473662078437926, 'svc_gamma': 0.3156473166395858}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:53,362]\u001b[0m Trial 27 finished with value: 0.7490118577075099 and parameters: {'svc_c': 15.104327136912802, 'svc_gamma': 0.4108254885984106}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:54,042]\u001b[0m Trial 28 finished with value: 0.5177865612648221 and parameters: {'svc_c': 14.996113958216313, 'svc_gamma': 25.921990330695536}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:54,626]\u001b[0m Trial 29 finished with value: 0.5177865612648221 and parameters: {'svc_c': 27.652440480428478, 'svc_gamma': 13.282010538484386}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:55,276]\u001b[0m Trial 30 finished with value: 0.5177865612648221 and parameters: {'svc_c': 18.38958113720214, 'svc_gamma': 12.22318102854208}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:55,861]\u001b[0m Trial 31 finished with value: 0.5869565217391305 and parameters: {'svc_c': 5.370191582823168, 'svc_gamma': 0.8336222574036899}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:56,429]\u001b[0m Trial 32 finished with value: 0.5177865612648221 and parameters: {'svc_c': 8.90978667782177, 'svc_gamma': 8.899533234218794}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:56,907]\u001b[0m Trial 33 finished with value: 0.6600790513833992 and parameters: {'svc_c': 12.902787950386108, 'svc_gamma': 0.608193023100803}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:57,552]\u001b[0m Trial 34 finished with value: 0.5177865612648221 and parameters: {'svc_c': 14.961965798835456, 'svc_gamma': 9.750093114591015}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:58,268]\u001b[0m Trial 35 finished with value: 0.5177865612648221 and parameters: {'svc_c': 22.6611713639675, 'svc_gamma': 20.55379464547858}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:58,907]\u001b[0m Trial 36 finished with value: 0.5177865612648221 and parameters: {'svc_c': 11.990664625775093, 'svc_gamma': 15.223059439334758}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:46:59,545]\u001b[0m Trial 37 finished with value: 0.5177865612648221 and parameters: {'svc_c': 18.597850478415115, 'svc_gamma': 6.809491968988338}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:00,119]\u001b[0m Trial 38 finished with value: 0.5177865612648221 and parameters: {'svc_c': 6.146355152984121, 'svc_gamma': 24.032174578234553}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:00,863]\u001b[0m Trial 39 finished with value: 0.5177865612648221 and parameters: {'svc_c': 28.46076291091541, 'svc_gamma': 14.273875561702802}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:01,405]\u001b[0m Trial 40 finished with value: 0.5177865612648221 and parameters: {'svc_c': 33.1213450516107, 'svc_gamma': 5.648670815036355}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:01,869]\u001b[0m Trial 41 finished with value: 0.6857707509881423 and parameters: {'svc_c': 4.83425618594214, 'svc_gamma': 0.5421653085835272}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:02,490]\u001b[0m Trial 42 finished with value: 0.7312252964426877 and parameters: {'svc_c': 5.275448764407853, 'svc_gamma': 0.44542220415956596}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:03,211]\u001b[0m Trial 43 finished with value: 0.5177865612648221 and parameters: {'svc_c': 10.625419330666853, 'svc_gamma': 5.872979252696341}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:03,860]\u001b[0m Trial 44 finished with value: 0.5177865612648221 and parameters: {'svc_c': 19.361438865812822, 'svc_gamma': 9.328873097144859}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:04,533]\u001b[0m Trial 45 finished with value: 0.5177865612648221 and parameters: {'svc_c': 5.270652624171272, 'svc_gamma': 4.722221888692817}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:05,135]\u001b[0m Trial 46 finished with value: 0.650197628458498 and parameters: {'svc_c': 14.398160257740518, 'svc_gamma': 0.635885796514536}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 11:47:05,764]\u001b[0m Trial 47 finished with value: 0.5158102766798419 and parameters: {'svc_c': 0.07006620824162724, 'svc_gamma': 21.841922809160884}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:06,373]\u001b[0m Trial 48 finished with value: 0.5177865612648221 and parameters: {'svc_c': 43.2123619480606, 'svc_gamma': 13.944202511774254}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:06,957]\u001b[0m Trial 49 finished with value: 0.5177865612648221 and parameters: {'svc_c': 22.073689039693324, 'svc_gamma': 17.8770019091505}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:07,801]\u001b[0m Trial 50 finished with value: 0.5177865612648221 and parameters: {'svc_c': 9.003065925712788, 'svc_gamma': 11.156054791482829}. Best is trial 26 with value: 0.7687747035573123.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:08,245]\u001b[0m Trial 51 finished with value: 0.8735177865612648 and parameters: {'svc_c': 14.99270459807389, 'svc_gamma': 0.07611819884796}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:08,823]\u001b[0m Trial 52 finished with value: 0.5177865612648221 and parameters: {'svc_c': 5.749966923367242, 'svc_gamma': 3.97824314954979}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:09,461]\u001b[0m Trial 53 finished with value: 0.5177865612648221 and parameters: {'svc_c': 12.402806198972852, 'svc_gamma': 4.844563477621962}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:09,955]\u001b[0m Trial 54 finished with value: 0.8300395256916996 and parameters: {'svc_c': 15.901514650786496, 'svc_gamma': 0.198341206828673}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:10,620]\u001b[0m Trial 55 finished with value: 0.5177865612648221 and parameters: {'svc_c': 16.523176780407073, 'svc_gamma': 8.780622882677788}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:11,127]\u001b[0m Trial 56 finished with value: 0.66600790513834 and parameters: {'svc_c': 4.302351555352635, 'svc_gamma': 0.5880594707504655}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:11,740]\u001b[0m Trial 57 finished with value: 0.5177865612648221 and parameters: {'svc_c': 23.79230338192657, 'svc_gamma': 8.542466774869634}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:12,344]\u001b[0m Trial 58 finished with value: 0.5177865612648221 and parameters: {'svc_c': 8.32565185248351, 'svc_gamma': 4.056093097091449}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:12,957]\u001b[0m Trial 59 finished with value: 0.5177865612648221 and parameters: {'svc_c': 3.0804805385487892, 'svc_gamma': 16.065334259519318}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:13,538]\u001b[0m Trial 60 finished with value: 0.5177865612648221 and parameters: {'svc_c': 20.159424722401535, 'svc_gamma': 3.73993714188555}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:14,053]\u001b[0m Trial 61 finished with value: 0.616600790513834 and parameters: {'svc_c': 3.521593775772068, 'svc_gamma': 0.7193507461868011}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:14,527]\u001b[0m Trial 62 finished with value: 0.841897233201581 and parameters: {'svc_c': 5.828361437854538, 'svc_gamma': 0.1416710643057973}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:15,210]\u001b[0m Trial 63 finished with value: 0.5177865612648221 and parameters: {'svc_c': 11.059098659193797, 'svc_gamma': 7.171084130364333}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:15,856]\u001b[0m Trial 64 finished with value: 0.5177865612648221 and parameters: {'svc_c': 7.490332611291886, 'svc_gamma': 13.419631178127473}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:16,396]\u001b[0m Trial 65 finished with value: 0.5177865612648221 and parameters: {'svc_c': 15.740957355264463, 'svc_gamma': 3.6274196067343283}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:16,977]\u001b[0m Trial 66 finished with value: 0.5177865612648221 and parameters: {'svc_c': 0.7872361792451361, 'svc_gamma': 10.375671343673977}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:17,510]\u001b[0m Trial 67 finished with value: 0.5177865612648221 and parameters: {'svc_c': 10.309361477319772, 'svc_gamma': 3.2982307499019416}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:17,961]\u001b[0m Trial 68 finished with value: 0.8399209486166008 and parameters: {'svc_c': 17.224449027593195, 'svc_gamma': 0.14836396506769145}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:18,493]\u001b[0m Trial 69 finished with value: 0.5177865612648221 and parameters: {'svc_c': 16.5796931137836, 'svc_gamma': 7.292146465060604}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:19,049]\u001b[0m Trial 70 finished with value: 0.5177865612648221 and parameters: {'svc_c': 23.721185198645884, 'svc_gamma': 12.643167708774177}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:19,532]\u001b[0m Trial 71 finished with value: 0.841897233201581 and parameters: {'svc_c': 13.856838678419328, 'svc_gamma': 0.14329151949131858}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:20,073]\u001b[0m Trial 72 finished with value: 0.5197628458498024 and parameters: {'svc_c': 13.213805302059075, 'svc_gamma': 3.1593824355153357}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:20,591]\u001b[0m Trial 73 finished with value: 0.5177865612648221 and parameters: {'svc_c': 19.553748475030783, 'svc_gamma': 5.637606961793944}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:21,192]\u001b[0m Trial 74 finished with value: 0.5177865612648221 and parameters: {'svc_c': 9.073718926510441, 'svc_gamma': 8.76228886069011}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:21,641]\u001b[0m Trial 75 finished with value: 0.7371541501976284 and parameters: {'svc_c': 15.890295183592492, 'svc_gamma': 0.4339976175905842}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:22,207]\u001b[0m Trial 76 finished with value: 0.5177865612648221 and parameters: {'svc_c': 16.999336058554057, 'svc_gamma': 11.066014861580788}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:22,815]\u001b[0m Trial 77 finished with value: 0.5197628458498024 and parameters: {'svc_c': 25.34683271127344, 'svc_gamma': 3.2267959737208303}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:23,408]\u001b[0m Trial 78 finished with value: 0.5177865612648221 and parameters: {'svc_c': 21.397132350192102, 'svc_gamma': 6.752840290806342}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:23,973]\u001b[0m Trial 79 finished with value: 0.5197628458498024 and parameters: {'svc_c': 29.856594369391523, 'svc_gamma': 2.9258731921152323}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:24,414]\u001b[0m Trial 80 finished with value: 0.8300395256916996 and parameters: {'svc_c': 13.247485092654149, 'svc_gamma': 0.20027383501616022}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:24,957]\u001b[0m Trial 81 finished with value: 0.7312252964426877 and parameters: {'svc_c': 13.8427664605395, 'svc_gamma': 0.4470581678103597}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:25,511]\u001b[0m Trial 82 finished with value: 0.5177865612648221 and parameters: {'svc_c': 11.03669501409717, 'svc_gamma': 5.630798953743204}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:25,976]\u001b[0m Trial 83 finished with value: 0.5217391304347826 and parameters: {'svc_c': 15.086643269983696, 'svc_gamma': 2.265673861338271}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:26,332]\u001b[0m Trial 84 finished with value: 0.8656126482213439 and parameters: {'svc_c': 7.403826653294563, 'svc_gamma': 0.08645024885073316}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:26,883]\u001b[0m Trial 85 finished with value: 0.5177865612648221 and parameters: {'svc_c': 7.0374575357005895, 'svc_gamma': 8.148375282246564}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:27,475]\u001b[0m Trial 86 finished with value: 0.5177865612648221 and parameters: {'svc_c': 18.693049209882243, 'svc_gamma': 11.160720357631943}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:27,966]\u001b[0m Trial 87 finished with value: 0.5197628458498024 and parameters: {'svc_c': 2.7309837728442146, 'svc_gamma': 2.8116384140622435}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:28,524]\u001b[0m Trial 88 finished with value: 0.5177865612648221 and parameters: {'svc_c': 11.75765181833263, 'svc_gamma': 5.587373318259302}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:29,055]\u001b[0m Trial 89 finished with value: 0.5177865612648221 and parameters: {'svc_c': 7.424651817628767, 'svc_gamma': 15.613764070336238}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:29,680]\u001b[0m Trial 90 finished with value: 0.5177865612648221 and parameters: {'svc_c': 20.711439332782394, 'svc_gamma': 7.705346386557681}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:30,164]\u001b[0m Trial 91 finished with value: 0.7055335968379447 and parameters: {'svc_c': 14.541976832982478, 'svc_gamma': 0.5120966393964536}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:30,644]\u001b[0m Trial 92 finished with value: 0.5237154150197628 and parameters: {'svc_c': 17.260820220792812, 'svc_gamma': 2.1202174144712016}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:31,102]\u001b[0m Trial 93 finished with value: 0.8003952569169961 and parameters: {'svc_c': 10.344631686213557, 'svc_gamma': 0.25492795420884234}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:31,626]\u001b[0m Trial 94 finished with value: 0.5177865612648221 and parameters: {'svc_c': 9.755812954634592, 'svc_gamma': 4.730878607030429}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:32,205]\u001b[0m Trial 95 finished with value: 0.5177865612648221 and parameters: {'svc_c': 12.843846752113086, 'svc_gamma': 9.460452706975309}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:32,656]\u001b[0m Trial 96 finished with value: 0.5197628458498024 and parameters: {'svc_c': 6.042063874161869, 'svc_gamma': 2.757169133536413}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:33,069]\u001b[0m Trial 97 finished with value: 0.841897233201581 and parameters: {'svc_c': 2.052905630483542, 'svc_gamma': 0.15785048382551736}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:33,490]\u001b[0m Trial 98 finished with value: 0.5217391304347826 and parameters: {'svc_c': 2.1203256667386245, 'svc_gamma': 2.2662573626774627}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:34,053]\u001b[0m Trial 99 finished with value: 0.5177865612648221 and parameters: {'svc_c': 3.749017906045143, 'svc_gamma': 5.882251669510696}. Best is trial 51 with value: 0.8735177865612648.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:34,067]\u001b[0m A new study created in memory with name: no-name-de2af5eb-e874-4821-9b4c-a0dfa061e5a0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "index  selected_features_all_best30       XGBClassifier            False   \n",
      "index  selected_features_all_best30      LGBMClassifier            False   \n",
      "index  selected_features_all_best30  LogisticRegression             True   \n",
      "index  selected_features_all_best30                 SVC             True   \n",
      "index  selected_features_all_best30       XGBClassifier             True   \n",
      "index  selected_features_all_best30      LGBMClassifier             True   \n",
      "index  selected_features_all_best50  LogisticRegression            False   \n",
      "index  selected_features_all_best50                 SVC            False   \n",
      "index  selected_features_all_best50       XGBClassifier            False   \n",
      "index  selected_features_all_best50      LGBMClassifier            False   \n",
      "index  selected_features_all_best50  LogisticRegression             True   \n",
      "index  selected_features_all_best50                 SVC             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.888807   \n",
      "index  {'C': 0.024422805336610946, 'penalty': 'l1', '...  0.889328   \n",
      "index  {'svc_c': 14.99270459807389, 'svc_gamma': 0.07...  0.873518   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "index     0.844898     0.923372   0.911894  0.877119  0.771973   \n",
      "index     0.840816     0.923372   0.911504  0.874735  0.768193   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.804082     0.938697   0.924883  0.860262  0.751864   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_no_...  \n",
      "index  selected_features_all_best50_LGBMClassifier_no...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index  selected_features_all_best50_SVC_with_hypertuning  \n",
      "Optimizing selected_features_all_best50 XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:47:35,034]\u001b[0m Trial 0 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.2747358549724469, 'max_depth': 4, 'n_estimators': 206}. Best is trial 0 with value: 0.8873517786561265.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:38,764]\u001b[0m Trial 1 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.049433721318135074, 'max_depth': 3, 'n_estimators': 927}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:40,534]\u001b[0m Trial 2 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.15622721022045377, 'max_depth': 5, 'n_estimators': 190}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:42,826]\u001b[0m Trial 3 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.1511430892067905, 'max_depth': 2, 'n_estimators': 996}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:45,294]\u001b[0m Trial 4 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.13183131438575832, 'max_depth': 4, 'n_estimators': 546}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:46,127]\u001b[0m Trial 5 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.028844342332965123, 'max_depth': 2, 'n_estimators': 336}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:46,876]\u001b[0m Trial 6 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.09958464535305538, 'max_depth': 5, 'n_estimators': 119}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:50,573]\u001b[0m Trial 7 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.20557284491330127, 'max_depth': 6, 'n_estimators': 918}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:51,803]\u001b[0m Trial 8 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.28925390501544057, 'max_depth': 3, 'n_estimators': 321}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:52,225]\u001b[0m Trial 9 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.11893853787929015, 'max_depth': 2, 'n_estimators': 139}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:55,310]\u001b[0m Trial 10 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.02775024627243295, 'max_depth': 3, 'n_estimators': 809}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:47:58,638]\u001b[0m Trial 11 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.07220529492779568, 'max_depth': 5, 'n_estimators': 656}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:01,194]\u001b[0m Trial 12 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.1983345247108354, 'max_depth': 6, 'n_estimators': 548}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:04,926]\u001b[0m Trial 13 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.07023334496028294, 'max_depth': 5, 'n_estimators': 691}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:06,594]\u001b[0m Trial 14 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.17604241334074694, 'max_depth': 3, 'n_estimators': 415}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:10,014]\u001b[0m Trial 15 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.08671618730991129, 'max_depth': 4, 'n_estimators': 794}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:13,323]\u001b[0m Trial 16 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.018822103759404827, 'max_depth': 5, 'n_estimators': 420}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:15,741]\u001b[0m Trial 17 finished with value: 0.8735177865612648 and parameters: {'learning_rate': 0.15471191375599358, 'max_depth': 3, 'n_estimators': 683}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:17,799]\u001b[0m Trial 18 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.054885215562698444, 'max_depth': 6, 'n_estimators': 259}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:20,036]\u001b[0m Trial 19 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.11732558717369593, 'max_depth': 4, 'n_estimators': 431}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:23,768]\u001b[0m Trial 20 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.053082326617909806, 'max_depth': 4, 'n_estimators': 843}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:27,644]\u001b[0m Trial 21 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.05301174824756624, 'max_depth': 4, 'n_estimators': 870}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:36,086]\u001b[0m Trial 22 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.013329492295477217, 'max_depth': 5, 'n_estimators': 991}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:39,138]\u001b[0m Trial 23 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.09897726767656737, 'max_depth': 3, 'n_estimators': 782}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:43,187]\u001b[0m Trial 24 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.048709433699719855, 'max_depth': 4, 'n_estimators': 902}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:47,936]\u001b[0m Trial 25 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.03827978209564282, 'max_depth': 4, 'n_estimators': 897}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:51,217]\u001b[0m Trial 26 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.036841662473278414, 'max_depth': 3, 'n_estimators': 855}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:55,986]\u001b[0m Trial 27 finished with value: 0.8754940711462451 and parameters: {'learning_rate': 0.010442472907658516, 'max_depth': 4, 'n_estimators': 942}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:48:59,436]\u001b[0m Trial 28 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.07072255812658565, 'max_depth': 3, 'n_estimators': 744}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:02,424]\u001b[0m Trial 29 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.04085753481195363, 'max_depth': 4, 'n_estimators': 615}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:04,703]\u001b[0m Trial 30 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.058574121781619845, 'max_depth': 2, 'n_estimators': 834}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:09,557]\u001b[0m Trial 31 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.04185990685675141, 'max_depth': 4, 'n_estimators': 921}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:13,652]\u001b[0m Trial 32 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.04369772007024786, 'max_depth': 4, 'n_estimators': 895}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:17,683]\u001b[0m Trial 33 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.08049787003610662, 'max_depth': 4, 'n_estimators': 969}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:21,536]\u001b[0m Trial 34 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.05657586179827545, 'max_depth': 4, 'n_estimators': 752}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:24,615]\u001b[0m Trial 35 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.02556920712685201, 'max_depth': 3, 'n_estimators': 867}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:29,121]\u001b[0m Trial 36 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.08984594941141315, 'max_depth': 5, 'n_estimators': 991}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:31,586]\u001b[0m Trial 37 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.024879562707172426, 'max_depth': 2, 'n_estimators': 733}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:35,674]\u001b[0m Trial 38 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.06466918114616128, 'max_depth': 4, 'n_estimators': 910}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:40,464]\u001b[0m Trial 39 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.04336147538445505, 'max_depth': 5, 'n_estimators': 836}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:43,052]\u001b[0m Trial 40 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.10049331991503149, 'max_depth': 3, 'n_estimators': 608}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:46,343]\u001b[0m Trial 41 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.05564717350585232, 'max_depth': 4, 'n_estimators': 742}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:49,944]\u001b[0m Trial 42 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.05742988331647172, 'max_depth': 4, 'n_estimators': 787}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:54,695]\u001b[0m Trial 43 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.0332665109965522, 'max_depth': 4, 'n_estimators': 937}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:49:59,156]\u001b[0m Trial 44 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.07736834427926068, 'max_depth': 5, 'n_estimators': 892}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:04,082]\u001b[0m Trial 45 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.020726786866582296, 'max_depth': 4, 'n_estimators': 945}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:07,424]\u001b[0m Trial 46 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.069837662723852, 'max_depth': 3, 'n_estimators': 825}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:11,313]\u001b[0m Trial 47 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.030977333752019498, 'max_depth': 4, 'n_estimators': 778}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:14,644]\u001b[0m Trial 48 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.010512088758073163, 'max_depth': 5, 'n_estimators': 512}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:17,591]\u001b[0m Trial 49 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.04948166553335928, 'max_depth': 3, 'n_estimators': 706}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:19,836]\u001b[0m Trial 50 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.06400514386959913, 'max_depth': 2, 'n_estimators': 876}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:21,432]\u001b[0m Trial 51 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.1412013222775527, 'max_depth': 5, 'n_estimators': 299}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:22,155]\u001b[0m Trial 52 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.16856041779317166, 'max_depth': 6, 'n_estimators': 108}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:23,148]\u001b[0m Trial 53 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.11836420537949924, 'max_depth': 4, 'n_estimators': 195}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:26,380]\u001b[0m Trial 54 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.0332669452914449, 'max_depth': 5, 'n_estimators': 462}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:28,353]\u001b[0m Trial 55 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.04933637110833891, 'max_depth': 4, 'n_estimators': 349}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:31,819]\u001b[0m Trial 56 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.08235919490304626, 'max_depth': 5, 'n_estimators': 634}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:36,020]\u001b[0m Trial 57 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.07571303528451738, 'max_depth': 6, 'n_estimators': 649}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:39,217]\u001b[0m Trial 58 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.06534078087773584, 'max_depth': 4, 'n_estimators': 593}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:43,286]\u001b[0m Trial 59 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.05885472795285947, 'max_depth': 4, 'n_estimators': 964}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:45,817]\u001b[0m Trial 60 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.019826044762966313, 'max_depth': 3, 'n_estimators': 565}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:49,201]\u001b[0m Trial 61 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.047396016382337314, 'max_depth': 4, 'n_estimators': 602}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:52,099]\u001b[0m Trial 62 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.0893108598417974, 'max_depth': 4, 'n_estimators': 668}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:54,860]\u001b[0m Trial 63 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.03587165251805628, 'max_depth': 4, 'n_estimators': 507}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:50:58,651]\u001b[0m Trial 64 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.06777875302163083, 'max_depth': 5, 'n_estimators': 718}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:02,030]\u001b[0m Trial 65 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.08105282803692354, 'max_depth': 4, 'n_estimators': 769}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:05,931]\u001b[0m Trial 66 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.0502667686767308, 'max_depth': 4, 'n_estimators': 809}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:08,152]\u001b[0m Trial 67 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.06460282496122323, 'max_depth': 3, 'n_estimators': 574}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:11,229]\u001b[0m Trial 68 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.04022334669241433, 'max_depth': 4, 'n_estimators': 632}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:17,379]\u001b[0m Trial 69 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.028725566309624865, 'max_depth': 5, 'n_estimators': 847}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:21,576]\u001b[0m Trial 70 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.05930337017737414, 'max_depth': 4, 'n_estimators': 888}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:25,204]\u001b[0m Trial 71 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.048379575531313085, 'max_depth': 4, 'n_estimators': 807}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:29,010]\u001b[0m Trial 72 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.05201139903291287, 'max_depth': 4, 'n_estimators': 762}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:32,990]\u001b[0m Trial 73 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.039617789206286703, 'max_depth': 4, 'n_estimators': 821}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:37,169]\u001b[0m Trial 74 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.07349934650217946, 'max_depth': 4, 'n_estimators': 911}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:41,469]\u001b[0m Trial 75 finished with value: 0.8774703557312253 and parameters: {'learning_rate': 0.019579483561422292, 'max_depth': 3, 'n_estimators': 692}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:46,848]\u001b[0m Trial 76 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.06200843646859018, 'max_depth': 5, 'n_estimators': 959}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:50,959]\u001b[0m Trial 77 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.046006344920584745, 'max_depth': 4, 'n_estimators': 855}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:55,689]\u001b[0m Trial 78 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.05458465592837063, 'max_depth': 4, 'n_estimators': 932}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:51:58,365]\u001b[0m Trial 79 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.08144133133112483, 'max_depth': 3, 'n_estimators': 752}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:52:02,287]\u001b[0m Trial 80 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.02810668832364034, 'max_depth': 4, 'n_estimators': 802}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:52:06,539]\u001b[0m Trial 81 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.062048606460242225, 'max_depth': 4, 'n_estimators': 888}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:52:10,757]\u001b[0m Trial 82 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.06940349016974875, 'max_depth': 4, 'n_estimators': 897}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:52:15,590]\u001b[0m Trial 83 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.06983848339959557, 'max_depth': 4, 'n_estimators': 997}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:52:21,505]\u001b[0m Trial 84 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.03955123531819789, 'max_depth': 4, 'n_estimators': 911}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:52:26,498]\u001b[0m Trial 85 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.03651638059998999, 'max_depth': 4, 'n_estimators': 907}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:52:29,087]\u001b[0m Trial 86 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.043119810936547306, 'max_depth': 2, 'n_estimators': 847}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:52:33,157]\u001b[0m Trial 87 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.09569187436724322, 'max_depth': 4, 'n_estimators': 870}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:52:37,648]\u001b[0m Trial 88 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.10685120637008047, 'max_depth': 4, 'n_estimators': 973}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:52:42,930]\u001b[0m Trial 89 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.08534200109075912, 'max_depth': 5, 'n_estimators': 927}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:52:43,817]\u001b[0m Trial 90 finished with value: 0.8715415019762845 and parameters: {'learning_rate': 0.07400336324259033, 'max_depth': 4, 'n_estimators': 155}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:52:47,668]\u001b[0m Trial 91 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.05252391057319636, 'max_depth': 4, 'n_estimators': 829}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:52:50,691]\u001b[0m Trial 92 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.05587799204005104, 'max_depth': 4, 'n_estimators': 520}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:52:54,853]\u001b[0m Trial 93 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.03698070875672929, 'max_depth': 4, 'n_estimators': 864}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:00,873]\u001b[0m Trial 94 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.06672475876102872, 'max_depth': 4, 'n_estimators': 947}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:06,466]\u001b[0m Trial 95 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.04519461324831292, 'max_depth': 6, 'n_estimators': 900}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:13,498]\u001b[0m Trial 96 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.025139413120095225, 'max_depth': 4, 'n_estimators': 795}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:16,348]\u001b[0m Trial 97 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.030660359112247196, 'max_depth': 3, 'n_estimators': 591}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:20,566]\u001b[0m Trial 98 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.05122601375503418, 'max_depth': 4, 'n_estimators': 880}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:25,133]\u001b[0m Trial 99 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.07417528611284999, 'max_depth': 5, 'n_estimators': 980}. Best is trial 1 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:25,151]\u001b[0m A new study created in memory with name: no-name-123ff715-6b94-462b-8088-6ab77fbd2e00\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "index  selected_features_all_best30       XGBClassifier            False   \n",
      "index  selected_features_all_best30      LGBMClassifier            False   \n",
      "index  selected_features_all_best30  LogisticRegression             True   \n",
      "index  selected_features_all_best30                 SVC             True   \n",
      "index  selected_features_all_best30       XGBClassifier             True   \n",
      "index  selected_features_all_best30      LGBMClassifier             True   \n",
      "index  selected_features_all_best50  LogisticRegression            False   \n",
      "index  selected_features_all_best50                 SVC            False   \n",
      "index  selected_features_all_best50       XGBClassifier            False   \n",
      "index  selected_features_all_best50      LGBMClassifier            False   \n",
      "index  selected_features_all_best50  LogisticRegression             True   \n",
      "index  selected_features_all_best50                 SVC             True   \n",
      "index  selected_features_all_best50       XGBClassifier             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.888807   \n",
      "index  {'C': 0.024422805336610946, 'penalty': 'l1', '...  0.889328   \n",
      "index  {'svc_c': 14.99270459807389, 'svc_gamma': 0.07...  0.873518   \n",
      "index  {'learning_rate': 0.049433721318135074, 'max_d...  0.893281   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "index     0.844898     0.923372   0.911894  0.877119  0.771973   \n",
      "index     0.840816     0.923372   0.911504  0.874735  0.768193   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.804082     0.938697   0.924883  0.860262  0.751864   \n",
      "index     0.844898     0.938697   0.928251  0.884615  0.788768   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_no_...  \n",
      "index  selected_features_all_best50_LGBMClassifier_no...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index  selected_features_all_best50_SVC_with_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_wit...  \n",
      "Optimizing selected_features_all_best50 LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:53:27,429]\u001b[0m Trial 0 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 227, 'max_depth': 43, 'learning_rate': 0.2778019303343961, 'n_estimators': 1461}. Best is trial 0 with value: 0.8774703557312253.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:31,940]\u001b[0m Trial 1 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 223, 'max_depth': 16, 'learning_rate': 0.10290531634605304, 'n_estimators': 1215}. Best is trial 1 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:38,623]\u001b[0m Trial 2 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 106, 'max_depth': 27, 'learning_rate': 0.031657949034507527, 'n_estimators': 1008}. Best is trial 1 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:40,454]\u001b[0m Trial 3 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 7, 'max_depth': 40, 'learning_rate': 0.2804540099026719, 'n_estimators': 1662}. Best is trial 1 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:42,778]\u001b[0m Trial 4 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 70, 'max_depth': 50, 'learning_rate': 0.247098647978207, 'n_estimators': 1464}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:47,277]\u001b[0m Trial 5 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 67, 'max_depth': 32, 'learning_rate': 0.02394441746310611, 'n_estimators': 732}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:49,637]\u001b[0m Trial 6 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 79, 'max_depth': 37, 'learning_rate': 0.13727474670710854, 'n_estimators': 823}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:51,724]\u001b[0m Trial 7 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 42, 'max_depth': 11, 'learning_rate': 0.19889917427980472, 'n_estimators': 1341}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:56,999]\u001b[0m Trial 8 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 98, 'max_depth': 19, 'learning_rate': 0.05186328141874624, 'n_estimators': 1552}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:53:59,881]\u001b[0m Trial 9 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 215, 'max_depth': 16, 'learning_rate': 0.10378634141095336, 'n_estimators': 1492}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:00,211]\u001b[0m Trial 10 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 152, 'max_depth': 4, 'learning_rate': 0.2114960901704434, 'n_estimators': 233}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:03,868]\u001b[0m Trial 11 finished with value: 0.883399209486166 and parameters: {'num_leaves': 154, 'max_depth': 50, 'learning_rate': 0.18008782966111533, 'n_estimators': 1957}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:05,744]\u001b[0m Trial 12 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 62, 'max_depth': 38, 'learning_rate': 0.14316549611035803, 'n_estimators': 657}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:06,431]\u001b[0m Trial 13 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 5, 'max_depth': 50, 'learning_rate': 0.2422179103014768, 'n_estimators': 882}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:08,060]\u001b[0m Trial 14 finished with value: 0.8754940711462451 and parameters: {'num_leaves': 121, 'max_depth': 34, 'learning_rate': 0.15914758221348083, 'n_estimators': 203}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:09,044]\u001b[0m Trial 15 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 79, 'max_depth': 44, 'learning_rate': 0.2360603289563477, 'n_estimators': 491}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:11,208]\u001b[0m Trial 16 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 156, 'max_depth': 45, 'learning_rate': 0.23505470200470757, 'n_estimators': 542}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:12,010]\u001b[0m Trial 17 finished with value: 0.883399209486166 and parameters: {'num_leaves': 42, 'max_depth': 46, 'learning_rate': 0.29150337561485357, 'n_estimators': 451}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:13,600]\u001b[0m Trial 18 finished with value: 0.883399209486166 and parameters: {'num_leaves': 38, 'max_depth': 28, 'learning_rate': 0.24910617566046664, 'n_estimators': 1150}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:16,377]\u001b[0m Trial 19 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 188, 'max_depth': 42, 'learning_rate': 0.2991692323002301, 'n_estimators': 1929}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:20,741]\u001b[0m Trial 20 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 89, 'max_depth': 47, 'learning_rate': 0.21195869318797483, 'n_estimators': 1756}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:22,189]\u001b[0m Trial 21 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 80, 'max_depth': 36, 'learning_rate': 0.2538347761238169, 'n_estimators': 885}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:23,867]\u001b[0m Trial 22 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 122, 'max_depth': 40, 'learning_rate': 0.18239296744604983, 'n_estimators': 398}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:25,179]\u001b[0m Trial 23 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 64, 'max_depth': 31, 'learning_rate': 0.2266623193136236, 'n_estimators': 781}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:26,976]\u001b[0m Trial 24 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 23, 'max_depth': 30, 'learning_rate': 0.23164509250483808, 'n_estimators': 1064}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:27,967]\u001b[0m Trial 25 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 59, 'max_depth': 23, 'learning_rate': 0.2654040279934537, 'n_estimators': 605}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:28,619]\u001b[0m Trial 26 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 102, 'max_depth': 47, 'learning_rate': 0.2629370835182472, 'n_estimators': 106}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:29,357]\u001b[0m Trial 27 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 48, 'max_depth': 23, 'learning_rate': 0.2254818751462364, 'n_estimators': 397}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:31,444]\u001b[0m Trial 28 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 130, 'max_depth': 34, 'learning_rate': 0.26699008061718654, 'n_estimators': 1305}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:33,013]\u001b[0m Trial 29 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 25, 'max_depth': 43, 'learning_rate': 0.2771905683463247, 'n_estimators': 979}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:34,318]\u001b[0m Trial 30 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 76, 'max_depth': 43, 'learning_rate': 0.21901464573451593, 'n_estimators': 737}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:36,534]\u001b[0m Trial 31 finished with value: 0.8754940711462451 and parameters: {'num_leaves': 71, 'max_depth': 50, 'learning_rate': 0.22084549435346562, 'n_estimators': 764}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:37,754]\u001b[0m Trial 32 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 87, 'max_depth': 43, 'learning_rate': 0.2458900823374548, 'n_estimators': 511}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:39,278]\u001b[0m Trial 33 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 57, 'max_depth': 40, 'learning_rate': 0.20019652395429915, 'n_estimators': 717}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:40,964]\u001b[0m Trial 34 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 109, 'max_depth': 45, 'learning_rate': 0.23277641871969687, 'n_estimators': 1128}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:42,619]\u001b[0m Trial 35 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 252, 'max_depth': 31, 'learning_rate': 0.27220556472752194, 'n_estimators': 940}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:44,981]\u001b[0m Trial 36 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 25, 'max_depth': 48, 'learning_rate': 0.250534696238516, 'n_estimators': 1312}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:46,766]\u001b[0m Trial 37 finished with value: 0.883399209486166 and parameters: {'num_leaves': 75, 'max_depth': 41, 'learning_rate': 0.21641226958098628, 'n_estimators': 641}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:48,315]\u001b[0m Trial 38 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 91, 'max_depth': 37, 'learning_rate': 0.19823839644299662, 'n_estimators': 796}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:49,208]\u001b[0m Trial 39 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 141, 'max_depth': 25, 'learning_rate': 0.28404196957343697, 'n_estimators': 318}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:50,213]\u001b[0m Trial 40 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 114, 'max_depth': 11, 'learning_rate': 0.25584860927073494, 'n_estimators': 569}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:51,997]\u001b[0m Trial 41 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 88, 'max_depth': 44, 'learning_rate': 0.24195166425688996, 'n_estimators': 515}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:53,248]\u001b[0m Trial 42 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 73, 'max_depth': 43, 'learning_rate': 0.23635184236694065, 'n_estimators': 704}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:55,186]\u001b[0m Trial 43 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 54, 'max_depth': 38, 'learning_rate': 0.2779919444448549, 'n_estimators': 1638}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:56,239]\u001b[0m Trial 44 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 95, 'max_depth': 48, 'learning_rate': 0.22403502200610062, 'n_estimators': 482}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:57,518]\u001b[0m Trial 45 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 34, 'max_depth': 34, 'learning_rate': 0.25022733249620804, 'n_estimators': 351}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:54:59,033]\u001b[0m Trial 46 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 65, 'max_depth': 40, 'learning_rate': 0.2114764738882552, 'n_estimators': 855}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:00,049]\u001b[0m Trial 47 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 81, 'max_depth': 49, 'learning_rate': 0.240517040980197, 'n_estimators': 270}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:01,750]\u001b[0m Trial 48 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 99, 'max_depth': 45, 'learning_rate': 0.1906846078698989, 'n_estimators': 663}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:03,579]\u001b[0m Trial 49 finished with value: 0.883399209486166 and parameters: {'num_leaves': 46, 'max_depth': 42, 'learning_rate': 0.26259395623112386, 'n_estimators': 1418}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:04,946]\u001b[0m Trial 50 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 183, 'max_depth': 10, 'learning_rate': 0.2863686902443642, 'n_estimators': 1056}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:07,553]\u001b[0m Trial 51 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 83, 'max_depth': 36, 'learning_rate': 0.16092637097111542, 'n_estimators': 823}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:09,998]\u001b[0m Trial 52 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 64, 'max_depth': 39, 'learning_rate': 0.11200158543017283, 'n_estimators': 903}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:11,412]\u001b[0m Trial 53 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 106, 'max_depth': 29, 'learning_rate': 0.20917965850454817, 'n_estimators': 583}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:13,519]\u001b[0m Trial 54 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 73, 'max_depth': 32, 'learning_rate': 0.2263088748128254, 'n_estimators': 1210}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:15,698]\u001b[0m Trial 55 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 52, 'max_depth': 46, 'learning_rate': 0.17620255827743825, 'n_estimators': 1766}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:16,671]\u001b[0m Trial 56 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 33, 'max_depth': 36, 'learning_rate': 0.2460830495032345, 'n_estimators': 782}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:17,646]\u001b[0m Trial 57 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 118, 'max_depth': 42, 'learning_rate': 0.25764771258309177, 'n_estimators': 424}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:18,826]\u001b[0m Trial 58 finished with value: 0.883399209486166 and parameters: {'num_leaves': 14, 'max_depth': 26, 'learning_rate': 0.2367388840278971, 'n_estimators': 504}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:21,144]\u001b[0m Trial 59 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 135, 'max_depth': 44, 'learning_rate': 0.12920585819356448, 'n_estimators': 696}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:23,095]\u001b[0m Trial 60 finished with value: 0.883399209486166 and parameters: {'num_leaves': 82, 'max_depth': 38, 'learning_rate': 0.27289320072244944, 'n_estimators': 1033}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:25,352]\u001b[0m Trial 61 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 164, 'max_depth': 46, 'learning_rate': 0.23063119133984894, 'n_estimators': 616}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:26,657]\u001b[0m Trial 62 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 166, 'max_depth': 50, 'learning_rate': 0.2217443796478293, 'n_estimators': 544}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:28,547]\u001b[0m Trial 63 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 150, 'max_depth': 48, 'learning_rate': 0.2451958129996075, 'n_estimators': 956}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:29,695]\u001b[0m Trial 64 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 66, 'max_depth': 44, 'learning_rate': 0.29569500264788423, 'n_estimators': 753}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:30,818]\u001b[0m Trial 65 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 190, 'max_depth': 41, 'learning_rate': 0.20608897989418626, 'n_estimators': 454}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:32,219]\u001b[0m Trial 66 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 89, 'max_depth': 47, 'learning_rate': 0.21708913902611165, 'n_estimators': 142}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:33,425]\u001b[0m Trial 67 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 57, 'max_depth': 34, 'learning_rate': 0.2588154847468558, 'n_estimators': 849}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:35,070]\u001b[0m Trial 68 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 100, 'max_depth': 32, 'learning_rate': 0.23124274489912908, 'n_estimators': 317}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:36,779]\u001b[0m Trial 69 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 125, 'max_depth': 45, 'learning_rate': 0.2656658566829736, 'n_estimators': 658}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:37,735]\u001b[0m Trial 70 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 43, 'max_depth': 41, 'learning_rate': 0.20052241856625336, 'n_estimators': 569}. Best is trial 4 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:38,750]\u001b[0m Trial 71 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 77, 'max_depth': 41, 'learning_rate': 0.2037385131573073, 'n_estimators': 538}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:39,665]\u001b[0m Trial 72 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 38, 'max_depth': 39, 'learning_rate': 0.20090980389112456, 'n_estimators': 366}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:40,487]\u001b[0m Trial 73 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 43, 'max_depth': 41, 'learning_rate': 0.2055912090307998, 'n_estimators': 385}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:40,899]\u001b[0m Trial 74 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 18, 'max_depth': 39, 'learning_rate': 0.21650129234185192, 'n_estimators': 202}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:42,521]\u001b[0m Trial 75 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 35, 'max_depth': 42, 'learning_rate': 0.19609747164871863, 'n_estimators': 447}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:43,594]\u001b[0m Trial 76 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 59, 'max_depth': 21, 'learning_rate': 0.19011599673529644, 'n_estimators': 546}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:44,407]\u001b[0m Trial 77 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 50, 'max_depth': 43, 'learning_rate': 0.2231136684142504, 'n_estimators': 248}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:44,666]\u001b[0m Trial 78 finished with value: 0.8754940711462451 and parameters: {'num_leaves': 4, 'max_depth': 37, 'learning_rate': 0.203419068805674, 'n_estimators': 359}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:45,637]\u001b[0m Trial 79 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 68, 'max_depth': 39, 'learning_rate': 0.2506539943914677, 'n_estimators': 601}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:46,351]\u001b[0m Trial 80 finished with value: 0.8774703557312253 and parameters: {'num_leaves': 29, 'max_depth': 35, 'learning_rate': 0.239235697360015, 'n_estimators': 472}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:47,715]\u001b[0m Trial 81 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 78, 'max_depth': 40, 'learning_rate': 0.21426736825920709, 'n_estimators': 720}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:49,257]\u001b[0m Trial 82 finished with value: 0.883399209486166 and parameters: {'num_leaves': 91, 'max_depth': 43, 'learning_rate': 0.22985516730915845, 'n_estimators': 659}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:50,325]\u001b[0m Trial 83 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 41, 'max_depth': 37, 'learning_rate': 0.17558782637909143, 'n_estimators': 510}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:52,716]\u001b[0m Trial 84 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 72, 'max_depth': 41, 'learning_rate': 0.2119365534855873, 'n_estimators': 1534}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:54,103]\u001b[0m Trial 85 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 62, 'max_depth': 33, 'learning_rate': 0.18748867630639557, 'n_estimators': 791}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:55,090]\u001b[0m Trial 86 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 78, 'max_depth': 46, 'learning_rate': 0.24058552755980647, 'n_estimators': 306}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:56,725]\u001b[0m Trial 87 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 86, 'max_depth': 30, 'learning_rate': 0.2008476028993613, 'n_estimators': 573}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:55:58,292]\u001b[0m Trial 88 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 109, 'max_depth': 38, 'learning_rate': 0.19567139098458408, 'n_estimators': 888}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:00,068]\u001b[0m Trial 89 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 115, 'max_depth': 39, 'learning_rate': 0.22127019784292443, 'n_estimators': 901}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:01,964]\u001b[0m Trial 90 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 94, 'max_depth': 35, 'learning_rate': 0.19531270237723736, 'n_estimators': 997}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:03,874]\u001b[0m Trial 91 finished with value: 0.883399209486166 and parameters: {'num_leaves': 112, 'max_depth': 38, 'learning_rate': 0.22224836458577218, 'n_estimators': 918}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:05,874]\u001b[0m Trial 92 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 117, 'max_depth': 44, 'learning_rate': 0.22828617746453503, 'n_estimators': 1145}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:08,021]\u001b[0m Trial 93 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 103, 'max_depth': 39, 'learning_rate': 0.20722590833959664, 'n_estimators': 1098}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:09,495]\u001b[0m Trial 94 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 109, 'max_depth': 17, 'learning_rate': 0.2186247873293115, 'n_estimators': 857}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:11,293]\u001b[0m Trial 95 finished with value: 0.883399209486166 and parameters: {'num_leaves': 47, 'max_depth': 42, 'learning_rate': 0.23527925074583034, 'n_estimators': 739}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:12,650]\u001b[0m Trial 96 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 96, 'max_depth': 48, 'learning_rate': 0.24319194860797172, 'n_estimators': 621}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:14,389]\u001b[0m Trial 97 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 69, 'max_depth': 40, 'learning_rate': 0.21005038887782726, 'n_estimators': 813}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:15,753]\u001b[0m Trial 98 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 85, 'max_depth': 45, 'learning_rate': 0.2511021730275806, 'n_estimators': 415}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:17,641]\u001b[0m Trial 99 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 77, 'max_depth': 36, 'learning_rate': 0.20187340643402057, 'n_estimators': 891}. Best is trial 71 with value: 0.8952569169960475.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature_type               model with_hypertuning   \n",
      "index  selected_features_all_best20  LogisticRegression            False  \\\n",
      "index  selected_features_all_best20                 SVC            False   \n",
      "index  selected_features_all_best20       XGBClassifier            False   \n",
      "index  selected_features_all_best20      LGBMClassifier            False   \n",
      "index  selected_features_all_best20  LogisticRegression             True   \n",
      "index  selected_features_all_best20                 SVC             True   \n",
      "index  selected_features_all_best20       XGBClassifier             True   \n",
      "index  selected_features_all_best20      LGBMClassifier             True   \n",
      "index  selected_features_all_best30  LogisticRegression            False   \n",
      "index  selected_features_all_best30                 SVC            False   \n",
      "index  selected_features_all_best30       XGBClassifier            False   \n",
      "index  selected_features_all_best30      LGBMClassifier            False   \n",
      "index  selected_features_all_best30  LogisticRegression             True   \n",
      "index  selected_features_all_best30                 SVC             True   \n",
      "index  selected_features_all_best30       XGBClassifier             True   \n",
      "index  selected_features_all_best30      LGBMClassifier             True   \n",
      "index  selected_features_all_best50  LogisticRegression            False   \n",
      "index  selected_features_all_best50                 SVC            False   \n",
      "index  selected_features_all_best50       XGBClassifier            False   \n",
      "index  selected_features_all_best50      LGBMClassifier            False   \n",
      "index  selected_features_all_best50  LogisticRegression             True   \n",
      "index  selected_features_all_best50                 SVC             True   \n",
      "index  selected_features_all_best50       XGBClassifier             True   \n",
      "index  selected_features_all_best50      LGBMClassifier             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.888807   \n",
      "index  {'C': 0.024422805336610946, 'penalty': 'l1', '...  0.889328   \n",
      "index  {'svc_c': 14.99270459807389, 'svc_gamma': 0.07...  0.873518   \n",
      "index  {'learning_rate': 0.049433721318135074, 'max_d...  0.893281   \n",
      "index  {'num_leaves': 77, 'max_depth': 41, 'learning_...  0.895257   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "index     0.844898     0.923372   0.911894  0.877119  0.771973   \n",
      "index     0.840816     0.923372   0.911504  0.874735  0.768193   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.804082     0.938697   0.924883  0.860262  0.751864   \n",
      "index     0.844898     0.938697   0.928251  0.884615  0.788768   \n",
      "index     0.848980     0.938697   0.928571  0.886994  0.792507   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_no_...  \n",
      "index  selected_features_all_best50_LGBMClassifier_no...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index  selected_features_all_best50_SVC_with_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_wit...  \n",
      "index  selected_features_all_best50_LGBMClassifier_wi...  \n",
      "Evaluating selected_features_all_best100 LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        feature_type               model with_hypertuning   \n",
      "index   selected_features_all_best20  LogisticRegression            False  \\\n",
      "index   selected_features_all_best20                 SVC            False   \n",
      "index   selected_features_all_best20       XGBClassifier            False   \n",
      "index   selected_features_all_best20      LGBMClassifier            False   \n",
      "index   selected_features_all_best20  LogisticRegression             True   \n",
      "index   selected_features_all_best20                 SVC             True   \n",
      "index   selected_features_all_best20       XGBClassifier             True   \n",
      "index   selected_features_all_best20      LGBMClassifier             True   \n",
      "index   selected_features_all_best30  LogisticRegression            False   \n",
      "index   selected_features_all_best30                 SVC            False   \n",
      "index   selected_features_all_best30       XGBClassifier            False   \n",
      "index   selected_features_all_best30      LGBMClassifier            False   \n",
      "index   selected_features_all_best30  LogisticRegression             True   \n",
      "index   selected_features_all_best30                 SVC             True   \n",
      "index   selected_features_all_best30       XGBClassifier             True   \n",
      "index   selected_features_all_best30      LGBMClassifier             True   \n",
      "index   selected_features_all_best50  LogisticRegression            False   \n",
      "index   selected_features_all_best50                 SVC            False   \n",
      "index   selected_features_all_best50       XGBClassifier            False   \n",
      "index   selected_features_all_best50      LGBMClassifier            False   \n",
      "index   selected_features_all_best50  LogisticRegression             True   \n",
      "index   selected_features_all_best50                 SVC             True   \n",
      "index   selected_features_all_best50       XGBClassifier             True   \n",
      "index   selected_features_all_best50      LGBMClassifier             True   \n",
      "index  selected_features_all_best100  LogisticRegression            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.888807   \n",
      "index  {'C': 0.024422805336610946, 'penalty': 'l1', '...  0.889328   \n",
      "index  {'svc_c': 14.99270459807389, 'svc_gamma': 0.07...  0.873518   \n",
      "index  {'learning_rate': 0.049433721318135074, 'max_d...  0.893281   \n",
      "index  {'num_leaves': 77, 'max_depth': 41, 'learning_...  0.895257   \n",
      "index                                               None  0.901161   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "index     0.844898     0.923372   0.911894  0.877119  0.771973   \n",
      "index     0.840816     0.923372   0.911504  0.874735  0.768193   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.804082     0.938697   0.924883  0.860262  0.751864   \n",
      "index     0.844898     0.938697   0.928251  0.884615  0.788768   \n",
      "index     0.848980     0.938697   0.928571  0.886994  0.792507   \n",
      "index     0.869388     0.923372   0.914163  0.891213  0.794850   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_no_...  \n",
      "index  selected_features_all_best50_LGBMClassifier_no...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index  selected_features_all_best50_SVC_with_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_wit...  \n",
      "index  selected_features_all_best50_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best100_LogisticRegressi...  \n",
      "Evaluating selected_features_all_best100 SVC\n",
      "                        feature_type               model with_hypertuning   \n",
      "index   selected_features_all_best20  LogisticRegression            False  \\\n",
      "index   selected_features_all_best20                 SVC            False   \n",
      "index   selected_features_all_best20       XGBClassifier            False   \n",
      "index   selected_features_all_best20      LGBMClassifier            False   \n",
      "index   selected_features_all_best20  LogisticRegression             True   \n",
      "index   selected_features_all_best20                 SVC             True   \n",
      "index   selected_features_all_best20       XGBClassifier             True   \n",
      "index   selected_features_all_best20      LGBMClassifier             True   \n",
      "index   selected_features_all_best30  LogisticRegression            False   \n",
      "index   selected_features_all_best30                 SVC            False   \n",
      "index   selected_features_all_best30       XGBClassifier            False   \n",
      "index   selected_features_all_best30      LGBMClassifier            False   \n",
      "index   selected_features_all_best30  LogisticRegression             True   \n",
      "index   selected_features_all_best30                 SVC             True   \n",
      "index   selected_features_all_best30       XGBClassifier             True   \n",
      "index   selected_features_all_best30      LGBMClassifier             True   \n",
      "index   selected_features_all_best50  LogisticRegression            False   \n",
      "index   selected_features_all_best50                 SVC            False   \n",
      "index   selected_features_all_best50       XGBClassifier            False   \n",
      "index   selected_features_all_best50      LGBMClassifier            False   \n",
      "index   selected_features_all_best50  LogisticRegression             True   \n",
      "index   selected_features_all_best50                 SVC             True   \n",
      "index   selected_features_all_best50       XGBClassifier             True   \n",
      "index   selected_features_all_best50      LGBMClassifier             True   \n",
      "index  selected_features_all_best100  LogisticRegression            False   \n",
      "index  selected_features_all_best100                 SVC            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.888807   \n",
      "index  {'C': 0.024422805336610946, 'penalty': 'l1', '...  0.889328   \n",
      "index  {'svc_c': 14.99270459807389, 'svc_gamma': 0.07...  0.873518   \n",
      "index  {'learning_rate': 0.049433721318135074, 'max_d...  0.893281   \n",
      "index  {'num_leaves': 77, 'max_depth': 41, 'learning_...  0.895257   \n",
      "index                                               None  0.901161   \n",
      "index                                               None  0.898695   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "index     0.844898     0.923372   0.911894  0.877119  0.771973   \n",
      "index     0.840816     0.923372   0.911504  0.874735  0.768193   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.804082     0.938697   0.924883  0.860262  0.751864   \n",
      "index     0.844898     0.938697   0.928251  0.884615  0.788768   \n",
      "index     0.848980     0.938697   0.928571  0.886994  0.792507   \n",
      "index     0.869388     0.923372   0.914163  0.891213  0.794850   \n",
      "index     0.853061     0.934866   0.924779  0.887473  0.792056   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_no_...  \n",
      "index  selected_features_all_best50_LGBMClassifier_no...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index  selected_features_all_best50_SVC_with_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_wit...  \n",
      "index  selected_features_all_best50_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best100_LogisticRegressi...  \n",
      "index   selected_features_all_best100_SVC_no_hypertuning  \n",
      "Evaluating selected_features_all_best100 XGBClassifier\n",
      "                        feature_type               model with_hypertuning   \n",
      "index   selected_features_all_best20  LogisticRegression            False  \\\n",
      "index   selected_features_all_best20                 SVC            False   \n",
      "index   selected_features_all_best20       XGBClassifier            False   \n",
      "index   selected_features_all_best20      LGBMClassifier            False   \n",
      "index   selected_features_all_best20  LogisticRegression             True   \n",
      "index   selected_features_all_best20                 SVC             True   \n",
      "index   selected_features_all_best20       XGBClassifier             True   \n",
      "index   selected_features_all_best20      LGBMClassifier             True   \n",
      "index   selected_features_all_best30  LogisticRegression            False   \n",
      "index   selected_features_all_best30                 SVC            False   \n",
      "index   selected_features_all_best30       XGBClassifier            False   \n",
      "index   selected_features_all_best30      LGBMClassifier            False   \n",
      "index   selected_features_all_best30  LogisticRegression             True   \n",
      "index   selected_features_all_best30                 SVC             True   \n",
      "index   selected_features_all_best30       XGBClassifier             True   \n",
      "index   selected_features_all_best30      LGBMClassifier             True   \n",
      "index   selected_features_all_best50  LogisticRegression            False   \n",
      "index   selected_features_all_best50                 SVC            False   \n",
      "index   selected_features_all_best50       XGBClassifier            False   \n",
      "index   selected_features_all_best50      LGBMClassifier            False   \n",
      "index   selected_features_all_best50  LogisticRegression             True   \n",
      "index   selected_features_all_best50                 SVC             True   \n",
      "index   selected_features_all_best50       XGBClassifier             True   \n",
      "index   selected_features_all_best50      LGBMClassifier             True   \n",
      "index  selected_features_all_best100  LogisticRegression            False   \n",
      "index  selected_features_all_best100                 SVC            False   \n",
      "index  selected_features_all_best100       XGBClassifier            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.888807   \n",
      "index  {'C': 0.024422805336610946, 'penalty': 'l1', '...  0.889328   \n",
      "index  {'svc_c': 14.99270459807389, 'svc_gamma': 0.07...  0.873518   \n",
      "index  {'learning_rate': 0.049433721318135074, 'max_d...  0.893281   \n",
      "index  {'num_leaves': 77, 'max_depth': 41, 'learning_...  0.895257   \n",
      "index                                               None  0.901161   \n",
      "index                                               None  0.898695   \n",
      "index                                               None  0.889304   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "index     0.844898     0.923372   0.911894  0.877119  0.771973   \n",
      "index     0.840816     0.923372   0.911504  0.874735  0.768193   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.804082     0.938697   0.924883  0.860262  0.751864   \n",
      "index     0.844898     0.938697   0.928251  0.884615  0.788768   \n",
      "index     0.848980     0.938697   0.928571  0.886994  0.792507   \n",
      "index     0.869388     0.923372   0.914163  0.891213  0.794850   \n",
      "index     0.853061     0.934866   0.924779  0.887473  0.792056   \n",
      "index     0.848980     0.931034   0.920354  0.883227  0.784102   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_no_...  \n",
      "index  selected_features_all_best50_LGBMClassifier_no...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index  selected_features_all_best50_SVC_with_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_wit...  \n",
      "index  selected_features_all_best50_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best100_LogisticRegressi...  \n",
      "index   selected_features_all_best100_SVC_no_hypertuning  \n",
      "index  selected_features_all_best100_XGBClassifier_no...  \n",
      "Evaluating selected_features_all_best100 LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:56:35,852]\u001b[0m A new study created in memory with name: no-name-43b144b1-9ee0-4e09-9aa9-0b9af1db68db\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:35,963]\u001b[0m Trial 0 finished with value: 0.8814229249011858 and parameters: {'C': 0.08534929086077442, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 755}. Best is trial 0 with value: 0.8814229249011858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        feature_type               model with_hypertuning   \n",
      "index   selected_features_all_best20  LogisticRegression            False  \\\n",
      "index   selected_features_all_best20                 SVC            False   \n",
      "index   selected_features_all_best20       XGBClassifier            False   \n",
      "index   selected_features_all_best20      LGBMClassifier            False   \n",
      "index   selected_features_all_best20  LogisticRegression             True   \n",
      "index   selected_features_all_best20                 SVC             True   \n",
      "index   selected_features_all_best20       XGBClassifier             True   \n",
      "index   selected_features_all_best20      LGBMClassifier             True   \n",
      "index   selected_features_all_best30  LogisticRegression            False   \n",
      "index   selected_features_all_best30                 SVC            False   \n",
      "index   selected_features_all_best30       XGBClassifier            False   \n",
      "index   selected_features_all_best30      LGBMClassifier            False   \n",
      "index   selected_features_all_best30  LogisticRegression             True   \n",
      "index   selected_features_all_best30                 SVC             True   \n",
      "index   selected_features_all_best30       XGBClassifier             True   \n",
      "index   selected_features_all_best30      LGBMClassifier             True   \n",
      "index   selected_features_all_best50  LogisticRegression            False   \n",
      "index   selected_features_all_best50                 SVC            False   \n",
      "index   selected_features_all_best50       XGBClassifier            False   \n",
      "index   selected_features_all_best50      LGBMClassifier            False   \n",
      "index   selected_features_all_best50  LogisticRegression             True   \n",
      "index   selected_features_all_best50                 SVC             True   \n",
      "index   selected_features_all_best50       XGBClassifier             True   \n",
      "index   selected_features_all_best50      LGBMClassifier             True   \n",
      "index  selected_features_all_best100  LogisticRegression            False   \n",
      "index  selected_features_all_best100                 SVC            False   \n",
      "index  selected_features_all_best100       XGBClassifier            False   \n",
      "index  selected_features_all_best100      LGBMClassifier            False   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.888807   \n",
      "index  {'C': 0.024422805336610946, 'penalty': 'l1', '...  0.889328   \n",
      "index  {'svc_c': 14.99270459807389, 'svc_gamma': 0.07...  0.873518   \n",
      "index  {'learning_rate': 0.049433721318135074, 'max_d...  0.893281   \n",
      "index  {'num_leaves': 77, 'max_depth': 41, 'learning_...  0.895257   \n",
      "index                                               None  0.901161   \n",
      "index                                               None  0.898695   \n",
      "index                                               None  0.889304   \n",
      "index                                               None  0.892762   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "index     0.844898     0.923372   0.911894  0.877119  0.771973   \n",
      "index     0.840816     0.923372   0.911504  0.874735  0.768193   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.804082     0.938697   0.924883  0.860262  0.751864   \n",
      "index     0.844898     0.938697   0.928251  0.884615  0.788768   \n",
      "index     0.848980     0.938697   0.928571  0.886994  0.792507   \n",
      "index     0.869388     0.923372   0.914163  0.891213  0.794850   \n",
      "index     0.853061     0.934866   0.924779  0.887473  0.792056   \n",
      "index     0.848980     0.931034   0.920354  0.883227  0.784102   \n",
      "index     0.844898     0.927203   0.915929  0.878981  0.776147   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_no_...  \n",
      "index  selected_features_all_best50_LGBMClassifier_no...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index  selected_features_all_best50_SVC_with_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_wit...  \n",
      "index  selected_features_all_best50_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best100_LogisticRegressi...  \n",
      "index   selected_features_all_best100_SVC_no_hypertuning  \n",
      "index  selected_features_all_best100_XGBClassifier_no...  \n",
      "index  selected_features_all_best100_LGBMClassifier_n...  \n",
      "Optimizing selected_features_all_best100 LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:56:39,417]\u001b[0m Trial 1 finished with value: 0.8853754940711462 and parameters: {'C': 0.06225657591442953, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 788}. Best is trial 1 with value: 0.8853754940711462.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:39,514]\u001b[0m Trial 2 finished with value: 0.8932806324110671 and parameters: {'C': 0.08263726939093811, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 623}. Best is trial 2 with value: 0.8932806324110671.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:40,858]\u001b[0m Trial 3 finished with value: 0.8952569169960475 and parameters: {'C': 0.08082468014153397, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 497}. Best is trial 3 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:40,941]\u001b[0m Trial 4 finished with value: 0.8932806324110671 and parameters: {'C': 0.07663931196568836, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 320}. Best is trial 3 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:41,018]\u001b[0m Trial 5 finished with value: 0.8893280632411067 and parameters: {'C': 0.04487665451060856, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 483}. Best is trial 3 with value: 0.8952569169960475.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:56:44,214]\u001b[0m Trial 6 finished with value: 0.883399209486166 and parameters: {'C': 0.07603853320921976, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 811}. Best is trial 3 with value: 0.8952569169960475.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:56:44,798]\u001b[0m Trial 7 finished with value: 0.8814229249011858 and parameters: {'C': 0.04416900662939269, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 131}. Best is trial 3 with value: 0.8952569169960475.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:44,832]\u001b[0m Trial 8 finished with value: 0.8517786561264822 and parameters: {'C': 0.011024979971963481, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 654}. Best is trial 3 with value: 0.8952569169960475.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:56:47,104]\u001b[0m Trial 9 finished with value: 0.8853754940711462 and parameters: {'C': 0.05850620023177643, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 558}. Best is trial 3 with value: 0.8952569169960475.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:56:48,139]\u001b[0m Trial 10 finished with value: 0.8972332015810277 and parameters: {'C': 0.09995242748229684, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 312}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:56:49,312]\u001b[0m Trial 11 finished with value: 0.8972332015810277 and parameters: {'C': 0.09946477981921274, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 332}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:56:50,186]\u001b[0m Trial 12 finished with value: 0.8972332015810277 and parameters: {'C': 0.09641915840527626, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 266}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:56:51,383]\u001b[0m Trial 13 finished with value: 0.8972332015810277 and parameters: {'C': 0.09810207213385891, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 360}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:52,911]\u001b[0m Trial 14 finished with value: 0.8972332015810277 and parameters: {'C': 0.09963324633394435, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 988}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:56:53,451]\u001b[0m Trial 15 finished with value: 0.8952569169960475 and parameters: {'C': 0.0908514709362179, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 148}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:56:54,872]\u001b[0m Trial 16 finished with value: 0.8972332015810277 and parameters: {'C': 0.09007993904320592, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 417}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:56:55,780]\u001b[0m Trial 17 finished with value: 0.8913043478260869 and parameters: {'C': 0.07104045126963668, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 275}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:56:56,481]\u001b[0m Trial 18 finished with value: 0.8952569169960475 and parameters: {'C': 0.08794542342531896, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 215}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:56:57,703]\u001b[0m Trial 19 finished with value: 0.8972332015810277 and parameters: {'C': 0.0987949322233307, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 400}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:56:58,267]\u001b[0m Trial 20 finished with value: 0.8932806324110671 and parameters: {'C': 0.07294331626911732, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 176}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:56:59,070]\u001b[0m Trial 21 finished with value: 0.8972332015810277 and parameters: {'C': 0.09994326590053121, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 252}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:00,003]\u001b[0m Trial 22 finished with value: 0.8972332015810277 and parameters: {'C': 0.09165077738873598, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 309}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:01,297]\u001b[0m Trial 23 finished with value: 0.8972332015810277 and parameters: {'C': 0.0931866155054519, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 442}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:01,741]\u001b[0m Trial 24 finished with value: 0.8932806324110671 and parameters: {'C': 0.08507649294830569, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 109}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:02,525]\u001b[0m Trial 25 finished with value: 0.8972332015810277 and parameters: {'C': 0.09211742875384717, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 214}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:03,784]\u001b[0m Trial 26 finished with value: 0.8952569169960475 and parameters: {'C': 0.08184151627671833, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 361}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:03,882]\u001b[0m Trial 27 finished with value: 0.8972332015810277 and parameters: {'C': 0.0998202235416987, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 268}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:05,318]\u001b[0m Trial 28 finished with value: 0.8972332015810277 and parameters: {'C': 0.09398038597593261, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 554}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:05,384]\u001b[0m Trial 29 finished with value: 0.8814229249011858 and parameters: {'C': 0.0850942170211846, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 364}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:05,995]\u001b[0m Trial 30 finished with value: 0.8952569169960475 and parameters: {'C': 0.08593535976096377, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 201}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:07,016]\u001b[0m Trial 31 finished with value: 0.8972332015810277 and parameters: {'C': 0.09690313787811226, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 338}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:08,445]\u001b[0m Trial 32 finished with value: 0.8972332015810277 and parameters: {'C': 0.09554863485260713, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 480}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:09,790]\u001b[0m Trial 33 finished with value: 0.8972332015810277 and parameters: {'C': 0.09422978825940831, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 389}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:10,730]\u001b[0m Trial 34 finished with value: 0.8972332015810277 and parameters: {'C': 0.08805597350604624, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 273}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:12,017]\u001b[0m Trial 35 finished with value: 0.8952569169960475 and parameters: {'C': 0.08079933481280138, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 622}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:12,092]\u001b[0m Trial 36 finished with value: 0.8794466403162056 and parameters: {'C': 0.09496459679836138, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 445}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:13,205]\u001b[0m Trial 37 finished with value: 0.8972332015810277 and parameters: {'C': 0.0893284634950715, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 305}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:13,290]\u001b[0m Trial 38 finished with value: 0.8972332015810277 and parameters: {'C': 0.09984367430541256, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 493}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:14,588]\u001b[0m Trial 39 finished with value: 0.8853754940711462 and parameters: {'C': 0.07824683058264795, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 322}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:15,415]\u001b[0m Trial 40 finished with value: 0.8952569169960475 and parameters: {'C': 0.08303960501136161, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 236}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:16,774]\u001b[0m Trial 41 finished with value: 0.8972332015810277 and parameters: {'C': 0.09652694173655638, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 921}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:18,228]\u001b[0m Trial 42 finished with value: 0.8972332015810277 and parameters: {'C': 0.0998898717576252, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 997}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:19,563]\u001b[0m Trial 43 finished with value: 0.8972332015810277 and parameters: {'C': 0.08974102537475512, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 641}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:20,848]\u001b[0m Trial 44 finished with value: 0.8972332015810277 and parameters: {'C': 0.09453149143338747, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 785}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:22,026]\u001b[0m Trial 45 finished with value: 0.8972332015810277 and parameters: {'C': 0.08764768127533784, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 719}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:22,106]\u001b[0m Trial 46 finished with value: 0.8794466403162056 and parameters: {'C': 0.09601947840529919, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 894}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:23,367]\u001b[0m Trial 47 finished with value: 0.8972332015810277 and parameters: {'C': 0.09163712469329238, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 597}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:24,478]\u001b[0m Trial 48 finished with value: 0.8932806324110671 and parameters: {'C': 0.07863784577539627, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 526}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:24,966]\u001b[0m Trial 49 finished with value: 0.8932806324110671 and parameters: {'C': 0.08531690489668856, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 147}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:27,528]\u001b[0m Trial 50 finished with value: 0.8794466403162056 and parameters: {'C': 0.0969522584222337, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 722}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:28,730]\u001b[0m Trial 51 finished with value: 0.8972332015810277 and parameters: {'C': 0.09174956285001346, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 406}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:29,974]\u001b[0m Trial 52 finished with value: 0.8972332015810277 and parameters: {'C': 0.09082011451020268, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 421}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:31,145]\u001b[0m Trial 53 finished with value: 0.8972332015810277 and parameters: {'C': 0.09713597022541486, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 364}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:32,052]\u001b[0m Trial 54 finished with value: 0.8972332015810277 and parameters: {'C': 0.09964468440362378, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 290}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:33,266]\u001b[0m Trial 55 finished with value: 0.8972332015810277 and parameters: {'C': 0.08905329571234487, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 448}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:33,845]\u001b[0m Trial 56 finished with value: 0.8893280632411067 and parameters: {'C': 0.06600489931869598, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 184}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:34,909]\u001b[0m Trial 57 finished with value: 0.8972332015810277 and parameters: {'C': 0.09391761067885965, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 344}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:35,006]\u001b[0m Trial 58 finished with value: 0.8972332015810277 and parameters: {'C': 0.0971589870346858, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 254}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:36,147]\u001b[0m Trial 59 finished with value: 0.8952569169960475 and parameters: {'C': 0.08359851407152646, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 457}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:37,457]\u001b[0m Trial 60 finished with value: 0.8972332015810277 and parameters: {'C': 0.09221605669960119, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 378}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:38,846]\u001b[0m Trial 61 finished with value: 0.8972332015810277 and parameters: {'C': 0.09837676834221037, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 411}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:40,037]\u001b[0m Trial 62 finished with value: 0.8972332015810277 and parameters: {'C': 0.09367917733994342, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 331}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:40,887]\u001b[0m Trial 63 finished with value: 0.8972332015810277 and parameters: {'C': 0.09977889010833267, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 233}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:42,083]\u001b[0m Trial 64 finished with value: 0.8972332015810277 and parameters: {'C': 0.08679386649953988, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 523}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:43,094]\u001b[0m Trial 65 finished with value: 0.8972332015810277 and parameters: {'C': 0.09618697319560232, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 305}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:44,336]\u001b[0m Trial 66 finished with value: 0.8972332015810277 and parameters: {'C': 0.09017776750387932, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 395}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:45,452]\u001b[0m Trial 67 finished with value: 0.8794466403162056 and parameters: {'C': 0.09292251435564299, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 294}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:45,549]\u001b[0m Trial 68 finished with value: 0.8952569169960475 and parameters: {'C': 0.0872528329169152, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 580}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:46,645]\u001b[0m Trial 69 finished with value: 0.8972332015810277 and parameters: {'C': 0.09719714523432446, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 357}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:48,020]\u001b[0m Trial 70 finished with value: 0.8972332015810277 and parameters: {'C': 0.09508490635356687, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 426}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:48,803]\u001b[0m Trial 71 finished with value: 0.8972332015810277 and parameters: {'C': 0.09937727369966394, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 254}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:49,397]\u001b[0m Trial 72 finished with value: 0.8972332015810277 and parameters: {'C': 0.09991431391114398, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 187}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:50,111]\u001b[0m Trial 73 finished with value: 0.8972332015810277 and parameters: {'C': 0.09426443015511497, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 225}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:51,366]\u001b[0m Trial 74 finished with value: 0.8972332015810277 and parameters: {'C': 0.09763632913487809, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 470}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:52,381]\u001b[0m Trial 75 finished with value: 0.8972332015810277 and parameters: {'C': 0.0906615892083897, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 322}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:53,211]\u001b[0m Trial 76 finished with value: 0.8972332015810277 and parameters: {'C': 0.09293629319881798, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 268}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:54,576]\u001b[0m Trial 77 finished with value: 0.883399209486166 and parameters: {'C': 0.08925726201442123, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 379}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:54,662]\u001b[0m Trial 78 finished with value: 0.8972332015810277 and parameters: {'C': 0.09545999453899931, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 343}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:55,049]\u001b[0m Trial 79 finished with value: 0.8932806324110671 and parameters: {'C': 0.09767873738161978, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 117}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:55,595]\u001b[0m Trial 80 finished with value: 0.8952569169960475 and parameters: {'C': 0.0867365998221825, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 166}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:56,523]\u001b[0m Trial 81 finished with value: 0.8972332015810277 and parameters: {'C': 0.0924379026535291, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 306}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:57,417]\u001b[0m Trial 82 finished with value: 0.8972332015810277 and parameters: {'C': 0.0959536861638325, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 282}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:57:58,150]\u001b[0m Trial 83 finished with value: 0.8972332015810277 and parameters: {'C': 0.09832676164813023, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 213}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:57:59,484]\u001b[0m Trial 84 finished with value: 0.8972332015810277 and parameters: {'C': 0.08934703497557002, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 854}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:58:00,415]\u001b[0m Trial 85 finished with value: 0.8972332015810277 and parameters: {'C': 0.0945074796165909, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 258}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:58:01,490]\u001b[0m Trial 86 finished with value: 0.8972332015810277 and parameters: {'C': 0.0913393183573767, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 324}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:58:02,582]\u001b[0m Trial 87 finished with value: 0.8972332015810277 and parameters: {'C': 0.0984220947396474, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 363}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:58:05,051]\u001b[0m Trial 88 finished with value: 0.883399209486166 and parameters: {'C': 0.08263889902051326, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 682}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:06,377]\u001b[0m Trial 89 finished with value: 0.8972332015810277 and parameters: {'C': 0.0957521787741299, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 438}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:06,513]\u001b[0m Trial 90 finished with value: 0.8952569169960475 and parameters: {'C': 0.08478408477214926, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 984}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:58:07,723]\u001b[0m Trial 91 finished with value: 0.8972332015810277 and parameters: {'C': 0.09998802744784008, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 407}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:58:08,883]\u001b[0m Trial 92 finished with value: 0.8972332015810277 and parameters: {'C': 0.09383272315064534, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 386}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:58:10,137]\u001b[0m Trial 93 finished with value: 0.8972332015810277 and parameters: {'C': 0.09700279049065214, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 349}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:11,528]\u001b[0m Trial 94 finished with value: 0.8972332015810277 and parameters: {'C': 0.09166065909413919, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 503}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:58:12,395]\u001b[0m Trial 95 finished with value: 0.8972332015810277 and parameters: {'C': 0.08853281976253288, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 240}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:58:13,443]\u001b[0m Trial 96 finished with value: 0.8972332015810277 and parameters: {'C': 0.09330774141488685, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 300}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:14,923]\u001b[0m Trial 97 finished with value: 0.8972332015810277 and parameters: {'C': 0.09819442096275457, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 424}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-14 11:58:15,920]\u001b[0m Trial 98 finished with value: 0.8972332015810277 and parameters: {'C': 0.0955837067673092, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 278}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:17,294]\u001b[0m Trial 99 finished with value: 0.8972332015810277 and parameters: {'C': 0.09152386327755069, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 472}. Best is trial 10 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:17,308]\u001b[0m A new study created in memory with name: no-name-65f9fac0-216c-492e-9d68-0c6efd7f3e94\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        feature_type               model with_hypertuning   \n",
      "index   selected_features_all_best20  LogisticRegression            False  \\\n",
      "index   selected_features_all_best20                 SVC            False   \n",
      "index   selected_features_all_best20       XGBClassifier            False   \n",
      "index   selected_features_all_best20      LGBMClassifier            False   \n",
      "index   selected_features_all_best20  LogisticRegression             True   \n",
      "index   selected_features_all_best20                 SVC             True   \n",
      "index   selected_features_all_best20       XGBClassifier             True   \n",
      "index   selected_features_all_best20      LGBMClassifier             True   \n",
      "index   selected_features_all_best30  LogisticRegression            False   \n",
      "index   selected_features_all_best30                 SVC            False   \n",
      "index   selected_features_all_best30       XGBClassifier            False   \n",
      "index   selected_features_all_best30      LGBMClassifier            False   \n",
      "index   selected_features_all_best30  LogisticRegression             True   \n",
      "index   selected_features_all_best30                 SVC             True   \n",
      "index   selected_features_all_best30       XGBClassifier             True   \n",
      "index   selected_features_all_best30      LGBMClassifier             True   \n",
      "index   selected_features_all_best50  LogisticRegression            False   \n",
      "index   selected_features_all_best50                 SVC            False   \n",
      "index   selected_features_all_best50       XGBClassifier            False   \n",
      "index   selected_features_all_best50      LGBMClassifier            False   \n",
      "index   selected_features_all_best50  LogisticRegression             True   \n",
      "index   selected_features_all_best50                 SVC             True   \n",
      "index   selected_features_all_best50       XGBClassifier             True   \n",
      "index   selected_features_all_best50      LGBMClassifier             True   \n",
      "index  selected_features_all_best100  LogisticRegression            False   \n",
      "index  selected_features_all_best100                 SVC            False   \n",
      "index  selected_features_all_best100       XGBClassifier            False   \n",
      "index  selected_features_all_best100      LGBMClassifier            False   \n",
      "index  selected_features_all_best100  LogisticRegression             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.888807   \n",
      "index  {'C': 0.024422805336610946, 'penalty': 'l1', '...  0.889328   \n",
      "index  {'svc_c': 14.99270459807389, 'svc_gamma': 0.07...  0.873518   \n",
      "index  {'learning_rate': 0.049433721318135074, 'max_d...  0.893281   \n",
      "index  {'num_leaves': 77, 'max_depth': 41, 'learning_...  0.895257   \n",
      "index                                               None  0.901161   \n",
      "index                                               None  0.898695   \n",
      "index                                               None  0.889304   \n",
      "index                                               None  0.892762   \n",
      "index  {'C': 0.09995242748229684, 'penalty': 'l2', 's...  0.897233   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "index     0.844898     0.923372   0.911894  0.877119  0.771973   \n",
      "index     0.840816     0.923372   0.911504  0.874735  0.768193   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.804082     0.938697   0.924883  0.860262  0.751864   \n",
      "index     0.844898     0.938697   0.928251  0.884615  0.788768   \n",
      "index     0.848980     0.938697   0.928571  0.886994  0.792507   \n",
      "index     0.869388     0.923372   0.914163  0.891213  0.794850   \n",
      "index     0.853061     0.934866   0.924779  0.887473  0.792056   \n",
      "index     0.848980     0.931034   0.920354  0.883227  0.784102   \n",
      "index     0.844898     0.927203   0.915929  0.878981  0.776147   \n",
      "index     0.869388     0.923372   0.914163  0.891213  0.794850   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_no_...  \n",
      "index  selected_features_all_best50_LGBMClassifier_no...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index  selected_features_all_best50_SVC_with_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_wit...  \n",
      "index  selected_features_all_best50_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best100_LogisticRegressi...  \n",
      "index   selected_features_all_best100_SVC_no_hypertuning  \n",
      "index  selected_features_all_best100_XGBClassifier_no...  \n",
      "index  selected_features_all_best100_LGBMClassifier_n...  \n",
      "index  selected_features_all_best100_LogisticRegressi...  \n",
      "Optimizing selected_features_all_best100 SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:58:18,108]\u001b[0m Trial 0 finished with value: 0.5177865612648221 and parameters: {'svc_c': 78.12209306408987, 'svc_gamma': 26.10190874864247}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:18,822]\u001b[0m Trial 1 finished with value: 0.5138339920948617 and parameters: {'svc_c': 56.51771659426793, 'svc_gamma': 93.67982138851708}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:19,444]\u001b[0m Trial 2 finished with value: 0.5177865612648221 and parameters: {'svc_c': 70.16516705408472, 'svc_gamma': 19.471233381399788}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:20,054]\u001b[0m Trial 3 finished with value: 0.5177865612648221 and parameters: {'svc_c': 6.87552501441381, 'svc_gamma': 42.74508324946356}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:20,652]\u001b[0m Trial 4 finished with value: 0.5138339920948617 and parameters: {'svc_c': 92.10256990605347, 'svc_gamma': 69.4395315432201}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:21,268]\u001b[0m Trial 5 finished with value: 0.5158102766798419 and parameters: {'svc_c': 87.9380330864905, 'svc_gamma': 54.49797561050639}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:21,848]\u001b[0m Trial 6 finished with value: 0.5138339920948617 and parameters: {'svc_c': 21.030219442710642, 'svc_gamma': 71.45267276654978}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:22,428]\u001b[0m Trial 7 finished with value: 0.5138339920948617 and parameters: {'svc_c': 74.55920066166092, 'svc_gamma': 99.32589946003345}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:23,063]\u001b[0m Trial 8 finished with value: 0.5177865612648221 and parameters: {'svc_c': 87.50991953128603, 'svc_gamma': 27.81719412067129}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:23,677]\u001b[0m Trial 9 finished with value: 0.5138339920948617 and parameters: {'svc_c': 89.09266109326043, 'svc_gamma': 78.49695776261838}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:24,300]\u001b[0m Trial 10 finished with value: 0.5177865612648221 and parameters: {'svc_c': 40.20383811729294, 'svc_gamma': 0.8261899603327763}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:24,953]\u001b[0m Trial 11 finished with value: 0.5177865612648221 and parameters: {'svc_c': 66.79999219438982, 'svc_gamma': 17.833754083919473}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:25,597]\u001b[0m Trial 12 finished with value: 0.5177865612648221 and parameters: {'svc_c': 69.91220050670486, 'svc_gamma': 25.38928724195918}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:26,309]\u001b[0m Trial 13 finished with value: 0.5177865612648221 and parameters: {'svc_c': 48.47693681417393, 'svc_gamma': 12.024390534385377}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:26,924]\u001b[0m Trial 14 finished with value: 0.5177865612648221 and parameters: {'svc_c': 98.87672630102877, 'svc_gamma': 37.502476777123114}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:27,600]\u001b[0m Trial 15 finished with value: 0.5177865612648221 and parameters: {'svc_c': 78.8911593680958, 'svc_gamma': 3.09781757138785}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:28,190]\u001b[0m Trial 16 finished with value: 0.5177865612648221 and parameters: {'svc_c': 62.901285902733086, 'svc_gamma': 34.762533786306065}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:28,848]\u001b[0m Trial 17 finished with value: 0.5177865612648221 and parameters: {'svc_c': 78.14503403953863, 'svc_gamma': 17.228605213815037}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:29,423]\u001b[0m Trial 18 finished with value: 0.5158102766798419 and parameters: {'svc_c': 59.89997779068876, 'svc_gamma': 52.640085836737754}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:30,050]\u001b[0m Trial 19 finished with value: 0.5177865612648221 and parameters: {'svc_c': 44.4004364077908, 'svc_gamma': 29.625521050794347}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:30,769]\u001b[0m Trial 20 finished with value: 0.5177865612648221 and parameters: {'svc_c': 77.86894185390364, 'svc_gamma': 11.758566694767751}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:31,430]\u001b[0m Trial 21 finished with value: 0.5177865612648221 and parameters: {'svc_c': 5.7959328247669895, 'svc_gamma': 41.77040995749499}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:32,095]\u001b[0m Trial 22 finished with value: 0.5177865612648221 and parameters: {'svc_c': 2.200677902693818, 'svc_gamma': 40.69328636989428}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:32,707]\u001b[0m Trial 23 finished with value: 0.5158102766798419 and parameters: {'svc_c': 33.689452201602876, 'svc_gamma': 46.4029457788706}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:33,314]\u001b[0m Trial 24 finished with value: 0.5177865612648221 and parameters: {'svc_c': 52.24518585298658, 'svc_gamma': 22.82846223378123}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:33,897]\u001b[0m Trial 25 finished with value: 0.5177865612648221 and parameters: {'svc_c': 65.46907374261639, 'svc_gamma': 33.09367121886532}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:34,610]\u001b[0m Trial 26 finished with value: 0.5177865612648221 and parameters: {'svc_c': 54.582688212601674, 'svc_gamma': 24.706578201078667}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:35,237]\u001b[0m Trial 27 finished with value: 0.5177865612648221 and parameters: {'svc_c': 27.419741687383453, 'svc_gamma': 32.25365245961089}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:35,870]\u001b[0m Trial 28 finished with value: 0.5158102766798419 and parameters: {'svc_c': 11.533441479676572, 'svc_gamma': 47.45700501094412}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:36,467]\u001b[0m Trial 29 finished with value: 0.5158102766798419 and parameters: {'svc_c': 60.4365018450656, 'svc_gamma': 56.49488338892749}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:37,080]\u001b[0m Trial 30 finished with value: 0.5177865612648221 and parameters: {'svc_c': 15.420250296772725, 'svc_gamma': 39.542115899802326}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:37,705]\u001b[0m Trial 31 finished with value: 0.5177865612648221 and parameters: {'svc_c': 84.16628261484625, 'svc_gamma': 27.230559391629807}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:38,366]\u001b[0m Trial 32 finished with value: 0.5177865612648221 and parameters: {'svc_c': 69.29057296844749, 'svc_gamma': 20.199094563844454}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:38,958]\u001b[0m Trial 33 finished with value: 0.5177865612648221 and parameters: {'svc_c': 93.63579586961617, 'svc_gamma': 32.46852597975328}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:39,662]\u001b[0m Trial 34 finished with value: 0.5177865612648221 and parameters: {'svc_c': 81.168342591493, 'svc_gamma': 11.078204117569328}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:40,238]\u001b[0m Trial 35 finished with value: 0.5177865612648221 and parameters: {'svc_c': 72.649605454717, 'svc_gamma': 29.604716904171745}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:40,818]\u001b[0m Trial 36 finished with value: 0.5177865612648221 and parameters: {'svc_c': 86.1308266113879, 'svc_gamma': 25.988657902022535}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:41,382]\u001b[0m Trial 37 finished with value: 0.5158102766798419 and parameters: {'svc_c': 74.42505335149937, 'svc_gamma': 56.3553582533944}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:42,060]\u001b[0m Trial 38 finished with value: 0.5177865612648221 and parameters: {'svc_c': 90.76340774304016, 'svc_gamma': 18.517763983663865}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:42,702]\u001b[0m Trial 39 finished with value: 0.5177865612648221 and parameters: {'svc_c': 60.027405165024874, 'svc_gamma': 36.08585591915288}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:43,328]\u001b[0m Trial 40 finished with value: 0.5158102766798419 and parameters: {'svc_c': 82.35107448440961, 'svc_gamma': 44.380511127653186}. Best is trial 0 with value: 0.5177865612648221.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:43,968]\u001b[0m Trial 41 finished with value: 0.541501976284585 and parameters: {'svc_c': 40.0077579058865, 'svc_gamma': 0.4559815297481933}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:44,679]\u001b[0m Trial 42 finished with value: 0.5177865612648221 and parameters: {'svc_c': 24.710500946402913, 'svc_gamma': 6.99552573524626}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:45,400]\u001b[0m Trial 43 finished with value: 0.5177865612648221 and parameters: {'svc_c': 41.07846518938144, 'svc_gamma': 15.525916351343954}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:46,010]\u001b[0m Trial 44 finished with value: 0.5177865612648221 and parameters: {'svc_c': 70.31288751675747, 'svc_gamma': 0.8041748993406301}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:46,728]\u001b[0m Trial 45 finished with value: 0.5177865612648221 and parameters: {'svc_c': 49.54715824082356, 'svc_gamma': 7.77038606645511}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:47,280]\u001b[0m Trial 46 finished with value: 0.5177865612648221 and parameters: {'svc_c': 34.18956059340391, 'svc_gamma': 19.8778322838498}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:47,908]\u001b[0m Trial 47 finished with value: 0.5177865612648221 and parameters: {'svc_c': 65.23870664686687, 'svc_gamma': 14.835425211423034}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:48,476]\u001b[0m Trial 48 finished with value: 0.5177865612648221 and parameters: {'svc_c': 75.75657438288198, 'svc_gamma': 22.507819760506923}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:49,104]\u001b[0m Trial 49 finished with value: 0.5177865612648221 and parameters: {'svc_c': 86.39540122245106, 'svc_gamma': 12.977993084503687}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:49,669]\u001b[0m Trial 50 finished with value: 0.5177865612648221 and parameters: {'svc_c': 55.649106879939886, 'svc_gamma': 29.71047647083089}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:50,289]\u001b[0m Trial 51 finished with value: 0.5177865612648221 and parameters: {'svc_c': 43.74403917218219, 'svc_gamma': 3.680271092441975}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:50,953]\u001b[0m Trial 52 finished with value: 0.5177865612648221 and parameters: {'svc_c': 95.25043980170712, 'svc_gamma': 6.482270378635739}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:51,578]\u001b[0m Trial 53 finished with value: 0.5177865612648221 and parameters: {'svc_c': 87.5978761466698, 'svc_gamma': 3.374586730935164}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:52,102]\u001b[0m Trial 54 finished with value: 0.5197628458498024 and parameters: {'svc_c': 79.8238833811842, 'svc_gamma': 0.6882095574355136}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:52,751]\u001b[0m Trial 55 finished with value: 0.5177865612648221 and parameters: {'svc_c': 80.74910550366529, 'svc_gamma': 9.237035818337468}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:53,361]\u001b[0m Trial 56 finished with value: 0.5177865612648221 and parameters: {'svc_c': 77.27924807856665, 'svc_gamma': 13.885294039087034}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:53,932]\u001b[0m Trial 57 finished with value: 0.5177865612648221 and parameters: {'svc_c': 90.56617479069408, 'svc_gamma': 1.028271321312662}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:54,488]\u001b[0m Trial 58 finished with value: 0.5177865612648221 and parameters: {'svc_c': 72.14370723250099, 'svc_gamma': 21.65320712112557}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2023-05-14 11:58:55,018]\u001b[0m Trial 59 finished with value: 0.5158102766798419 and parameters: {'svc_c': 0.2241604782472706, 'svc_gamma': 16.82387118129886}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:55,661]\u001b[0m Trial 60 finished with value: 0.5177865612648221 and parameters: {'svc_c': 99.61197814730885, 'svc_gamma': 9.980635335718425}. Best is trial 41 with value: 0.541501976284585.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:56,192]\u001b[0m Trial 61 finished with value: 0.549407114624506 and parameters: {'svc_c': 67.34452739000359, 'svc_gamma': 0.3767760345092279}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:56,788]\u001b[0m Trial 62 finished with value: 0.5177865612648221 and parameters: {'svc_c': 67.91807574320663, 'svc_gamma': 2.134119354637569}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:57,470]\u001b[0m Trial 63 finished with value: 0.5177865612648221 and parameters: {'svc_c': 79.05984313027163, 'svc_gamma': 6.167742284621662}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:58,212]\u001b[0m Trial 64 finished with value: 0.5177865612648221 and parameters: {'svc_c': 63.32810578157674, 'svc_gamma': 5.313682615466945}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:58,911]\u001b[0m Trial 65 finished with value: 0.5177865612648221 and parameters: {'svc_c': 84.02604950784888, 'svc_gamma': 10.759901004671239}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:58:59,461]\u001b[0m Trial 66 finished with value: 0.5395256916996047 and parameters: {'svc_c': 57.45734990550913, 'svc_gamma': 0.4917907994260844}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:00,108]\u001b[0m Trial 67 finished with value: 0.5177865612648221 and parameters: {'svc_c': 67.09237317635507, 'svc_gamma': 3.4761602079549814}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:00,701]\u001b[0m Trial 68 finished with value: 0.5177865612648221 and parameters: {'svc_c': 54.25199886070488, 'svc_gamma': 0.8883587214380526}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:01,397]\u001b[0m Trial 69 finished with value: 0.5177865612648221 and parameters: {'svc_c': 58.46342898981147, 'svc_gamma': 8.134384269612127}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:02,036]\u001b[0m Trial 70 finished with value: 0.5177865612648221 and parameters: {'svc_c': 63.9384244034017, 'svc_gamma': 12.71448352263352}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:02,710]\u001b[0m Trial 71 finished with value: 0.5177865612648221 and parameters: {'svc_c': 74.41090304104212, 'svc_gamma': 4.392280322535236}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:03,296]\u001b[0m Trial 72 finished with value: 0.5177865612648221 and parameters: {'svc_c': 70.91322675793022, 'svc_gamma': 17.29549618679265}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:03,896]\u001b[0m Trial 73 finished with value: 0.5177865612648221 and parameters: {'svc_c': 57.54754674473161, 'svc_gamma': 24.693386183097967}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:04,453]\u001b[0m Trial 74 finished with value: 0.5177865612648221 and parameters: {'svc_c': 46.91424234826596, 'svc_gamma': 38.065188489516004}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:05,096]\u001b[0m Trial 75 finished with value: 0.5177865612648221 and parameters: {'svc_c': 62.116887888267, 'svc_gamma': 9.51289035137472}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:05,651]\u001b[0m Trial 76 finished with value: 0.5217391304347826 and parameters: {'svc_c': 69.0834459958098, 'svc_gamma': 0.6146482852752728}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:06,203]\u001b[0m Trial 77 finished with value: 0.5395256916996047 and parameters: {'svc_c': 67.65309020408299, 'svc_gamma': 0.4923471900873218}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:06,795]\u001b[0m Trial 78 finished with value: 0.5395256916996047 and parameters: {'svc_c': 67.93724587498527, 'svc_gamma': 0.4657738748022488}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:07,357]\u001b[0m Trial 79 finished with value: 0.5177865612648221 and parameters: {'svc_c': 68.23468194284818, 'svc_gamma': 0.8928780120547333}. Best is trial 61 with value: 0.549407114624506.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:07,905]\u001b[0m Trial 80 finished with value: 0.782608695652174 and parameters: {'svc_c': 65.86290153385131, 'svc_gamma': 0.11904978014531864}. Best is trial 80 with value: 0.782608695652174.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:08,551]\u001b[0m Trial 81 finished with value: 0.5177865612648221 and parameters: {'svc_c': 66.01501499572534, 'svc_gamma': 4.514291135448202}. Best is trial 80 with value: 0.782608695652174.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:09,073]\u001b[0m Trial 82 finished with value: 0.5177865612648221 and parameters: {'svc_c': 71.73489086964884, 'svc_gamma': 1.0286822527761732}. Best is trial 80 with value: 0.782608695652174.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:09,636]\u001b[0m Trial 83 finished with value: 0.5553359683794467 and parameters: {'svc_c': 60.43673293089242, 'svc_gamma': 0.35760934187154875}. Best is trial 80 with value: 0.782608695652174.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:10,172]\u001b[0m Trial 84 finished with value: 0.5513833992094862 and parameters: {'svc_c': 60.350428599391996, 'svc_gamma': 0.3750546089426725}. Best is trial 80 with value: 0.782608695652174.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:10,698]\u001b[0m Trial 85 finished with value: 0.8537549407114624 and parameters: {'svc_c': 61.61503292652254, 'svc_gamma': 0.06504249547943969}. Best is trial 85 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:11,368]\u001b[0m Trial 86 finished with value: 0.5177865612648221 and parameters: {'svc_c': 61.66460851310706, 'svc_gamma': 6.366137664385801}. Best is trial 85 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:12,028]\u001b[0m Trial 87 finished with value: 0.5177865612648221 and parameters: {'svc_c': 58.81707662626825, 'svc_gamma': 4.108345031080367}. Best is trial 85 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:12,689]\u001b[0m Trial 88 finished with value: 0.5177865612648221 and parameters: {'svc_c': 52.21580661780672, 'svc_gamma': 8.124753847543058}. Best is trial 85 with value: 0.8537549407114624.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:13,167]\u001b[0m Trial 89 finished with value: 0.857707509881423 and parameters: {'svc_c': 64.25208237539199, 'svc_gamma': 0.060529061603055156}. Best is trial 89 with value: 0.857707509881423.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:13,797]\u001b[0m Trial 90 finished with value: 0.5177865612648221 and parameters: {'svc_c': 60.41790344827232, 'svc_gamma': 3.3227577076389485}. Best is trial 89 with value: 0.857707509881423.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:14,451]\u001b[0m Trial 91 finished with value: 0.5177865612648221 and parameters: {'svc_c': 64.43941660574065, 'svc_gamma': 5.537332978180605}. Best is trial 89 with value: 0.857707509881423.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:15,044]\u001b[0m Trial 92 finished with value: 0.5177865612648221 and parameters: {'svc_c': 57.380402697177374, 'svc_gamma': 2.6312188727709955}. Best is trial 89 with value: 0.857707509881423.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:15,682]\u001b[0m Trial 93 finished with value: 0.5177865612648221 and parameters: {'svc_c': 61.67273429713002, 'svc_gamma': 7.492000218830354}. Best is trial 89 with value: 0.857707509881423.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:16,283]\u001b[0m Trial 94 finished with value: 0.5177865612648221 and parameters: {'svc_c': 64.87633401286764, 'svc_gamma': 3.1106568997932715}. Best is trial 89 with value: 0.857707509881423.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:16,962]\u001b[0m Trial 95 finished with value: 0.5177865612648221 and parameters: {'svc_c': 66.2773608096853, 'svc_gamma': 11.172693320337725}. Best is trial 89 with value: 0.857707509881423.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:17,495]\u001b[0m Trial 96 finished with value: 0.7687747035573123 and parameters: {'svc_c': 55.79377286071175, 'svc_gamma': 0.12960445791754843}. Best is trial 89 with value: 0.857707509881423.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:18,153]\u001b[0m Trial 97 finished with value: 0.5177865612648221 and parameters: {'svc_c': 56.601014102504614, 'svc_gamma': 5.482633144432434}. Best is trial 89 with value: 0.857707509881423.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:18,690]\u001b[0m Trial 98 finished with value: 0.7213438735177866 and parameters: {'svc_c': 53.333521804046036, 'svc_gamma': 0.15325989946300844}. Best is trial 89 with value: 0.857707509881423.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:19,332]\u001b[0m Trial 99 finished with value: 0.5177865612648221 and parameters: {'svc_c': 53.50872440634743, 'svc_gamma': 9.30280088803868}. Best is trial 89 with value: 0.857707509881423.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:19,343]\u001b[0m A new study created in memory with name: no-name-13591680-6693-4878-9fcd-baecec84049d\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        feature_type               model with_hypertuning   \n",
      "index   selected_features_all_best20  LogisticRegression            False  \\\n",
      "index   selected_features_all_best20                 SVC            False   \n",
      "index   selected_features_all_best20       XGBClassifier            False   \n",
      "index   selected_features_all_best20      LGBMClassifier            False   \n",
      "index   selected_features_all_best20  LogisticRegression             True   \n",
      "index   selected_features_all_best20                 SVC             True   \n",
      "index   selected_features_all_best20       XGBClassifier             True   \n",
      "index   selected_features_all_best20      LGBMClassifier             True   \n",
      "index   selected_features_all_best30  LogisticRegression            False   \n",
      "index   selected_features_all_best30                 SVC            False   \n",
      "index   selected_features_all_best30       XGBClassifier            False   \n",
      "index   selected_features_all_best30      LGBMClassifier            False   \n",
      "index   selected_features_all_best30  LogisticRegression             True   \n",
      "index   selected_features_all_best30                 SVC             True   \n",
      "index   selected_features_all_best30       XGBClassifier             True   \n",
      "index   selected_features_all_best30      LGBMClassifier             True   \n",
      "index   selected_features_all_best50  LogisticRegression            False   \n",
      "index   selected_features_all_best50                 SVC            False   \n",
      "index   selected_features_all_best50       XGBClassifier            False   \n",
      "index   selected_features_all_best50      LGBMClassifier            False   \n",
      "index   selected_features_all_best50  LogisticRegression             True   \n",
      "index   selected_features_all_best50                 SVC             True   \n",
      "index   selected_features_all_best50       XGBClassifier             True   \n",
      "index   selected_features_all_best50      LGBMClassifier             True   \n",
      "index  selected_features_all_best100  LogisticRegression            False   \n",
      "index  selected_features_all_best100                 SVC            False   \n",
      "index  selected_features_all_best100       XGBClassifier            False   \n",
      "index  selected_features_all_best100      LGBMClassifier            False   \n",
      "index  selected_features_all_best100  LogisticRegression             True   \n",
      "index  selected_features_all_best100                 SVC             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.888807   \n",
      "index  {'C': 0.024422805336610946, 'penalty': 'l1', '...  0.889328   \n",
      "index  {'svc_c': 14.99270459807389, 'svc_gamma': 0.07...  0.873518   \n",
      "index  {'learning_rate': 0.049433721318135074, 'max_d...  0.893281   \n",
      "index  {'num_leaves': 77, 'max_depth': 41, 'learning_...  0.895257   \n",
      "index                                               None  0.901161   \n",
      "index                                               None  0.898695   \n",
      "index                                               None  0.889304   \n",
      "index                                               None  0.892762   \n",
      "index  {'C': 0.09995242748229684, 'penalty': 'l2', 's...  0.897233   \n",
      "index  {'svc_c': 64.25208237539199, 'svc_gamma': 0.06...  0.857708   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "index     0.844898     0.923372   0.911894  0.877119  0.771973   \n",
      "index     0.840816     0.923372   0.911504  0.874735  0.768193   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.804082     0.938697   0.924883  0.860262  0.751864   \n",
      "index     0.844898     0.938697   0.928251  0.884615  0.788768   \n",
      "index     0.848980     0.938697   0.928571  0.886994  0.792507   \n",
      "index     0.869388     0.923372   0.914163  0.891213  0.794850   \n",
      "index     0.853061     0.934866   0.924779  0.887473  0.792056   \n",
      "index     0.848980     0.931034   0.920354  0.883227  0.784102   \n",
      "index     0.844898     0.927203   0.915929  0.878981  0.776147   \n",
      "index     0.869388     0.923372   0.914163  0.891213  0.794850   \n",
      "index     0.746939     0.961686   0.948187  0.835616  0.729069   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_no_...  \n",
      "index  selected_features_all_best50_LGBMClassifier_no...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index  selected_features_all_best50_SVC_with_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_wit...  \n",
      "index  selected_features_all_best50_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best100_LogisticRegressi...  \n",
      "index   selected_features_all_best100_SVC_no_hypertuning  \n",
      "index  selected_features_all_best100_XGBClassifier_no...  \n",
      "index  selected_features_all_best100_LGBMClassifier_n...  \n",
      "index  selected_features_all_best100_LogisticRegressi...  \n",
      "index  selected_features_all_best100_SVC_with_hypertu...  \n",
      "Optimizing selected_features_all_best100 XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 11:59:21,611]\u001b[0m Trial 0 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.21246312417174512, 'max_depth': 2, 'n_estimators': 616}. Best is trial 0 with value: 0.8893280632411067.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:25,717]\u001b[0m Trial 1 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.05172888818693755, 'max_depth': 5, 'n_estimators': 403}. Best is trial 1 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:30,699]\u001b[0m Trial 2 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.05498622277393403, 'max_depth': 4, 'n_estimators': 496}. Best is trial 1 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:33,145]\u001b[0m Trial 3 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.2611868850156039, 'max_depth': 4, 'n_estimators': 354}. Best is trial 1 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:38,608]\u001b[0m Trial 4 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.1243897891289126, 'max_depth': 4, 'n_estimators': 966}. Best is trial 1 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:46,368]\u001b[0m Trial 5 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.03667566766486474, 'max_depth': 5, 'n_estimators': 979}. Best is trial 1 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:48,653]\u001b[0m Trial 6 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.28880765451505963, 'max_depth': 2, 'n_estimators': 573}. Best is trial 1 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:53,228]\u001b[0m Trial 7 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.032429486033561855, 'max_depth': 5, 'n_estimators': 422}. Best is trial 1 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 11:59:56,499]\u001b[0m Trial 8 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.2821243953020519, 'max_depth': 5, 'n_estimators': 347}. Best is trial 1 with value: 0.8972332015810277.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:00:02,190]\u001b[0m Trial 9 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.2920560087238877, 'max_depth': 6, 'n_estimators': 768}. Best is trial 9 with value: 0.8992094861660079.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:00:11,263]\u001b[0m Trial 10 finished with value: 0.9011857707509882 and parameters: {'learning_rate': 0.2127264711148268, 'max_depth': 6, 'n_estimators': 764}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:00:21,840]\u001b[0m Trial 11 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.23358501763865008, 'max_depth': 6, 'n_estimators': 760}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:00:27,071]\u001b[0m Trial 12 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.19452557147907185, 'max_depth': 6, 'n_estimators': 752}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:00:32,233]\u001b[0m Trial 13 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.237601434553587, 'max_depth': 6, 'n_estimators': 790}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:00:33,202]\u001b[0m Trial 14 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.29588493745030875, 'max_depth': 3, 'n_estimators': 149}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:00:39,888]\u001b[0m Trial 15 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.17393674473697301, 'max_depth': 6, 'n_estimators': 855}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:00:44,926]\u001b[0m Trial 16 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.25428495693129033, 'max_depth': 6, 'n_estimators': 672}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:00:49,679]\u001b[0m Trial 17 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.13932695065337997, 'max_depth': 3, 'n_estimators': 844}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:00:55,463]\u001b[0m Trial 18 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.21539106043897027, 'max_depth': 5, 'n_estimators': 672}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:01:01,305]\u001b[0m Trial 19 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.2720752302317462, 'max_depth': 6, 'n_estimators': 895}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:01:04,970]\u001b[0m Trial 20 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.25099685066440114, 'max_depth': 3, 'n_estimators': 222}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:01:11,719]\u001b[0m Trial 21 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.16801418941330376, 'max_depth': 6, 'n_estimators': 874}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:01:16,855]\u001b[0m Trial 22 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.185704326710073, 'max_depth': 6, 'n_estimators': 716}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:01:21,816]\u001b[0m Trial 23 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.1606775469160277, 'max_depth': 5, 'n_estimators': 810}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:01:27,117]\u001b[0m Trial 24 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.22645179964734047, 'max_depth': 6, 'n_estimators': 900}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:01:31,129]\u001b[0m Trial 25 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.20109625361938918, 'max_depth': 5, 'n_estimators': 645}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:01:35,725]\u001b[0m Trial 26 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.27000335724073726, 'max_depth': 6, 'n_estimators': 528}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:01:40,412]\u001b[0m Trial 27 finished with value: 0.9051383399209486 and parameters: {'learning_rate': 0.29754822620365323, 'max_depth': 4, 'n_estimators': 926}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:01:45,359]\u001b[0m Trial 28 finished with value: 0.8814229249011858 and parameters: {'learning_rate': 0.28314310488681954, 'max_depth': 4, 'n_estimators': 1000}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:01:49,970]\u001b[0m Trial 29 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.2951848350145878, 'max_depth': 4, 'n_estimators': 912}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:01:52,524]\u001b[0m Trial 30 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.2985193482664913, 'max_depth': 2, 'n_estimators': 595}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:01:56,854]\u001b[0m Trial 31 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.24756977382343415, 'max_depth': 5, 'n_estimators': 820}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:02:00,624]\u001b[0m Trial 32 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.22560172116797947, 'max_depth': 3, 'n_estimators': 718}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:02:06,024]\u001b[0m Trial 33 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.26747054155262945, 'max_depth': 5, 'n_estimators': 947}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:02:10,904]\u001b[0m Trial 34 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.21176683564733245, 'max_depth': 4, 'n_estimators': 839}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:02:14,845]\u001b[0m Trial 35 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.24606750733735794, 'max_depth': 6, 'n_estimators': 720}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:02:20,047]\u001b[0m Trial 36 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.1772349247013713, 'max_depth': 4, 'n_estimators': 939}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:02:26,586]\u001b[0m Trial 37 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.26328345096574696, 'max_depth': 5, 'n_estimators': 856}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:02:32,173]\u001b[0m Trial 38 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.11105999803649838, 'max_depth': 6, 'n_estimators': 780}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:02:34,941]\u001b[0m Trial 39 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.2760313969090726, 'max_depth': 5, 'n_estimators': 466}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:02:39,351]\u001b[0m Trial 40 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.20757327783901858, 'max_depth': 4, 'n_estimators': 632}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:02:45,081]\u001b[0m Trial 41 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.2811216896533811, 'max_depth': 6, 'n_estimators': 903}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:02:52,796]\u001b[0m Trial 42 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.27118623407852, 'max_depth': 6, 'n_estimators': 954}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:02:58,376]\u001b[0m Trial 43 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.2567371035571457, 'max_depth': 6, 'n_estimators': 871}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:03:02,779]\u001b[0m Trial 44 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.29983822198222354, 'max_depth': 6, 'n_estimators': 769}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:03:10,160]\u001b[0m Trial 45 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.28215829028683154, 'max_depth': 5, 'n_estimators': 1000}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:03:16,379]\u001b[0m Trial 46 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.285667121330633, 'max_depth': 6, 'n_estimators': 907}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:03:21,713]\u001b[0m Trial 47 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.26115019548506374, 'max_depth': 6, 'n_estimators': 815}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:03:26,440]\u001b[0m Trial 48 finished with value: 0.9031620553359684 and parameters: {'learning_rate': 0.22947498993670024, 'max_depth': 6, 'n_estimators': 748}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:03:31,180]\u001b[0m Trial 49 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.19131072271684396, 'max_depth': 5, 'n_estimators': 682}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:03:34,784]\u001b[0m Trial 50 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.23769632288672438, 'max_depth': 3, 'n_estimators': 753}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:03:39,964]\u001b[0m Trial 51 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.22213779845793782, 'max_depth': 6, 'n_estimators': 799}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:03:44,625]\u001b[0m Trial 52 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.23606785411789183, 'max_depth': 6, 'n_estimators': 735}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:03:50,169]\u001b[0m Trial 53 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.27531180485021267, 'max_depth': 6, 'n_estimators': 859}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:03:55,310]\u001b[0m Trial 54 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.2898701633868209, 'max_depth': 6, 'n_estimators': 931}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:00,068]\u001b[0m Trial 55 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.2463879946267618, 'max_depth': 6, 'n_estimators': 687}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:05,462]\u001b[0m Trial 56 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.20170310708388497, 'max_depth': 6, 'n_estimators': 883}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:07,422]\u001b[0m Trial 57 finished with value: 0.9011857707509882 and parameters: {'learning_rate': 0.21609636760199058, 'max_depth': 5, 'n_estimators': 314}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:10,244]\u001b[0m Trial 58 finished with value: 0.8853754940711462 and parameters: {'learning_rate': 0.18728006541178452, 'max_depth': 5, 'n_estimators': 319}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:13,285]\u001b[0m Trial 59 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.22039410401956758, 'max_depth': 5, 'n_estimators': 560}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:14,344]\u001b[0m Trial 60 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.2135920624676218, 'max_depth': 4, 'n_estimators': 131}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:16,323]\u001b[0m Trial 61 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.26155589040271077, 'max_depth': 6, 'n_estimators': 262}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:18,947]\u001b[0m Trial 62 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.22958743193933065, 'max_depth': 6, 'n_estimators': 416}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:20,198]\u001b[0m Trial 63 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.20163001162972724, 'max_depth': 6, 'n_estimators': 181}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:23,544]\u001b[0m Trial 64 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.28989120471385865, 'max_depth': 4, 'n_estimators': 831}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:28,304]\u001b[0m Trial 65 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.24026042321437613, 'max_depth': 6, 'n_estimators': 968}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:31,387]\u001b[0m Trial 66 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.23032957569567228, 'max_depth': 5, 'n_estimators': 607}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:34,019]\u001b[0m Trial 67 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.2520718667433394, 'max_depth': 6, 'n_estimators': 518}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:36,761]\u001b[0m Trial 68 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.27206514022852896, 'max_depth': 5, 'n_estimators': 461}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:40,802]\u001b[0m Trial 69 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.25596544577256874, 'max_depth': 6, 'n_estimators': 782}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:43,167]\u001b[0m Trial 70 finished with value: 0.8794466403162056 and parameters: {'learning_rate': 0.17376661131001642, 'max_depth': 4, 'n_estimators': 357}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:46,560]\u001b[0m Trial 71 finished with value: 0.9011857707509882 and parameters: {'learning_rate': 0.18432265152881894, 'max_depth': 6, 'n_estimators': 694}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:50,743]\u001b[0m Trial 72 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.195901637423439, 'max_depth': 6, 'n_estimators': 699}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:54,351]\u001b[0m Trial 73 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.18343393539659553, 'max_depth': 6, 'n_estimators': 755}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:04:58,555]\u001b[0m Trial 74 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.21129302999224214, 'max_depth': 6, 'n_estimators': 636}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:05:03,143]\u001b[0m Trial 75 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.22006102104221675, 'max_depth': 6, 'n_estimators': 801}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:05:08,056]\u001b[0m Trial 76 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.29306509049472, 'max_depth': 6, 'n_estimators': 736}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:05:13,231]\u001b[0m Trial 77 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.2998113448556124, 'max_depth': 5, 'n_estimators': 843}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:05:18,295]\u001b[0m Trial 78 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.1686072112727568, 'max_depth': 6, 'n_estimators': 878}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:05:21,185]\u001b[0m Trial 79 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.15500441384246894, 'max_depth': 2, 'n_estimators': 659}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:05:25,976]\u001b[0m Trial 80 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.26820882442378985, 'max_depth': 5, 'n_estimators': 925}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:05:29,619]\u001b[0m Trial 81 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.2060601589089161, 'max_depth': 6, 'n_estimators': 715}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:05:34,227]\u001b[0m Trial 82 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.18053848928117078, 'max_depth': 6, 'n_estimators': 783}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:05:39,285]\u001b[0m Trial 83 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.19151591932934708, 'max_depth': 6, 'n_estimators': 814}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:05:43,066]\u001b[0m Trial 84 finished with value: 0.8893280632411067 and parameters: {'learning_rate': 0.19828926128191002, 'max_depth': 6, 'n_estimators': 586}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:05:47,430]\u001b[0m Trial 85 finished with value: 0.8992094861660079 and parameters: {'learning_rate': 0.1858645241158682, 'max_depth': 6, 'n_estimators': 733}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:05:50,176]\u001b[0m Trial 86 finished with value: 0.8873517786561265 and parameters: {'learning_rate': 0.2820310915229983, 'max_depth': 3, 'n_estimators': 664}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:05:54,904]\u001b[0m Trial 87 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.21792641521758266, 'max_depth': 6, 'n_estimators': 709}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:05:58,838]\u001b[0m Trial 88 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.2076964324290555, 'max_depth': 4, 'n_estimators': 888}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:02,960]\u001b[0m Trial 89 finished with value: 0.9011857707509882 and parameters: {'learning_rate': 0.27726762368150704, 'max_depth': 6, 'n_estimators': 852}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:07,053]\u001b[0m Trial 90 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.276199601005673, 'max_depth': 6, 'n_estimators': 850}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:10,075]\u001b[0m Trial 91 finished with value: 0.8913043478260869 and parameters: {'learning_rate': 0.28971903001550187, 'max_depth': 6, 'n_estimators': 771}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:14,310]\u001b[0m Trial 92 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.2641429984166648, 'max_depth': 6, 'n_estimators': 826}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:19,385]\u001b[0m Trial 93 finished with value: 0.8972332015810277 and parameters: {'learning_rate': 0.24255571742605672, 'max_depth': 6, 'n_estimators': 912}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:25,090]\u001b[0m Trial 94 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.2275934718489548, 'max_depth': 6, 'n_estimators': 979}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:30,002]\u001b[0m Trial 95 finished with value: 0.8952569169960475 and parameters: {'learning_rate': 0.28349030806618775, 'max_depth': 6, 'n_estimators': 957}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:34,156]\u001b[0m Trial 96 finished with value: 0.883399209486166 and parameters: {'learning_rate': 0.29265708832082366, 'max_depth': 6, 'n_estimators': 759}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:38,620]\u001b[0m Trial 97 finished with value: 0.9011857707509882 and parameters: {'learning_rate': 0.27729980817900696, 'max_depth': 6, 'n_estimators': 864}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:42,961]\u001b[0m Trial 98 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.27510506699826426, 'max_depth': 6, 'n_estimators': 869}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:47,011]\u001b[0m Trial 99 finished with value: 0.8932806324110671 and parameters: {'learning_rate': 0.2564774984174971, 'max_depth': 4, 'n_estimators': 894}. Best is trial 27 with value: 0.9051383399209486.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:47,037]\u001b[0m A new study created in memory with name: no-name-a6efb0b9-d5e1-4c8e-ab73-41f8a2926f70\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        feature_type               model with_hypertuning   \n",
      "index   selected_features_all_best20  LogisticRegression            False  \\\n",
      "index   selected_features_all_best20                 SVC            False   \n",
      "index   selected_features_all_best20       XGBClassifier            False   \n",
      "index   selected_features_all_best20      LGBMClassifier            False   \n",
      "index   selected_features_all_best20  LogisticRegression             True   \n",
      "index   selected_features_all_best20                 SVC             True   \n",
      "index   selected_features_all_best20       XGBClassifier             True   \n",
      "index   selected_features_all_best20      LGBMClassifier             True   \n",
      "index   selected_features_all_best30  LogisticRegression            False   \n",
      "index   selected_features_all_best30                 SVC            False   \n",
      "index   selected_features_all_best30       XGBClassifier            False   \n",
      "index   selected_features_all_best30      LGBMClassifier            False   \n",
      "index   selected_features_all_best30  LogisticRegression             True   \n",
      "index   selected_features_all_best30                 SVC             True   \n",
      "index   selected_features_all_best30       XGBClassifier             True   \n",
      "index   selected_features_all_best30      LGBMClassifier             True   \n",
      "index   selected_features_all_best50  LogisticRegression            False   \n",
      "index   selected_features_all_best50                 SVC            False   \n",
      "index   selected_features_all_best50       XGBClassifier            False   \n",
      "index   selected_features_all_best50      LGBMClassifier            False   \n",
      "index   selected_features_all_best50  LogisticRegression             True   \n",
      "index   selected_features_all_best50                 SVC             True   \n",
      "index   selected_features_all_best50       XGBClassifier             True   \n",
      "index   selected_features_all_best50      LGBMClassifier             True   \n",
      "index  selected_features_all_best100  LogisticRegression            False   \n",
      "index  selected_features_all_best100                 SVC            False   \n",
      "index  selected_features_all_best100       XGBClassifier            False   \n",
      "index  selected_features_all_best100      LGBMClassifier            False   \n",
      "index  selected_features_all_best100  LogisticRegression             True   \n",
      "index  selected_features_all_best100                 SVC             True   \n",
      "index  selected_features_all_best100       XGBClassifier             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.888807   \n",
      "index  {'C': 0.024422805336610946, 'penalty': 'l1', '...  0.889328   \n",
      "index  {'svc_c': 14.99270459807389, 'svc_gamma': 0.07...  0.873518   \n",
      "index  {'learning_rate': 0.049433721318135074, 'max_d...  0.893281   \n",
      "index  {'num_leaves': 77, 'max_depth': 41, 'learning_...  0.895257   \n",
      "index                                               None  0.901161   \n",
      "index                                               None  0.898695   \n",
      "index                                               None  0.889304   \n",
      "index                                               None  0.892762   \n",
      "index  {'C': 0.09995242748229684, 'penalty': 'l2', 's...  0.897233   \n",
      "index  {'svc_c': 64.25208237539199, 'svc_gamma': 0.06...  0.857708   \n",
      "index  {'learning_rate': 0.29754822620365323, 'max_de...  0.905138   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "index     0.844898     0.923372   0.911894  0.877119  0.771973   \n",
      "index     0.840816     0.923372   0.911504  0.874735  0.768193   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.804082     0.938697   0.924883  0.860262  0.751864   \n",
      "index     0.844898     0.938697   0.928251  0.884615  0.788768   \n",
      "index     0.848980     0.938697   0.928571  0.886994  0.792507   \n",
      "index     0.869388     0.923372   0.914163  0.891213  0.794850   \n",
      "index     0.853061     0.934866   0.924779  0.887473  0.792056   \n",
      "index     0.848980     0.931034   0.920354  0.883227  0.784102   \n",
      "index     0.844898     0.927203   0.915929  0.878981  0.776147   \n",
      "index     0.869388     0.923372   0.914163  0.891213  0.794850   \n",
      "index     0.746939     0.961686   0.948187  0.835616  0.729069   \n",
      "index     0.861224     0.946360   0.937778  0.897872  0.812170   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_no_...  \n",
      "index  selected_features_all_best50_LGBMClassifier_no...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index  selected_features_all_best50_SVC_with_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_wit...  \n",
      "index  selected_features_all_best50_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best100_LogisticRegressi...  \n",
      "index   selected_features_all_best100_SVC_no_hypertuning  \n",
      "index  selected_features_all_best100_XGBClassifier_no...  \n",
      "index  selected_features_all_best100_LGBMClassifier_n...  \n",
      "index  selected_features_all_best100_LogisticRegressi...  \n",
      "index  selected_features_all_best100_SVC_with_hypertu...  \n",
      "index  selected_features_all_best100_XGBClassifier_wi...  \n",
      "Optimizing selected_features_all_best100 LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-14 12:06:48,046]\u001b[0m Trial 0 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 98, 'max_depth': 22, 'learning_rate': 0.26204601918854353, 'n_estimators': 444}. Best is trial 0 with value: 0.8873517786561265.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:49,925]\u001b[0m Trial 1 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 37, 'max_depth': 32, 'learning_rate': 0.0747843128262703, 'n_estimators': 364}. Best is trial 1 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:53,805]\u001b[0m Trial 2 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 177, 'max_depth': 32, 'learning_rate': 0.14651735429553095, 'n_estimators': 1942}. Best is trial 1 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:56,951]\u001b[0m Trial 3 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 120, 'max_depth': 8, 'learning_rate': 0.09491243639916087, 'n_estimators': 1849}. Best is trial 1 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:06:59,431]\u001b[0m Trial 4 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 127, 'max_depth': 37, 'learning_rate': 0.22604242726241228, 'n_estimators': 550}. Best is trial 1 with value: 0.8913043478260869.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:07:21,585]\u001b[0m Trial 5 finished with value: 0.8992094861660079 and parameters: {'num_leaves': 184, 'max_depth': 20, 'learning_rate': 0.006351363152992852, 'n_estimators': 1858}. Best is trial 5 with value: 0.8992094861660079.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:07:33,496]\u001b[0m Trial 6 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 151, 'max_depth': 33, 'learning_rate': 0.016760276542685127, 'n_estimators': 1254}. Best is trial 5 with value: 0.8992094861660079.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:07:36,627]\u001b[0m Trial 7 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 90, 'max_depth': 20, 'learning_rate': 0.0881056672701243, 'n_estimators': 1142}. Best is trial 5 with value: 0.8992094861660079.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:07:38,818]\u001b[0m Trial 8 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 233, 'max_depth': 49, 'learning_rate': 0.27003796452459133, 'n_estimators': 917}. Best is trial 5 with value: 0.8992094861660079.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:07:41,167]\u001b[0m Trial 9 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 58, 'max_depth': 23, 'learning_rate': 0.23814815913655465, 'n_estimators': 567}. Best is trial 5 with value: 0.8992094861660079.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:07:45,103]\u001b[0m Trial 10 finished with value: 0.9011857707509882 and parameters: {'num_leaves': 245, 'max_depth': 5, 'learning_rate': 0.007001654229489285, 'n_estimators': 1599}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:07:47,247]\u001b[0m Trial 11 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 253, 'max_depth': 4, 'learning_rate': 0.003570759959457393, 'n_estimators': 1546}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:07:54,437]\u001b[0m Trial 12 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 189, 'max_depth': 10, 'learning_rate': 0.038302197011485455, 'n_estimators': 1474}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:08:11,289]\u001b[0m Trial 13 finished with value: 0.8794466403162056 and parameters: {'num_leaves': 214, 'max_depth': 14, 'learning_rate': 0.0015362734029856617, 'n_estimators': 1659}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:08:16,599]\u001b[0m Trial 14 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 202, 'max_depth': 15, 'learning_rate': 0.05882176642099174, 'n_estimators': 1751}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:08:17,311]\u001b[0m Trial 15 finished with value: 0.8814229249011858 and parameters: {'num_leaves': 255, 'max_depth': 2, 'learning_rate': 0.04258102289310523, 'n_estimators': 1303}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:08:19,868]\u001b[0m Trial 16 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 161, 'max_depth': 16, 'learning_rate': 0.11208337790521736, 'n_estimators': 880}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:08:26,164]\u001b[0m Trial 17 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 222, 'max_depth': 41, 'learning_rate': 0.04252132567278376, 'n_estimators': 1986}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:08:27,868]\u001b[0m Trial 18 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 4, 'max_depth': 28, 'learning_rate': 0.13068091170039026, 'n_estimators': 1435}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:08:31,335]\u001b[0m Trial 19 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 169, 'max_depth': 8, 'learning_rate': 0.18038715373383296, 'n_estimators': 1676}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:08:34,486]\u001b[0m Trial 20 finished with value: 0.8992094861660079 and parameters: {'num_leaves': 198, 'max_depth': 26, 'learning_rate': 0.060759157177552404, 'n_estimators': 998}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:08:42,540]\u001b[0m Trial 21 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 234, 'max_depth': 26, 'learning_rate': 0.022526386598914386, 'n_estimators': 856}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:08:47,264]\u001b[0m Trial 22 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 203, 'max_depth': 17, 'learning_rate': 0.04377397504878746, 'n_estimators': 1126}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:08:49,205]\u001b[0m Trial 23 finished with value: 0.8992094861660079 and parameters: {'num_leaves': 143, 'max_depth': 27, 'learning_rate': 0.0683948586870417, 'n_estimators': 149}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:08:56,803]\u001b[0m Trial 24 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 185, 'max_depth': 12, 'learning_rate': 0.021397167219452992, 'n_estimators': 1330}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:09:06,437]\u001b[0m Trial 25 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 234, 'max_depth': 41, 'learning_rate': 0.004053217452077262, 'n_estimators': 774}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:09:10,959]\u001b[0m Trial 26 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 195, 'max_depth': 19, 'learning_rate': 0.06902781181039985, 'n_estimators': 1016}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:09:14,464]\u001b[0m Trial 27 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 215, 'max_depth': 5, 'learning_rate': 0.028019472913287317, 'n_estimators': 1822}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:09:22,181]\u001b[0m Trial 28 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 245, 'max_depth': 23, 'learning_rate': 0.050803735009379555, 'n_estimators': 1561}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:09:30,032]\u001b[0m Trial 29 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 108, 'max_depth': 24, 'learning_rate': 0.025584686437228523, 'n_estimators': 688}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:09:34,701]\u001b[0m Trial 30 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 155, 'max_depth': 29, 'learning_rate': 0.0906919070544431, 'n_estimators': 1012}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:09:37,689]\u001b[0m Trial 31 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 147, 'max_depth': 29, 'learning_rate': 0.06303956754824809, 'n_estimators': 143}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:09:40,393]\u001b[0m Trial 32 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 139, 'max_depth': 34, 'learning_rate': 0.07555075326348526, 'n_estimators': 249}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:09:43,883]\u001b[0m Trial 33 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 207, 'max_depth': 20, 'learning_rate': 0.060980942462882964, 'n_estimators': 463}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:09:53,054]\u001b[0m Trial 34 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 173, 'max_depth': 26, 'learning_rate': 0.029332067696794334, 'n_estimators': 1854}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:09:57,326]\u001b[0m Trial 35 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 81, 'max_depth': 38, 'learning_rate': 0.08150916689831518, 'n_estimators': 335}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:10:02,416]\u001b[0m Trial 36 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 131, 'max_depth': 30, 'learning_rate': 0.10617152623330653, 'n_estimators': 1674}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:10:08,811]\u001b[0m Trial 37 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 168, 'max_depth': 34, 'learning_rate': 0.05298431800198406, 'n_estimators': 1886}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:10:09,603]\u001b[0m Trial 38 finished with value: 0.8656126482213439 and parameters: {'num_leaves': 118, 'max_depth': 26, 'learning_rate': 0.010546019916580697, 'n_estimators': 108}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:10:20,044]\u001b[0m Trial 39 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 226, 'max_depth': 50, 'learning_rate': 0.01865268591263491, 'n_estimators': 1199}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:10:23,722]\u001b[0m Trial 40 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 181, 'max_depth': 21, 'learning_rate': 0.07767908779600538, 'n_estimators': 1748}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:10:31,382]\u001b[0m Trial 41 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 187, 'max_depth': 9, 'learning_rate': 0.0345219887442935, 'n_estimators': 1403}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:10:37,227]\u001b[0m Trial 42 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 194, 'max_depth': 13, 'learning_rate': 0.037295007038998455, 'n_estimators': 1458}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:10:46,377]\u001b[0m Trial 43 finished with value: 0.8695652173913043 and parameters: {'num_leaves': 140, 'max_depth': 11, 'learning_rate': 0.0012458664754841572, 'n_estimators': 1540}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:10:49,999]\u001b[0m Trial 44 finished with value: 0.8992094861660079 and parameters: {'num_leaves': 240, 'max_depth': 6, 'learning_rate': 0.05185163935188631, 'n_estimators': 1585}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:10:53,042]\u001b[0m Trial 45 finished with value: 0.8992094861660079 and parameters: {'num_leaves': 245, 'max_depth': 6, 'learning_rate': 0.05562655138659355, 'n_estimators': 1920}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:10:53,713]\u001b[0m Trial 46 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 238, 'max_depth': 2, 'learning_rate': 0.06796150558721119, 'n_estimators': 1599}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:11:05,575]\u001b[0m Trial 47 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 218, 'max_depth': 18, 'learning_rate': 0.015306319865607456, 'n_estimators': 1760}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:11:07,645]\u001b[0m Trial 48 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 255, 'max_depth': 7, 'learning_rate': 0.09580196953839765, 'n_estimators': 598}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:11:15,904]\u001b[0m Trial 49 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 208, 'max_depth': 31, 'learning_rate': 0.047621881547766955, 'n_estimators': 1986}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:11:27,241]\u001b[0m Trial 50 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 158, 'max_depth': 15, 'learning_rate': 0.013892926823980077, 'n_estimators': 1280}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:11:29,873]\u001b[0m Trial 51 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 247, 'max_depth': 5, 'learning_rate': 0.054581154288590485, 'n_estimators': 1911}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:11:33,937]\u001b[0m Trial 52 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 227, 'max_depth': 7, 'learning_rate': 0.03600751854579849, 'n_estimators': 1747}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:11:35,020]\u001b[0m Trial 53 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 241, 'max_depth': 3, 'learning_rate': 0.06172157723410361, 'n_estimators': 1618}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:11:38,591]\u001b[0m Trial 54 finished with value: 0.9011857707509882 and parameters: {'num_leaves': 227, 'max_depth': 6, 'learning_rate': 0.047443865000724665, 'n_estimators': 1796}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:11:44,951]\u001b[0m Trial 55 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 221, 'max_depth': 11, 'learning_rate': 0.031187419233294187, 'n_estimators': 1808}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:11:49,736]\u001b[0m Trial 56 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 196, 'max_depth': 24, 'learning_rate': 0.045201362481111396, 'n_estimators': 1403}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:11:58,865]\u001b[0m Trial 57 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 211, 'max_depth': 45, 'learning_rate': 0.019224175061048423, 'n_estimators': 1658}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:02,704]\u001b[0m Trial 58 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 230, 'max_depth': 27, 'learning_rate': 0.07167093990087557, 'n_estimators': 1497}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:07,983]\u001b[0m Trial 59 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 72, 'max_depth': 9, 'learning_rate': 0.005459453368791896, 'n_estimators': 948}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:09,310]\u001b[0m Trial 60 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 200, 'max_depth': 4, 'learning_rate': 0.04318711429488622, 'n_estimators': 1142}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:12,902]\u001b[0m Trial 61 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 248, 'max_depth': 7, 'learning_rate': 0.05180000849634319, 'n_estimators': 1969}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:17,297]\u001b[0m Trial 62 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 256, 'max_depth': 5, 'learning_rate': 0.026162811094831755, 'n_estimators': 1917}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:20,643]\u001b[0m Trial 63 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 236, 'max_depth': 6, 'learning_rate': 0.08398731565999437, 'n_estimators': 1716}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:21,471]\u001b[0m Trial 64 finished with value: 0.8873517786561265 and parameters: {'num_leaves': 245, 'max_depth': 2, 'learning_rate': 0.059902281256237824, 'n_estimators': 1804}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:29,045]\u001b[0m Trial 65 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 221, 'max_depth': 10, 'learning_rate': 0.03955271301565398, 'n_estimators': 1879}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:31,735]\u001b[0m Trial 66 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 42, 'max_depth': 13, 'learning_rate': 0.07068998335975751, 'n_estimators': 1344}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:43,068]\u001b[0m Trial 67 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 213, 'max_depth': 32, 'learning_rate': 0.016164244274019496, 'n_estimators': 1606}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:47,949]\u001b[0m Trial 68 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 176, 'max_depth': 17, 'learning_rate': 0.027869992277633544, 'n_estimators': 796}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:50,225]\u001b[0m Trial 69 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 99, 'max_depth': 4, 'learning_rate': 0.010131476698485284, 'n_estimators': 1816}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:51,846]\u001b[0m Trial 70 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 229, 'max_depth': 24, 'learning_rate': 0.05292414720522236, 'n_estimators': 207}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:55,650]\u001b[0m Trial 71 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 186, 'max_depth': 9, 'learning_rate': 0.039047870788613645, 'n_estimators': 1529}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:12:58,641]\u001b[0m Trial 72 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 240, 'max_depth': 6, 'learning_rate': 0.023571042614938732, 'n_estimators': 1210}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:00,321]\u001b[0m Trial 73 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 192, 'max_depth': 8, 'learning_rate': 0.06390378106493454, 'n_estimators': 440}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:05,572]\u001b[0m Trial 74 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 168, 'max_depth': 21, 'learning_rate': 0.034392718861310054, 'n_estimators': 1715}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:08,335]\u001b[0m Trial 75 finished with value: 0.8992094861660079 and parameters: {'num_leaves': 205, 'max_depth': 11, 'learning_rate': 0.07647497467503861, 'n_estimators': 1470}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:11,339]\u001b[0m Trial 76 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 216, 'max_depth': 11, 'learning_rate': 0.08151288092548081, 'n_estimators': 1647}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:12,346]\u001b[0m Trial 77 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 234, 'max_depth': 4, 'learning_rate': 0.09347831224766287, 'n_estimators': 1076}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:15,557]\u001b[0m Trial 78 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 203, 'max_depth': 14, 'learning_rate': 0.07341799421468337, 'n_estimators': 1928}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:19,611]\u001b[0m Trial 79 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 248, 'max_depth': 22, 'learning_rate': 0.05808049150697987, 'n_estimators': 1857}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:23,515]\u001b[0m Trial 80 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 222, 'max_depth': 28, 'learning_rate': 0.04821164959702125, 'n_estimators': 1565}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:27,084]\u001b[0m Trial 81 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 182, 'max_depth': 10, 'learning_rate': 0.043683604814898844, 'n_estimators': 1367}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:31,603]\u001b[0m Trial 82 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 205, 'max_depth': 8, 'learning_rate': 0.023821935926284475, 'n_estimators': 1491}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:34,970]\u001b[0m Trial 83 finished with value: 0.8952569169960475 and parameters: {'num_leaves': 162, 'max_depth': 13, 'learning_rate': 0.0676262195005602, 'n_estimators': 1438}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:36,183]\u001b[0m Trial 84 finished with value: 0.8893280632411067 and parameters: {'num_leaves': 121, 'max_depth': 3, 'learning_rate': 0.03391850499554823, 'n_estimators': 1769}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:40,489]\u001b[0m Trial 85 finished with value: 0.9011857707509882 and parameters: {'num_leaves': 193, 'max_depth': 6, 'learning_rate': 0.008088344143474514, 'n_estimators': 1703}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:41,018]\u001b[0m Trial 86 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 2, 'max_depth': 6, 'learning_rate': 0.004353416198398227, 'n_estimators': 1700}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:45,126]\u001b[0m Trial 87 finished with value: 0.8913043478260869 and parameters: {'num_leaves': 197, 'max_depth': 6, 'learning_rate': 0.018060489273660586, 'n_estimators': 1775}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:52,542]\u001b[0m Trial 88 finished with value: 0.8992094861660079 and parameters: {'num_leaves': 227, 'max_depth': 8, 'learning_rate': 0.010214539967002076, 'n_estimators': 2000}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:53,638]\u001b[0m Trial 89 finished with value: 0.8972332015810277 and parameters: {'num_leaves': 147, 'max_depth': 5, 'learning_rate': 0.052668923023433276, 'n_estimators': 638}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:13:57,007]\u001b[0m Trial 90 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 210, 'max_depth': 25, 'learning_rate': 0.0874344182144889, 'n_estimators': 1630}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:14:04,724]\u001b[0m Trial 91 finished with value: 0.9011857707509882 and parameters: {'num_leaves': 251, 'max_depth': 8, 'learning_rate': 0.00981288953929796, 'n_estimators': 1997}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:14:05,822]\u001b[0m Trial 92 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 251, 'max_depth': 2, 'learning_rate': 0.004472543623309595, 'n_estimators': 1946}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:14:07,071]\u001b[0m Trial 93 finished with value: 0.8853754940711462 and parameters: {'num_leaves': 239, 'max_depth': 3, 'learning_rate': 0.02965641550963031, 'n_estimators': 1858}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:14:12,863]\u001b[0m Trial 94 finished with value: 0.8992094861660079 and parameters: {'num_leaves': 242, 'max_depth': 7, 'learning_rate': 0.01233494617360778, 'n_estimators': 1895}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:14:19,495]\u001b[0m Trial 95 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 232, 'max_depth': 10, 'learning_rate': 0.018951310307270725, 'n_estimators': 1693}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:14:23,099]\u001b[0m Trial 96 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 251, 'max_depth': 30, 'learning_rate': 0.07750449764405203, 'n_estimators': 1805}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:14:26,026]\u001b[0m Trial 97 finished with value: 0.8675889328063241 and parameters: {'num_leaves': 190, 'max_depth': 9, 'learning_rate': 0.002238077097625175, 'n_estimators': 511}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:14:30,031]\u001b[0m Trial 98 finished with value: 0.8932806324110671 and parameters: {'num_leaves': 217, 'max_depth': 12, 'learning_rate': 0.04577357392705138, 'n_estimators': 1572}. Best is trial 10 with value: 0.9011857707509882.\u001b[0m\n",
      "\u001b[32m[I 2023-05-14 12:14:30,686]\u001b[0m Trial 99 finished with value: 0.9031620553359684 and parameters: {'num_leaves': 242, 'max_depth': 5, 'learning_rate': 0.05798877920107935, 'n_estimators': 359}. Best is trial 99 with value: 0.9031620553359684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        feature_type               model with_hypertuning   \n",
      "index   selected_features_all_best20  LogisticRegression            False  \\\n",
      "index   selected_features_all_best20                 SVC            False   \n",
      "index   selected_features_all_best20       XGBClassifier            False   \n",
      "index   selected_features_all_best20      LGBMClassifier            False   \n",
      "index   selected_features_all_best20  LogisticRegression             True   \n",
      "index   selected_features_all_best20                 SVC             True   \n",
      "index   selected_features_all_best20       XGBClassifier             True   \n",
      "index   selected_features_all_best20      LGBMClassifier             True   \n",
      "index   selected_features_all_best30  LogisticRegression            False   \n",
      "index   selected_features_all_best30                 SVC            False   \n",
      "index   selected_features_all_best30       XGBClassifier            False   \n",
      "index   selected_features_all_best30      LGBMClassifier            False   \n",
      "index   selected_features_all_best30  LogisticRegression             True   \n",
      "index   selected_features_all_best30                 SVC             True   \n",
      "index   selected_features_all_best30       XGBClassifier             True   \n",
      "index   selected_features_all_best30      LGBMClassifier             True   \n",
      "index   selected_features_all_best50  LogisticRegression            False   \n",
      "index   selected_features_all_best50                 SVC            False   \n",
      "index   selected_features_all_best50       XGBClassifier            False   \n",
      "index   selected_features_all_best50      LGBMClassifier            False   \n",
      "index   selected_features_all_best50  LogisticRegression             True   \n",
      "index   selected_features_all_best50                 SVC             True   \n",
      "index   selected_features_all_best50       XGBClassifier             True   \n",
      "index   selected_features_all_best50      LGBMClassifier             True   \n",
      "index  selected_features_all_best100  LogisticRegression            False   \n",
      "index  selected_features_all_best100                 SVC            False   \n",
      "index  selected_features_all_best100       XGBClassifier            False   \n",
      "index  selected_features_all_best100      LGBMClassifier            False   \n",
      "index  selected_features_all_best100  LogisticRegression             True   \n",
      "index  selected_features_all_best100                 SVC             True   \n",
      "index  selected_features_all_best100       XGBClassifier             True   \n",
      "index  selected_features_all_best100      LGBMClassifier             True   \n",
      "\n",
      "                                             best_params  accuracy   \n",
      "index                                               None  0.861630  \\\n",
      "index                                               None  0.884356   \n",
      "index                                               None  0.865564   \n",
      "index                                               None  0.870999   \n",
      "index  {'C': 0.05772645471274076, 'penalty': 'l1', 's...  0.863636   \n",
      "index  {'svc_c': 95.94113392322917, 'svc_gamma': 0.23...  0.833992   \n",
      "index  {'learning_rate': 0.2530441854025399, 'max_dep...  0.881423   \n",
      "index  {'num_leaves': 139, 'max_depth': 18, 'learning...  0.879447   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.892260   \n",
      "index                                               None  0.878430   \n",
      "index                                               None  0.876457   \n",
      "index  {'C': 0.0722445950942323, 'penalty': 'l2', 'so...  0.891304   \n",
      "index  {'svc_c': 91.89133569306787, 'svc_gamma': 0.03...  0.853755   \n",
      "index  {'learning_rate': 0.05933139707386613, 'max_de...  0.901186   \n",
      "index  {'num_leaves': 141, 'max_depth': 11, 'learning...  0.897233   \n",
      "index                                               None  0.901168   \n",
      "index                                               None  0.900180   \n",
      "index                                               None  0.889811   \n",
      "index                                               None  0.888807   \n",
      "index  {'C': 0.024422805336610946, 'penalty': 'l1', '...  0.889328   \n",
      "index  {'svc_c': 14.99270459807389, 'svc_gamma': 0.07...  0.873518   \n",
      "index  {'learning_rate': 0.049433721318135074, 'max_d...  0.893281   \n",
      "index  {'num_leaves': 77, 'max_depth': 41, 'learning_...  0.895257   \n",
      "index                                               None  0.901161   \n",
      "index                                               None  0.898695   \n",
      "index                                               None  0.889304   \n",
      "index                                               None  0.892762   \n",
      "index  {'C': 0.09995242748229684, 'penalty': 'l2', 's...  0.897233   \n",
      "index  {'svc_c': 64.25208237539199, 'svc_gamma': 0.06...  0.857708   \n",
      "index  {'learning_rate': 0.29754822620365323, 'max_de...  0.905138   \n",
      "index  {'num_leaves': 242, 'max_depth': 5, 'learning_...  0.903162   \n",
      "\n",
      "       sensitivity  specificity  precision        f1       mcc   \n",
      "index     0.832653     0.850575   0.839506  0.836066  0.683420  \\\n",
      "index     0.816327     0.915709   0.900901  0.856531  0.737224   \n",
      "index     0.840816     0.908046   0.895652  0.867368  0.751600   \n",
      "index     0.832653     0.919540   0.906667  0.868085  0.756464   \n",
      "index     0.857143     0.869732   0.860656  0.858896  0.726971   \n",
      "index     0.795918     0.869732   0.851528  0.822785  0.668331   \n",
      "index     0.828571     0.931034   0.918552  0.871245  0.765373   \n",
      "index     0.828571     0.927203   0.914414  0.869379  0.761132   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.840816     0.934866   0.923767  0.880342  0.780803   \n",
      "index     0.848980     0.919540   0.908297  0.877637  0.771615   \n",
      "index     0.857143     0.896552   0.886076  0.871369  0.754829   \n",
      "index     0.865306     0.915709   0.905983  0.885177  0.782835   \n",
      "index     0.820408     0.885057   0.870130  0.844538  0.707794   \n",
      "index     0.865306     0.934866   0.925764  0.894515  0.803395   \n",
      "index     0.848980     0.942529   0.932735  0.888889  0.796734   \n",
      "index     0.853061     0.915709   0.904762  0.878151  0.771307   \n",
      "index     0.828571     0.942529   0.931193  0.876890  0.778197   \n",
      "index     0.844898     0.923372   0.911894  0.877119  0.771973   \n",
      "index     0.840816     0.923372   0.911504  0.874735  0.768193   \n",
      "index     0.857143     0.919540   0.909091  0.882353  0.779246   \n",
      "index     0.804082     0.938697   0.924883  0.860262  0.751864   \n",
      "index     0.844898     0.938697   0.928251  0.884615  0.788768   \n",
      "index     0.848980     0.938697   0.928571  0.886994  0.792507   \n",
      "index     0.869388     0.923372   0.914163  0.891213  0.794850   \n",
      "index     0.853061     0.934866   0.924779  0.887473  0.792056   \n",
      "index     0.848980     0.931034   0.920354  0.883227  0.784102   \n",
      "index     0.844898     0.927203   0.915929  0.878981  0.776147   \n",
      "index     0.869388     0.923372   0.914163  0.891213  0.794850   \n",
      "index     0.746939     0.961686   0.948187  0.835616  0.729069   \n",
      "index     0.861224     0.946360   0.937778  0.897872  0.812170   \n",
      "index     0.861224     0.942529   0.933628  0.895966  0.807965   \n",
      "\n",
      "                                                   index  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index    selected_features_all_best20_SVC_no_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_no_...  \n",
      "index  selected_features_all_best20_LGBMClassifier_no...  \n",
      "index  selected_features_all_best20_LogisticRegressio...  \n",
      "index  selected_features_all_best20_SVC_with_hypertuning  \n",
      "index  selected_features_all_best20_XGBClassifier_wit...  \n",
      "index  selected_features_all_best20_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index    selected_features_all_best30_SVC_no_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_no_...  \n",
      "index  selected_features_all_best30_LGBMClassifier_no...  \n",
      "index  selected_features_all_best30_LogisticRegressio...  \n",
      "index  selected_features_all_best30_SVC_with_hypertuning  \n",
      "index  selected_features_all_best30_XGBClassifier_wit...  \n",
      "index  selected_features_all_best30_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index    selected_features_all_best50_SVC_no_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_no_...  \n",
      "index  selected_features_all_best50_LGBMClassifier_no...  \n",
      "index  selected_features_all_best50_LogisticRegressio...  \n",
      "index  selected_features_all_best50_SVC_with_hypertuning  \n",
      "index  selected_features_all_best50_XGBClassifier_wit...  \n",
      "index  selected_features_all_best50_LGBMClassifier_wi...  \n",
      "index  selected_features_all_best100_LogisticRegressi...  \n",
      "index   selected_features_all_best100_SVC_no_hypertuning  \n",
      "index  selected_features_all_best100_XGBClassifier_no...  \n",
      "index  selected_features_all_best100_LGBMClassifier_n...  \n",
      "index  selected_features_all_best100_LogisticRegressi...  \n",
      "index  selected_features_all_best100_SVC_with_hypertu...  \n",
      "index  selected_features_all_best100_XGBClassifier_wi...  \n",
      "index  selected_features_all_best100_LGBMClassifier_w...  \n"
     ]
    }
   ],
   "source": [
    "# empty dataframe to store results with the columns feature_type, model, with_hypertuning, accuracy, sensitivity, specificity, precision, f1, mcc\n",
    "results = pd.DataFrame(columns=['feature_type', 'model', 'with_hypertuning', 'best_params', 'accuracy', 'sensitivity', 'specificity', 'precision', 'f1', 'mcc', 'index'])\n",
    "feature_types = ['selected_features_all_best20', 'selected_features_all_best30', 'selected_features_all_best50', 'selected_features_all_best100']\n",
    "for feature_type in feature_types:\n",
    "\n",
    "    # Load the training dataset\n",
    "    data = pd.read_csv(f'{feature_engineered_data_dir}/TR_{feature_type}.csv')\n",
    "\n",
    "    # Separate features and target\n",
    "    X = data.drop(columns=['label', 'id'], axis=1)\n",
    "    y = data['label']\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Evaluate models without hyperparameters tuning\n",
    "    for name, model in models.items():\n",
    "        print(f\"Evaluating {feature_type} {name}\")\n",
    "        results = evaluate_model(name, model, X_train, y_train, X_test, y_test, results, feature_type)\n",
    "        print(results)\n",
    "\n",
    "    # Optimize hyperparameters\n",
    "    for name, model in models_.items():\n",
    "        objective = objectives.get(name)\n",
    "        if objective is not None:\n",
    "            print(f\"Optimizing {feature_type} {name}\")\n",
    "            results = optimize_hyperparameters(name, model, objective, trials=100, results_dataframe=results, feature_type=feature_type, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)\n",
    "            print(results)\n",
    "\n",
    "results.to_csv(f'{feature_engineered_data_dir}/results_20&30&50&100.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model with Full Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Type: AAC done!\n",
      "Feature Type: APAAC done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Type: CTD done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Type: DPC done!\n",
      "Feature Type: PAAC done!\n",
      "Feature Type: selected_features_all_best20 done!\n",
      "Feature Type: selected_features_all_best30 done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Type: selected_features_all_best50 done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/darshana/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Type: selected_features_all_best100 done!\n"
     ]
    }
   ],
   "source": [
    "# Load the results\n",
    "results_without_selected_features = pd.read_csv('results_v2.csv')\n",
    "results_with_selected_features = pd.read_csv(f'{feature_engineered_data_dir}/results_20&30&50&100.csv')\n",
    "\n",
    "feature_types = ['AAC', 'APAAC', 'CTD', 'DPC', 'PAAC']\n",
    "selected_feature_types = ['selected_features_all_best20', 'selected_features_all_best30', 'selected_features_all_best50', 'selected_features_all_best100']\n",
    "\n",
    "# Combine the feature types\n",
    "feature_types.extend(selected_feature_types)\n",
    "\n",
    "test_results = []\n",
    "\n",
    "# iterate through each row of results\n",
    "for feature_type in feature_types:\n",
    "\n",
    "    # Check if the feature type is selected features\n",
    "    if 'selected_features' in feature_type:\n",
    "        # Load the training dataset\n",
    "        train_data = pd.read_csv(f'{feature_engineered_data_dir}/TR_{feature_type}.csv')\n",
    "        test_data = pd.read_csv(f'{feature_engineered_data_dir}/TS_{feature_type}.csv')\n",
    "        results = results_with_selected_features\n",
    "    else:\n",
    "        # Load the training dataset\n",
    "        train_data = pd.read_csv(f'{data_dir}/TR_{feature_type}.csv')\n",
    "        test_data = pd.read_csv(f'{data_dir}/TS_{feature_type}.csv')\n",
    "        results = results_without_selected_features\n",
    "\n",
    "    # Separate features and target\n",
    "    X_train = train_data.drop(columns=['label', 'id'], axis=1)\n",
    "    y_train = train_data['label']\n",
    "\n",
    "    X_test = test_data.drop(columns=['label', 'id'], axis=1)\n",
    "    y_test = test_data['label']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # iterate through each model\n",
    "    for name, model in models.items():\n",
    "        # get the row of the model\n",
    "\n",
    "        \n",
    "        rows = results[(results['feature_type'] == feature_type) & (results['model'] == name)]\n",
    "\n",
    "        # iterate through each row\n",
    "        for index, row in rows.iterrows():\n",
    "\n",
    "            # check whether the model has hyperparameters\n",
    "            if row['with_hypertuning'] == True:\n",
    "                hyperparameters = ast.literal_eval(row['best_params'])\n",
    "                # check the model is SVC\n",
    "                if row['model'] == 'SVC':\n",
    "                    hyperparameters = {k[4:]: v for k, v in hyperparameters.items()}\n",
    "                    # make key 'c' to 'C'\n",
    "                    hyperparameters['C'] = hyperparameters.pop('c')\n",
    "                # set best hyperparameters\n",
    "                model.set_params(**hyperparameters)\n",
    "\n",
    "            # fit model\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # predict\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # evaluate using accuracy, sensitivity, specificity, precision, f1, mcc\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            sensitivity = recall_score(y_test, y_pred)\n",
    "            specificity = recall_score(y_test, y_pred, pos_label=0)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "            # append to test_results\n",
    "            test_results.append({'feature_type': feature_type, 'model': name, 'with_hypertuning': row['with_hypertuning'], 'best_params': row['best_params'], 'accuracy': accuracy, 'sensitivity': sensitivity, 'specificity': specificity, 'precision': precision, 'f1': f1, 'mcc': mcc, 'index': row['index']})\n",
    "    print(f'Feature Type: {feature_type} done!')\n",
    "\n",
    "test_results = pd.DataFrame(test_results)\n",
    "test_results.to_csv('test_results.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create a dictionary to store the trained models\n",
    "trained_models = {}\n",
    "\n",
    "feature_types = ['AAC', 'APAAC', 'DPC', 'PAAC']\n",
    "\n",
    "# get the results\n",
    "results = pd.read_csv('results_v2.csv')\n",
    "\n",
    "# create an empty DataFrame to store the merged dataset\n",
    "merged_train_data = pd.DataFrame()\n",
    "merged_test_data = pd.DataFrame()\n",
    "\n",
    "# iterate through the feature types\n",
    "for feature_type in feature_types:\n",
    "    # Load the training dataset\n",
    "    train_data = pd.read_csv(f'{, columns=data_dir}/TR_{feature_type}.csv')\n",
    "    test_data = pd.read_csv(f'{data_dir}/TS_{feature_type}.csv')\n",
    "    \n",
    "    # Separate features and target\n",
    "    X_train = train_data.drop(columns=['label', 'id'], axis=1)\n",
    "    y_train = train_data['label']\n",
    "\n",
    "    X_test = test_data.drop(columns=['label', 'id'], axis=1)\n",
    "    y_test = test_data['label']\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    train_data = pd.concat([train_data['id'], train_data['label'], pd.DataFrame(X_train)], axis=1)\n",
    "    test_data = pd.concat([test_data['id'], test_data['label'], pd.DataFrame(X_test)], axis=1)\n",
    "\n",
    "    # check whether the merged dataset is empty\n",
    "    if merged_train_data.empty:\n",
    "        merged_train_data = train_data\n",
    "        merged_test_data = test_data\n",
    "    else:\n",
    "        # assume 'id' is the common column\n",
    "        merged_train_data = pd.merge(merged_train_data, train_data, on=['id', 'label'])\n",
    "        merged_test_data = pd.merge(merged_test_data, test_data, on=['id', 'label'])\n",
    "\n",
    "    # Get the best model for each feature type\n",
    "    best_model = results[results['feature_type'] == feature_type].sort_values(by='accuracy', ascending=False).iloc[0]\n",
    "    model = models[best_model['model']]\n",
    "    # check whether the model has hyperparameters\n",
    "    if best_model['with_hypertuning'] == True:\n",
    "        hyperparameters = ast.literal_eval(best_model['best_params'])\n",
    "        # check the model is SVC\n",
    "        if best_model['model'] == 'SVC':\n",
    "            hyperparameters = {k[4:]: v for k, v in hyperparameters.items()}\n",
    "            # make key 'c' to 'C'\n",
    "            hyperparameters['C'] = hyperparameters.pop('c')\n",
    "        # set best hyperparameters\n",
    "        model.set_params(**hyperparameters)\n",
    "    # fit model\n",
    "    model.fit(X_train, y_train)\n",
    "    # append to trained_models \n",
    "    trained_models[feature_type] = model\n",
    "\n",
    "# Create the ensemble model\n",
    "ensemble = VotingClassifier(estimators=list(trained_models.items()), voting='hard')\n",
    "\n",
    "# Seperate features and target\n",
    "X_train = merged_train_data.drop(columns=['label', 'id'], axis=1)\n",
    "y_train = merged_train_data['label']\n",
    "\n",
    "X_test = merged_test_data.drop(columns=['label', 'id'], axis=1)\n",
    "y_test = merged_test_data['label']\n",
    "\n",
    "# fit model\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = ensemble.predict(X_test)\n",
    "\n",
    "# evaluate using accuracy, sensitivity, specificity, precision, f1, mcc\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "sensitivity = recall_score(y_test, y_pred)\n",
    "specificity = recall_score(y_test, y_pred, pos_label=0)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Ensembling with Selected Features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "druggable_proteins",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
